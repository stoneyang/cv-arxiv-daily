---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2022.09.16

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#pretrain>pretrain</a></li>
    <li><a href=#downstream>downstream</a></li>
    <li><a href=#adaptor>adaptor</a></li>
    <li><a href=#object-detection>object detection</a></li>
  </ol>
</details>

## pretrain

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2022-09-14**|**PaLI: A Jointly-Scaled Multilingual Language-Image Model**|Xi Chen et.al.|[2209.06794v1](http://arxiv.org/abs/2209.06794v1)|null|
|**2022-09-14**|**Drawing Causal Inferences About Performance Effects in NLP**|Sandra Wankm√ºller et.al.|[2209.06790v1](http://arxiv.org/abs/2209.06790v1)|null|
|**2022-09-14**|**CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Representation Alignment**|Hongwei Xue et.al.|[2209.06430v1](http://arxiv.org/abs/2209.06430v1)|**[link](https://github.com/microsoft/xpretrain)**|
|**2022-09-13**|**CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task**|Ricardo Rei et.al.|[2209.06243v1](http://arxiv.org/abs/2209.06243v1)|null|
|**2022-09-13**|**StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation**|Adyasha Maharana et.al.|[2209.06192v1](http://arxiv.org/abs/2209.06192v1)|**[link](https://github.com/adymaharana/storydalle)**|
|**2022-09-13**|**Automated classification for open-ended questions with BERT**|Hyukjun Gweon et.al.|[2209.06178v1](http://arxiv.org/abs/2209.06178v1)|null|
|**2022-09-12**|**VL-Taboo: An Analysis of Attribute-based Zero-shot Capabilities of Vision-Language Models**|Felix Vogel et.al.|[2209.06103v1](http://arxiv.org/abs/2209.06103v1)|null|
|**2022-09-13**|**SeRP: Self-Supervised Representation Learning Using Perturbed Point Clouds**|Siddhant Garg et.al.|[2209.06067v1](http://arxiv.org/abs/2209.06067v1)|null|
|**2022-09-13**|**Neural3Points: Learning to Generate Physically Realistic Full-body Motion for Virtual Reality Users**|Yongjing Ye et.al.|[2209.05753v1](http://arxiv.org/abs/2209.05753v1)|null|
|**2022-09-12**|**Polycrystal Graph Neural Network**|Minyi Dai et.al.|[2209.05583v1](http://arxiv.org/abs/2209.05583v1)|**[link](https://github.com/mdai26/pgnn)**|
|**2022-09-12**|**A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language**|Bing Su et.al.|[2209.05481v1](http://arxiv.org/abs/2209.05481v1)|null|
|**2022-09-11**|**Learning When to Say "I Don't Know"**|Nicholas Kashani Motlagh et.al.|[2209.04944v1](http://arxiv.org/abs/2209.04944v1)|**[link](https://github.com/osu-cvl/learning-idk)**|
|**2022-09-11**|**Learning to diagnose common thorax diseases on chest radiographs from radiology reports in Vietnamese**|Thao T. B. Nguyen et.al.|[2209.04794v1](http://arxiv.org/abs/2209.04794v1)|null|
|**2022-09-10**|**Simple and Effective Gradient-Based Tuning of Sequence-to-Sequence Models**|Jared Lichtarge et.al.|[2209.04683v1](http://arxiv.org/abs/2209.04683v1)|null|

<p align=right>(<a href=#Updated-on-20220916>back to top</a>)</p>

## downstream

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2022-09-14**|**Efficient multi-relational network representation using primes**|Konstantinos Bougiatiotis et.al.|[2209.06575v1](http://arxiv.org/abs/2209.06575v1)|null|
|**2022-09-15**|**Learning to Evaluate Performance of Multi-modal Semantic Localization**|Zhiqiang Yuan et.al.|[2209.06515v2](http://arxiv.org/abs/2209.06515v2)|**[link](https://github.com/xiaoyuan1996/semanticlocalizationmetrics)**|
|**2022-09-14**|**Jointly Contrastive Representation Learning on Road Network and Trajectory**|Zhenyu Mao et.al.|[2209.06389v1](http://arxiv.org/abs/2209.06389v1)|**[link](https://github.com/mzy94/jclrnt)**|
|**2022-09-13**|**CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task**|Ricardo Rei et.al.|[2209.06243v1](http://arxiv.org/abs/2209.06243v1)|null|
|**2022-09-13**|**Space-Efficient Random Walks on Streaming Graphs**|Serafeim Papadias et.al.|[2209.06063v1](http://arxiv.org/abs/2209.06063v1)|**[link](https://github.com/spapadias/wharf)**|
|**2022-09-13**|**Streaming End-to-End Multilingual Speech Recognition with Joint Language Identification**|Chao Zhang et.al.|[2209.06058v1](http://arxiv.org/abs/2209.06058v1)|null|
|**2022-09-13**|**Don't Judge a Language Model by Its Last Layer: Contrastive Learning with Layer-Wise Attention Pooling**|Dongsuk Oh et.al.|[2209.05972v1](http://arxiv.org/abs/2209.05972v1)|**[link](https://github.com/nlpods/layerattpooler)**|
|**2022-09-12**|**Manifold Rewiring for Unlabeled Imaging**|Valentin Debarnot et.al.|[2209.05168v1](http://arxiv.org/abs/2209.05168v1)|null|
|**2022-09-14**|**Knowledge Base Question Answering: A Semantic Parsing Perspective**|Yu Gu et.al.|[2209.04994v2](http://arxiv.org/abs/2209.04994v2)|null|
|**2022-09-11**|**Inverse Image Frequency for Long-tailed Image Recognition**|Konstantinos Panagiotis Alexandridis et.al.|[2209.04861v1](http://arxiv.org/abs/2209.04861v1)|**[link](https://github.com/kostas1515/iif)**|

<p align=right>(<a href=#Updated-on-20220916>back to top</a>)</p>

## adaptor

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2022-08-17**|**Learning with Local Gradients at the Edge**|Michael Lomnitz et.al.|[2208.08503v1](http://arxiv.org/abs/2208.08503v1)|null|
|**2022-08-15**|**MM-GNN: Mix-Moment Graph Neural Network towards Modeling Neighborhood Feature Distribution**|Wendong Bi et.al.|[2208.07012v1](http://arxiv.org/abs/2208.07012v1)|null|
|**2022-06-18**|**Camera Adaptation for Fundus-Image-Based CVD Risk Estimation**|Zhihong Lin et.al.|[2206.09202v1](http://arxiv.org/abs/2206.09202v1)|**[link](https://github.com/linzhlalala/cvd-risk-based-on-retinal-fundus-images)**|
|**2022-06-13**|**Towards Universal Sequence Representation Learning for Recommender Systems**|Yupeng Hou et.al.|[2206.05941v1](http://arxiv.org/abs/2206.05941v1)|**[link](https://github.com/rucaibox/unisrec)**|
|**2022-05-25**|**Domain Adaptation for Object Detection using SE Adaptors and Center Loss**|Sushruth Nagesh et.al.|[2205.12923v1](http://arxiv.org/abs/2205.12923v1)|**[link](https://github.com/shreyasrajesh/DA-Object-Detection)**|
|**2022-05-22**|**All Birds with One Stone: Multi-task Text Classification for Efficient Inference with One Forward Pass**|Jiaxin Huang et.al.|[2205.10744v1](http://arxiv.org/abs/2205.10744v1)|null|
|**2022-05-15**|**GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech Synthesis**|Rongjie Huang et.al.|[2205.07211v1](http://arxiv.org/abs/2205.07211v1)|null|
|**2022-04-21**|**Primary accelerometer calibration with two-axis automatic positioning stage**|Wataru Kokuyama et.al.|[2204.09212v2](http://arxiv.org/abs/2204.09212v2)|null|
|**2022-04-01**|**Universal Adaptor: Converting Mel-Spectrograms Between Different Configurations for Speech Synthesis**|Fan-Lin Wang et.al.|[2204.00170v1](http://arxiv.org/abs/2204.00170v1)|**[link](https://github.com/BogiHsu/Universal-Adaptor)**|
|**2022-06-20**|**Style-Guided Domain Adaptation for Face Presentation Attack Detection**|Young-Eun Kim et.al.|[2203.14565v2](http://arxiv.org/abs/2203.14565v2)|null|

<p align=right>(<a href=#Updated-on-20220916>back to top</a>)</p>

## object detection

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2022-09-14**|**Evaluating a GAN for enhancing camera simulation for robotics**|Asher Elmquist et.al.|[2209.06710v1](http://arxiv.org/abs/2209.06710v1)|null|
|**2022-09-13**|**CMR3D: Contextualized Multi-Stage Refinement for 3D Object Detection**|Dhanalaxmi Gaddam et.al.|[2209.06641v1](http://arxiv.org/abs/2209.06641v1)|null|
|**2022-09-12**|**One-Shot Doc Snippet Detection: Powering Search in Document Beyond Text**|Abhinav Java et.al.|[2209.06584v1](http://arxiv.org/abs/2209.06584v1)|null|
|**2022-09-14**|**CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer**|Youngseok Kim et.al.|[2209.06535v1](http://arxiv.org/abs/2209.06535v1)|null|
|**2022-09-14**|**Viewer-Centred Surface Completion for Unsupervised Domain Adaptation in 3D Object Detection**|Darren Tsai et.al.|[2209.06407v1](http://arxiv.org/abs/2209.06407v1)|**[link](https://github.com/darrenjkt/SEE-VCN)**|
|**2022-09-14**|**A Survey on Evolutionary Computation for Computer Vision and Image Analysis: Past, Present, and Future Trends**|Ying Bi et.al.|[2209.06399v1](http://arxiv.org/abs/2209.06399v1)|null|
|**2022-09-13**|**Computer vision based vehicle tracking as a complementary and scalable approach to RFID tagging**|Pranav Kant Gaur et.al.|[2209.05911v1](http://arxiv.org/abs/2209.05911v1)|null|
|**2022-09-13**|**PSAQ-ViT V2: Towards Accurate and General Data-Free Quantization for Vision Transformers**|Zhikai Li et.al.|[2209.05687v1](http://arxiv.org/abs/2209.05687v1)|**[link](https://github.com/zkkli/psaq-vit)**|
|**2022-09-13**|**ComplETR: Reducing the cost of annotations for object detection in dense scenes with vision transformers**|Achin Jain et.al.|[2209.05654v1](http://arxiv.org/abs/2209.05654v1)|null|
|**2022-09-12**|**CenterFormer: Center-based Transformer for 3D Object Detection**|Zixiang Zhou et.al.|[2209.05588v1](http://arxiv.org/abs/2209.05588v1)|**[link](https://github.com/tusimple/centerformer)**|

<p align=right>(<a href=#Updated-on-20220916>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/stoneyang/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/stoneyang/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/stoneyang/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/stoneyang/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/stoneyang/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/stoneyang/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/stoneyang/cv-arxiv-daily/issues

