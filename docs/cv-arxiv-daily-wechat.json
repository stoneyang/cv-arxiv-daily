{"pretrain": {"2209.06192": "- 2022-09-13, **StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation**, Adyasha Maharana et.al., Paper: [http://arxiv.org/abs/2209.06192v1](http://arxiv.org/abs/2209.06192v1), Code: **[https://github.com/adymaharana/storydalle](https://github.com/adymaharana/storydalle)**\n", "2209.06178": "- 2022-09-13, **Automated classification for open-ended questions with BERT**, Hyukjun Gweon et.al., Paper: [http://arxiv.org/abs/2209.06178v1](http://arxiv.org/abs/2209.06178v1)\n", "2209.06067": "- 2022-09-13, **SeRP: Self-Supervised Representation Learning Using Perturbed Point Clouds**, Siddhant Garg et.al., Paper: [http://arxiv.org/abs/2209.06067v1](http://arxiv.org/abs/2209.06067v1)\n", "2209.05753": "- 2022-09-13, **Neural3Points: Learning to Generate Physically Realistic Full-body Motion for Virtual Reality Users**, Yongjing Ye et.al., Paper: [http://arxiv.org/abs/2209.05753v1](http://arxiv.org/abs/2209.05753v1)\n", "2209.05583": "- 2022-09-12, **Polycrystal Graph Neural Network**, Minyi Dai et.al., Paper: [http://arxiv.org/abs/2209.05583v1](http://arxiv.org/abs/2209.05583v1), Code: **[https://github.com/mdai26/pgnn](https://github.com/mdai26/pgnn)**\n", "2209.06103": "- 2022-09-12, **VL-Taboo: An Analysis of Attribute-based Zero-shot Capabilities of Vision-Language Models**, Felix Vogel et.al., Paper: [http://arxiv.org/abs/2209.06103v1](http://arxiv.org/abs/2209.06103v1)\n", "2209.05481": "- 2022-09-12, **A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language**, Bing Su et.al., Paper: [http://arxiv.org/abs/2209.05481v1](http://arxiv.org/abs/2209.05481v1)\n", "2209.04944": "- 2022-09-11, **Learning When to Say \"I Don't Know\"**, Nicholas Kashani Motlagh et.al., Paper: [http://arxiv.org/abs/2209.04944v1](http://arxiv.org/abs/2209.04944v1), Code: **[https://github.com/osu-cvl/learning-idk](https://github.com/osu-cvl/learning-idk)**\n", "2209.04794": "- 2022-09-11, **Learning to diagnose common thorax diseases on chest radiographs from radiology reports in Vietnamese**, Thao T. B. Nguyen et.al., Paper: [http://arxiv.org/abs/2209.04794v1](http://arxiv.org/abs/2209.04794v1)\n", "2209.04683": "- 2022-09-10, **Simple and Effective Gradient-Based Tuning of Sequence-to-Sequence Models**, Jared Lichtarge et.al., Paper: [http://arxiv.org/abs/2209.04683v1](http://arxiv.org/abs/2209.04683v1)\n", "2209.06794": "- 2022-09-16, **PaLI: A Jointly-Scaled Multilingual Language-Image Model**, Xi Chen et.al., Paper: [http://arxiv.org/abs/2209.06794v2](http://arxiv.org/abs/2209.06794v2)\n", "2209.06790": "- 2022-09-14, **Drawing Causal Inferences About Performance Effects in NLP**, Sandra Wankm\u00fcller et.al., Paper: [http://arxiv.org/abs/2209.06790v1](http://arxiv.org/abs/2209.06790v1)\n", "2209.06430": "- 2022-09-14, **CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Representation Alignment**, Hongwei Xue et.al., Paper: [http://arxiv.org/abs/2209.06430v1](http://arxiv.org/abs/2209.06430v1), Code: **[https://github.com/microsoft/xpretrain](https://github.com/microsoft/xpretrain)**\n", "2209.06243": "- 2022-09-13, **CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task**, Ricardo Rei et.al., Paper: [http://arxiv.org/abs/2209.06243v1](http://arxiv.org/abs/2209.06243v1)\n", "2209.07526": "- 2022-09-15, **OmniVL:One Foundation Model for Image-Language and Video-Language Tasks**, Junke Wang et.al., Paper: [http://arxiv.org/abs/2209.07526v1](http://arxiv.org/abs/2209.07526v1)\n", "2209.07431": "- 2022-09-19, **Compositional generalization through abstract representations in human and artificial neural networks**, Takuya Ito et.al., Paper: [http://arxiv.org/abs/2209.07431v2](http://arxiv.org/abs/2209.07431v2)\n", "2209.07278": "- 2022-09-15, **\u00daFAL CorPipe at CRAC 2022: Effectivity of Multilingual Models for Coreference Resolution**, Milan Straka et.al., Paper: [http://arxiv.org/abs/2209.07278v1](http://arxiv.org/abs/2209.07278v1), Code: **[https://github.com/ufal/crac2022-corpipe](https://github.com/ufal/crac2022-corpipe)**\n", "2209.07068": "- 2022-09-15, **uChecker: Masked Pretrained Language Models as Unsupervised Chinese Spelling Checkers**, Piji Li et.al., Paper: [http://arxiv.org/abs/2209.07068v1](http://arxiv.org/abs/2209.07068v1)\n", "2209.07000": "- 2022-09-15, **VIPHY: Probing \"Visible\" Physical Commonsense Knowledge**, Shikhar Singh et.al., Paper: [http://arxiv.org/abs/2209.07000v1](http://arxiv.org/abs/2209.07000v1), Code: **[https://github.com/axe--/viphy](https://github.com/axe--/viphy)**\n", "2209.06987": "- 2022-09-15, **Non-Parallel Voice Conversion for ASR Augmentation**, Gary Wang et.al., Paper: [http://arxiv.org/abs/2209.06987v1](http://arxiv.org/abs/2209.06987v1)\n", "2209.06971": "- 2022-09-14, **PointACL:Adversarial Contrastive Learning for Robust Point Clouds Representation under Adversarial Attack**, Junxuan Huang et.al., Paper: [http://arxiv.org/abs/2209.06971v1](http://arxiv.org/abs/2209.06971v1)\n", "2209.06954": "- 2022-09-14, **Finetuning Pretrained Vision-Language Models with Correlation Information Bottleneck for Robust Visual Question Answering**, Jingjing Jiang et.al., Paper: [http://arxiv.org/abs/2209.06954v1](http://arxiv.org/abs/2209.06954v1)\n", "2209.07932": "- 2022-09-16, **Fine-tuning or top-tuning? Transfer learning with pretrained features and fast kernel methods**, Paolo Didier Alfano et.al., Paper: [http://arxiv.org/abs/2209.07932v1](http://arxiv.org/abs/2209.07932v1)\n", "2209.07919": "- 2022-09-16, **iDF-SLAM: End-to-End RGB-D SLAM with Neural Implicit Mapping and Deep Feature Tracking**, Yuhang Ming et.al., Paper: [http://arxiv.org/abs/2209.07919v1](http://arxiv.org/abs/2209.07919v1)\n", "2209.07760": "- 2022-09-16, **Possible Stories: Evaluating Situated Commonsense Reasoning under Multiple Possible Scenarios**, Mana Ashida et.al., Paper: [http://arxiv.org/abs/2209.07760v1](http://arxiv.org/abs/2209.07760v1)\n", "2209.07683": "- 2022-09-16, **SQ-Swin: a Pretrained Siamese Quadratic Swin Transformer for Lettuce Browning Prediction**, Dayang Wang et.al., Paper: [http://arxiv.org/abs/2209.07683v1](http://arxiv.org/abs/2209.07683v1)\n", "2209.08956": "- 2022-09-19, **Panoramic Vision Transformer for Saliency Detection in 360\u00b0 Videos**, Heeseung Yun et.al., Paper: [http://arxiv.org/abs/2209.08956v1](http://arxiv.org/abs/2209.08956v1)\n", "2209.08953": "- 2022-09-19, **Effective Adaptation in Multi-Task Co-Training for Unified Autonomous Driving**, Xiwen Liang et.al., Paper: [http://arxiv.org/abs/2209.08953v1](http://arxiv.org/abs/2209.08953v1)\n", "2209.08930": "- 2022-09-19, **HiMFR: A Hybrid Masked Face Recognition Through Face Inpainting**, Md Imran Hosen et.al., Paper: [http://arxiv.org/abs/2209.08930v1](http://arxiv.org/abs/2209.08930v1), Code: **[https://github.com/mdhosen/himfr](https://github.com/mdhosen/himfr)**\n", "2209.08814": "- 2022-09-19, **T2V-DDPM: Thermal to Visible Face Translation using Denoising Diffusion Probabilistic Models**, Nithin Gopalakrishnan Nair et.al., Paper: [http://arxiv.org/abs/2209.08814v1](http://arxiv.org/abs/2209.08814v1)\n", "2209.08759": "- 2022-09-19, **Tree-based Text-Vision BERT for Video Search in Baidu Video Advertising**, Tan Yu et.al., Paper: [http://arxiv.org/abs/2209.08759v1](http://arxiv.org/abs/2209.08759v1)\n", "2209.08754": "- 2022-09-19, **Toward Understanding Privileged Features Distillation in Learning-to-Rank**, Shuo Yang et.al., Paper: [http://arxiv.org/abs/2209.08754v1](http://arxiv.org/abs/2209.08754v1)\n", "2209.08527": "- 2022-09-18, **Adaptive Dimension Reduction and Variational Inference for Transductive Few-Shot Classification**, Yuqing Hu et.al., Paper: [http://arxiv.org/abs/2209.08527v1](http://arxiv.org/abs/2209.08527v1)\n", "2209.08452": "- 2022-09-18, **MetaDIP: Accelerating Deep Image Prior with Meta Learning**, Kevin Zhang et.al., Paper: [http://arxiv.org/abs/2209.08452v1](http://arxiv.org/abs/2209.08452v1)\n", "2209.08351": "- 2022-09-17, **Sample-Efficient Multi-Agent Reinforcement Learning with Demonstrations for Flocking Control**, Yunbo Qiu et.al., Paper: [http://arxiv.org/abs/2209.08351v1](http://arxiv.org/abs/2209.08351v1)\n", "2209.08212": "- 2022-09-17, **Compose & Embellish: Well-Structured Piano Performance Generation via A Two-Stage Approach**, Shih-Lun Wu et.al., Paper: [http://arxiv.org/abs/2209.08212v1](http://arxiv.org/abs/2209.08212v1)\n", "2209.09870": "- 2022-09-20, **Physical Logic Enhanced Network for Small-Sample Bi-Layer Metallic Tubes Bending Springback Prediction**, Chang Sun et.al., Paper: [http://arxiv.org/abs/2209.09870v1](http://arxiv.org/abs/2209.09870v1)\n", "2209.09760": "- 2022-09-20, **Dynamic Graph Message Passing Networks for Visual Recognition**, Li Zhang et.al., Paper: [http://arxiv.org/abs/2209.09760v1](http://arxiv.org/abs/2209.09760v1), Code: **[https://github.com/fudan-zvg/dgmn2](https://github.com/fudan-zvg/dgmn2)**\n", "2209.09714": "- 2022-09-20, **Cardiac Segmentation using Transfer Learning under Respiratory Motion Artifacts**, Carles Garcia-Cabrera et.al., Paper: [http://arxiv.org/abs/2209.09714v1](http://arxiv.org/abs/2209.09714v1)\n", "2209.09489": "- 2022-09-22, **Perceptual Quality Assessment for Digital Human Heads**, Zicheng Zhang et.al., Paper: [http://arxiv.org/abs/2209.09489v2](http://arxiv.org/abs/2209.09489v2)\n", "2209.09485": "- 2022-09-20, **Generalizing through Forgetting -- Domain Generalization for Symptom Event Extraction in Clinical Notes**, Sitong Zhou et.al., Paper: [http://arxiv.org/abs/2209.09485v1](http://arxiv.org/abs/2209.09485v1)\n", "2209.10106": "- 2022-09-21, **Extreme Multi-Domain, Multi-Task Learning With Unified Text-to-Text Transfer Transformers**, Adebayo Oshingbesan et.al., Paper: [http://arxiv.org/abs/2209.10106v1](http://arxiv.org/abs/2209.10106v1), Code: **[https://github.com/dehbaiyor/idlfall2021project](https://github.com/dehbaiyor/idlfall2021project)**\n", "2209.10052": "- 2022-09-21, **Adapting Pretrained Text-to-Text Models for Long Text Sequences**, Wenhan Xiong et.al., Paper: [http://arxiv.org/abs/2209.10052v1](http://arxiv.org/abs/2209.10052v1)\n", "2209.11133": "- 2022-09-23, **PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training**, Rogerio Bonatti et.al., Paper: [http://arxiv.org/abs/2209.11133v2](http://arxiv.org/abs/2209.11133v2)\n", "2209.11055": "- 2022-09-22, **Efficient Few-Shot Learning Without Prompts**, Lewis Tunstall et.al., Paper: [http://arxiv.org/abs/2209.11055v1](http://arxiv.org/abs/2209.11055v1), Code: **[https://github.com/huggingface/setfit](https://github.com/huggingface/setfit)**\n", "2209.11035": "- 2022-09-22, **MonoByte: A Pool of Monolingual Byte-level Language Models**, Hugo Abonizio et.al., Paper: [http://arxiv.org/abs/2209.11035v1](http://arxiv.org/abs/2209.11035v1), Code: **[https://github.com/lersouza/lang-agnostic](https://github.com/lersouza/lang-agnostic)**\n", "2209.10901": "- 2022-09-22, **Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement Learning**, Manuel Goul\u00e3o et.al., Paper: [http://arxiv.org/abs/2209.10901v1](http://arxiv.org/abs/2209.10901v1), Code: **[https://github.com/mgoulao/tov-vicreg](https://github.com/mgoulao/tov-vicreg)**\n", "2209.10848": "- 2022-09-22, **MnTTS: An Open-Source Mongolian Text-to-Speech Synthesis Dataset and Accompanied Baseline**, Yifan Hu et.al., Paper: [http://arxiv.org/abs/2209.10848v1](http://arxiv.org/abs/2209.10848v1), Code: **[https://github.com/walker-hyf/mntts](https://github.com/walker-hyf/mntts)**\n", "2209.10754": "- 2022-09-22, **INFINITY: A Simple Yet Effective Unsupervised Framework for Graph-Text Mutual Conversion**, Yi Xu et.al., Paper: [http://arxiv.org/abs/2209.10754v1](http://arxiv.org/abs/2209.10754v1)\n", "2209.11488": "- 2022-09-23, **GIDP: Learning a Good Initialization and Inducing Descriptor Post-enhancing for Large-scale Place Recognition**, Zhaoxin Fan et.al., Paper: [http://arxiv.org/abs/2209.11488v1](http://arxiv.org/abs/2209.11488v1)\n", "2209.11475": "- 2022-09-23, **Unsupervised Hashing with Semantic Concept Mining**, Rong-Cheng Tu et.al., Paper: [http://arxiv.org/abs/2209.11475v1](http://arxiv.org/abs/2209.11475v1), Code: **[https://github.com/rongchengtu1/uhscm](https://github.com/rongchengtu1/uhscm)**\n", "2209.11252": "- 2022-09-22, **XF2T: Cross-lingual Fact-to-Text Generation for Low-Resource Languages**, Shivprasad Sagare et.al., Paper: [http://arxiv.org/abs/2209.11252v1](http://arxiv.org/abs/2209.11252v1)\n", "2209.12711": "- 2022-09-26, **Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts**, Joel Jang et.al., Paper: [http://arxiv.org/abs/2209.12711v1](http://arxiv.org/abs/2209.12711v1), Code: **[https://github.com/joeljang/negated-prompts-for-llms](https://github.com/joeljang/negated-prompts-for-llms)**\n", "2209.12602": "- 2022-09-26, **Effects of language mismatch in automatic forensic voice comparison using deep learning embeddings**, D\u00e1vid Sztah\u00f3 et.al., Paper: [http://arxiv.org/abs/2209.12602v1](http://arxiv.org/abs/2209.12602v1)\n", "2209.12412": "- 2022-09-26, **DEFT: Diverse Ensembles for Fast Transfer in Reinforcement Learning**, Simeon Adebola et.al., Paper: [http://arxiv.org/abs/2209.12412v1](http://arxiv.org/abs/2209.12412v1)\n", "2209.12157": "- 2022-09-25, **Dive into Self-Supervised Learning for Medical Image Analysis: Data, Models and Tasks**, Chuyan Zhang et.al., Paper: [http://arxiv.org/abs/2209.12157v1](http://arxiv.org/abs/2209.12157v1), Code: **[https://github.com/chuyan99/medical-ssl](https://github.com/chuyan99/medical-ssl)**\n", "2209.12050": "- 2022-09-24, **Controllable Face Manipulation and UV Map Generation by Self-supervised Learning**, Yuanming Li et.al., Paper: [http://arxiv.org/abs/2209.12050v1](http://arxiv.org/abs/2209.12050v1)\n", "2209.12031": "- 2022-09-24, **Pseudo-CTs from T1-weighted MRI for planning of low-intensity transcranial focused ultrasound neuromodulation: an open-source tool**, Siti Nurbaya Yaakub et.al., Paper: [http://arxiv.org/abs/2209.12031v1](http://arxiv.org/abs/2209.12031v1), Code: **[https://github.com/sitiny/bric_tus_simulation_tools](https://github.com/sitiny/bric_tus_simulation_tools)**\n", "2209.11910": "- 2022-09-24, **A Focused Study on Sequence Length for Dialogue Summarization**, Bin Wang et.al., Paper: [http://arxiv.org/abs/2209.11910v1](http://arxiv.org/abs/2209.11910v1)\n", "2209.11830": "- 2022-09-23, **Multiple-Choice Question Generation: Towards an Automated Assessment Framework**, Vatsal Raina et.al., Paper: [http://arxiv.org/abs/2209.11830v1](http://arxiv.org/abs/2209.11830v1)\n", "2209.13558": "- 2022-09-27, **FreeSeg: Free Mask from Interpretable Contrastive Language-Image Pretraining for Semantic Segmentation**, Yi Li et.al., Paper: [http://arxiv.org/abs/2209.13558v1](http://arxiv.org/abs/2209.13558v1), Code: **[https://github.com/xmed-lab/freeseg](https://github.com/xmed-lab/freeseg)**\n", "2209.13375": "- 2022-09-27, **StyleMask: Disentangling the Style Space of StyleGAN2 for Neural Face Reenactment**, Stella Bounareli et.al., Paper: [http://arxiv.org/abs/2209.13375v1](http://arxiv.org/abs/2209.13375v1), Code: **[https://github.com/stelabou/stylemask](https://github.com/stelabou/stylemask)**\n", "2209.13360": "- 2022-09-28, **Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion**, Nisha Huang et.al., Paper: [http://arxiv.org/abs/2209.13360v2](http://arxiv.org/abs/2209.13360v2), Code: **[https://github.com/haha-lisa/mgad-multimodal-guided-artwork-diffusion](https://github.com/haha-lisa/mgad-multimodal-guided-artwork-diffusion)**\n", "2209.13492": "- 2022-09-26, **Taking a Respite from Representation Learning for Molecular Property Prediction**, Jianyuan Deng et.al., Paper: [http://arxiv.org/abs/2209.13492v1](http://arxiv.org/abs/2209.13492v1)\n", "2209.14272": "- 2022-09-28, **Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results**, Lukas Christ et.al., Paper: [http://arxiv.org/abs/2209.14272v1](http://arxiv.org/abs/2209.14272v1), Code: **[https://github.com/eihw/passau-sfch](https://github.com/eihw/passau-sfch)**\n", "2209.14150": "- 2022-09-28, **Speech Enhancement Using Self-Supervised Pre-Trained Model and Vector Quantization**, Xiao-Ying Zhao et.al., Paper: [http://arxiv.org/abs/2209.14150v1](http://arxiv.org/abs/2209.14150v1)\n", "2209.13983": "- 2022-09-28, **Medical Image Captioning via Generative Pretrained Transformers**, Alexander Selivanov et.al., Paper: [http://arxiv.org/abs/2209.13983v1](http://arxiv.org/abs/2209.13983v1)\n", "2209.13674": "- 2022-09-27, **Mixed-domain Training Improves Multi-Mission Terrain Segmentation**, Grace Vincent et.al., Paper: [http://arxiv.org/abs/2209.13674v1](http://arxiv.org/abs/2209.13674v1)\n", "2209.13654": "- 2022-09-27, **Embarrassingly Easy Document-Level MT Metrics: How to Convert Any Pretrained Metric Into a Document-Level Metric**, Giorgos Vernikos et.al., Paper: [http://arxiv.org/abs/2209.13654v1](http://arxiv.org/abs/2209.13654v1)\n", "2209.14988": "- 2022-09-29, **DreamFusion: Text-to-3D using 2D Diffusion**, Ben Poole et.al., Paper: [http://arxiv.org/abs/2209.14988v1](http://arxiv.org/abs/2209.14988v1)\n", "2209.14926": "- 2022-09-29, **Domain-Unified Prompt Representations for Source-Free Domain Generalization**, Hongjing Niu et.al., Paper: [http://arxiv.org/abs/2209.14926v1](http://arxiv.org/abs/2209.14926v1)\n", "2209.14842": "- 2022-09-29, **Classification of Vocal Bursts for ACII 2022 A-VB-Type Competition using Convolutional Network Networks and Deep Acoustic Embeddings**, Muhammad Shehram Shah Syed et.al., Paper: [http://arxiv.org/abs/2209.14842v1](http://arxiv.org/abs/2209.14842v1)\n", "2209.14644": "- 2022-09-29, **Increasing Model Generalizability for Unsupervised Domain Adaptation**, Mohammad Rostami et.al., Paper: [http://arxiv.org/abs/2209.14644v1](http://arxiv.org/abs/2209.14644v1)\n", "2209.14498": "- 2022-09-29, **Teaching Where to Look: Attention Similarity Knowledge Distillation for Low Resolution Face Recognition**, Sungho Shin et.al., Paper: [http://arxiv.org/abs/2209.14498v1](http://arxiv.org/abs/2209.14498v1), Code: **[https://github.com/gist-ailab/teaching-where-to-look](https://github.com/gist-ailab/teaching-where-to-look)**\n", "2209.14472": "- 2022-09-28, **medigan: A Python Library of Pretrained Generative Models for Enriched Data Access in Medical Imaging**, Richard Osuala et.al., Paper: [http://arxiv.org/abs/2209.14472v1](http://arxiv.org/abs/2209.14472v1), Code: **[https://github.com/richardobi/medigan](https://github.com/richardobi/medigan)**\n", "2209.14389": "- 2022-09-28, **Downstream Datasets Make Surprisingly Good Pretraining Corpora**, Kundan Krishna et.al., Paper: [http://arxiv.org/abs/2209.14389v1](http://arxiv.org/abs/2209.14389v1)\n", "2209.14969": "- 2022-09-28, **Transfer Learning with Pretrained Remote Sensing Transformers**, Anthony Fuller et.al., Paper: [http://arxiv.org/abs/2209.14969v1](http://arxiv.org/abs/2209.14969v1), Code: **[https://github.com/antofuller/satvit](https://github.com/antofuller/satvit)**\n", "2209.15639": "- 2022-09-30, **F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models**, Weicheng Kuo et.al., Paper: [http://arxiv.org/abs/2209.15639v1](http://arxiv.org/abs/2209.15639v1)\n", "2209.15517": "- 2022-09-30, **Medical Image Understanding with Pretrained Vision Language Models: A Comprehensive Study**, Ziyuan Qin et.al., Paper: [http://arxiv.org/abs/2209.15517v1](http://arxiv.org/abs/2209.15517v1)\n", "2209.15236": "- 2022-09-30, **Language-Family Adapters for Multilingual Neural Machine Translation**, Alexandra Chronopoulou et.al., Paper: [http://arxiv.org/abs/2209.15236v1](http://arxiv.org/abs/2209.15236v1)\n", "2209.15168": "- 2022-09-30, **Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification**, Muhammad ElNokrashy et.al., Paper: [http://arxiv.org/abs/2209.15168v1](http://arxiv.org/abs/2209.15168v1)\n", "2209.15162": "- 2022-09-30, **Linearly Mapping from Image to Text Space**, Jack Merullo et.al., Paper: [http://arxiv.org/abs/2209.15162v1](http://arxiv.org/abs/2209.15162v1)\n", "2209.15101": "- 2022-09-29, **Improving Molecular Pretraining with Complementary Featurizations**, Yanqiao Zhu et.al., Paper: [http://arxiv.org/abs/2209.15101v1](http://arxiv.org/abs/2209.15101v1)\n", "2210.01116": "- 2022-10-03, **That Sounds Right: Auditory Self-Supervision for Dynamic Robot Manipulation**, Abitha Thankaraj et.al., Paper: [http://arxiv.org/abs/2210.01116v1](http://arxiv.org/abs/2210.01116v1), Code: **[https://github.com/abitha-thankaraj/audio-robot-learning](https://github.com/abitha-thankaraj/audio-robot-learning)**\n", "2210.01033": "- 2022-10-03, **LPT: Long-tailed Prompt Tuning for Image Classification**, Bowen Dong et.al., Paper: [http://arxiv.org/abs/2210.01033v1](http://arxiv.org/abs/2210.01033v1)\n", "2210.00939": "- 2022-10-04, **Improving Sample Quality of Diffusion Models Using Self-Attention Guidance**, Susung Hong et.al., Paper: [http://arxiv.org/abs/2210.00939v2](http://arxiv.org/abs/2210.00939v2)\n", "2210.00843": "- 2022-10-03, **A Strong Transfer Baseline for RGB-D Fusion in Vision Transformers**, Georgios Tziafas et.al., Paper: [http://arxiv.org/abs/2210.00843v1](http://arxiv.org/abs/2210.00843v1)\n", "2210.00667": "- 2022-10-03, **Probing of Quantitative Values in Abstractive Summarization Models**, Nathan M. White et.al., Paper: [http://arxiv.org/abs/2210.00667v1](http://arxiv.org/abs/2210.00667v1)\n", "2210.00662": "- 2022-10-03, **Under the Cover Infant Pose Estimation using Multimodal Data**, Daniel G. Kyrollos et.al., Paper: [http://arxiv.org/abs/2210.00662v1](http://arxiv.org/abs/2210.00662v1)\n", "2210.00407": "- 2022-10-02, **PCONet: A Convolutional Neural Network Architecture to Detect Polycystic Ovary Syndrome (PCOS) from Ovarian Ultrasound Images**, A. K. M. Salman Hosain et.al., Paper: [http://arxiv.org/abs/2210.00407v1](http://arxiv.org/abs/2210.00407v1)\n", "2210.00066": "- 2022-09-30, **Improving Policy Learning via Language Dynamics Distillation**, Victor Zhong et.al., Paper: [http://arxiv.org/abs/2210.00066v1](http://arxiv.org/abs/2210.00066v1), Code: **[https://github.com/vzhong/language-dynamics-distillation](https://github.com/vzhong/language-dynamics-distillation)**\n", "2210.00044": "- 2022-09-30, **Task Formulation Matters When Learning Continually: A Case Study in Visual Question Answering**, Mavina Nikandrou et.al., Paper: [http://arxiv.org/abs/2210.00044v1](http://arxiv.org/abs/2210.00044v1)\n", "2210.01738": "- 2022-10-04, **ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training**, Antonio Norelli et.al., Paper: [http://arxiv.org/abs/2210.01738v1](http://arxiv.org/abs/2210.01738v1)\n", "2210.01703": "- 2022-10-04, **Improving Label-Deficient Keyword Spotting Using Self-Supervised Pretraining**, Holger Severin Bovbjerg et.al., Paper: [http://arxiv.org/abs/2210.01703v1](http://arxiv.org/abs/2210.01703v1), Code: **[https://github.com/holgerbovbjerg/data2vec-kws](https://github.com/holgerbovbjerg/data2vec-kws)**\n", "2210.01571": "- 2022-10-04, **VICRegL: Self-Supervised Learning of Local Visual Features**, Adrien Bardes et.al., Paper: [http://arxiv.org/abs/2210.01571v1](http://arxiv.org/abs/2210.01571v1), Code: **[https://github.com/facebookresearch/vicregl](https://github.com/facebookresearch/vicregl)**\n", "2210.01504": "- 2022-10-04, **Knowledge Unlearning for Mitigating Privacy Risks in Language Models**, Joel Jang et.al., Paper: [http://arxiv.org/abs/2210.01504v1](http://arxiv.org/abs/2210.01504v1), Code: **[https://github.com/joeljang/knowledge-unlearning](https://github.com/joeljang/knowledge-unlearning)**\n", "2210.01425": "- 2022-10-04, **Guiding the PLMs with Semantic Anchors as Intermediate Supervision: Towards Interpretable Semantic Parsing**, Lunyiu Nie et.al., Paper: [http://arxiv.org/abs/2210.01425v1](http://arxiv.org/abs/2210.01425v1)\n", "2210.01260": "- 2022-10-03, **Enriching Vulnerability Reports Through Automated and Augmented Description Summarization**, Hattan Althebeiti et.al., Paper: [http://arxiv.org/abs/2210.01260v1](http://arxiv.org/abs/2210.01260v1)\n", "2210.02254": "- 2022-10-05, **Granularity-aware Adaptation for Image Retrieval over Multiple Tasks**, Jon Almaz\u00e1n et.al., Paper: [http://arxiv.org/abs/2210.02254v1](http://arxiv.org/abs/2210.02254v1)\n", "2210.02249": "- 2022-10-05, **LDEdit: Towards Generalized Text Guided Image Manipulation via Latent Diffusion Models**, Paramanand Chandramouli et.al., Paper: [http://arxiv.org/abs/2210.02249v1](http://arxiv.org/abs/2210.02249v1)\n", "2210.02156": "- 2022-10-05, **Fine-Tuning with Differential Privacy Necessitates an Additional Hyperparameter Search**, Yannis Cattan et.al., Paper: [http://arxiv.org/abs/2210.02156v1](http://arxiv.org/abs/2210.02156v1)\n", "2210.01936": "- 2022-10-06, **When and why vision-language models behave like bags-of-words, and what to do about it?**, Mert Yuksekgonul et.al., Paper: [http://arxiv.org/abs/2210.01936v2](http://arxiv.org/abs/2210.01936v2)\n", "2210.01820": "- 2022-10-04, **MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models**, Chenglin Yang et.al., Paper: [http://arxiv.org/abs/2210.01820v1](http://arxiv.org/abs/2210.01820v1)\n", "2210.03116": "- 2022-10-06, **Content-Based Search for Deep Generative Models**, Daohan Lu et.al., Paper: [http://arxiv.org/abs/2210.03116v1](http://arxiv.org/abs/2210.03116v1), Code: **[https://github.com/generative-intelligence-lab/modelverse](https://github.com/generative-intelligence-lab/modelverse)**\n", "2210.03114": "- 2022-10-06, **CLIP model is an Efficient Continual Learner**, Vishal Thengane et.al., Paper: [http://arxiv.org/abs/2210.03114v1](http://arxiv.org/abs/2210.03114v1), Code: **[https://github.com/vgthengane/continual-clip](https://github.com/vgthengane/continual-clip)**\n", "2210.03113": "- 2022-10-06, **IR-MCL: Implicit Representation-Based Online Global Localization**, Haofei Kuang et.al., Paper: [http://arxiv.org/abs/2210.03113v1](http://arxiv.org/abs/2210.03113v1), Code: **[https://github.com/prbonn/ir-mcl](https://github.com/prbonn/ir-mcl)**\n", "2210.03094": "- 2022-10-06, **VIMA: General Robot Manipulation with Multimodal Prompts**, Yunfan Jiang et.al., Paper: [http://arxiv.org/abs/2210.03094v1](http://arxiv.org/abs/2210.03094v1)\n", "2210.02989": "- 2022-10-07, **SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data**, Ching-Yun Ko et.al., Paper: [http://arxiv.org/abs/2210.02989v2](http://arxiv.org/abs/2210.02989v2)\n", "2210.02984": "- 2022-10-06, **The Lie Derivative for Measuring Learned Equivariance**, Nate Gruver et.al., Paper: [http://arxiv.org/abs/2210.02984v1](http://arxiv.org/abs/2210.02984v1), Code: **[https://github.com/ngruver/lie-deriv](https://github.com/ngruver/lie-deriv)**\n", "2210.02952": "- 2022-10-06, **Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation**, Xu Guo et.al., Paper: [http://arxiv.org/abs/2210.02952v1](http://arxiv.org/abs/2210.02952v1)\n", "2210.02946": "- 2022-10-06, **VLSNR:Vision-Linguistics Coordination Time Sequence-aware News Recommendation**, Songhao Han et.al., Paper: [http://arxiv.org/abs/2210.02946v1](http://arxiv.org/abs/2210.02946v1), Code: **[https://github.com/Aaronhuang-778/V-MIND](https://github.com/Aaronhuang-778/V-MIND)**\n", "2210.02935": "- 2022-10-06, **A Review of Uncertainty Calibration in Pretrained Object Detectors**, Denis Huseljic et.al., Paper: [http://arxiv.org/abs/2210.02935v1](http://arxiv.org/abs/2210.02935v1), Code: **[https://github.com/ies-research/uncertainty-object-detection](https://github.com/ies-research/uncertainty-object-detection)**\n", "2210.02833": "- 2022-10-06, **Matching Text and Audio Embeddings: Exploring Transfer-learning Strategies for Language-based Audio Retrieval**, Benno Weck et.al., Paper: [http://arxiv.org/abs/2210.02833v1](http://arxiv.org/abs/2210.02833v1)\n", "2210.03595": "- 2022-10-07, **Unsupervised Few-shot Learning via Deep Laplacian Eigenmaps**, Kuilin Chen et.al., Paper: [http://arxiv.org/abs/2210.03595v1](http://arxiv.org/abs/2210.03595v1)\n", "2210.03459": "- 2022-10-07, **Mutual Learning of Single- and Multi-Channel End-to-End Neural Diarization**, Shota Horiguchi et.al., Paper: [http://arxiv.org/abs/2210.03459v1](http://arxiv.org/abs/2210.03459v1)\n", "2210.03350": "- 2022-10-07, **Measuring and Narrowing the Compositionality Gap in Language Models**, Ofir Press et.al., Paper: [http://arxiv.org/abs/2210.03350v1](http://arxiv.org/abs/2210.03350v1), Code: **[https://github.com/ofirpress/self-ask](https://github.com/ofirpress/self-ask)**\n", "2210.03347": "- 2022-10-07, **Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding**, Kenton Lee et.al., Paper: [http://arxiv.org/abs/2210.03347v1](http://arxiv.org/abs/2210.03347v1)\n", "2210.03329": "- 2022-10-07, **Calibrating Factual Knowledge in Pretrained Language Models**, Qingxiu Dong et.al., Paper: [http://arxiv.org/abs/2210.03329v1](http://arxiv.org/abs/2210.03329v1), Code: **[https://github.com/dqxiu/calinet](https://github.com/dqxiu/calinet)**\n", "2210.03304": "- 2022-10-07, **Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding**, Zhichao Yang et.al., Paper: [http://arxiv.org/abs/2210.03304v1](http://arxiv.org/abs/2210.03304v1), Code: **[https://github.com/whaleloops/KEPT](https://github.com/whaleloops/KEPT)**\n", "2210.03265": "- 2022-10-07, **Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision Tasks**, Yen-Cheng Liu et.al., Paper: [http://arxiv.org/abs/2210.03265v1](http://arxiv.org/abs/2210.03265v1)\n", "2210.03205": "- 2022-10-10, **Synthetic Dataset Generation for Privacy-Preserving Machine Learning**, Efstathia Soufleri et.al., Paper: [http://arxiv.org/abs/2210.03205v2](http://arxiv.org/abs/2210.03205v2)\n", "2210.03168": "- 2022-10-06, **Gastrointestinal Disorder Detection with a Transformer Based Approach**, A. K. M. Salman Hosain et.al., Paper: [http://arxiv.org/abs/2210.03168v1](http://arxiv.org/abs/2210.03168v1)\n", "2210.04864": "- 2022-10-10, **Transformer-based Localization from Embodied Dialog with Large-scale Pre-training**, Meera Hahn et.al., Paper: [http://arxiv.org/abs/2210.04864v1](http://arxiv.org/abs/2210.04864v1)\n", "2210.04834": "- 2022-10-11, **Knowledge Distillation Transfer Sets and their Impact on Downstream NLU Tasks**, Charith Peris et.al., Paper: [http://arxiv.org/abs/2210.04834v2](http://arxiv.org/abs/2210.04834v2)\n", "2210.04782": "- 2022-10-10, **Robustification of Multilingual Language Models to Real-world Noise with Robust Contrastive Pretraining**, Asa Cooper Stickland et.al., Paper: [http://arxiv.org/abs/2210.04782v1](http://arxiv.org/abs/2210.04782v1)\n", "2210.04672": "- 2022-10-10, **Exploiting map information for self-supervised learning in motion forecasting**, Caio Azevedo et.al., Paper: [http://arxiv.org/abs/2210.04672v1](http://arxiv.org/abs/2210.04672v1)\n", "2210.04545": "- 2022-10-10, **Automatic Evaluation and Analysis of Idioms in Neural Machine Translation**, Christos Baziotis et.al., Paper: [http://arxiv.org/abs/2210.04545v1](http://arxiv.org/abs/2210.04545v1)\n", "2210.04477": "- 2022-10-10, **HiCo: Hierarchical Contrastive Learning for Ultrasound Video Model Pretraining**, Chunhui Zhang et.al., Paper: [http://arxiv.org/abs/2210.04477v1](http://arxiv.org/abs/2210.04477v1), Code: **[https://github.com/983632847/hico](https://github.com/983632847/hico)**\n", "2210.04428": "- 2022-10-10, **A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning**, Paul Janson et.al., Paper: [http://arxiv.org/abs/2210.04428v1](http://arxiv.org/abs/2210.04428v1), Code: **[https://github.com/pauljanson002/pretrained-cl](https://github.com/pauljanson002/pretrained-cl)**\n", "2210.04382": "- 2022-10-10, **Parameter-Efficient Tuning with Special Token Adaptation**, Xiaoocong Yang et.al., Paper: [http://arxiv.org/abs/2210.04382v1](http://arxiv.org/abs/2210.04382v1), Code: **[https://github.com/luka-group/pasta](https://github.com/luka-group/pasta)**\n", "2210.04325": "- 2022-10-11, **ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models**, Jiannan Xiang et.al., Paper: [http://arxiv.org/abs/2210.04325v2](http://arxiv.org/abs/2210.04325v2), Code: **[https://github.com/szxiangjn/any-shot-data2text](https://github.com/szxiangjn/any-shot-data2text)**\n", "2210.04320": "- 2022-10-09, **QAScore -- An Unsupervised Unreferenced Metric for the Question Generation Evaluation**, Tianbo Ji et.al., Paper: [http://arxiv.org/abs/2210.04320v1](http://arxiv.org/abs/2210.04320v1)\n", "2210.05613": "- 2022-10-11, **Contrastive Training Improves Zero-Shot Classification of Semi-structured Documents**, Muhammad Khalifa et.al., Paper: [http://arxiv.org/abs/2210.05613v1](http://arxiv.org/abs/2210.05613v1)\n", "2210.05610": "- 2022-10-11, **MTet: Multi-domain Translation for English and Vietnamese**, Chinh Ngo et.al., Paper: [http://arxiv.org/abs/2210.05610v1](http://arxiv.org/abs/2210.05610v1), Code: **[https://github.com/vietai/SAT](https://github.com/vietai/SAT)**\n", "2210.05598": "- 2022-10-11, **Enriching Biomedical Knowledge for Low-resource Language Through Translation**, Long Phan et.al., Paper: [http://arxiv.org/abs/2210.05598v1](http://arxiv.org/abs/2210.05598v1)\n", "2210.05557": "- 2022-10-11, **OPERA: Omni-Supervised Representation Learning with Hierarchical Supervisions**, Chengkun Wang et.al., Paper: [http://arxiv.org/abs/2210.05557v1](http://arxiv.org/abs/2210.05557v1), Code: **[https://github.com/wangck20/opera](https://github.com/wangck20/opera)**\n", "2210.05506": "- 2022-10-11, **Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration**, Matteo Paltenghi et.al., Paper: [http://arxiv.org/abs/2210.05506v1](http://arxiv.org/abs/2210.05506v1)\n", "2210.05497": "- 2022-10-11, **Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models**, Qihuang Zhong et.al., Paper: [http://arxiv.org/abs/2210.05497v1](http://arxiv.org/abs/2210.05497v1), Code: **[https://github.com/whu-zqh/fsam4plm](https://github.com/whu-zqh/fsam4plm)**\n", "2210.05470": "- 2022-10-11, **Block Format Error Bounds and Optimal Block Size Selection**, Ilya Soloveychik et.al., Paper: [http://arxiv.org/abs/2210.05470v1](http://arxiv.org/abs/2210.05470v1)\n", "2210.05457": "- 2022-10-11, **Are Pretrained Multilingual Models Equally Fair Across Languages?**, Laura Cabello Piqueras et.al., Paper: [http://arxiv.org/abs/2210.05457v1](http://arxiv.org/abs/2210.05457v1), Code: **[https://github.com/coastalcph/mozart](https://github.com/coastalcph/mozart)**\n", "2210.05248": "- 2022-10-11, **Self-supervised debiasing using low rank regularization**, Geon Yeong Park et.al., Paper: [http://arxiv.org/abs/2210.05248v1](http://arxiv.org/abs/2210.05248v1)\n", "2210.05246": "- 2022-10-11, **Cluster-level pseudo-labelling for source-free cross-domain facial expression recognition**, Alessandro Conti et.al., Paper: [http://arxiv.org/abs/2210.05246v1](http://arxiv.org/abs/2210.05246v1), Code: **[https://github.com/altndrr/clup](https://github.com/altndrr/clup)**\n", "2210.06466": "- 2022-10-12, **Prompt Generation Networks for Efficient Adaptation of Frozen Vision Transformers**, Jochem Loedeman et.al., Paper: [http://arxiv.org/abs/2210.06466v1](http://arxiv.org/abs/2210.06466v1), Code: **[https://github.com/jochemloedeman/pgn](https://github.com/jochemloedeman/pgn)**\n", "2210.06442": "- 2022-10-12, **Can Pretrained Language Models (Yet) Reason Deductively?**, Zhangdie Yuan et.al., Paper: [http://arxiv.org/abs/2210.06442v1](http://arxiv.org/abs/2210.06442v1)\n", "2210.06440": "- 2022-10-12, **The Devil is in the Details: On Models and Training Regimes for Few-Shot Intent Classification**, Mohsen Mesgar et.al., Paper: [http://arxiv.org/abs/2210.06440v1](http://arxiv.org/abs/2210.06440v1)\n", "2210.06433": "- 2022-10-12, **Self-supervised video pretraining yields strong image representations**, Nikhil Parthasarathy et.al., Paper: [http://arxiv.org/abs/2210.06433v1](http://arxiv.org/abs/2210.06433v1)\n", "2210.06423": "- 2022-10-12, **Foundation Transformers**, Hongyu Wang et.al., Paper: [http://arxiv.org/abs/2210.06423v1](http://arxiv.org/abs/2210.06423v1)\n", "2210.06349": "- 2022-10-12, **Context Generation Improves Open Domain Question Answering**, Dan Su et.al., Paper: [http://arxiv.org/abs/2210.06349v1](http://arxiv.org/abs/2210.06349v1)\n", "2210.06071": "- 2022-10-12, **Self-Validated Physics-Embedding Network: A General Framework for Inverse Modelling**, Ruiyuan Kang et.al., Paper: [http://arxiv.org/abs/2210.06071v1](http://arxiv.org/abs/2210.06071v1)\n", "2210.06031": "- 2022-10-12, **Long-Form Video-Language Pre-Training with Multimodal Temporal Contrastive Learning**, Yuchong Sun et.al., Paper: [http://arxiv.org/abs/2210.06031v1](http://arxiv.org/abs/2210.06031v1), Code: **[https://github.com/microsoft/xpretrain](https://github.com/microsoft/xpretrain)**\n", "2210.05991": "- 2022-10-12, **Distilling Knowledge from Language Models for Video-based Action Anticipation**, Sayontan Ghosh et.al., Paper: [http://arxiv.org/abs/2210.05991v1](http://arxiv.org/abs/2210.05991v1)\n", "2210.05872": "- 2022-10-12, **Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation**, Chaerin Kong et.al., Paper: [http://arxiv.org/abs/2210.05872v1](http://arxiv.org/abs/2210.05872v1)\n", "2210.07241": "- 2022-10-13, **Visual Reinforcement Learning with Self-Supervised 3D Representations**, Yanjie Ze et.al., Paper: [http://arxiv.org/abs/2210.07241v1](http://arxiv.org/abs/2210.07241v1)\n", "2210.07158": "- 2022-10-13, **HSurf-Net: Normal Estimation for 3D Point Clouds by Learning Hyper Surfaces**, Qing Li et.al., Paper: [http://arxiv.org/abs/2210.07158v1](http://arxiv.org/abs/2210.07158v1)\n", "2210.07154": "- 2022-10-13, **Fast Estimation of Bayesian State Space Models Using Amortized Simulation-Based Inference**, Ramis Khabibullin et.al., Paper: [http://arxiv.org/abs/2210.07154v1](http://arxiv.org/abs/2210.07154v1)\n", "2210.07135": "- 2022-10-13, **You Can Have Your Data and Balance It Too: Towards Balanced and Efficient Multilingual Models**, Tomasz Limisiewicz et.al., Paper: [http://arxiv.org/abs/2210.07135v1](http://arxiv.org/abs/2210.07135v1)\n", "2210.07111": "- 2022-10-13, **A Multi-dimensional Evaluation of Tokenizer-free Multilingual Pretrained Models**, Jimin Sun et.al., Paper: [http://arxiv.org/abs/2210.07111v1](http://arxiv.org/abs/2210.07111v1)\n", "2210.06886": "- 2022-10-13, **ImaginaryNet: Learning Object Detectors without Real Images and Annotations**, Minheng Ni et.al., Paper: [http://arxiv.org/abs/2210.06886v1](http://arxiv.org/abs/2210.06886v1), Code: **[https://github.com/kodenii/imaginarynet](https://github.com/kodenii/imaginarynet)**\n", "2210.06475": "- 2022-10-13, **Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models**, Sourya Basu et.al., Paper: [http://arxiv.org/abs/2210.06475v1](http://arxiv.org/abs/2210.06475v1)\n", "2210.06786": "- 2022-10-13, **Evaluating the Label Efficiency of Contrastive Self-Supervised Learning for Multi-Resolution Satellite Imagery**, Jules BOURCIER et.al., Paper: [http://arxiv.org/abs/2210.06786v1](http://arxiv.org/abs/2210.06786v1)\n", "2210.06725": "- 2022-10-13, **Assessing Out-of-Domain Language Model Performance from Few Examples**, Prasann Singhal et.al., Paper: [http://arxiv.org/abs/2210.06725v1](http://arxiv.org/abs/2210.06725v1)\n", "2210.06722": "- 2022-10-13, **Few-shot Relational Reasoning via Connection Subgraph Pretraining**, Qian Huang et.al., Paper: [http://arxiv.org/abs/2210.06722v1](http://arxiv.org/abs/2210.06722v1), Code: **[https://github.com/snap-stanford/csr](https://github.com/snap-stanford/csr)**\n", "2210.07936": "- 2022-10-14, **Data-Limited Tissue Segmentation using Inpainting-Based Self-Supervised Learning**, Jeffrey Dominic et.al., Paper: [http://arxiv.org/abs/2210.07936v1](http://arxiv.org/abs/2210.07936v1)\n", "2210.07856": "- 2022-10-14, **Description and analysis of novelties introduced in DCASE Task 4 2022 on the baseline system**, Francesca Ronchini et.al., Paper: [http://arxiv.org/abs/2210.07856v1](http://arxiv.org/abs/2210.07856v1)\n", "2210.07677": "- 2022-10-14, **TransFusion: Transcribing Speech with Multinomial Diffusion**, Matthew Baas et.al., Paper: [http://arxiv.org/abs/2210.07677v1](http://arxiv.org/abs/2210.07677v1), Code: **[https://github.com/rf5/transfusion-asr](https://github.com/rf5/transfusion-asr)**\n", "2210.07663": "- 2022-10-14, **Pretrained Transformers Do not Always Improve Robustness**, Swaroop Mishra et.al., Paper: [http://arxiv.org/abs/2210.07663v1](http://arxiv.org/abs/2210.07663v1)\n", "2210.07587": "- 2022-10-14, **ConEntail: An Entailment-based Framework for Universal Zero and Few Shot Classification with Supervised Contrastive Pretraining**, Haoran Zhang et.al., Paper: [http://arxiv.org/abs/2210.07587v1](http://arxiv.org/abs/2210.07587v1)\n", "2210.07488": "- 2022-10-14, **MetaFill: Text Infilling for Meta-Path Generation on Heterogeneous Information Networks**, Zequn Liu et.al., Paper: [http://arxiv.org/abs/2210.07488v1](http://arxiv.org/abs/2210.07488v1), Code: **[https://github.com/zequnl/metafill](https://github.com/zequnl/metafill)**\n", "2210.07485": "- 2022-10-14, **Holistic Sentence Embeddings for Better Out-of-Distribution Detection**, Sishuo Chen et.al., Paper: [http://arxiv.org/abs/2210.07485v1](http://arxiv.org/abs/2210.07485v1), Code: **[https://github.com/lancopku/avg-avg](https://github.com/lancopku/avg-avg)**\n", "2210.07453": "- 2022-10-14, **Using Graph Algorithms to Pretrain Graph Completion Transformers**, Jonathan Pilault et.al., Paper: [http://arxiv.org/abs/2210.07453v1](http://arxiv.org/abs/2210.07453v1)\n", "2210.07435": "- 2022-10-14, **NOCaL: Calibration-Free Semi-Supervised Learning of Odometry and Camera Intrinsics**, Ryan Griffiths et.al., Paper: [http://arxiv.org/abs/2210.07435v1](http://arxiv.org/abs/2210.07435v1)\n", "2210.07426": "- 2022-10-17, **Skill-Based Reinforcement Learning with Intrinsic Reward Matching**, Ademi Adeniji et.al., Paper: [http://arxiv.org/abs/2210.07426v2](http://arxiv.org/abs/2210.07426v2), Code: **[https://github.com/ademiadeniji/irm](https://github.com/ademiadeniji/irm)**\n", "2210.08929": "- 2022-10-17, **DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers**, Gaurav Kumar Nayak et.al., Paper: [http://arxiv.org/abs/2210.08929v1](http://arxiv.org/abs/2210.08929v1)\n", "2210.08773": "- 2022-10-17, **Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training**, Anthony Meng Huat Tiong et.al., Paper: [http://arxiv.org/abs/2210.08773v1](http://arxiv.org/abs/2210.08773v1), Code: **[https://github.com/salesforce/lavis](https://github.com/salesforce/lavis)**\n", "2210.08759": "- 2022-10-17, **Towards Relation Extraction From Speech**, Tongtong Wu et.al., Paper: [http://arxiv.org/abs/2210.08759v1](http://arxiv.org/abs/2210.08759v1), Code: **[https://github.com/wutong8023/speechre](https://github.com/wutong8023/speechre)**\n", "2210.08692": "- 2022-10-18, **A Generative User Simulator with GPT-based Architecture and Goal State Tracking for Reinforced Multi-Domain Dialog Systems**, Hong Liu et.al., Paper: [http://arxiv.org/abs/2210.08692v2](http://arxiv.org/abs/2210.08692v2), Code: **[https://github.com/thu-spmi/gus](https://github.com/thu-spmi/gus)**\n", "2210.08604": "- 2022-10-16, **NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly**, Yi R. Fung et.al., Paper: [http://arxiv.org/abs/2210.08604v1](http://arxiv.org/abs/2210.08604v1)\n", "2210.08475": "- 2022-10-16, **RedApt: An Adaptor for wav2vec 2 Encoding \\\\ Faster and Smaller Speech Translation without Quality Compromise**, Jinming Zhao et.al., Paper: [http://arxiv.org/abs/2210.08475v1](http://arxiv.org/abs/2210.08475v1)\n", "2210.08458": "- 2022-10-16, **Learning Self-Regularized Adversarial Views for Self-Supervised Vision Transformers**, Tao Tang et.al., Paper: [http://arxiv.org/abs/2210.08458v1](http://arxiv.org/abs/2210.08458v1), Code: **[https://github.com/trent-tangtao/autoview](https://github.com/trent-tangtao/autoview)**\n", "2210.08355": "- 2022-10-15, **A Simple and Strong Baseline for End-to-End Neural RST-style Discourse Parsing**, Naoki Kobayashi et.al., Paper: [http://arxiv.org/abs/2210.08355v1](http://arxiv.org/abs/2210.08355v1)\n", "2210.08284": "- 2022-10-15, **AraLegal-BERT: A pretrained language model for Arabic Legal text**, Muhammad AL-Qurishi et.al., Paper: [http://arxiv.org/abs/2210.08284v1](http://arxiv.org/abs/2210.08284v1)\n", "2210.08243": "- 2022-10-15, **Substructure-Atom Cross Attention for Molecular Representation Learning**, Jiye Kim et.al., Paper: [http://arxiv.org/abs/2210.08243v1](http://arxiv.org/abs/2210.08243v1)\n", "2210.10041": "- 2022-10-19, **Hidden State Variability of Pretrained Language Models Can Guide Computation Reduction for Transfer Learning**, Shuo Xie et.al., Paper: [http://arxiv.org/abs/2210.10041v2](http://arxiv.org/abs/2210.10041v2)\n", "2210.09761": "- 2022-10-18, **Personality-adapted multimodal dialogue system**, Tamotsu Miyama et.al., Paper: [http://arxiv.org/abs/2210.09761v1](http://arxiv.org/abs/2210.09761v1)\n", "2210.09644": "- 2022-10-18, **Tencent's Multilingual Machine Translation System for WMT22 Large-Scale African Languages**, Wenxiang Jiao et.al., Paper: [http://arxiv.org/abs/2210.09644v1](http://arxiv.org/abs/2210.09644v1), Code: **[https://github.com/wxjiao/wmt2022-large-scale-african](https://github.com/wxjiao/wmt2022-large-scale-african)**\n", "2210.09537": "- 2022-10-18, **Less is More: Simplifying Feature Extractors Prevents Overfitting for Neural Discourse Parsing Models**, Ming Li et.al., Paper: [http://arxiv.org/abs/2210.09537v1](http://arxiv.org/abs/2210.09537v1)\n", "2210.09449": "- 2022-10-17, **Early Diagnosis of Retinal Blood Vessel Damage via Deep Learning-Powered Collective Intelligence Models**, Pranjal Bhardwaj et.al., Paper: [http://arxiv.org/abs/2210.09449v1](http://arxiv.org/abs/2210.09449v1), Code: **[https://github.com/0xpranjal/DR-Detection-using-Swarm-intelligence](https://github.com/0xpranjal/DR-Detection-using-Swarm-intelligence)**\n", "2210.09338": "- 2022-10-19, **Deep Bidirectional Language-Knowledge Graph Pretraining**, Michihiro Yasunaga et.al., Paper: [http://arxiv.org/abs/2210.09338v2](http://arxiv.org/abs/2210.09338v2), Code: **[https://github.com/michiyasunaga/dragon](https://github.com/michiyasunaga/dragon)**\n", "2210.10763": "- 2022-10-19, **On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning**, Yifan Xu et.al., Paper: [http://arxiv.org/abs/2210.10763v1](http://arxiv.org/abs/2210.10763v1), Code: **[https://github.com/mlpc-ucsd/xtra](https://github.com/mlpc-ucsd/xtra)**\n", "2210.10693": "- 2022-10-19, **Robustness of Demonstration-based Learning Under Limited Data Scenario**, Hongxin Zhang et.al., Paper: [http://arxiv.org/abs/2210.10693v1](http://arxiv.org/abs/2210.10693v1), Code: **[https://github.com/salt-nlp/robustdemo](https://github.com/salt-nlp/robustdemo)**\n", "2210.10670": "- 2022-10-19, **Attaining Class-level Forgetting in Pretrained Model using Few Samples**, Pravendra Singh et.al., Paper: [http://arxiv.org/abs/2210.10670v1](http://arxiv.org/abs/2210.10670v1)\n", "2210.10615": "- 2022-10-19, **A Unified View of Masked Image Modeling**, Zhiliang Peng et.al., Paper: [http://arxiv.org/abs/2210.10615v1](http://arxiv.org/abs/2210.10615v1)\n", "2210.10542": "- 2022-10-19, **PoseGPT: Quantization-based 3D Human Motion Generation and Forecasting**, Thomas Lucas et.al., Paper: [http://arxiv.org/abs/2210.10542v1](http://arxiv.org/abs/2210.10542v1), Code: **[https://github.com/naver/posegpt](https://github.com/naver/posegpt)**\n", "2210.10325": "- 2022-10-19, **Improving Stability of Fine-Tuning Pretrained Language Models via Component-Wise Gradient Norm Clipping**, Chenghao Yang et.al., Paper: [http://arxiv.org/abs/2210.10325v1](http://arxiv.org/abs/2210.10325v1), Code: **[https://github.com/yangalan123/finetuningstability](https://github.com/yangalan123/finetuningstability)**\n", "2210.10320": "- 2022-10-19, **Learning from the Dictionary: Heterogeneous Knowledge Guided Fine-tuning for Chinese Spell Checking**, Yinghui Li et.al., Paper: [http://arxiv.org/abs/2210.10320v1](http://arxiv.org/abs/2210.10320v1), Code: **[https://github.com/geekjuruo/lead](https://github.com/geekjuruo/lead)**\n", "2210.10317": "- 2022-10-19, **LAVA: Label-efficient Visual Learning and Adaptation**, Islam Nassar et.al., Paper: [http://arxiv.org/abs/2210.10317v1](http://arxiv.org/abs/2210.10317v1)\n", "2210.10258": "- 2022-10-19, **Continued Pretraining for Better Zero- and Few-Shot Promptability**, Zhaofeng Wu et.al., Paper: [http://arxiv.org/abs/2210.10258v1](http://arxiv.org/abs/2210.10258v1)\n", "2210.10090": "- 2022-10-18, **How to Boost Face Recognition with StyleGAN?**, Artem Sevastopolsky et.al., Paper: [http://arxiv.org/abs/2210.10090v1](http://arxiv.org/abs/2210.10090v1), Code: **[https://github.com/seva100/stylegan-for-facerec](https://github.com/seva100/stylegan-for-facerec)**\n", "2210.11431": "- 2022-10-20, **Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario**, Xiao Liu et.al., Paper: [http://arxiv.org/abs/2210.11431v1](http://arxiv.org/abs/2210.11431v1), Code: **[https://github.com/xxxiaol/counterfactual-recipe-generation](https://github.com/xxxiaol/counterfactual-recipe-generation)**\n", "2210.11416": "- 2022-10-21, **Scaling Instruction-Finetuned Language Models**, Hyung Won Chung et.al., Paper: [http://arxiv.org/abs/2210.11416v2](http://arxiv.org/abs/2210.11416v2), Code: **[https://github.com/google-research/t5x](https://github.com/google-research/t5x)**\n", "2210.11309": "- 2022-10-20, **The University of Edinburgh's Submission to the WMT22 Code-Mixing Shared Task (MixMT)**, Faheem Kirefu et.al., Paper: [http://arxiv.org/abs/2210.11309v1](http://arxiv.org/abs/2210.11309v1)\n", "2210.11219": "- 2022-10-20, **YOWO-Plus: An Incremental Improvement**, Jianhua Yang et.al., Paper: [http://arxiv.org/abs/2210.11219v1](http://arxiv.org/abs/2210.11219v1), Code: **[https://github.com/yjh0410/pytorch_yowo](https://github.com/yjh0410/pytorch_yowo)**\n", "2210.11065": "- 2022-10-20, **MovieCLIP: Visual Scene Recognition in Movies**, Digbalay Bose et.al., Paper: [http://arxiv.org/abs/2210.11065v1](http://arxiv.org/abs/2210.11065v1)\n", "2210.11058": "- 2022-10-20, **Representation Learning with Diffusion Models**, Jeremias Traub et.al., Paper: [http://arxiv.org/abs/2210.11058v1](http://arxiv.org/abs/2210.11058v1), Code: **[https://github.com/jeremiastraub/diffusion](https://github.com/jeremiastraub/diffusion)**\n", "2210.11024": "- 2022-10-20, **A survey on Self Supervised learning approaches for improving Multimodal representation learning**, Naman Goyal et.al., Paper: [http://arxiv.org/abs/2210.11024v1](http://arxiv.org/abs/2210.11024v1)\n", "2210.11016": "- 2022-10-20, **Towards Sustainable Self-supervised Learning**, Shanghua Gao et.al., Paper: [http://arxiv.org/abs/2210.11016v1](http://arxiv.org/abs/2210.11016v1)\n", "2210.11006": "- 2022-10-20, **SimpleClick: Interactive Image Segmentation with Simple Vision Transformers**, Qin Liu et.al., Paper: [http://arxiv.org/abs/2210.11006v1](http://arxiv.org/abs/2210.11006v1), Code: **[https://github.com/uncbiag/simpleclick](https://github.com/uncbiag/simpleclick)**\n", "2210.10960": "- 2022-10-20, **Diffusion Models already have a Semantic Latent Space**, Mingi Kwon et.al., Paper: [http://arxiv.org/abs/2210.10960v1](http://arxiv.org/abs/2210.10960v1)\n", "2210.12112": "- 2022-10-21, **Describing Sets of Images with Textual-PCA**, Oded Hupert et.al., Paper: [http://arxiv.org/abs/2210.12112v1](http://arxiv.org/abs/2210.12112v1)\n", "2210.12100": "- 2022-10-21, **Boomerang: Local sampling on image manifolds using diffusion models**, Lorenzo Luzi et.al., Paper: [http://arxiv.org/abs/2210.12100v1](http://arxiv.org/abs/2210.12100v1)\n", "2210.12079": "- 2022-10-21, **Do Vision-and-Language Transformers Learn Grounded Predicate-Noun Dependencies?**, Mitja Nikolaus et.al., Paper: [http://arxiv.org/abs/2210.12079v1](http://arxiv.org/abs/2210.12079v1), Code: **[https://github.com/mitjanikolaus/multimodal-predicate-noun-dependencies](https://github.com/mitjanikolaus/multimodal-predicate-noun-dependencies)**\n", "2210.11885": "- 2022-10-21, **Deep LSTM Spoken Term Detection using Wav2Vec 2.0 Recognizer**, Jan \u0160vec et.al., Paper: [http://arxiv.org/abs/2210.11885v1](http://arxiv.org/abs/2210.11885v1)\n", "2210.11815": "- 2022-10-21, **Self-Supervised Pretraining on Satellite Imagery: a Case Study on Label-Efficient Vehicle Detection**, Jules BOURCIER et.al., Paper: [http://arxiv.org/abs/2210.11815v1](http://arxiv.org/abs/2210.11815v1)\n", "2210.11795": "- 2022-10-21, **PoseScript: 3D Human Poses from Natural Language**, Ginger Delmas et.al., Paper: [http://arxiv.org/abs/2210.11795v1](http://arxiv.org/abs/2210.11795v1)\n", "2210.11771": "- 2022-10-21, **InforMask: Unsupervised Informative Masking for Language Model Pretraining**, Nafis Sadeq et.al., Paper: [http://arxiv.org/abs/2210.11771v1](http://arxiv.org/abs/2210.11771v1)\n", "2210.11689": "- 2022-10-21, **SLING: Sino Linguistic Evaluation of Large Language Models**, Yixiao Song et.al., Paper: [http://arxiv.org/abs/2210.11689v1](http://arxiv.org/abs/2210.11689v1), Code: **[https://github.com/yixiao-song/sling_data_code](https://github.com/yixiao-song/sling_data_code)**\n", "2210.11522": "- 2022-10-20, **Composing Ensembles of Pre-trained Models via Iterative Consensus**, Shuang Li et.al., Paper: [http://arxiv.org/abs/2210.11522v1](http://arxiv.org/abs/2210.11522v1)\n", "2210.13449": "- 2022-10-24, **Controlled Text Reduction**, Aviv Slobodkin et.al., Paper: [http://arxiv.org/abs/2210.13449v1](http://arxiv.org/abs/2210.13449v1), Code: **[https://github.com/lovodkin93/controlled_text_reduction](https://github.com/lovodkin93/controlled_text_reduction)**\n", "2210.13361": "- 2022-10-24, **NASA: Neural Architecture Search and Acceleration for Hardware Inspired Hybrid Networks**, Huihong Shi et.al., Paper: [http://arxiv.org/abs/2210.13361v1](http://arxiv.org/abs/2210.13361v1), Code: **[https://github.com/rice-eic/nasa](https://github.com/rice-eic/nasa)**\n", "2210.13248": "- 2022-10-24, **Brouhaha: multi-task training for voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation**, Marvin Lavechin et.al., Paper: [http://arxiv.org/abs/2210.13248v1](http://arxiv.org/abs/2210.13248v1), Code: **[https://github.com/marianne-m/brouhaha-vad](https://github.com/marianne-m/brouhaha-vad)**\n", "2210.13181": "- 2022-10-24, **The Better Your Syntax, the Better Your Semantics? Probing Pretrained Language Models for the English Comparative Correlative**, Leonie Weissweiler et.al., Paper: [http://arxiv.org/abs/2210.13181v1](http://arxiv.org/abs/2210.13181v1)\n", "2210.13134": "- 2022-10-24, **Multilingual Multimodal Learning with Machine Translated Text**, Chen Qiu et.al., Paper: [http://arxiv.org/abs/2210.13134v1](http://arxiv.org/abs/2210.13134v1), Code: **[https://github.com/danoneata/td-mml](https://github.com/danoneata/td-mml)**\n", "2210.13084": "- 2022-10-24, **Full-Text Argumentation Mining on Scientific Publications**, Arne Binder et.al., Paper: [http://arxiv.org/abs/2210.13084v1](http://arxiv.org/abs/2210.13084v1), Code: **[https://github.com/dfki-nlp/sam](https://github.com/dfki-nlp/sam)**\n", "2210.13002": "- 2022-10-24, **An Empirical Revisiting of Linguistic Knowledge Fusion in Language Understanding Tasks**, Changlong Yu et.al., Paper: [http://arxiv.org/abs/2210.13002v1](http://arxiv.org/abs/2210.13002v1), Code: **[https://github.com/hkust-knowcomp/revisit-nlu-linguistic-knowledge](https://github.com/hkust-knowcomp/revisit-nlu-linguistic-knowledge)**\n", "2210.12763": "- 2022-10-23, **Discriminative Language Model as Semantic Consistency Scorer for Prompt-based Few-Shot Text Classification**, Zhipeng Xie et.al., Paper: [http://arxiv.org/abs/2210.12763v1](http://arxiv.org/abs/2210.12763v1)\n", "2210.12642": "- 2022-10-23, **Accelerated Linearized Laplace Approximation for Bayesian Deep Learning**, Zhijie Deng et.al., Paper: [http://arxiv.org/abs/2210.12642v1](http://arxiv.org/abs/2210.12642v1), Code: **[https://github.com/thudzj/ella](https://github.com/thudzj/ella)**\n", "2210.12607": "- 2022-10-23, **Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models**, Victor S. Bursztyn et.al., Paper: [http://arxiv.org/abs/2210.12607v1](http://arxiv.org/abs/2210.12607v1), Code: **[https://github.com/vbursztyn/compositional-fine-tuning](https://github.com/vbursztyn/compositional-fine-tuning)**\n", "2210.14188": "- 2022-10-25, **MOFormer: Self-Supervised Transformer model for Metal-Organic Framework Property Prediction**, Zhonglin Cao et.al., Paper: [http://arxiv.org/abs/2210.14188v1](http://arxiv.org/abs/2210.14188v1)\n", "2210.14085": "- 2022-10-25, **Audio MFCC-gram Transformers for respiratory insufficiency detection in COVID-19**, Marcelo Matheus Gauy et.al., Paper: [http://arxiv.org/abs/2210.14085v1](http://arxiv.org/abs/2210.14085v1), Code: **[https://github.com/marcelomatheusgauy/audio_mfcc_gram_transformers](https://github.com/marcelomatheusgauy/audio_mfcc_gram_transformers)**\n", "2210.13803": "- 2022-10-25, **Adapitch: Adaption Multi-Speaker Text-to-Speech Conditioned on Pitch Disentangling with Untranscribed Data**, Xulong Zhang et.al., Paper: [http://arxiv.org/abs/2210.13803v1](http://arxiv.org/abs/2210.13803v1)\n", "2210.13746": "- 2022-10-25, **DEMETR: Diagnosing Evaluation Metrics for Translation**, Marzena Karpinska et.al., Paper: [http://arxiv.org/abs/2210.13746v1](http://arxiv.org/abs/2210.13746v1), Code: **[https://github.com/marzenakrp/demetr](https://github.com/marzenakrp/demetr)**\n", "2210.13715": "- 2022-10-25, **PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph Completion**, Jianhao Shen et.al., Paper: [http://arxiv.org/abs/2210.13715v1](http://arxiv.org/abs/2210.13715v1), Code: **[https://github.com/yuanyehome/palt](https://github.com/yuanyehome/palt)**\n", "2210.13604": "- 2022-10-24, **The Robustness Limits of SoTA Vision Models to Natural Variation**, Mark Ibrahim et.al., Paper: [http://arxiv.org/abs/2210.13604v1](http://arxiv.org/abs/2210.13604v1)\n", "2210.13540": "- 2022-10-24, **Video based Object 6D Pose Estimation using Transformers**, Apoorva Beedu et.al., Paper: [http://arxiv.org/abs/2210.13540v1](http://arxiv.org/abs/2210.13540v1), Code: **[https://github.com/apoorvabeedu/videopose](https://github.com/apoorvabeedu/videopose)**\n", "2210.14803": "- 2022-10-26, **Don't Prompt, Search! Mining-based Zero-Shot Learning with Language Models**, Mozes van de Kar et.al., Paper: [http://arxiv.org/abs/2210.14803v1](http://arxiv.org/abs/2210.14803v1)\n", "2210.14716": "- 2022-10-26, **Pretrained audio neural networks for Speech emotion recognition in Portuguese**, Marcelo Matheus Gauy et.al., Paper: [http://arxiv.org/abs/2210.14716v1](http://arxiv.org/abs/2210.14716v1), Code: **[https://github.com/marcelomatheusgauy/pretrained_audio_neural_networks_emotion_recognition](https://github.com/marcelomatheusgauy/pretrained_audio_neural_networks_emotion_recognition)**\n", "2210.14698": "- 2022-10-26, **Autoregressive Structured Prediction with Language Models**, Tianyu Liu et.al., Paper: [http://arxiv.org/abs/2210.14698v1](http://arxiv.org/abs/2210.14698v1), Code: **[https://github.com/lyutyuh/asp](https://github.com/lyutyuh/asp)**\n", "2210.14678": "- 2022-10-26, **Investigating the Role of Centering Theory in the Context of Neural Coreference Resolution Systems**, Yuchen Eleanor Jiang et.al., Paper: [http://arxiv.org/abs/2210.14678v1](http://arxiv.org/abs/2210.14678v1)\n", "2210.14636": "- 2022-10-26, **Fast Yet Effective Speech Emotion Recognition with Self-distillation**, Zhao Ren et.al., Paper: [http://arxiv.org/abs/2210.14636v1](http://arxiv.org/abs/2210.14636v1)\n", "2210.14514": "- 2022-10-26, **Improving Speech-to-Speech Translation Through Unlabeled Text**, Xuan-Phi Nguyen et.al., Paper: [http://arxiv.org/abs/2210.14514v1](http://arxiv.org/abs/2210.14514v1)\n", "2210.14493": "- 2022-10-26, **AVES: Animal Vocalization Encoder based on Self-Supervision**, Masato Hagiwara et.al., Paper: [http://arxiv.org/abs/2210.14493v1](http://arxiv.org/abs/2210.14493v1), Code: **[https://github.com/earthspecies/aves](https://github.com/earthspecies/aves)**\n", "2210.14486": "- 2022-10-26, **Leveraging Affirmative Interpretations from Negation Improves Natural Language Understanding**, Md Mosharaf Hossain et.al., Paper: [http://arxiv.org/abs/2210.14486v1](http://arxiv.org/abs/2210.14486v1), Code: **[https://github.com/mosharafhossain/large-afin-and-nlu](https://github.com/mosharafhossain/large-afin-and-nlu)**\n", "2210.14473": "- 2022-10-26, **Benchmarking Language Models for Code Syntax Understanding**, Da Shen et.al., Paper: [http://arxiv.org/abs/2210.14473v1](http://arxiv.org/abs/2210.14473v1), Code: **[https://github.com/dashends/codesyntax](https://github.com/dashends/codesyntax)**\n", "2210.14463": "- 2022-10-26, **Bi-Link: Bridging Inductive Link Predictions from Text via Contrastive Learning of Transformers and Prompts**, Bohua Peng et.al., Paper: [http://arxiv.org/abs/2210.14463v1](http://arxiv.org/abs/2210.14463v1)\n", "2210.15447": "- 2022-10-27, **Virtuoso: Massive Multilingual Speech-Text Joint Semi-Supervised Learning for Text-To-Speech**, Takaaki Saeki et.al., Paper: [http://arxiv.org/abs/2210.15447v1](http://arxiv.org/abs/2210.15447v1)\n", "2210.15374": "- 2022-10-27, **2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth Estimation**, Rohit Choudhary et.al., Paper: [http://arxiv.org/abs/2210.15374v1](http://arxiv.org/abs/2210.15374v1)\n", "2210.15271": "- 2022-10-27, **Drug repositioning for Alzheimer's disease with transfer learning**, Yetao Wu et.al., Paper: [http://arxiv.org/abs/2210.15271v1](http://arxiv.org/abs/2210.15271v1)\n", "2210.15231": "- 2022-10-27, **Unsupervised Boundary-Aware Language Model Pretraining for Chinese Sequence Labeling**, Peijie Jiang et.al., Paper: [http://arxiv.org/abs/2210.15231v1](http://arxiv.org/abs/2210.15231v1)\n", "2210.15212": "- 2022-10-27, **COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning**, Yue Yu et.al., Paper: [http://arxiv.org/abs/2210.15212v1](http://arxiv.org/abs/2210.15212v1), Code: **[https://github.com/openmatch/coco-dr](https://github.com/openmatch/coco-dr)**\n", "2210.15206": "- 2022-10-27, **Learning on the Job: Self-Rewarding Offline-to-Online Finetuning for Industrial Insertion of Novel Connectors from Vision**, Ashvin Nair et.al., Paper: [http://arxiv.org/abs/2210.15206v1](http://arxiv.org/abs/2210.15206v1)\n", "2210.15172": "- 2022-10-27, **Dictionary-Assisted Supervised Contrastive Learning**, Patrick Y. Wu et.al., Paper: [http://arxiv.org/abs/2210.15172v1](http://arxiv.org/abs/2210.15172v1), Code: **[https://github.com/smappnyu/dascl](https://github.com/smappnyu/dascl)**\n", "2210.15134": "- 2022-10-28, **Learning Variational Motion Prior for Video-based Motion Capture**, Xin Chen et.al., Paper: [http://arxiv.org/abs/2210.15134v2](http://arxiv.org/abs/2210.15134v2)\n", "2210.15445": "- 2022-10-26, **Efficient Use of Large Pre-Trained Models for Low Resource ASR**, Peter Vieting et.al., Paper: [http://arxiv.org/abs/2210.15445v1](http://arxiv.org/abs/2210.15445v1)\n", "2210.16169": "- 2022-10-28, **LOFT: Finding Lottery Tickets through Filter-wise Training**, Qihan Wang et.al., Paper: [http://arxiv.org/abs/2210.16169v1](http://arxiv.org/abs/2210.16169v1)\n", "2210.16058": "- 2022-10-28, **Goal Exploration Augmentation via Pre-trained Skills for Sparse-Reward Long-Horizon Goal-Conditioned Reinforcement Learning**, Lisheng Wu et.al., Paper: [http://arxiv.org/abs/2210.16058v1](http://arxiv.org/abs/2210.16058v1), Code: **[https://github.com/geaps/geaps](https://github.com/geaps/geaps)**\n", "2210.16045": "- 2022-10-28, **Towards zero-shot Text-based voice editing using acoustic context conditioning, utterance embeddings, and reference encoders**, Jason Fong et.al., Paper: [http://arxiv.org/abs/2210.16045v1](http://arxiv.org/abs/2210.16045v1)\n", "2210.16031": "- 2022-10-31, **UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance**, Wei Li et.al., Paper: [http://arxiv.org/abs/2210.16031v2](http://arxiv.org/abs/2210.16031v2)\n", "2210.15929": "- 2022-10-28, **OhMG: Zero-shot Open-vocabulary Human Motion Generation**, Junfan Lin et.al., Paper: [http://arxiv.org/abs/2210.15929v1](http://arxiv.org/abs/2210.15929v1)\n", "2210.15868": "- 2022-10-28, **Residual Adapters for Few-Shot Text-to-Speech Speaker Adaptation**, Nobuyuki Morioka et.al., Paper: [http://arxiv.org/abs/2210.15868v1](http://arxiv.org/abs/2210.15868v1)\n", "2210.15765": "- 2022-10-27, **An Adversarial Active Sampling-based Data Augmentation Framework for Manufacturable Chip Design**, Mingjie Liu et.al., Paper: [http://arxiv.org/abs/2210.15765v1](http://arxiv.org/abs/2210.15765v1)\n", "2210.15762": "- 2022-10-27, **Nearest Neighbor Language Models for Stylistic Controllable Generation**, Severino Trotta et.al., Paper: [http://arxiv.org/abs/2210.15762v1](http://arxiv.org/abs/2210.15762v1)\n", "2210.17541": "- 2022-10-31, **Zero-Shot Text Classification with Self-Training**, Ariel Gera et.al., Paper: [http://arxiv.org/abs/2210.17541v1](http://arxiv.org/abs/2210.17541v1), Code: **[https://github.com/ibm/zero-shot-classification-boost-with-self-training](https://github.com/ibm/zero-shot-classification-boost-with-self-training)**\n", "2210.17463": "- 2022-10-31, **Domain Curricula for Code-Switched MT at MixMT 2022**, Lekan Raheem et.al., Paper: [http://arxiv.org/abs/2210.17463v1](http://arxiv.org/abs/2210.17463v1)\n", "2210.17322": "- 2022-10-31, **Generative Negative Text Replay for Continual Vision-Language Pretraining**, Shipeng Yan et.al., Paper: [http://arxiv.org/abs/2210.17322v1](http://arxiv.org/abs/2210.17322v1)\n", "2210.17041": "- 2022-10-31, **GPS: Genetic Prompt Search for Efficient Few-shot Learning**, Hanwei Xu et.al., Paper: [http://arxiv.org/abs/2210.17041v1](http://arxiv.org/abs/2210.17041v1), Code: **[https://github.com/hwxu20/gps](https://github.com/hwxu20/gps)**\n", "2210.16953": "- 2022-10-30, **Improving Bilingual Lexicon Induction with Cross-Encoder Reranking**, Yaoyiran Li et.al., Paper: [http://arxiv.org/abs/2210.16953v1](http://arxiv.org/abs/2210.16953v1), Code: **[https://github.com/cambridgeltl/BLICEr](https://github.com/cambridgeltl/BLICEr)**\n", "2210.16952": "- 2022-10-30, **Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning**, Roshanak Mirzaee et.al., Paper: [http://arxiv.org/abs/2210.16952v1](http://arxiv.org/abs/2210.16952v1)\n", "2210.16943": "- 2022-10-30, **ViTASD: Robust Vision Transformer Baselines for Autism Spectrum Disorder Facial Diagnosis**, Xu Cao et.al., Paper: [http://arxiv.org/abs/2210.16943v1](http://arxiv.org/abs/2210.16943v1), Code: **[https://github.com/irohxu/vitasd](https://github.com/irohxu/vitasd)**\n", "2210.16881": "- 2022-10-30, **Real-Time MRI Video synthesis from time aligned phonemes with sequence-to-sequence networks**, Sathvik Udupa et.al., Paper: [http://arxiv.org/abs/2210.16881v1](http://arxiv.org/abs/2210.16881v1)\n", "2210.16871": "- 2022-10-30, **Improved acoustic-to-articulatory inversion using representations from pretrained self-supervised learning models**, Sathvik Udupa et.al., Paper: [http://arxiv.org/abs/2210.16871v1](http://arxiv.org/abs/2210.16871v1)\n", "2210.16771": "- 2022-10-30, **Parameter-Efficient Tuning Makes a Good Classification Head**, Zhuoyi Yang et.al., Paper: [http://arxiv.org/abs/2210.16771v1](http://arxiv.org/abs/2210.16771v1), Code: **[https://github.com/thudm/efficient-head-finetuning](https://github.com/thudm/efficient-head-finetuning)**\n", "2211.00635": "- 2022-11-01, **Preserving In-Context Learning ability in Large Language Model Fine-tuning**, Yihan Wang et.al., Paper: [http://arxiv.org/abs/2211.00635v1](http://arxiv.org/abs/2211.00635v1)\n", "2211.00586": "- 2022-11-01, **T5lephone: Bridging Speech and Text Self-supervised Models for Spoken Language Understanding via Phoneme level T5**, Chan-Jan Hsu et.al., Paper: [http://arxiv.org/abs/2211.00586v1](http://arxiv.org/abs/2211.00586v1), Code: **[https://github.com/splend1d/t5lephone](https://github.com/splend1d/t5lephone)**\n", "2211.00497": "- 2022-11-01, **Modelling black-box audio effects with time-varying feature modulation**, Marco Comunit\u00e0 et.al., Paper: [http://arxiv.org/abs/2211.00497v1](http://arxiv.org/abs/2211.00497v1)\n", "2211.00342": "- 2022-11-01, **Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using Prosodic and Linguistic Features**, Alexandra Vioni et.al., Paper: [http://arxiv.org/abs/2211.00342v1](http://arxiv.org/abs/2211.00342v1)\n", "2211.00325": "- 2022-11-01, **Speech-text based multi-modal training with bidirectional attention for improved speech recognition**, Yuhang Yang et.al., Paper: [http://arxiv.org/abs/2211.00325v1](http://arxiv.org/abs/2211.00325v1), Code: **[https://github.com/yuhangear/multi-modal-learning](https://github.com/yuhangear/multi-modal-learning)**\n", "2211.00322": "- 2022-11-01, **DensePure: Understanding Diffusion Models towards Adversarial Robustness**, Chaowei Xiao et.al., Paper: [http://arxiv.org/abs/2211.00322v1](http://arxiv.org/abs/2211.00322v1)\n", "2211.00262": "- 2022-11-01, **Training Vision-Language Models with Less Bimodal Supervision**, Elad Segal et.al., Paper: [http://arxiv.org/abs/2211.00262v1](http://arxiv.org/abs/2211.00262v1), Code: **[https://github.com/eladsegal/less-bimodal-sup](https://github.com/eladsegal/less-bimodal-sup)**\n", "2211.00251": "- 2022-11-01, **End-to-End Optimization and Learning for Multiagent Ensembles**, James Kotary et.al., Paper: [http://arxiv.org/abs/2211.00251v1](http://arxiv.org/abs/2211.00251v1)\n", "2211.00151": "- 2022-10-31, **A Close Look into the Calibration of Pre-trained Language Models**, Yangyi Chen et.al., Paper: [http://arxiv.org/abs/2211.00151v1](http://arxiv.org/abs/2211.00151v1), Code: **[https://github.com/lifan-yuan/plmcalibration](https://github.com/lifan-yuan/plmcalibration)**\n", "2211.00119": "- 2022-10-31, **Active Learning of Non-semantic Speech Tasks with Pretrained Models**, Harlin Lee et.al., Paper: [http://arxiv.org/abs/2211.00119v1](http://arxiv.org/abs/2211.00119v1)\n", "2211.01335": "- 2022-11-03, **Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese**, An Yang et.al., Paper: [http://arxiv.org/abs/2211.01335v2](http://arxiv.org/abs/2211.01335v2), Code: **[https://github.com/ofa-sys/chinese-clip](https://github.com/ofa-sys/chinese-clip)**\n", "2211.01165": "- 2022-11-02, **RegCLR: A Self-Supervised Framework for Tabular Representation Learning in the Wild**, Weiyao Wang et.al., Paper: [http://arxiv.org/abs/2211.01165v1](http://arxiv.org/abs/2211.01165v1)\n", "2211.01079": "- 2022-11-02, **Intermediate Fine-Tuning Using Imperfect Synthetic Speech for Improving Electrolaryngeal Speech Recognition**, Lester Phillip Violeta et.al., Paper: [http://arxiv.org/abs/2211.01079v1](http://arxiv.org/abs/2211.01079v1)\n", "2211.00922": "- 2022-11-02, **Dialect-robust Evaluation of Generated Text**, Jiao Sun et.al., Paper: [http://arxiv.org/abs/2211.00922v1](http://arxiv.org/abs/2211.00922v1)\n", "2211.00849": "- 2022-11-02, **P$^3$OVD: Fine-grained Visual-Text Prompt-Driven Self-Training for Open-Vocabulary Object Detection**, Yanxin Long et.al., Paper: [http://arxiv.org/abs/2211.00849v1](http://arxiv.org/abs/2211.00849v1)\n", "2211.02043": "- 2022-11-03, **Could Giant Pretrained Image Models Extract Universal Representations?**, Yutong Lin et.al., Paper: [http://arxiv.org/abs/2211.02043v1](http://arxiv.org/abs/2211.02043v1)\n", "2211.01874": "- 2022-11-03, **Contextual information integration for stance detection via cross-attention**, Tilman Beck et.al., Paper: [http://arxiv.org/abs/2211.01874v1](http://arxiv.org/abs/2211.01874v1)\n", "2211.01786": "- 2022-11-03, **Crosslingual Generalization through Multitask Finetuning**, Niklas Muennighoff et.al., Paper: [http://arxiv.org/abs/2211.01786v1](http://arxiv.org/abs/2211.01786v1), Code: **[https://github.com/bigscience-workshop/xmtf](https://github.com/bigscience-workshop/xmtf)**\n", "2211.01736": "- 2022-11-03, **Exploring the State-of-the-Art Language Modeling Methods and Data Augmentation Techniques for Multilingual Clause-Level Morphology**, Emre Can Acikgoz et.al., Paper: [http://arxiv.org/abs/2211.01736v1](http://arxiv.org/abs/2211.01736v1), Code: **[https://github.com/emrecanacikgoz/mrl2022](https://github.com/emrecanacikgoz/mrl2022)**\n", "2211.01669": "- 2022-11-03, **Channel-Aware Pretraining of Joint Encoder-Decoder Self-Supervised Model for Telephonic-Speech ASR**, Vrunda N. Sukhadia et.al., Paper: [http://arxiv.org/abs/2211.01669v1](http://arxiv.org/abs/2211.01669v1)\n", "2211.01635": "- 2022-11-03, **Revisiting Grammatical Error Correction Evaluation and Beyond**, Peiyuan Gong et.al., Paper: [http://arxiv.org/abs/2211.01635v1](http://arxiv.org/abs/2211.01635v1)\n", "2211.01598": "- 2022-11-03, **Robust Few-shot Learning Without Using any Adversarial Samples**, Gaurav Kumar Nayak et.al., Paper: [http://arxiv.org/abs/2211.01598v1](http://arxiv.org/abs/2211.01598v1), Code: **[https://github.com/vcl-iisc/robust-few-shot-learning](https://github.com/vcl-iisc/robust-few-shot-learning)**\n", "2211.01562": "- 2022-11-03, **PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales**, Peifeng Wang et.al., Paper: [http://arxiv.org/abs/2211.01562v1](http://arxiv.org/abs/2211.01562v1)\n", "2211.01542": "- 2022-11-03, **Continual Learning of Neural Machine Translation within Low Forgetting Risk Regions**, Shuhao Gu et.al., Paper: [http://arxiv.org/abs/2211.01542v1](http://arxiv.org/abs/2211.01542v1), Code: **[https://github.com/ictnlp/lfr-nmt](https://github.com/ictnlp/lfr-nmt)**\n", "2211.01407": "- 2022-11-02, **On the Informativeness of Supervision Signals**, Ilia Sucholutsky et.al., Paper: [http://arxiv.org/abs/2211.01407v1](http://arxiv.org/abs/2211.01407v1)\n", "2211.02366": "- 2022-11-04, **SPEAKER VGG CCT: Cross-corpus Speech Emotion Recognition with Speaker Embedding and Vision Transformers**, A. Arezzo et.al., Paper: [http://arxiv.org/abs/2211.02366v1](http://arxiv.org/abs/2211.02366v1), Code: **[https://github.com/jabumldev/speaker-vgg-cct](https://github.com/jabumldev/speaker-vgg-cct)**\n", "2211.02272": "- 2022-11-04, **Logits are predictive of network type**, Ali Borji et.al., Paper: [http://arxiv.org/abs/2211.02272v1](http://arxiv.org/abs/2211.02272v1), Code: **[https://github.com/aliborji/logits](https://github.com/aliborji/logits)**\n", "2211.02269": "- 2022-11-04, **Late Fusion with Triplet Margin Objective for Multimodal Ideology Prediction and Analysis**, Changyuan Qiu et.al., Paper: [http://arxiv.org/abs/2211.02269v1](http://arxiv.org/abs/2211.02269v1)\n", "2211.02178": "- 2022-11-03, **Zero-shot Video Moment Retrieval With Off-the-Shelf Models**, Anuj Diwan et.al., Paper: [http://arxiv.org/abs/2211.02178v1](http://arxiv.org/abs/2211.02178v1)\n", "2211.03663": "- 2022-11-08, **Generalizable Re-Identification from Videos with Cycle Association**, Zhongdao Wang et.al., Paper: [http://arxiv.org/abs/2211.03663v2](http://arxiv.org/abs/2211.03663v2)\n", "2211.03660": "- 2022-11-07, **SC-DepthV3: Robust Self-supervised Monocular Depth Estimation for Dynamic Scenes**, Libo Sun et.al., Paper: [http://arxiv.org/abs/2211.03660v1](http://arxiv.org/abs/2211.03660v1), Code: **[https://github.com/JiawangBian/sc_depth_pl](https://github.com/JiawangBian/sc_depth_pl)**\n", "2211.03594": "- 2022-11-07, **Group DETR v2: Strong Object Detector with Encoder-Decoder Pretraining**, Qiang Chen et.al., Paper: [http://arxiv.org/abs/2211.03594v1](http://arxiv.org/abs/2211.03594v1)\n", "2211.03545": "- 2022-11-07, **ERNIE-SAT: Speech and Text Joint Pretraining for Cross-Lingual Multi-Speaker Text-to-Speech**, Xiaoran Fan et.al., Paper: [http://arxiv.org/abs/2211.03545v1](http://arxiv.org/abs/2211.03545v1), Code: **[https://github.com/PaddlePaddle/PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech)**\n", "2211.03521": "- 2022-11-07, **C3PO: Learning to Achieve Arbitrary Goals via Massively Entropic Pretraining**, Alexis Jacq et.al., Paper: [http://arxiv.org/abs/2211.03521v1](http://arxiv.org/abs/2211.03521v1)\n", "2211.03495": "- 2022-11-07, **How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers**, Michael Hassid et.al., Paper: [http://arxiv.org/abs/2211.03495v1](http://arxiv.org/abs/2211.03495v1), Code: **[https://github.com/schwartz-lab-nlp/papa](https://github.com/schwartz-lab-nlp/papa)**\n", "2211.03284": "- 2022-11-07, **Peak-First CTC: Reducing the Peak Latency of CTC Models by Applying Peak-First Regularization**, Zhengkun Tian et.al., Paper: [http://arxiv.org/abs/2211.03284v1](http://arxiv.org/abs/2211.03284v1)\n", "2211.03263": "- 2022-11-07, **AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages**, Bonaventure F. P. Dossou et.al., Paper: [http://arxiv.org/abs/2211.03263v1](http://arxiv.org/abs/2211.03263v1), Code: **[https://github.com/bonaventuredossou/mlm_al](https://github.com/bonaventuredossou/mlm_al)**\n", "2211.03154": "- 2022-11-06, **On the Domain Adaptation and Generalization of Pretrained Language Models: A Survey**, Xu Guo et.al., Paper: [http://arxiv.org/abs/2211.03154v1](http://arxiv.org/abs/2211.03154v1)\n", "2211.03044": "- 2022-11-06, **Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning**, Yu Meng et.al., Paper: [http://arxiv.org/abs/2211.03044v1](http://arxiv.org/abs/2211.03044v1), Code: **[https://github.com/yumeng5/fewgen](https://github.com/yumeng5/fewgen)**\n", "2211.03988": "- 2022-11-08, **Unsupervised Domain Adaptation for Sparse Retrieval by Filling Vocabulary and Word Frequency Gaps**, Hiroki Iida et.al., Paper: [http://arxiv.org/abs/2211.03988v1](http://arxiv.org/abs/2211.03988v1)\n", "2211.03966": "- 2022-11-08, **Parameter and Data Efficient Continual Pre-training for Robustness to Dialectal Variance in Arabic**, Soumajyoti Sarkar et.al., Paper: [http://arxiv.org/abs/2211.03966v1](http://arxiv.org/abs/2211.03966v1)\n", "2211.03959": "- 2022-11-08, **Pretraining in Deep Reinforcement Learning: A Survey**, Zhihui Xie et.al., Paper: [http://arxiv.org/abs/2211.03959v1](http://arxiv.org/abs/2211.03959v1)\n", "2211.03937": "- 2022-11-08, **From fat droplets to floating forests: cross-domain transfer learning using a PatchGAN-based segmentation model**, Kameswara Bharadwaj Mantha et.al., Paper: [http://arxiv.org/abs/2211.03937v1](http://arxiv.org/abs/2211.03937v1)\n", "2211.03808": "- 2022-11-07, **ToDD: Topological Compound Fingerprinting in Computer-Aided Drug Discovery**, Andac Demir et.al., Paper: [http://arxiv.org/abs/2211.03808v1](http://arxiv.org/abs/2211.03808v1)\n", "2211.05110": "- 2022-11-09, **Large Language Models with Controllable Working Memory**, Daliang Li et.al., Paper: [http://arxiv.org/abs/2211.05110v1](http://arxiv.org/abs/2211.05110v1)\n", "2211.05015": "- 2022-11-09, **Detecting Languages Unintelligible to Multilingual Models through Local Structure Probes**, Louis Clou\u00e2tre et.al., Paper: [http://arxiv.org/abs/2211.05015v1](http://arxiv.org/abs/2211.05015v1)\n", "2211.04926": "- 2022-11-09, **Optimized Global Perturbation Attacks For Brain Tumour ROI Extraction From Binary Classification Models**, Sajith Rajapaksa et.al., Paper: [http://arxiv.org/abs/2211.04926v1](http://arxiv.org/abs/2211.04926v1)\n", "2211.04878": "- 2022-11-09, **Foundation Models for Semantic Novelty in Reinforcement Learning**, Tarun Gupta et.al., Paper: [http://arxiv.org/abs/2211.04878v1](http://arxiv.org/abs/2211.04878v1)\n", "2211.04785": "- 2022-11-09, **Masked Vision-Language Transformers for Scene Text Recognition**, Jie Wu et.al., Paper: [http://arxiv.org/abs/2211.04785v1](http://arxiv.org/abs/2211.04785v1), Code: **[https://github.com/onealwj/mvlt](https://github.com/onealwj/mvlt)**\n", "2211.04598": "- 2022-11-08, **Reducing Down(stream)time: Pretraining Molecular GNNs using Heterogeneous AI Accelerators**, Jenna A. Bilbrey et.al., Paper: [http://arxiv.org/abs/2211.04598v1](http://arxiv.org/abs/2211.04598v1), Code: **[https://github.com/pnnl/downstream_mol_gnn](https://github.com/pnnl/downstream_mol_gnn)**\n", "2211.05750": "- 2022-11-10, **Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control**, Xiang Fan et.al., Paper: [http://arxiv.org/abs/2211.05750v1](http://arxiv.org/abs/2211.05750v1), Code: **[https://github.com/sfanxiang/nano](https://github.com/sfanxiang/nano)**\n", "2211.05352": "- 2022-11-10, **3D-CSL: self-supervised 3D context similarity learning for Near-Duplicate Video Retrieval**, Rui Deng et.al., Paper: [http://arxiv.org/abs/2211.05352v1](http://arxiv.org/abs/2211.05352v1)\n", "2211.05213": "- 2022-11-09, **Flaky Performances when Pretraining on Relational Databases**, Shengchao Liu et.al., Paper: [http://arxiv.org/abs/2211.05213v1](http://arxiv.org/abs/2211.05213v1)\n", "2211.05183": "- 2022-11-09, **An Empirical Study on Clustering Pretrained Embeddings: Is Deep Strictly Better?**, Tyler R. Scott et.al., Paper: [http://arxiv.org/abs/2211.05183v1](http://arxiv.org/abs/2211.05183v1)\n", "2211.06408": "- 2022-11-11, **Physically-Based Face Rendering for NIR-VIS Face Recognition**, Yunqi Miao et.al., Paper: [http://arxiv.org/abs/2211.06408v1](http://arxiv.org/abs/2211.06408v1), Code: **[https://github.com/deepinsight/insightface](https://github.com/deepinsight/insightface)**\n", "2211.06212": "- 2022-11-11, **From Competition to Collaboration: Making Toy Datasets on Kaggle Clinically Useful for Chest X-Ray Diagnosis Using Federated Learning**, Pranav Kulkarni et.al., Paper: [http://arxiv.org/abs/2211.06212v1](http://arxiv.org/abs/2211.06212v1)\n", "2211.06116": "- 2022-11-11, **How Much Hate with #china? A Preliminary Analysis on China-related Hateful Tweets Two Years After the Covid Pandemic Began**, Jinghua Xu et.al., Paper: [http://arxiv.org/abs/2211.06116v1](http://arxiv.org/abs/2211.06116v1), Code: **[https://github.com/jinhxu/how-much-hate-with-china](https://github.com/jinhxu/how-much-hate-with-china)**\n", "2211.06023": "- 2022-11-11, **Soft-Landing Strategy for Alleviating the Task Discrepancy Problem in Temporal Action Localization Tasks**, Hyolim Kang et.al., Paper: [http://arxiv.org/abs/2211.06023v1](http://arxiv.org/abs/2211.06023v1)\n", "2211.05853": "- 2022-11-10, **Measuring Reliability of Large Language Models through Semantic Consistency**, Harsh Raj et.al., Paper: [http://arxiv.org/abs/2211.05853v1](http://arxiv.org/abs/2211.05853v1)\n", "2211.07600": "- 2022-11-14, **Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures**, Gal Metzer et.al., Paper: [http://arxiv.org/abs/2211.07600v1](http://arxiv.org/abs/2211.07600v1), Code: **[https://github.com/eladrich/latent-nerf](https://github.com/eladrich/latent-nerf)**\n", "2211.07517": "- 2022-11-14, **Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations**, Swarnadeep Saha et.al., Paper: [http://arxiv.org/abs/2211.07517v1](http://arxiv.org/abs/2211.07517v1), Code: **[https://github.com/swarnahub/explanationhardness](https://github.com/swarnahub/explanationhardness)**\n", "2211.07384": "- 2022-11-14, **Language models are good pathologists: using attention-based sequence reduction and text-pretrained transformers for efficient WSI classification**, Juan I. Pisula et.al., Paper: [http://arxiv.org/abs/2211.07384v1](http://arxiv.org/abs/2211.07384v1), Code: **[https://github.com/bozeklab/lmagp](https://github.com/bozeklab/lmagp)**\n", "2211.07292": "- 2022-11-14, **Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces**, Dominic Rampas et.al., Paper: [http://arxiv.org/abs/2211.07292v1](http://arxiv.org/abs/2211.07292v1), Code: **[https://github.com/dome272/paella](https://github.com/dome272/paella)**\n", "2211.07254": "- 2022-11-14, **The Role of Local Alignment and Uniformity in Image-Text Contrastive Learning on Medical Images**, Philip M\u00fcller et.al., Paper: [http://arxiv.org/abs/2211.07254v1](http://arxiv.org/abs/2211.07254v1)\n", "2211.07201": "- 2022-11-14, **Towards A Unified Conformer Structure: from ASR to ASV Task**, Dexin Liao et.al., Paper: [http://arxiv.org/abs/2211.07201v1](http://arxiv.org/abs/2211.07201v1), Code: **[https://github.com/Snowdar/asv-subtools](https://github.com/Snowdar/asv-subtools)**\n", "2211.07168": "- 2022-11-14, **Unsupervised Galaxy Morphological Visual Representation with Deep Contrastive Learning**, Shoulin Wei et.al., Paper: [http://arxiv.org/abs/2211.07168v1](http://arxiv.org/abs/2211.07168v1)\n", "2211.07118": "- 2022-11-14, **Information-guided pixel augmentation for pixel-wise contrastive learning**, Quan Quan et.al., Paper: [http://arxiv.org/abs/2211.07118v1](http://arxiv.org/abs/2211.07118v1)\n", "2211.07091": "- 2022-11-14, **BiViT: Extremely Compressed Binary Vision Transformer**, Yefei He et.al., Paper: [http://arxiv.org/abs/2211.07091v1](http://arxiv.org/abs/2211.07091v1)\n", "2211.07078": "- 2022-11-14, **SPE: Symmetrical Prompt Enhancement for Fact Probing**, Yiyuan Li et.al., Paper: [http://arxiv.org/abs/2211.07078v1](http://arxiv.org/abs/2211.07078v1)\n", "2211.08422": "- 2022-11-15, **Mechanistic Mode Connectivity**, Ekdeep Singh Lubana et.al., Paper: [http://arxiv.org/abs/2211.08422v1](http://arxiv.org/abs/2211.08422v1), Code: **[https://github.com/ekdeepslubana/mmc](https://github.com/ekdeepslubana/mmc)**\n", "2211.08279": "- 2022-11-15, **Towards an objective characterization of an individual's facial movements using Self-Supervised Person-Specific-Models**, Yanis Tazi et.al., Paper: [http://arxiv.org/abs/2211.08279v1](http://arxiv.org/abs/2211.08279v1), Code: **[https://github.com/yanistazi/PSM_release](https://github.com/yanistazi/PSM_release)**\n", "2211.08099": "- 2022-11-15, **A Universal Discriminator for Zero-Shot Generalization**, Haike Xu et.al., Paper: [http://arxiv.org/abs/2211.08099v1](http://arxiv.org/abs/2211.08099v1)\n", "2211.08081": "- 2022-11-15, **Autonomous Golf Putting with Data-Driven and Physics-Based Methods**, Annika Junker et.al., Paper: [http://arxiv.org/abs/2211.08081v1](http://arxiv.org/abs/2211.08081v1)\n", "2211.08057": "- 2022-11-15, **Multilingual and Multimodal Topic Modelling with Pretrained Embeddings**, Elaine Zosa et.al., Paper: [http://arxiv.org/abs/2211.08057v1](http://arxiv.org/abs/2211.08057v1), Code: **[https://github.com/ezosa/m3l-topic-model](https://github.com/ezosa/m3l-topic-model)**\n", "2211.08029": "- 2022-11-15, **Persian Emotion Detection using ParsBERT and Imbalanced Data Handling Approaches**, Amirhossein Abaskohi et.al., Paper: [http://arxiv.org/abs/2211.08029v1](http://arxiv.org/abs/2211.08029v1)\n", "2211.08016": "- 2022-11-15, **Contextual Transformer for Offline Meta Reinforcement Learning**, Runji Lin et.al., Paper: [http://arxiv.org/abs/2211.08016v1](http://arxiv.org/abs/2211.08016v1)\n", "2211.07993": "- 2022-11-15, **DIGEST: Deeply supervIsed knowledGE tranSfer neTwork learning for brain tumor segmentation with incomplete multi-modal MRI scans**, Haoran Li et.al., Paper: [http://arxiv.org/abs/2211.07993v1](http://arxiv.org/abs/2211.07993v1)\n", "2211.07968": "- 2022-11-15, **NeRFFaceEditing: Disentangled Face Editing in Neural Radiance Fields**, Kaiwen Jiang et.al., Paper: [http://arxiv.org/abs/2211.07968v1](http://arxiv.org/abs/2211.07968v1)\n", "2211.07928": "- 2022-11-15, **False: False Negative Samples Aware Contrastive Learning for Semantic Segmentation of High-Resolution Remote Sensing Image**, Zhaoyang Zhang et.al., Paper: [http://arxiv.org/abs/2211.07928v1](http://arxiv.org/abs/2211.07928v1)\n", "2211.09084": "- 2022-11-16, **Technical Report on Neural Language Models and Few-Shot Learning for Systematic Requirements Processing in MDSE**, Vincent Bertram et.al., Paper: [http://arxiv.org/abs/2211.09084v1](http://arxiv.org/abs/2211.09084v1)\n", "2211.08904": "- 2022-11-16, **Self-supervised Egomotion and Depth Learning via Bi-directional Coarse-to-Fine Scale Recovery**, Hao Qu et.al., Paper: [http://arxiv.org/abs/2211.08904v1](http://arxiv.org/abs/2211.08904v1)\n", "2211.08794": "- 2022-11-16, **Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations**, Linlin Liu et.al., Paper: [http://arxiv.org/abs/2211.08794v1](http://arxiv.org/abs/2211.08794v1)\n", "2211.08570": "- 2022-11-15, **Dynamic-Pix2Pix: Noise Injected cGAN for Modeling Input and Target Domain Joint Distributions with Limited Training Data**, Mohammadreza Naderi et.al., Paper: [http://arxiv.org/abs/2211.08570v1](http://arxiv.org/abs/2211.08570v1)\n", "2211.08533": "- 2022-11-15, **A Point in the Right Direction: Vector Prediction for Spatially-aware Self-supervised Volumetric Representation Learning**, Yejia Zhang et.al., Paper: [http://arxiv.org/abs/2211.08533v1](http://arxiv.org/abs/2211.08533v1)\n", "2211.08473": "- 2022-11-15, **On the Compositional Generalization Gap of In-Context Learning**, Arian Hosseini et.al., Paper: [http://arxiv.org/abs/2211.08473v1](http://arxiv.org/abs/2211.08473v1)\n", "2211.09809": "- 2022-11-17, **SPACEx: Speech-driven Portrait Animation with Controllable Expression**, Siddharth Gururani et.al., Paper: [http://arxiv.org/abs/2211.09809v1](http://arxiv.org/abs/2211.09809v1)\n", "2211.09800": "- 2022-11-17, **InstructPix2Pix: Learning to Follow Image Editing Instructions**, Tim Brooks et.al., Paper: [http://arxiv.org/abs/2211.09800v1](http://arxiv.org/abs/2211.09800v1)\n", "2211.09794": "- 2022-11-17, **Null-text Inversion for Editing Real Images using Guided Diffusion Models**, Ron Mokady et.al., Paper: [http://arxiv.org/abs/2211.09794v1](http://arxiv.org/abs/2211.09794v1)\n", "2211.09791": "- 2022-11-17, **MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors**, Yuang Zhang et.al., Paper: [http://arxiv.org/abs/2211.09791v1](http://arxiv.org/abs/2211.09791v1), Code: **[https://github.com/megvii-research/MOTRv2](https://github.com/megvii-research/MOTRv2)**\n", "2211.09782": "- 2022-11-17, **Assessing Neural Network Robustness via Adversarial Pivotal Tuning**, Peter Ebert Christensen et.al., Paper: [http://arxiv.org/abs/2211.09782v1](http://arxiv.org/abs/2211.09782v1)\n", "2211.09770": "- 2022-11-17, **3DLatNav: Navigating Generative Latent Spaces for Semantic-Aware 3D Object Manipulation**, Amaya Dharmasiri et.al., Paper: [http://arxiv.org/abs/2211.09770v1](http://arxiv.org/abs/2211.09770v1), Code: **[https://github.com/theamaya/3dlatnav](https://github.com/theamaya/3dlatnav)**\n", "2211.09710": "- 2022-11-17, **Style Classification of Rabbinic Literature for Detection of Lost Midrash Tanhuma Material**, Shlomo Tannor et.al., Paper: [http://arxiv.org/abs/2211.09710v1](http://arxiv.org/abs/2211.09710v1)\n", "2211.09552": "- 2022-11-17, **UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer**, Kunchang Li et.al., Paper: [http://arxiv.org/abs/2211.09552v1](http://arxiv.org/abs/2211.09552v1), Code: **[https://github.com/OpenGVLab/UniFormerV2](https://github.com/OpenGVLab/UniFormerV2)**\n", "2211.09371": "- 2022-11-17, **CapEnrich: Enriching Caption Semantics for Web Images via Cross-modal Pre-trained Knowledge**, Linli Yao et.al., Paper: [http://arxiv.org/abs/2211.09371v1](http://arxiv.org/abs/2211.09371v1)\n", "2211.10265": "- 2022-11-18, **Context Variance Evaluation of Pretrained Language Models for Prompt-based Biomedical Knowledge Probing**, Zonghai Yao et.al., Paper: [http://arxiv.org/abs/2211.10265v1](http://arxiv.org/abs/2211.10265v1)\n", "2211.10003": "- 2022-11-18, **3d human motion generation from the text via gesture action classification and the autoregressive model**, Gwantae Kim et.al., Paper: [http://arxiv.org/abs/2211.10003v1](http://arxiv.org/abs/2211.10003v1)\n", "2211.09927": "- 2022-11-17, **SAR-based landslide classification pretraining leads to better segmentation**, Vanessa B\u00f6hm et.al., Paper: [http://arxiv.org/abs/2211.09927v1](http://arxiv.org/abs/2211.09927v1), Code: **[https://github.com/vmboehm/sar-landslide-detection-pretraining](https://github.com/vmboehm/sar-landslide-detection-pretraining)**\n", "2211.11736": "- 2022-11-22, **Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models**, Ted Xiao et.al., Paper: [http://arxiv.org/abs/2211.11736v2](http://arxiv.org/abs/2211.11736v2)\n", "2211.11720": "- 2022-11-22, **Multitask Vision-Language Prompt Tuning**, Sheng Shen et.al., Paper: [http://arxiv.org/abs/2211.11720v2](http://arxiv.org/abs/2211.11720v2), Code: **[https://github.com/sincerass/mvlpt](https://github.com/sincerass/mvlpt)**\n", "2211.11701": "- 2022-11-21, **Perceiver-VL: Efficient Vision-and-Language Modeling with Iterative Latent Attention**, Zineng Tang et.al., Paper: [http://arxiv.org/abs/2211.11701v1](http://arxiv.org/abs/2211.11701v1), Code: **[https://github.com/zinengtang/perceiver_vl](https://github.com/zinengtang/perceiver_vl)**\n", "2211.11635": "- 2022-11-21, **Understanding and Improving Visual Prompting: A Label-Mapping Perspective**, Aochuan Chen et.al., Paper: [http://arxiv.org/abs/2211.11635v1](http://arxiv.org/abs/2211.11635v1), Code: **[https://github.com/optml-group/ilm-vp](https://github.com/optml-group/ilm-vp)**\n", "2211.11483": "- 2022-11-21, **Deanthropomorphising NLP: Can a Language Model Be Conscious?**, Matthew Shardlow et.al., Paper: [http://arxiv.org/abs/2211.11483v1](http://arxiv.org/abs/2211.11483v1)\n", "2211.11363": "- 2022-11-21, **CBEAF-Adapting: Enhanced Continual Pretraining for Building Chinese Biomedical Language Model**, Yongyu Yan et.al., Paper: [http://arxiv.org/abs/2211.11363v1](http://arxiv.org/abs/2211.11363v1)\n", "2211.11319": "- 2022-11-21, **VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models**, Ajay Jain et.al., Paper: [http://arxiv.org/abs/2211.11319v1](http://arxiv.org/abs/2211.11319v1)\n", "2211.11176": "- 2022-11-21, **Spatiotemporal Modeling of Multivariate Signals With Graph Neural Networks and Structured State Space Models**, Siyi Tang et.al., Paper: [http://arxiv.org/abs/2211.11176v1](http://arxiv.org/abs/2211.11176v1), Code: **[https://github.com/tsy935/graphs4mer](https://github.com/tsy935/graphs4mer)**\n", "2211.11153": "- 2022-11-21, **Unifying Vision-Language Representation Space with Single-tower Transformer**, Jiho Jang et.al., Paper: [http://arxiv.org/abs/2211.11153v1](http://arxiv.org/abs/2211.11153v1)\n", "2211.11131": "- 2022-11-21, **Doubly Contrastive End-to-End Semantic Segmentation for Autonomous Driving under Adverse Weather**, Jongoh Jeong et.al., Paper: [http://arxiv.org/abs/2211.11131v1](http://arxiv.org/abs/2211.11131v1)\n", "2211.12446": "- 2022-11-22, **EDICT: Exact Diffusion Inversion via Coupled Transformations**, Bram Wallace et.al., Paper: [http://arxiv.org/abs/2211.12446v1](http://arxiv.org/abs/2211.12446v1)\n", "2211.11870": "- 2022-11-21, **LoopDA: Constructing Self-loops to Adapt Nighttime Semantic Segmentation**, Fengyi Shen et.al., Paper: [http://arxiv.org/abs/2211.11870v1](http://arxiv.org/abs/2211.11870v1), Code: **[https://github.com/fy-vision/loopda](https://github.com/fy-vision/loopda)**\n", "2211.13189": "- 2022-11-23, **ASiT: Audio Spectrogram vIsion Transformer for General Audio Representation**, Sara Atito et.al., Paper: [http://arxiv.org/abs/2211.13189v1](http://arxiv.org/abs/2211.13189v1)\n", "2211.12931": "- 2022-11-23, **Can we Adopt Self-supervised Pretraining for Chest X-Rays?**, Arsh Verma et.al., Paper: [http://arxiv.org/abs/2211.12931v1](http://arxiv.org/abs/2211.12931v1)\n", "2211.12791": "- 2022-11-23, **An ensemble of VisNet, Transformer-M, and pretraining models for molecular property prediction in OGB Large-Scale Challenge @ NeurIPS 2022**, Yusong Wang et.al., Paper: [http://arxiv.org/abs/2211.12791v1](http://arxiv.org/abs/2211.12791v1)\n", "2211.12740": "- 2022-11-23, **Masked Autoencoding for Scalable and Generalizable Decision Making**, Fangchen Liu et.al., Paper: [http://arxiv.org/abs/2211.12740v1](http://arxiv.org/abs/2211.12740v1), Code: **[https://github.com/fangchenliu/maskdp_public](https://github.com/fangchenliu/maskdp_public)**\n", "2211.12650": "- 2022-11-23, **FRE: A Fast Method For Anomaly Detection And Segmentation**, Ibrahima Ndiour et.al., Paper: [http://arxiv.org/abs/2211.12650v1](http://arxiv.org/abs/2211.12650v1)\n", "2211.12561": "- 2022-11-22, **Retrieval-Augmented Multimodal Language Modeling**, Michihiro Yasunaga et.al., Paper: [http://arxiv.org/abs/2211.12561v1](http://arxiv.org/abs/2211.12561v1)\n", "2211.13052": "- 2022-11-22, **Pyrocast: a Machine Learning Pipeline to Forecast Pyrocumulonimbus (PyroCb) Clouds**, Kenza Tazi et.al., Paper: [http://arxiv.org/abs/2211.13052v1](http://arxiv.org/abs/2211.13052v1)\n", "2211.14308": "- 2022-11-25, **WALDO: Future Video Synthesis using Object Layer Decomposition and Parametric Flow Prediction**, Guillaume Le Moing et.al., Paper: [http://arxiv.org/abs/2211.14308v1](http://arxiv.org/abs/2211.14308v1)\n", "2211.14133": "- 2022-11-25, **PipeFisher: Efficient Training of Large Language Models Using Pipelining and Fisher Information Matrices**, Kazuki Osawa et.al., Paper: [http://arxiv.org/abs/2211.14133v1](http://arxiv.org/abs/2211.14133v1)\n", "2211.14053": "- 2022-11-25, **Re^2TAL: Rewiring Pretrained Video Backbones for Reversible Temporal Action Localization**, Chen Zhao et.al., Paper: [http://arxiv.org/abs/2211.14053v1](http://arxiv.org/abs/2211.14053v1)\n", "2211.14005": "- 2022-11-25, **Efficient Feature Extraction for High-resolution Video Frame Interpolation**, Moritz Nottebaum et.al., Paper: [http://arxiv.org/abs/2211.14005v1](http://arxiv.org/abs/2211.14005v1)\n", "2211.13883": "- 2022-11-25, **Learning with Silver Standard Data for Zero-shot Relation Extraction**, Tianyin Wang et.al., Paper: [http://arxiv.org/abs/2211.13883v1](http://arxiv.org/abs/2211.13883v1)\n", "2211.13854": "- 2022-11-25, **ComCLIP: Training-Free Compositional Image and Text Matching**, Kenan Jiang et.al., Paper: [http://arxiv.org/abs/2211.13854v1](http://arxiv.org/abs/2211.13854v1)\n", "2211.13813": "- 2022-11-24, **Multi-label Few-shot ICD Coding as Autoregressive Generation with Prompt**, Zhichao Yang et.al., Paper: [http://arxiv.org/abs/2211.13813v1](http://arxiv.org/abs/2211.13813v1), Code: **[https://github.com/whaleloops/KEPT](https://github.com/whaleloops/KEPT)**\n", "2211.13756": "- 2022-11-24, **Contrastive pretraining for semantic segmentation is robust to noisy positive pairs**, Sebastian Gerard et.al., Paper: [http://arxiv.org/abs/2211.13756v1](http://arxiv.org/abs/2211.13756v1)\n", "2211.13752": "- 2022-11-24, **Sketch-Guided Text-to-Image Diffusion Models**, Andrey Voynov et.al., Paper: [http://arxiv.org/abs/2211.13752v1](http://arxiv.org/abs/2211.13752v1)\n", "2211.13638": "- 2022-11-24, **Prototypical Fine-tuning: Towards Robust Performance Under Varying Data Sizes**, Yiqiao Jin et.al., Paper: [http://arxiv.org/abs/2211.13638v1](http://arxiv.org/abs/2211.13638v1)\n", "2211.15603": "- 2022-11-28, **Action-GPT: Leveraging Large-scale Language Models for Improved and Generalized Zero Shot Action Generation**, Sai Shashank Kalakonda et.al., Paper: [http://arxiv.org/abs/2211.15603v1](http://arxiv.org/abs/2211.15603v1)\n", "2211.15268": "- 2022-11-28, **Scientific and Creative Analogies in Pretrained Language Models**, Tamara Czinczoll et.al., Paper: [http://arxiv.org/abs/2211.15268v1](http://arxiv.org/abs/2211.15268v1)\n", "2211.14905": "- 2022-11-27, **Multi-Modal Few-Shot Temporal Action Detection via Vision-Language Meta-Adaptation**, Sauradip Nag et.al., Paper: [http://arxiv.org/abs/2211.14905v1](http://arxiv.org/abs/2211.14905v1)\n", "2211.14876": "- 2022-11-27, **Dense Text Retrieval based on Pretrained Language Models: A Survey**, Wayne Xin Zhao et.al., Paper: [http://arxiv.org/abs/2211.14876v1](http://arxiv.org/abs/2211.14876v1), Code: **[https://github.com/RUCAIBox/DenseRetrieval](https://github.com/RUCAIBox/DenseRetrieval)**\n", "2211.14875": "- 2022-11-27, **Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5**, Nghi D. Q. Bui et.al., Paper: [http://arxiv.org/abs/2211.14875v1](http://arxiv.org/abs/2211.14875v1)\n", "2211.14860": "- 2022-11-27, **Foiling Explanations in Deep Neural Networks**, Snir Vitrack Tamam et.al., Paper: [http://arxiv.org/abs/2211.14860v1](http://arxiv.org/abs/2211.14860v1)\n", "2211.14785": "- 2022-11-27, **Training Deep Learning Models for Massive MIMO CSI Feedback with Small Datasets in New Environments**, Zhenyu Liu et.al., Paper: [http://arxiv.org/abs/2211.14785v1](http://arxiv.org/abs/2211.14785v1)\n", "2211.14699": "- 2022-11-27, **A Theoretical Study of Inductive Biases in Contrastive Learning**, Jeff Z. HaoChen et.al., Paper: [http://arxiv.org/abs/2211.14699v1](http://arxiv.org/abs/2211.14699v1)\n", "2211.14694": "- 2022-11-27, **DigGAN: Discriminator gradIent Gap Regularization for GAN Training with Limited Data**, Tiantian Fang et.al., Paper: [http://arxiv.org/abs/2211.14694v1](http://arxiv.org/abs/2211.14694v1), Code: **[https://github.com/ailsaf/diggan](https://github.com/ailsaf/diggan)**\n", "2211.14575": "- 2022-11-26, **Randomized Conditional Flow Matching for Video Prediction**, Aram Davtyan et.al., Paper: [http://arxiv.org/abs/2211.14575v1](http://arxiv.org/abs/2211.14575v1)\n", "2211.16349": "- 2022-11-29, **BARTSmiles: Generative Masked Language Models for Molecular Representations**, Gayane Chilingaryan et.al., Paper: [http://arxiv.org/abs/2211.16349v1](http://arxiv.org/abs/2211.16349v1), Code: **[https://github.com/yerevann/bartsmiles](https://github.com/yerevann/bartsmiles)**\n", "2211.16164": "- 2022-11-29, **Few-shot Query-Focused Summarization with Prefix-Merging**, Ruifeng Yuan et.al., Paper: [http://arxiv.org/abs/2211.16164v1](http://arxiv.org/abs/2211.16164v1)\n", "2211.16095": "- 2022-11-29, **Better Generalized Few-Shot Learning Even Without Base Data**, Seongwoong Kim et.al., Paper: [http://arxiv.org/abs/2211.16095v1](http://arxiv.org/abs/2211.16095v1)\n", "2211.16031": "- 2022-11-29, **Syntactic Substitutability as Unsupervised Dependency Syntax**, Jasper Jian et.al., Paper: [http://arxiv.org/abs/2211.16031v1](http://arxiv.org/abs/2211.16031v1)\n", "2211.15992": "- 2022-11-29, **MoDA: Map style transfer for self-supervised Domain Adaptation of embodied agents**, Eun Sun Lee et.al., Paper: [http://arxiv.org/abs/2211.15992v1](http://arxiv.org/abs/2211.15992v1)\n", "2211.15965": "- 2022-11-29, **Extending the Subwording Model of Multilingual Pretrained Models for New Languages**, Kenji Imamura et.al., Paper: [http://arxiv.org/abs/2211.15965v1](http://arxiv.org/abs/2211.15965v1), Code: **[https://github.com/kenji-imamura/sentpiece_mimic](https://github.com/kenji-imamura/sentpiece_mimic)**\n", "2211.15940": "- 2022-11-29, **PiggyBack: Pretrained Visual Question Answering Environment for Backing up Non-deep Learning Professionals**, Zhihao Zhang et.al., Paper: [http://arxiv.org/abs/2211.15940v1](http://arxiv.org/abs/2211.15940v1)\n", "2211.15848": "- 2022-11-29, **ClueWeb22: 10 Billion Web Documents with Rich Information**, Arnold Overwijk et.al., Paper: [http://arxiv.org/abs/2211.15848v1](http://arxiv.org/abs/2211.15848v1)\n", "2211.15817": "- 2022-11-28, **COVID-19 Classification Using Deep Learning Two-Stage Approach**, Mostapha Alsaidi et.al., Paper: [http://arxiv.org/abs/2211.15817v1](http://arxiv.org/abs/2211.15817v1)\n", "2211.15790": "- 2022-11-28, **Handling Image and Label Resolution Mismatch in Remote Sensing**, Scott Workman et.al., Paper: [http://arxiv.org/abs/2211.15790v1](http://arxiv.org/abs/2211.15790v1)\n", "2211.17228": "- 2022-11-30, **AIO-P: Expanding Neural Performance Predictors Beyond Image Classification**, Keith G. Mills et.al., Paper: [http://arxiv.org/abs/2211.17228v1](http://arxiv.org/abs/2211.17228v1), Code: **[https://github.com/Ascend-Research/AIO-P](https://github.com/Ascend-Research/AIO-P)**\n", "2211.17226": "- 2022-11-30, **GENNAPE: Towards Generalized Neural Architecture Performance Estimators**, Keith G. Mills et.al., Paper: [http://arxiv.org/abs/2211.17226v1](http://arxiv.org/abs/2211.17226v1), Code: **[https://github.com/Ascend-Research/GENNAPE](https://github.com/Ascend-Research/GENNAPE)**\n", "2211.17223": "- 2022-11-30, **Topological Data Analysis for Speech Processing**, Eduard Tulchinskii et.al., Paper: [http://arxiv.org/abs/2211.17223v1](http://arxiv.org/abs/2211.17223v1)\n", "2211.17201": "- 2022-11-30, **ExtremeBERT: A Toolkit for Accelerating Pretraining of Customized BERT**, Rui Pan et.al., Paper: [http://arxiv.org/abs/2211.17201v1](http://arxiv.org/abs/2211.17201v1), Code: **[https://github.com/extreme-bert/extreme-bert](https://github.com/extreme-bert/extreme-bert)**\n", "2211.17142": "- 2022-11-30, **Learning Label Modular Prompts for Text Classification in the Wild**, Hailin Chen et.al., Paper: [http://arxiv.org/abs/2211.17142v1](http://arxiv.org/abs/2211.17142v1)\n", "2211.17135": "- 2022-11-30, **BudgetLongformer: Can we Cheaply Pretrain a SotA Legal Language Model From Scratch?**, Joel Niklaus et.al., Paper: [http://arxiv.org/abs/2211.17135v1](http://arxiv.org/abs/2211.17135v1)\n", "2211.16912": "- 2022-11-30, **Quadapter: Adapter for GPT-2 Quantization**, Minseop Park et.al., Paper: [http://arxiv.org/abs/2211.16912v1](http://arxiv.org/abs/2211.16912v1)\n", "2211.16663": "- 2022-11-30, **Geoclidean: Few-Shot Generalization in Euclidean Geometry**, Joy Hsu et.al., Paper: [http://arxiv.org/abs/2211.16663v1](http://arxiv.org/abs/2211.16663v1), Code: **[https://github.com/joyhsu0504/geoclidean_framework](https://github.com/joyhsu0504/geoclidean_framework)**\n", "2211.16594": "- 2022-11-29, **Exploiting Category Names for Few-Shot Classification with Vision-Language Models**, Taihong Xiao et.al., Paper: [http://arxiv.org/abs/2211.16594v1](http://arxiv.org/abs/2211.16594v1)\n", "2212.00790": "- 2022-12-01, **Sparsity Agnostic Depth Completion**, Andrea Conti et.al., Paper: [http://arxiv.org/abs/2212.00790v1](http://arxiv.org/abs/2212.00790v1)\n", "2212.00774": "- 2022-12-01, **Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation**, Haochen Wang et.al., Paper: [http://arxiv.org/abs/2212.00774v1](http://arxiv.org/abs/2212.00774v1), Code: **[https://github.com/pals-ttic/sjc](https://github.com/pals-ttic/sjc)**\n", "2212.00678": "- 2022-12-01, **Adapted Multimodal BERT with Layer-wise Fusion for Sentiment Analysis**, Odysseas S. Chlapanis et.al., Paper: [http://arxiv.org/abs/2212.00678v1](http://arxiv.org/abs/2212.00678v1)\n", "2212.00653": "- 2022-12-01, **Hyperbolic Contrastive Learning for Visual Representations beyond Objects**, Songwei Ge et.al., Paper: [http://arxiv.org/abs/2212.00653v1](http://arxiv.org/abs/2212.00653v1), Code: **[https://github.com/shlokk/hcl](https://github.com/shlokk/hcl)**\n", "2212.00638": "- 2022-12-01, **Finetune like you pretrain: Improved finetuning of zero-shot vision models**, Sachin Goyal et.al., Paper: [http://arxiv.org/abs/2212.00638v1](http://arxiv.org/abs/2212.00638v1), Code: **[https://github.com/locuslab/flyp](https://github.com/locuslab/flyp)**\n", "2212.00596": "- 2022-12-01, **Language models and brain alignment: beyond word-level semantics and prediction**, Gabriele Merlin et.al., Paper: [http://arxiv.org/abs/2212.00596v1](http://arxiv.org/abs/2212.00596v1)\n", "2212.00482": "- 2022-12-01, **IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn Response Selection**, Jingcheng Deng et.al., Paper: [http://arxiv.org/abs/2212.00482v1](http://arxiv.org/abs/2212.00482v1), Code: **[https://github.com/djc-go-solo/irrgn](https://github.com/djc-go-solo/irrgn)**\n", "2212.00281": "- 2022-12-01, **Localization vs. Semantics: How Can Language Benefit Visual Representation Learning?**, Zhuowan Li et.al., Paper: [http://arxiv.org/abs/2212.00281v1](http://arxiv.org/abs/2212.00281v1)\n", "2212.01378": "- 2022-12-02, **ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning**, Shachar Don-Yehiya et.al., Paper: [http://arxiv.org/abs/2212.01378v1](http://arxiv.org/abs/2212.01378v1)\n", "2212.01173": "- 2022-12-02, **DWRSeg: Dilation-wise Residual Network for Real-time Semantic Segmentation**, Haoran Wei et.al., Paper: [http://arxiv.org/abs/2212.01173v1](http://arxiv.org/abs/2212.01173v1)\n", "2212.01140": "- 2022-12-02, **Tackling Low-Resourced Sign Language Translation: UPC at WMT-SLT 22**, Laia Tarr\u00e9s et.al., Paper: [http://arxiv.org/abs/2212.01140v1](http://arxiv.org/abs/2212.01140v1)\n", "2212.00986": "- 2022-12-02, **Masked Contrastive Pre-Training for Efficient Video-Text Retrieval**, Fangxun Shu et.al., Paper: [http://arxiv.org/abs/2212.00986v1](http://arxiv.org/abs/2212.00986v1)\n", "2212.00847": "- 2022-12-01, **Weakly Supervised Annotations for Multi-modal Greeting Cards Dataset**, Sidra Hanif et.al., Paper: [http://arxiv.org/abs/2212.00847v1](http://arxiv.org/abs/2212.00847v1)\n", "2212.00822": "- 2022-12-01, **Navigating an Ocean of Video Data: Deep Learning for Humpback Whale Classification in YouTube Videos**, Michelle Ramirez et.al., Paper: [http://arxiv.org/abs/2212.00822v1](http://arxiv.org/abs/2212.00822v1)\n", "2302.08427": "- 2023-02-16, **Learning to diagnose cirrhosis from radiological and histological labels with joint self and weakly-supervised pretraining strategies**, Emma Sarfati et.al., Paper: [http://arxiv.org/abs/2302.08427v1](http://arxiv.org/abs/2302.08427v1)\n", "2302.08268": "- 2023-02-16, **Retrieval-augmented Image Captioning**, Rita Ramos et.al., Paper: [http://arxiv.org/abs/2302.08268v1](http://arxiv.org/abs/2302.08268v1), Code: **[https://github.com/ritaramo/extra](https://github.com/ritaramo/extra)**\n", "2302.08091": "- 2023-02-16, **Do We Still Need Clinical Language Models?**, Eric Lehman et.al., Paper: [http://arxiv.org/abs/2302.08091v1](http://arxiv.org/abs/2302.08091v1)\n", "2302.08007": "- 2023-02-16, **Shared Microexponents: A Little Shifting Goes a Long Way**, Bita Rouhani et.al., Paper: [http://arxiv.org/abs/2302.08007v1](http://arxiv.org/abs/2302.08007v1)\n", "2302.07937": "- 2023-02-15, **The Expressive Power of Tuning Only the Norm Layers**, Angeliki Giannou et.al., Paper: [http://arxiv.org/abs/2302.07937v1](http://arxiv.org/abs/2302.07937v1)\n", "2302.07926": "- 2023-02-15, **Commonsense Reasoning for Conversational AI: A Survey of the State of the Art**, Christopher Richardson et.al., Paper: [http://arxiv.org/abs/2302.07926v1](http://arxiv.org/abs/2302.07926v1)\n", "2302.07912": "- 2023-02-15, **Meeting the Needs of Low-Resource Languages: The Value of Automatic Alignments via Pretrained Models**, Abteen Ebrahimi et.al., Paper: [http://arxiv.org/abs/2302.07912v1](http://arxiv.org/abs/2302.07912v1)\n", "2302.07388": "- 2023-02-14, **Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models**, Shrimai Prabhumoye et.al., Paper: [http://arxiv.org/abs/2302.07388v1](http://arxiv.org/abs/2302.07388v1)\n", "2302.07371": "- 2023-02-14, **AutoBiasTest: Controllable Sentence Generation for Automated and Open-Ended Social Bias Testing in Language Models**, Rafal Kocielnik et.al., Paper: [http://arxiv.org/abs/2302.07371v1](http://arxiv.org/abs/2302.07371v1)\n", "2302.07324": "- 2023-02-14, **READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input Noises**, Chenglei Si et.al., Paper: [http://arxiv.org/abs/2302.07324v1](http://arxiv.org/abs/2302.07324v1), Code: **[https://github.com/thunlp/readin](https://github.com/thunlp/readin)**\n", "2302.09042": "- 2023-02-17, **Privately Customizing Prefinetuning to Better Match User Data in Federated Learning**, Charlie Hou et.al., Paper: [http://arxiv.org/abs/2302.09042v1](http://arxiv.org/abs/2302.09042v1)\n", "2302.08582": "- 2023-02-16, **Pretraining Language Models with Human Preferences**, Tomasz Korbak et.al., Paper: [http://arxiv.org/abs/2302.08582v1](http://arxiv.org/abs/2302.08582v1)\n", "2302.08908": "- 2023-02-16, **LayoutDiffuse: Adapting Foundational Diffusion Models for Layout-to-Image Generation**, Jiaxin Cheng et.al., Paper: [http://arxiv.org/abs/2302.08908v1](http://arxiv.org/abs/2302.08908v1)\n", "2302.10174": "- 2023-02-20, **Towards Universal Fake Image Detectors that Generalize Across Generative Models**, Utkarsh Ojha et.al., Paper: [http://arxiv.org/abs/2302.10174v1](http://arxiv.org/abs/2302.10174v1)\n", "2302.10167": "- 2023-02-20, **Cross-domain Compositing with Pretrained Diffusion Models**, Roy Hachnochi et.al., Paper: [http://arxiv.org/abs/2302.10167v1](http://arxiv.org/abs/2302.10167v1), Code: **[https://github.com/cross-domain-compositing/cross-domain-compositing](https://github.com/cross-domain-compositing/cross-domain-compositing)**\n", "2302.10093": "- 2023-02-20, **Progressive Knowledge Distillation: Building Ensembles for Efficient Inference**, Don Kurian Dennis et.al., Paper: [http://arxiv.org/abs/2302.10093v1](http://arxiv.org/abs/2302.10093v1)\n", "2302.09833": "- 2023-02-20, **Domain-Specific Pretraining Improves Confidence in Whole Slide Image Classification**, Soham Rohit Chitnis et.al., Paper: [http://arxiv.org/abs/2302.09833v1](http://arxiv.org/abs/2302.09833v1)\n", "2302.09778": "- 2023-02-20, **Composer: Creative and Controllable Image Synthesis with Composable Conditions**, Lianghua Huang et.al., Paper: [http://arxiv.org/abs/2302.09778v1](http://arxiv.org/abs/2302.09778v1)\n", "2302.09509": "- 2023-02-19, **Text Classification in the Wild: a Large-scale Long-tailed Name Normalization Dataset**, Jiexing Qi et.al., Paper: [http://arxiv.org/abs/2302.09509v1](http://arxiv.org/abs/2302.09509v1), Code: **[https://github.com/lumia-group/lot-insts](https://github.com/lumia-group/lot-insts)**\n", "2302.09502": "- 2023-02-19, **Self-supervised Cloth Reconstruction via Action-conditioned Cloth Tracking**, Zixuan Huang et.al., Paper: [http://arxiv.org/abs/2302.09502v1](http://arxiv.org/abs/2302.09502v1)\n", "2302.09483": "- 2023-02-19, **Why Is Public Pretraining Necessary for Private Model Training?**, Arun Ganesh et.al., Paper: [http://arxiv.org/abs/2302.09483v1](http://arxiv.org/abs/2302.09483v1)\n", "2302.09458": "- 2023-02-19, **Learning Language Representations with Logical Inductive Bias**, Jianshu Chen et.al., Paper: [http://arxiv.org/abs/2302.09458v1](http://arxiv.org/abs/2302.09458v1)\n", "2302.09419": "- 2023-02-18, **A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT**, Ce Zhou et.al., Paper: [http://arxiv.org/abs/2302.09419v1](http://arxiv.org/abs/2302.09419v1)\n", "2302.10688": "- 2023-02-21, **On Calibrating Diffusion Probabilistic Models**, Tianyu Pang et.al., Paper: [http://arxiv.org/abs/2302.10688v1](http://arxiv.org/abs/2302.10688v1), Code: **[https://github.com/thudzj/calibrated-dpms](https://github.com/thudzj/calibrated-dpms)**\n", "2302.10646": "- 2023-02-21, **Playing the Werewolf game with artificial intelligence for language understanding**, Hisaichi Shibata et.al., Paper: [http://arxiv.org/abs/2302.10646v1](http://arxiv.org/abs/2302.10646v1)\n", "2302.10501": "- 2023-02-21, **Few-Shot Point Cloud Semantic Segmentation via Contrastive Self-Supervision and Multi-Resolution Attention**, Jiahui Wang et.al., Paper: [http://arxiv.org/abs/2302.10501v1](http://arxiv.org/abs/2302.10501v1)\n", "2302.11259": "- 2023-02-22, **Transfer Learning Enhanced Full Waveform Inversion**, Stefan Kollmannsberger et.al., Paper: [http://arxiv.org/abs/2302.11259v1](http://arxiv.org/abs/2302.11259v1)\n", "2302.11254": "- 2023-02-22, **Cross-modal Audio-visual Co-learning for Text-independent Speaker Verification**, Meng Liu et.al., Paper: [http://arxiv.org/abs/2302.11254v1](http://arxiv.org/abs/2302.11254v1), Code: **[https://github.com/danielmengliu/audiovisuallip](https://github.com/danielmengliu/audiovisuallip)**\n", "2302.11154": "- 2023-02-22, **Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities**, Hexiang Hu et.al., Paper: [http://arxiv.org/abs/2302.11154v1](http://arxiv.org/abs/2302.11154v1)\n", "2302.10924": "- 2023-02-21, **A Reinforcement Learning Framework for Online Speaker Diarization**, Baihan Lin et.al., Paper: [http://arxiv.org/abs/2302.10924v1](http://arxiv.org/abs/2302.10924v1)\n", "2302.12238": "- 2023-02-23, **Improving Adaptive Conformal Prediction Using Self-Supervised Learning**, Nabeel Seedat et.al., Paper: [http://arxiv.org/abs/2302.12238v1](http://arxiv.org/abs/2302.12238v1), Code: **[https://github.com/seedatnabeel/sscp](https://github.com/seedatnabeel/sscp)**\n", "2302.11940": "- 2023-02-23, **Uncertainty Guided Ensemble Self-Training for Semi-Supervised Global Field Reconstruction**, Yunyang Zhang et.al., Paper: [http://arxiv.org/abs/2302.11940v1](http://arxiv.org/abs/2302.11940v1), Code: **[https://github.com/meitounao110/uge-st](https://github.com/meitounao110/uge-st)**\n", "2302.11939": "- 2023-02-23, **Power Time Series Forecasting by Pretrained LM**, Tian Zhou et.al., Paper: [http://arxiv.org/abs/2302.11939v1](http://arxiv.org/abs/2302.11939v1)\n", "2302.11893": "- 2023-02-23, **A framework for benchmarking class-out-of-distribution detection and its application to ImageNet**, Ido Galil et.al., Paper: [http://arxiv.org/abs/2302.11893v1](http://arxiv.org/abs/2302.11893v1), Code: **[https://github.com/mdabbah/COOD_benchmarking](https://github.com/mdabbah/COOD_benchmarking)**\n", "2302.11874": "- 2023-02-23, **What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers**, Ido Galil et.al., Paper: [http://arxiv.org/abs/2302.11874v1](http://arxiv.org/abs/2302.11874v1), Code: **[https://github.com/idogalil/benchmarking-uncertainty-estimation-performance](https://github.com/idogalil/benchmarking-uncertainty-estimation-performance)**\n", "2302.11730": "- 2023-02-23, **Detachedly Learn a Classifier for Class-Incremental Learning**, Ziheng Li et.al., Paper: [http://arxiv.org/abs/2302.11730v1](http://arxiv.org/abs/2302.11730v1)\n", "2302.11716": "- 2023-02-23, **An efficient method for Out-of-Distribution Detection**, Mingyu Xu et.al., Paper: [http://arxiv.org/abs/2302.11716v1](http://arxiv.org/abs/2302.11716v1)\n", "2302.11705": "- 2023-02-22, **ACE: Zero-Shot Image to Image Translation via Pretrained Auto-Contrastive-Encoder**, Sihan Xu et.al., Paper: [http://arxiv.org/abs/2302.11705v1](http://arxiv.org/abs/2302.11705v1), Code: **[https://github.com/sihanxu/ace](https://github.com/sihanxu/ace)**\n", "2302.11649": "- 2023-02-22, **Lang2LTL: Translating Natural Language Commands to Temporal Robot Task Specification**, Jason Xinyu Liu et.al., Paper: [http://arxiv.org/abs/2302.11649v1](http://arxiv.org/abs/2302.11649v1)\n", "2302.12764": "- 2023-02-24, **Modulating Pretrained Diffusion Models for Multimodal Image Synthesis**, Cusuh Ham et.al., Paper: [http://arxiv.org/abs/2302.12764v1](http://arxiv.org/abs/2302.12764v1)\n", "2302.12692": "- 2023-02-27, **Language Models are Few-shot Learners for Prognostic Prediction**, Zekai Chen et.al., Paper: [http://arxiv.org/abs/2302.12692v2](http://arxiv.org/abs/2302.12692v2)\n", "2302.12562": "- 2023-02-24, **A Knowledge Distillation framework for Multi-Organ Segmentation of Medaka Fish in Tomographic Image**, Jwalin Bhatt et.al., Paper: [http://arxiv.org/abs/2302.12562v1](http://arxiv.org/abs/2302.12562v1)\n", "2302.12297": "- 2023-02-23, **Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views**, Katerina Margatina et.al., Paper: [http://arxiv.org/abs/2302.12297v1](http://arxiv.org/abs/2302.12297v1)\n", "2302.13869": "- 2023-02-27, **EDMAE: An Efficient Decoupled Masked Autoencoder for Standard View Identification in Pediatric Echocardiography**, Yiman Liu et.al., Paper: [http://arxiv.org/abs/2302.13869v1](http://arxiv.org/abs/2302.13869v1)\n", "2302.13668": "- 2023-02-27, **Contrastive Video Question Answering via Video Graph Transformer**, Junbin Xiao et.al., Paper: [http://arxiv.org/abs/2302.13668v1](http://arxiv.org/abs/2302.13668v1)\n", "2302.13661": "- 2023-02-27, **Using Auxiliary Tasks In Multimodal Fusion Of Wav2vec 2.0 And BERT For Multimodal Emotion Recognition**, Dekai Sun et.al., Paper: [http://arxiv.org/abs/2302.13661v1](http://arxiv.org/abs/2302.13661v1)\n", "2302.13498": "- 2023-02-27, **Pretraining De-Biased Language Model with Large-scale Click Logs for Document Ranking**, Xiangsheng Li et.al., Paper: [http://arxiv.org/abs/2302.13498v1](http://arxiv.org/abs/2302.13498v1)\n", "2302.13485": "- 2023-02-27, **FedCLIP: Fast Generalization and Personalization for CLIP in Federated Learning**, Wang Lu et.al., Paper: [http://arxiv.org/abs/2302.13485v1](http://arxiv.org/abs/2302.13485v1), Code: **[https://github.com/microsoft/personalizedfl](https://github.com/microsoft/personalizedfl)**\n", "2302.13289": "- 2023-02-26, **Improving Representational Continuity via Continued Pretraining**, Michael Sun et.al., Paper: [http://arxiv.org/abs/2302.13289v1](http://arxiv.org/abs/2302.13289v1)\n", "2302.13136": "- 2023-02-25, **Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling**, Rui Wang et.al., Paper: [http://arxiv.org/abs/2302.13136v1](http://arxiv.org/abs/2302.13136v1)\n", "2302.13086": "- 2023-02-25, **Self-Supervised and Supervised Deep Learning for PET Image Reconstruction**, Andrew J. Reader et.al., Paper: [http://arxiv.org/abs/2302.13086v1](http://arxiv.org/abs/2302.13086v1)\n", "2302.14691": "- 2023-02-28, **In-Context Instruction Learning**, Seonghyeon Ye et.al., Paper: [http://arxiv.org/abs/2302.14691v1](http://arxiv.org/abs/2302.14691v1), Code: **[https://github.com/seonghyeonye/icil](https://github.com/seonghyeonye/icil)**\n", "2302.14623": "- 2023-02-28, **Fast as CHITA: Neural Network Pruning with Combinatorial Optimization**, Riade Benbaki et.al., Paper: [http://arxiv.org/abs/2302.14623v1](http://arxiv.org/abs/2302.14623v1)\n", "2302.14604": "- 2023-02-28, **IQ-Flow: Mechanism Design for Inducing Cooperative Behavior to Self-Interested Agents in Sequential Social Dilemmas**, Bengisu Guresti et.al., Paper: [http://arxiv.org/abs/2302.14604v1](http://arxiv.org/abs/2302.14604v1), Code: **[https://github.com/data-and-decision-lab/iq-flow](https://github.com/data-and-decision-lab/iq-flow)**\n", "2302.14367": "- 2023-02-28, **BrainBERT: Self-supervised representation learning for intracranial recordings**, Christopher Wang et.al., Paper: [http://arxiv.org/abs/2302.14367v1](http://arxiv.org/abs/2302.14367v1), Code: **[https://github.com/czlwang/brainbert](https://github.com/czlwang/brainbert)**\n", "2302.14338": "- 2023-03-01, **Turning a CLIP Model into a Scene Text Detector**, Wenwen Yu et.al., Paper: [http://arxiv.org/abs/2302.14338v2](http://arxiv.org/abs/2302.14338v2)\n", "2302.14256": "- 2023-02-28, **Remote Sensing Scene Classification with Masked Image Modeling (MIM)**, Liya Wang et.al., Paper: [http://arxiv.org/abs/2302.14256v1](http://arxiv.org/abs/2302.14256v1)\n", "2302.14231": "- 2023-02-28, **CHGNet: Pretrained universal neural network potential for charge-informed atomistic modeling**, Bowen Deng et.al., Paper: [http://arxiv.org/abs/2302.14231v1](http://arxiv.org/abs/2302.14231v1), Code: **[https://github.com/CederGroupHub/chgnet](https://github.com/CederGroupHub/chgnet)**\n", "2302.14225": "- 2023-02-28, **Weighted Sampling for Masked Language Modeling**, Linhan Zhang et.al., Paper: [http://arxiv.org/abs/2302.14225v1](http://arxiv.org/abs/2302.14225v1)\n", "2302.14220": "- 2023-02-28, **Are Character-level Translations Worth the Wait? An Extensive Comparison of Character- and Subword-level Models for Machine Translation**, Lukas Edman et.al., Paper: [http://arxiv.org/abs/2302.14220v1](http://arxiv.org/abs/2302.14220v1)\n", "2302.14141": "- 2023-02-27, **Linear pretraining in recurrent mixture density networks**, Hubert Normandin-Taillon et.al., Paper: [http://arxiv.org/abs/2302.14141v1](http://arxiv.org/abs/2302.14141v1)\n", "2303.00534": "- 2023-03-01, **RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training**, Zheng Yuan et.al., Paper: [http://arxiv.org/abs/2303.00534v1](http://arxiv.org/abs/2303.00534v1)\n", "2303.00333": "- 2023-03-01, **Competence-Based Analysis of Language Models**, Adam Davies et.al., Paper: [http://arxiv.org/abs/2303.00333v1](http://arxiv.org/abs/2303.00333v1)\n", "2303.00261": "- 2023-03-01, **Speeding Up EfficientNet: Selecting Update Blocks of Convolutional Neural Networks using Genetic Algorithm in Transfer Learning**, Md. Mehedi Hasana et.al., Paper: [http://arxiv.org/abs/2303.00261v1](http://arxiv.org/abs/2303.00261v1)\n", "2303.01491": "- 2023-03-02, **Transferring Models Trained on Natural Images to 3D MRI via Position Encoded Slice Models**, Umang Gupta et.al., Paper: [http://arxiv.org/abs/2303.01491v1](http://arxiv.org/abs/2303.01491v1), Code: **[https://github.com/umgupta/2d-slice-set-networks](https://github.com/umgupta/2d-slice-set-networks)**\n", "2303.01313": "- 2023-03-02, **Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning**, Bo Wan et.al., Paper: [http://arxiv.org/abs/2303.01313v1](http://arxiv.org/abs/2303.01313v1)\n", "2303.01239": "- 2023-03-02, **MixPHM: Redundancy-Aware Parameter-Efficient Tuning for Low-Resource Visual Question Answering**, Jingjing Jiang et.al., Paper: [http://arxiv.org/abs/2303.01239v1](http://arxiv.org/abs/2303.01239v1), Code: **[https://github.com/jingjing12110/mixphm](https://github.com/jingjing12110/mixphm)**\n", "2303.01237": "- 2023-03-02, **FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical Flow Estimation**, Xiaoyu Shi et.al., Paper: [http://arxiv.org/abs/2303.01237v1](http://arxiv.org/abs/2303.01237v1)\n", "2303.00996": "- 2023-03-02, **Unsupervised Meta-Learning via Few-shot Pseudo-supervised Contrastive Learning**, Huiwon Jang et.al., Paper: [http://arxiv.org/abs/2303.00996v1](http://arxiv.org/abs/2303.00996v1), Code: **[https://github.com/alinlab/psco](https://github.com/alinlab/psco)**\n", "2303.00980": "- 2023-03-02, **Learning to Grow Pretrained Models for Efficient Transformer Training**, Peihao Wang et.al., Paper: [http://arxiv.org/abs/2303.00980v1](http://arxiv.org/abs/2303.00980v1)\n", "2303.00973": "- 2023-03-02, **Image Labels Are All You Need for Coarse Seagrass Segmentation**, Scarlett Raine et.al., Paper: [http://arxiv.org/abs/2303.00973v1](http://arxiv.org/abs/2303.00973v1), Code: **[https://github.com/sgraine/bag-of-seagrass](https://github.com/sgraine/bag-of-seagrass)**\n", "2303.00917": "- 2023-03-02, **Enhancing General Face Forgery Detection via Vision Transformer with Low-Rank Adaptation**, Chenqi Kong et.al., Paper: [http://arxiv.org/abs/2303.00917v1](http://arxiv.org/abs/2303.00917v1)\n", "2303.00915": "- 2023-03-02, **Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language Processing**, Sheng Zhang et.al., Paper: [http://arxiv.org/abs/2303.00915v1](http://arxiv.org/abs/2303.00915v1)\n", "2303.02095": "- 2023-03-03, **Data-Efficient Training of CNNs and Transformers with Coresets: A Stability Perspective**, Animesh Gupta et.al., Paper: [http://arxiv.org/abs/2303.02095v1](http://arxiv.org/abs/2303.02095v1), Code: **[https://github.com/transmuteai/data-efficient-transformers](https://github.com/transmuteai/data-efficient-transformers)**\n", "2303.01913": "- 2023-03-03, **Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment**, Jong-Ryul Lee et.al., Paper: [http://arxiv.org/abs/2303.01913v1](http://arxiv.org/abs/2303.01913v1)\n", "2303.01818": "- 2023-03-03, **Word-As-Image for Semantic Typography**, Shir Iluz et.al., Paper: [http://arxiv.org/abs/2303.01818v1](http://arxiv.org/abs/2303.01818v1)\n", "2303.01794": "- 2023-03-03, **Team Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News**, Yuta Koreeda et.al., Paper: [http://arxiv.org/abs/2303.01794v1](http://arxiv.org/abs/2303.01794v1)\n", "2303.01740": "- 2023-03-03, **DeepfakeMAE: Facial Part Consistency Aware Masked Autoencoder for Deepfake Video Detection**, Juan Hu et.al., Paper: [http://arxiv.org/abs/2303.01740v1](http://arxiv.org/abs/2303.01740v1)\n", "2303.01605": "- 2023-03-02, **Hierarchical discriminative learning improves visual representations of biomedical microscopy**, Cheng Jiang et.al., Paper: [http://arxiv.org/abs/2303.01605v1](http://arxiv.org/abs/2303.01605v1)\n", "2303.01584": "- 2023-03-02, **Evolutionary Augmentation Policy Optimization for Self-supervised Learning**, Noah Barrett et.al., Paper: [http://arxiv.org/abs/2303.01584v1](http://arxiv.org/abs/2303.01584v1)\n", "2303.01566": "- 2023-03-02, **On the Provable Advantage of Unsupervised Pretraining**, Jiawei Ge et.al., Paper: [http://arxiv.org/abs/2303.01566v1](http://arxiv.org/abs/2303.01566v1)\n", "2303.03323": "- 2023-03-06, **CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning**, Hritik Bansal et.al., Paper: [http://arxiv.org/abs/2303.03323v1](http://arxiv.org/abs/2303.03323v1)\n", "2303.03144": "- 2023-03-06, **IPA-CLIP: Integrating Phonetic Priors into Vision and Language Pretraining**, Chihaya Matsuhira et.al., Paper: [http://arxiv.org/abs/2303.03144v1](http://arxiv.org/abs/2303.03144v1)\n", "2303.03127": "- 2023-03-06, **ST-KeyS: Self-Supervised Transformer for Keyword Spotting in Historical Handwritten Documents**, Sana Khamekhem Jemni et.al., Paper: [http://arxiv.org/abs/2303.03127v1](http://arxiv.org/abs/2303.03127v1)\n", "2303.02995": "- 2023-03-06, **HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention**, Shijie Geng et.al., Paper: [http://arxiv.org/abs/2303.02995v1](http://arxiv.org/abs/2303.02995v1), Code: **[https://github.com/jeykigung/hiclip](https://github.com/jeykigung/hiclip)**\n", "2303.02861": "- 2023-03-06, **Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning**, Zhen Wang et.al., Paper: [http://arxiv.org/abs/2303.02861v1](http://arxiv.org/abs/2303.02861v1)\n", "2303.02717": "- 2023-03-05, **Learning to Localize in Unseen Scenes with Relative Pose Regressors**, Ofer Idan et.al., Paper: [http://arxiv.org/abs/2303.02717v1](http://arxiv.org/abs/2303.02717v1), Code: **[https://github.com/yolish/relformer](https://github.com/yolish/relformer)**\n", "2303.02668": "- 2023-03-05, **Knowledge-Enhanced Semi-Supervised Federated Learning for Aggregating Heterogeneous Lightweight Clients in IoT**, Jiaqi Wang et.al., Paper: [http://arxiv.org/abs/2303.02668v1](http://arxiv.org/abs/2303.02668v1)\n", "2303.02648": "- 2023-03-05, **Comparative study of Transformer and LSTM Network with attention mechanism on Image Captioning**, Pranav Dandwate et.al., Paper: [http://arxiv.org/abs/2303.02648v1](http://arxiv.org/abs/2303.02648v1)\n", "2303.02577": "- 2023-03-05, **Effectiveness of Data Augmentation for Prefix Tuning with Limited Data**, Stephen Obadinma et.al., Paper: [http://arxiv.org/abs/2303.02577v1](http://arxiv.org/abs/2303.02577v1)\n", "2303.02489": "- 2023-03-04, **CapDet: Unifying Dense Captioning and Open-World Detection Pretraining**, Yanxin Long et.al., Paper: [http://arxiv.org/abs/2303.02489v1](http://arxiv.org/abs/2303.02489v1)\n", "2303.04143": "- 2023-03-07, **Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?**, Boris Knyazev et.al., Paper: [http://arxiv.org/abs/2303.04143v1](http://arxiv.org/abs/2303.04143v1), Code: **[https://github.com/samsungsailmontreal/ghn3](https://github.com/samsungsailmontreal/ghn3)**\n", "2303.04129": "- 2023-03-07, **Foundation Models for Decision Making: Problems, Methods, and Opportunities**, Sherry Yang et.al., Paper: [http://arxiv.org/abs/2303.04129v1](http://arxiv.org/abs/2303.04129v1)\n", "2303.04092": "- 2023-03-07, **CroCoSum: A Benchmark Dataset for Cross-Lingual Code-Switched Summarization**, Ruochen Zhang et.al., Paper: [http://arxiv.org/abs/2303.04092v1](http://arxiv.org/abs/2303.04092v1)\n", "2303.03846": "- 2023-03-07, **Larger language models do in-context learning differently**, Jerry Wei et.al., Paper: [http://arxiv.org/abs/2303.03846v1](http://arxiv.org/abs/2303.03846v1)\n", "2303.03800": "- 2023-03-07, **Lformer: Text-to-Image Generation with L-shape Block Parallel Decoding**, Jiacheng Li et.al., Paper: [http://arxiv.org/abs/2303.03800v1](http://arxiv.org/abs/2303.03800v1)\n", "2303.03695": "- 2023-03-07, **Prediction of transonic flow over supercritical airfoils using geometric-encoding and deep-learning strategies**, Zhiwen Deng et.al., Paper: [http://arxiv.org/abs/2303.03695v1](http://arxiv.org/abs/2303.03695v1)\n", "2303.03689": "- 2023-03-07, **AST-SED: An Effective Sound Event Detection Method Based on Audio Spectrogram Transformer**, Kang Li et.al., Paper: [http://arxiv.org/abs/2303.03689v1](http://arxiv.org/abs/2303.03689v1)\n", "2303.03472": "- 2023-03-06, **Structured Kernel Estimation for Photon-Limited Deconvolution**, Yash Sanghvi et.al., Paper: [http://arxiv.org/abs/2303.03472v1](http://arxiv.org/abs/2303.03472v1), Code: **[https://github.com/sanghviyashiitb/structured-kernel-cvpr23](https://github.com/sanghviyashiitb/structured-kernel-cvpr23)**\n", "2303.04681": "- 2023-03-08, **Enhancing Low-resolution Face Recognition with Feature Similarity Knowledge Distillation**, Sungho Shin et.al., Paper: [http://arxiv.org/abs/2303.04681v1](http://arxiv.org/abs/2303.04681v1)\n", "2303.04654": "- 2023-03-08, **Aberration-Aware Depth-from-Focus**, Xinge Yang et.al., Paper: [http://arxiv.org/abs/2303.04654v1](http://arxiv.org/abs/2303.04654v1)\n", "2303.04508": "- 2023-03-08, **FastSurf: Fast Neural RGB-D Surface Reconstruction using Per-Frame Intrinsic Refinement and TSDF Fusion Prior Learning**, Seunghwan Lee et.al., Paper: [http://arxiv.org/abs/2303.04508v1](http://arxiv.org/abs/2303.04508v1)\n", "2303.04485": "- 2023-03-08, **Onsets and Velocities: Affordable Real-Time Piano Transcription Using Convolutional Neural Networks**, Andres Fernandez et.al., Paper: [http://arxiv.org/abs/2303.04485v1](http://arxiv.org/abs/2303.04485v1), Code: **[https://github.com/andres-fr/iamusica_demo](https://github.com/andres-fr/iamusica_demo)**\n", "2303.04269": "- 2023-03-07, **PSDNet: Determination of Particle Size Distributions Using Synthetic Soil Images and Convolutional Neural Networks**, Javad Manashti et.al., Paper: [http://arxiv.org/abs/2303.04269v1](http://arxiv.org/abs/2303.04269v1)\n", "2303.04265": "- 2023-03-07, **Comparing PSDNet, pretrained networks, and traditional feature extraction for predicting the particle size distribution of granular materials from photographs**, Javad Manashti et.al., Paper: [http://arxiv.org/abs/2303.04265v1](http://arxiv.org/abs/2303.04265v1)\n", "2303.04238": "- 2023-03-09, **Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on Object Detectors**, Raz Lapid et.al., Paper: [http://arxiv.org/abs/2303.04238v2](http://arxiv.org/abs/2303.04238v2)\n", "2303.05416": "- 2023-03-09, **FaceXHuBERT: Text-less Speech-driven E(X)pressive 3D Facial Animation Synthesis Using Self-Supervised Speech Representation Learning**, Kazi Injamamul Haque et.al., Paper: [http://arxiv.org/abs/2303.05416v1](http://arxiv.org/abs/2303.05416v1), Code: **[https://github.com/galib360/facexhubert](https://github.com/galib360/facexhubert)**\n", "2303.05378": "- 2023-03-09, **Greener yet Powerful: Taming Large Code Generation Models with Quantization**, Xiaokai Wei et.al., Paper: [http://arxiv.org/abs/2303.05378v1](http://arxiv.org/abs/2303.05378v1)\n", "2303.05153": "- 2023-03-09, **Can a Frozen Pretrained Language Model be used for Zero-shot Neural Retrieval on Entity-centric Questions?**, Yasuto Hoshi et.al., Paper: [http://arxiv.org/abs/2303.05153v1](http://arxiv.org/abs/2303.05153v1)\n", "2303.06135": "- 2023-03-10, **Rewarding Chatbots for Real-World Engagement with Millions of Users**, Robert Irvine et.al., Paper: [http://arxiv.org/abs/2303.06135v1](http://arxiv.org/abs/2303.06135v1)\n", "2303.06088": "- 2023-03-13, **Improving Domain-Invariance in Self-Supervised Learning via Batch Styles Standardization**, Marin Scalbert et.al., Paper: [http://arxiv.org/abs/2303.06088v2](http://arxiv.org/abs/2303.06088v2)\n", "2303.06042": "- 2023-03-10, **MVImgNet: A Large-scale Dataset of Multi-view Images**, Xianggang Yu et.al., Paper: [http://arxiv.org/abs/2303.06042v1](http://arxiv.org/abs/2303.06042v1)\n", "2303.05929": "- 2023-03-10, **Marginalia and machine learning: Handwritten text recognition for Marginalia Collections**, Adam Axelsson et.al., Paper: [http://arxiv.org/abs/2303.05929v1](http://arxiv.org/abs/2303.05929v1), Code: **[https://github.com/ektavats/project-marginalia](https://github.com/ektavats/project-marginalia)**\n", "2303.05892": "- 2023-03-10, **Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection**, Luting Wang et.al., Paper: [http://arxiv.org/abs/2303.05892v1](http://arxiv.org/abs/2303.05892v1)\n", "2303.05861": "- 2023-03-10, **3D Masked Autoencoders with Application to Anomaly Detection in Non-Contrast Enhanced Breast MRI**, Daniel M. Lang et.al., Paper: [http://arxiv.org/abs/2303.05861v1](http://arxiv.org/abs/2303.05861v1)\n", "2303.05828": "- 2023-03-10, **Contrastive Language-Image Pretrained (CLIP) Models are Powerful Out-of-Distribution Detectors**, Felix Michels et.al., Paper: [http://arxiv.org/abs/2303.05828v1](http://arxiv.org/abs/2303.05828v1)\n", "2303.05785": "- 2023-03-10, **Scaling Up 3D Kernels with Bayesian Frequency Re-parameterization for Medical Image Segmentation**, Ho Hin Lee et.al., Paper: [http://arxiv.org/abs/2303.05785v1](http://arxiv.org/abs/2303.05785v1)\n", "2303.05725": "- 2023-03-10, **CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language Recognition with Variational Alignment**, Jiangbin Zheng et.al., Paper: [http://arxiv.org/abs/2303.05725v1](http://arxiv.org/abs/2303.05725v1)\n", "2303.05707": "- 2023-03-10, **MuLTI: Efficient Video-and-Language Understanding with MultiWay-Sampler and Multiple Choice Modeling**, Jiaqi Xu et.al., Paper: [http://arxiv.org/abs/2303.05707v1](http://arxiv.org/abs/2303.05707v1)\n", "2303.07320": "- 2023-03-13, **Model-tuning Via Prompts Makes NLP Models Adversarially Robust**, Mrigank Raman et.al., Paper: [http://arxiv.org/abs/2303.07320v1](http://arxiv.org/abs/2303.07320v1)\n", "2303.07280": "- 2023-03-13, **Vision-Language Models as Success Detectors**, Yuqing Du et.al., Paper: [http://arxiv.org/abs/2303.07280v1](http://arxiv.org/abs/2303.07280v1)\n", "2303.07263": "- 2023-03-13, **InferFix: End-to-End Program Repair with LLMs**, Matthew Jin et.al., Paper: [http://arxiv.org/abs/2303.07263v1](http://arxiv.org/abs/2303.07263v1)\n", "2303.07240": "- 2023-03-13, **PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents**, Weixiong Lin et.al., Paper: [http://arxiv.org/abs/2303.07240v1](http://arxiv.org/abs/2303.07240v1)\n", "2303.07129": "- 2023-03-13, **AdaptiveNet: Post-deployment Neural Architecture Adaptation for Diverse Edge Environments**, Hao Wen et.al., Paper: [http://arxiv.org/abs/2303.07129v1](http://arxiv.org/abs/2303.07129v1)\n", "2303.07069": "- 2023-03-13, **Generating multiple-choice questions for medical question answering with distractors and cue-masking**, Damien Sileo et.al., Paper: [http://arxiv.org/abs/2303.07069v1](http://arxiv.org/abs/2303.07069v1)\n", "2303.07034": "- 2023-03-14, **Pretrained ViTs Yield Versatile Representations For Medical Images**, Christos Matsoukas et.al., Paper: [http://arxiv.org/abs/2303.07034v2](http://arxiv.org/abs/2303.07034v2), Code: **[https://github.com/chrismats/medical_transformers](https://github.com/chrismats/medical_transformers)**\n", "2303.06980": "- 2023-03-13, **Self-supervised based general laboratory progress pretrained model for cardiovascular event detection**, Li-Chin Chen et.al., Paper: [http://arxiv.org/abs/2303.06980v1](http://arxiv.org/abs/2303.06980v1)\n", "2303.06965": "- 2023-03-14, **Uni-RXN: A Unified Framework Bridging the Gap between Chemical Reaction Pretraining and Conditional Molecule Generation**, Bo Qiang et.al., Paper: [http://arxiv.org/abs/2303.06965v2](http://arxiv.org/abs/2303.06965v2), Code: **[https://github.com/qiangbo1222/uni-rxn-official](https://github.com/qiangbo1222/uni-rxn-official)**\n", "2303.06904": "- 2023-03-13, **Contextually-rich human affect perception using multimodal scene information**, Digbalay Bose et.al., Paper: [http://arxiv.org/abs/2303.06904v1](http://arxiv.org/abs/2303.06904v1), Code: **[https://github.com/usc-sail/mica-context-emotion-recognition](https://github.com/usc-sail/mica-context-emotion-recognition)**\n", "2303.08138": "- 2023-03-14, **Diversity-Aware Meta Visual Prompting**, Qidong Huang et.al., Paper: [http://arxiv.org/abs/2303.08138v1](http://arxiv.org/abs/2303.08138v1), Code: **[https://github.com/shikiw/dam-vp](https://github.com/shikiw/dam-vp)**\n", "2303.08112": "- 2023-03-15, **Eliciting Latent Predictions from Transformers with the Tuned Lens**, Nora Belrose et.al., Paper: [http://arxiv.org/abs/2303.08112v2](http://arxiv.org/abs/2303.08112v2), Code: **[https://github.com/alignmentresearch/tuned-lens](https://github.com/alignmentresearch/tuned-lens)**\n", "2303.08019": "- 2023-03-14, **Leveraging Pretrained Representations with Task-related Keywords for Alzheimer's Disease Detection**, Jinchao Li et.al., Paper: [http://arxiv.org/abs/2303.08019v1](http://arxiv.org/abs/2303.08019v1)\n", "2303.07971": "- 2023-03-14, **A Theory of Emergent In-Context Learning as Implicit Structure Induction**, Michael Hahn et.al., Paper: [http://arxiv.org/abs/2303.07971v1](http://arxiv.org/abs/2303.07971v1)\n", "2303.07945": "- 2023-03-14, **Edit-A-Video: Single Video Editing with Object-Aware Consistency**, Chaehun Shin et.al., Paper: [http://arxiv.org/abs/2303.07945v1](http://arxiv.org/abs/2303.07945v1)\n", "2303.07937": "- 2023-03-15, **Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation**, Junyoung Seo et.al., Paper: [http://arxiv.org/abs/2303.07937v2](http://arxiv.org/abs/2303.07937v2)\n", "2303.07895": "- 2023-03-14, **The Learnability of In-Context Learning**, Noam Wies et.al., Paper: [http://arxiv.org/abs/2303.07895v1](http://arxiv.org/abs/2303.07895v1)\n", "2303.07865": "- 2023-03-14, **Geolocation Predicting of Tweets Using BERT-Based Models**, Kateryna Lutsai et.al., Paper: [http://arxiv.org/abs/2303.07865v1](http://arxiv.org/abs/2303.07865v1)\n", "2303.07679": "- 2023-03-14, **Feature representations useful for predicting image memorability**, Takumi Harada et.al., Paper: [http://arxiv.org/abs/2303.07679v1](http://arxiv.org/abs/2303.07679v1)\n", "2303.07615": "- 2023-03-14, **Variation of Gender Biases in Visual Recognition Models Before and After Finetuning**, Jaspreet Ranjit et.al., Paper: [http://arxiv.org/abs/2303.07615v1](http://arxiv.org/abs/2303.07615v1)\n", "2303.08789": "- 2023-03-15, **PLEX: Making the Most of the Available Data for Robotic Manipulation Pretraining**, Garrett Thomas et.al., Paper: [http://arxiv.org/abs/2303.08789v1](http://arxiv.org/abs/2303.08789v1)\n", "2303.08740": "- 2023-03-15, **2D and 3D CNN-Based Fusion Approach for COVID-19 Severity Prediction from 3D CT-Scans**, Fares Bougourzi et.al., Paper: [http://arxiv.org/abs/2303.08740v1](http://arxiv.org/abs/2303.08740v1), Code: **[https://github.com/faresbougourzi/3rd-cov19d-competition](https://github.com/faresbougourzi/3rd-cov19d-competition)**\n", "2303.08511": "- 2023-03-15, **Mapping Urban Population Growth from Sentinel-2 MSI and Census Data Using Deep Learning: A Case Study in Kigali, Rwanda**, Sebastian Hafner et.al., Paper: [http://arxiv.org/abs/2303.08511v1](http://arxiv.org/abs/2303.08511v1), Code: **[https://github.com/sebastianhafner/populationgrowthmapping_kigali](https://github.com/sebastianhafner/populationgrowthmapping_kigali)**\n", "2303.08446": "- 2023-03-15, **Task-specific Fine-tuning via Variational Information Bottleneck for Weakly-supervised Pathology Whole Slide Image Classification**, Honglin Li et.al., Paper: [http://arxiv.org/abs/2303.08446v1](http://arxiv.org/abs/2303.08446v1)\n", "2303.08409": "- 2023-03-15, **Lana: A Language-Capable Navigator for Instruction Following and Generation**, Xiaohan Wang et.al., Paper: [http://arxiv.org/abs/2303.08409v1](http://arxiv.org/abs/2303.08409v1), Code: **[https://github.com/wxh1996/lana-vln](https://github.com/wxh1996/lana-vln)**\n", "2303.08303": "- 2023-03-15, **SegPrompt: Using Segmentation Map as a Better Prompt to Finetune Deep Models for Kidney Stone Classification**, Wei Zhu et.al., Paper: [http://arxiv.org/abs/2303.08303v1](http://arxiv.org/abs/2303.08303v1)\n", "2303.08259": "- 2023-03-14, **Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures**, Aokun Chen et.al., Paper: [http://arxiv.org/abs/2303.08259v1](http://arxiv.org/abs/2303.08259v1)\n", "2303.09472": "- 2023-03-16, **DiffIR: Efficient Diffusion Model for Image Restoration**, Bin Xia et.al., Paper: [http://arxiv.org/abs/2303.09472v1](http://arxiv.org/abs/2303.09472v1)\n", "2303.09421": "- 2023-03-16, **Team SheffieldVeraAI at SemEval-2023 Task 3: Mono and multilingual approaches for news genre, topic and persuasion technique classification**, Ben Wu et.al., Paper: [http://arxiv.org/abs/2303.09421v1](http://arxiv.org/abs/2303.09421v1)\n", "2303.09373": "- 2023-03-16, **3D Masked Autoencoding and Pseudo-labeling for Domain Adaptive Segmentation of Heterogeneous Infant Brain MRI**, Xuzhe Zhang et.al., Paper: [http://arxiv.org/abs/2303.09373v1](http://arxiv.org/abs/2303.09373v1)\n", "2303.09268": "- 2023-03-16, **StylerDALLE: Language-Guided Style Transfer Using a Vector-Quantized Tokenizer of a Large-Scale Generative Model**, Zipeng Xu et.al., Paper: [http://arxiv.org/abs/2303.09268v1](http://arxiv.org/abs/2303.09268v1), Code: **[https://github.com/zipengxuc/stylerdalle](https://github.com/zipengxuc/stylerdalle)**\n", "2303.09252": "- 2023-03-16, **GridCLIP: One-Stage Object Detection by Grid-Level CLIP Representation Learning**, Jiayi Lin et.al., Paper: [http://arxiv.org/abs/2303.09252v1](http://arxiv.org/abs/2303.09252v1)\n", "2303.09167": "- 2023-03-16, **Emotional Reaction Intensity Estimation Based on Multimodal Data**, Shangfei Wang et.al., Paper: [http://arxiv.org/abs/2303.09167v1](http://arxiv.org/abs/2303.09167v1)\n", "2303.08986": "- 2023-03-15, **Deep Learning Weight Pruning with RMT-SVD: Increasing Accuracy and Reducing Overfitting**, Yitzchak Shmalo et.al., Paper: [http://arxiv.org/abs/2303.08986v1](http://arxiv.org/abs/2303.08986v1), Code: **[https://github.com/jtj5311/nn-rmt-svd](https://github.com/jtj5311/nn-rmt-svd)**\n", "2303.08983": "- 2023-03-15, **Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement**, Fartash Faghri et.al., Paper: [http://arxiv.org/abs/2303.08983v1](http://arxiv.org/abs/2303.08983v1)\n", "2303.10093": "- 2023-03-17, **Enhancing the Role of Context in Region-Word Alignment for Object Detection**, Kyle Buettner et.al., Paper: [http://arxiv.org/abs/2303.10093v1](http://arxiv.org/abs/2303.10093v1)\n", "2303.10073": "- 2023-03-17, **DialogPaint: A Dialog-based Image Editing Model**, Jingxuan Wei et.al., Paper: [http://arxiv.org/abs/2303.10073v1](http://arxiv.org/abs/2303.10073v1)\n", "2303.09987": "- 2023-03-17, **Breast Cancer Histopathology Image based Gene Expression Prediction using Spatial Transcriptomics data and Deep Learning**, Md Mamunur Rahaman et.al., Paper: [http://arxiv.org/abs/2303.09987v1](http://arxiv.org/abs/2303.09987v1)\n", "2303.09857": "- 2023-03-17, **Dual-path Adaptation from Image to Video Transformers**, Jungin Park et.al., Paper: [http://arxiv.org/abs/2303.09857v1](http://arxiv.org/abs/2303.09857v1), Code: **[https://github.com/park-jungin/dualpath](https://github.com/park-jungin/dualpath)**\n", "2303.09713": "- 2023-03-17, **CHAMPAGNE: Learning Real-world Conversation from Large-Scale Web Videos**, Seungju Han et.al., Paper: [http://arxiv.org/abs/2303.09713v1](http://arxiv.org/abs/2303.09713v1)\n", "2303.09608": "- 2023-03-16, **VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection**, Arushi Rai et.al., Paper: [http://arxiv.org/abs/2303.09608v1](http://arxiv.org/abs/2303.09608v1)\n", "2303.11325": "- 2023-03-20, **Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding**, Jihao Liu et.al., Paper: [http://arxiv.org/abs/2303.11325v1](http://arxiv.org/abs/2303.11325v1)\n", "2303.11184": "- 2023-03-20, **Conversation Modeling to Predict Derailment**, Jiaqing Yuan et.al., Paper: [http://arxiv.org/abs/2303.11184v1](http://arxiv.org/abs/2303.11184v1)\n", "2303.11101": "- 2023-03-20, **Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning**, Sungnyun Kim et.al., Paper: [http://arxiv.org/abs/2303.11101v1](http://arxiv.org/abs/2303.11101v1)\n", "2303.11073": "- 2023-03-20, **Discovering Interpretable Directions in the Semantic Latent Space of Diffusion Models**, Ren\u00e9 Haas et.al., Paper: [http://arxiv.org/abs/2303.11073v1](http://arxiv.org/abs/2303.11073v1)\n", "2303.11003": "- 2023-03-20, **Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization**, Fida Mohammad Thoker et.al., Paper: [http://arxiv.org/abs/2303.11003v1](http://arxiv.org/abs/2303.11003v1)\n", "2303.10934": "- 2023-03-20, **EMC2-Net: Joint Equalization and Modulation Classification based on Constellation Network**, Hyun Ryu et.al., Paper: [http://arxiv.org/abs/2303.10934v1](http://arxiv.org/abs/2303.10934v1), Code: **[https://github.com/hyun-ryu/emc2net](https://github.com/hyun-ryu/emc2net)**\n", "2303.10912": "- 2023-03-20, **Exploring Representation Learning for Small-Footprint Keyword Spotting**, Fan Cui et.al., Paper: [http://arxiv.org/abs/2303.10912v1](http://arxiv.org/abs/2303.10912v1)\n", "2303.10904": "- 2023-03-21, **Actionlet-Dependent Contrastive Learning for Unsupervised Skeleton-Based Action Recognition**, Lilang Lin et.al., Paper: [http://arxiv.org/abs/2303.10904v2](http://arxiv.org/abs/2303.10904v2)\n", "2303.10893": "- 2023-03-20, **Character, Word, or Both? Revisiting the Segmentation Granularity for Chinese Pre-trained Language Models**, Xinnian Liang et.al., Paper: [http://arxiv.org/abs/2303.10893v1](http://arxiv.org/abs/2303.10893v1)\n", "2303.10800": "- 2023-03-20, **A Global Model Approach to Robust Few-Shot SAR Automatic Target Recognition**, Nathan Inkawhich et.al., Paper: [http://arxiv.org/abs/2303.10800v1](http://arxiv.org/abs/2303.10800v1)\n", "2303.12023": "- 2023-03-21, **Logical Reasoning over Natural Language as Knowledge Representation: A Survey**, Zonglin Yang et.al., Paper: [http://arxiv.org/abs/2303.12023v1](http://arxiv.org/abs/2303.12023v1)\n", "2303.11717": "- 2023-03-21, **A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**, Chaoning Zhang et.al., Paper: [http://arxiv.org/abs/2303.11717v1](http://arxiv.org/abs/2303.11717v1)\n", "2303.11643": "- 2023-03-21, **Manipulating Transfer Learning for Property Inference**, Yulong Tian et.al., Paper: [http://arxiv.org/abs/2303.11643v1](http://arxiv.org/abs/2303.11643v1), Code: **[https://github.com/yulongt23/transfer-inference](https://github.com/yulongt23/transfer-inference)**\n", "2303.11568": "- 2023-03-21, **Large AI Models in Health Informatics: Applications, Challenges, and the Future**, Jianing Qiu et.al., Paper: [http://arxiv.org/abs/2303.11568v1](http://arxiv.org/abs/2303.11568v1)\n", "2303.11403": "- 2023-03-20, **eP-ALM: Efficient Perceptual Augmentation of Language Models**, Mustafa Shukor et.al., Paper: [http://arxiv.org/abs/2303.11403v1](http://arxiv.org/abs/2303.11403v1), Code: **[https://github.com/mshukor/ep-alm](https://github.com/mshukor/ep-alm)**\n", "2303.12417": "- 2023-03-22, **CLIP^2: Contrastive Language-Image-Point Pretraining from Real-World Point Cloud Data**, Yihan Zeng et.al., Paper: [http://arxiv.org/abs/2303.12417v1](http://arxiv.org/abs/2303.12417v1)\n", "2303.12214": "- 2023-03-21, **Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning**, Jingwei Zhang et.al., Paper: [http://arxiv.org/abs/2303.12214v1](http://arxiv.org/abs/2303.12214v1)\n", "2303.12188": "- 2023-03-21, **Toward Accurate Interpretable Predictions of Materials Properties within Transformer Language Models**, Vadim Korolev et.al., Paper: [http://arxiv.org/abs/2303.12188v1](http://arxiv.org/abs/2303.12188v1)\n", "2303.12130": "- 2023-03-21, **MV-MR: multi-views and multi-representations for self-supervised learning and knowledge distillation**, Vitaliy Kinakh et.al., Paper: [http://arxiv.org/abs/2303.12130v1](http://arxiv.org/abs/2303.12130v1), Code: **[https://github.com/vkinakh/mv-mr](https://github.com/vkinakh/mv-mr)**\n", "2303.12538": "- 2023-03-21, **Affordance Diffusion: Synthesizing Hand-Object Interactions**, Yufei Ye et.al., Paper: [http://arxiv.org/abs/2303.12538v1](http://arxiv.org/abs/2303.12538v1)\n", "2303.12513": "- 2023-03-21, **Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding**, Morris Alper et.al., Paper: [http://arxiv.org/abs/2303.12513v1](http://arxiv.org/abs/2303.12513v1), Code: **[https://github.com/TAU-VAILab/isbertblind](https://github.com/TAU-VAILab/isbertblind)**\n", "2303.13518": "- 2023-03-23, **Three ways to improve feature alignment for open vocabulary detection**, Relja Arandjelovi\u0107 et.al., Paper: [http://arxiv.org/abs/2303.13518v1](http://arxiv.org/abs/2303.13518v1)\n", "2303.13516": "- 2023-03-23, **Ablating Concepts in Text-to-Image Diffusion Models**, Nupur Kumari et.al., Paper: [http://arxiv.org/abs/2303.13516v1](http://arxiv.org/abs/2303.13516v1), Code: **[https://github.com/nupurkmr9/concept-ablation](https://github.com/nupurkmr9/concept-ablation)**\n", "2303.13500": "- 2023-03-23, **A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias**, Puja Trivedi et.al., Paper: [http://arxiv.org/abs/2303.13500v1](http://arxiv.org/abs/2303.13500v1)\n", "2303.13496": "- 2023-03-23, **The effectiveness of MAE pre-pretraining for billion-scale pretraining**, Mannat Singh et.al., Paper: [http://arxiv.org/abs/2303.13496v1](http://arxiv.org/abs/2303.13496v1)\n", "2303.13340": "- 2023-03-23, **Increasing Textual Context Size Boosts Medical Image-Text Matching**, Idan Glassberg et.al., Paper: [http://arxiv.org/abs/2303.13340v1](http://arxiv.org/abs/2303.13340v1)\n", "2303.13220": "- 2023-03-23, **Parameter-Efficient Sparse Retrievers and Rerankers using Adapters**, Vaishali Pal et.al., Paper: [http://arxiv.org/abs/2303.13220v1](http://arxiv.org/abs/2303.13220v1), Code: **[https://github.com/naver/splade](https://github.com/naver/splade)**\n", "2303.13065": "- 2023-03-23, **Retrieval-Augmented Classification with Decoupled Representation**, Xinnian Liang et.al., Paper: [http://arxiv.org/abs/2303.13065v1](http://arxiv.org/abs/2303.13065v1), Code: **[https://github.com/xnliang98/migbert](https://github.com/xnliang98/migbert)**\n", "2303.13041": "- 2023-03-23, **gDoc: Automatic Generation of Structured API Documentation**, Shujun Wang et.al., Paper: [http://arxiv.org/abs/2303.13041v1](http://arxiv.org/abs/2303.13041v1)\n", "2303.13009": "- 2023-03-23, **MELTR: Meta Loss Transformer for Learning to Fine-tune Video Foundation Models**, Dohwan Ko et.al., Paper: [http://arxiv.org/abs/2303.13009v1](http://arxiv.org/abs/2303.13009v1), Code: **[https://github.com/mlvlab/MELTR](https://github.com/mlvlab/MELTR)**\n", "2303.12869": "- 2023-03-22, **JaCoText: A Pretrained Model for Java Code-Text Generation**, Jessica L\u00f3pez Espejel et.al., Paper: [http://arxiv.org/abs/2303.12869v1](http://arxiv.org/abs/2303.12869v1)\n", "2303.14080": "- 2023-03-27, **Best of Both Worlds: Multimodal Contrastive Learning with Tabular and Imaging Data**, Paul Hager et.al., Paper: [http://arxiv.org/abs/2303.14080v2](http://arxiv.org/abs/2303.14080v2), Code: **[https://github.com/paulhager/mmcl-tabular-imaging](https://github.com/paulhager/mmcl-tabular-imaging)**\n", "2303.14038": "- 2023-03-24, **Accelerating Vision-Language Pretraining with Free Language Modeling**, Teng Wang et.al., Paper: [http://arxiv.org/abs/2303.14038v1](http://arxiv.org/abs/2303.14038v1), Code: **[https://github.com/tencentarc/flm](https://github.com/tencentarc/flm)**\n", "2303.14011": "- 2023-03-24, **SPEC: Summary Preference Decomposition for Low-Resource Abstractive Summarization**, Yi-Syuan Chen et.al., Paper: [http://arxiv.org/abs/2303.14011v1](http://arxiv.org/abs/2303.14011v1)\n", "2303.13899": "- 2023-03-24, **Robust Test-Time Adaptation in Dynamic Scenarios**, Longhui Yuan et.al., Paper: [http://arxiv.org/abs/2303.13899v1](http://arxiv.org/abs/2303.13899v1), Code: **[https://github.com/bit-da/rotta](https://github.com/bit-da/rotta)**\n", "2303.15403": "- 2023-03-27, **Training-free Style Transfer Emerges from h-space in Diffusion models**, Jaeseok Jeong et.al., Paper: [http://arxiv.org/abs/2303.15403v1](http://arxiv.org/abs/2303.15403v1)\n", "2303.15387": "- 2023-03-27, **Generalizable Neural Voxels for Fast Human Radiance Fields**, Taoran Yi et.al., Paper: [http://arxiv.org/abs/2303.15387v1](http://arxiv.org/abs/2303.15387v1)\n", "2303.15350": "- 2023-03-27, **Improving Neural Topic Models with Wasserstein Knowledge Distillation**, Suman Adhya et.al., Paper: [http://arxiv.org/abs/2303.15350v1](http://arxiv.org/abs/2303.15350v1), Code: **[https://github.com/adhyasuman/ctmkd](https://github.com/adhyasuman/ctmkd)**\n", "2303.15167": "- 2023-03-27, **Prompt-Guided Zero-Shot Anomaly Action Recognition using Pretrained Deep Skeleton Features**, Fumiaki Sato et.al., Paper: [http://arxiv.org/abs/2303.15167v1](http://arxiv.org/abs/2303.15167v1)\n", "2303.15122": "- 2023-03-27, **Parameter Efficient Local Implicit Image Function Network for Face Segmentation**, Mausoom Sarkar et.al., Paper: [http://arxiv.org/abs/2303.15122v1](http://arxiv.org/abs/2303.15122v1)\n", "2303.14920": "- 2023-03-27, **Adapting Pretrained Language Models for Solving Tabular Prediction Problems in the Electronic Health Record**, Christopher McMaster et.al., Paper: [http://arxiv.org/abs/2303.14920v1](http://arxiv.org/abs/2303.14920v1)\n", "2303.14897": "- 2023-03-27, **Seer: Language Instructed Video Prediction with Latent Diffusion Models**, Xianfan Gu et.al., Paper: [http://arxiv.org/abs/2303.14897v1](http://arxiv.org/abs/2303.14897v1)\n", "2303.14461": "- 2023-03-25, **Indian Language Summarization using Pretrained Sequence-to-Sequence Models**, Ashok Urlana et.al., Paper: [http://arxiv.org/abs/2303.14461v1](http://arxiv.org/abs/2303.14461v1)\n", "2303.14425": "- 2023-03-25, **Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining**, Zhouhong Gu et.al., Paper: [http://arxiv.org/abs/2303.14425v1](http://arxiv.org/abs/2303.14425v1)\n", "2303.14409": "- 2023-03-25, **Vision Models Can Be Efficiently Specialized via Few-Shot Task-Aware Compression**, Denis Kuznedelev et.al., Paper: [http://arxiv.org/abs/2303.14409v1](http://arxiv.org/abs/2303.14409v1)\n", "2303.16105": "- 2023-03-28, **Variational Distribution Learning for Unsupervised Text-to-Image Generation**, Minsoo Kang et.al., Paper: [http://arxiv.org/abs/2303.16105v1](http://arxiv.org/abs/2303.16105v1)\n", "2303.15846": "- 2023-03-28, **Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes**, Auke Elfrink et.al., Paper: [http://arxiv.org/abs/2303.15846v1](http://arxiv.org/abs/2303.15846v1)\n", "2303.15780": "- 2023-03-28, **Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion**, Hiromichi Kamata et.al., Paper: [http://arxiv.org/abs/2303.15780v1](http://arxiv.org/abs/2303.15780v1)\n", "2303.15748": "- 2023-03-28, **SVD-DIP: Overcoming the Overfitting Problem in DIP-based CT Reconstruction**, Marco Nittscher et.al., Paper: [http://arxiv.org/abs/2303.15748v1](http://arxiv.org/abs/2303.15748v1), Code: **[https://github.com/educating-dip/svd_dip](https://github.com/educating-dip/svd_dip)**\n", "2303.15693": "- 2023-03-28, **Large-scale pretraining on pathological images for fine-tuning of small pathological benchmarks**, Masataka Kawai et.al., Paper: [http://arxiv.org/abs/2303.15693v1](http://arxiv.org/abs/2303.15693v1)\n", "2303.15682": "- 2023-03-28, **Pre-training Transformers for Knowledge Graph Completion**, Sanxing Chen et.al., Paper: [http://arxiv.org/abs/2303.15682v1](http://arxiv.org/abs/2303.15682v1)\n", "2303.15649": "- 2023-03-28, **StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing**, Senmao Li et.al., Paper: [http://arxiv.org/abs/2303.15649v1](http://arxiv.org/abs/2303.15649v1)\n", "2303.16899": "- 2023-03-29, **AutoAD: Movie Description in Context**, Tengda Han et.al., Paper: [http://arxiv.org/abs/2303.16899v1](http://arxiv.org/abs/2303.16899v1), Code: **[https://github.com/Soldelli/MAD](https://github.com/Soldelli/MAD)**\n", "2303.16887": "- 2023-03-29, **Towards Understanding the Effect of Pretraining Label Granularity**, Guan Zhe Hong et.al., Paper: [http://arxiv.org/abs/2303.16887v1](http://arxiv.org/abs/2303.16887v1)\n", "2303.16479": "- 2023-03-29, **Visibility Aware Human-Object Interaction Tracking from Single RGB Camera**, Xianghui Xie et.al., Paper: [http://arxiv.org/abs/2303.16479v1](http://arxiv.org/abs/2303.16479v1)\n", "2303.16755": "- 2023-03-28, **Training Language Models with Language Feedback at Scale**, J\u00e9r\u00e9my Scheurer et.al., Paper: [http://arxiv.org/abs/2303.16755v1](http://arxiv.org/abs/2303.16755v1)\n", "2303.17593": "- 2023-03-30, **Anatomically aware dual-hop learning for pulmonary embolism detection in CT pulmonary angiograms**, Florin Condrea et.al., Paper: [http://arxiv.org/abs/2303.17593v1](http://arxiv.org/abs/2303.17593v1)\n", "2303.17550": "- 2023-03-30, **DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder**, Chenpng Du et.al., Paper: [http://arxiv.org/abs/2303.17550v1](http://arxiv.org/abs/2303.17550v1)\n", "2303.17396": "- 2023-03-30, **Finetuning from Offline Reinforcement Learning: Challenges, Trade-offs and Practical Solutions**, Yicheng Luo et.al., Paper: [http://arxiv.org/abs/2303.17396v1](http://arxiv.org/abs/2303.17396v1)\n", "2303.17376": "- 2023-03-30, **A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision**, Lucas Beyer et.al., Paper: [http://arxiv.org/abs/2303.17376v1](http://arxiv.org/abs/2303.17376v1)\n", "2303.17342": "- 2023-03-30, **PMatch: Paired Masked Image Modeling for Dense Geometric Matching**, Shengjie Zhu et.al., Paper: [http://arxiv.org/abs/2303.17342v1](http://arxiv.org/abs/2303.17342v1)\n", "2303.17155": "- 2023-03-30, **Discriminative Class Tokens for Text-to-Image Diffusion Models**, Idan Schwartz et.al., Paper: [http://arxiv.org/abs/2303.17155v1](http://arxiv.org/abs/2303.17155v1)\n", "2303.17051": "- 2023-03-29, **Transductive few-shot adapters for medical image segmentation**, Julio Silva-Rodr\u00edguez et.al., Paper: [http://arxiv.org/abs/2303.17051v1](http://arxiv.org/abs/2303.17051v1), Code: **[https://github.com/jusiro/fewshot-finetuning](https://github.com/jusiro/fewshot-finetuning)**\n", "2303.18230": "- 2023-03-31, **Procedure-Aware Pretraining for Instructional Video Understanding**, Honglu Zhou et.al., Paper: [http://arxiv.org/abs/2303.18230v1](http://arxiv.org/abs/2303.18230v1), Code: **[https://github.com/salesforce/paprika](https://github.com/salesforce/paprika)**\n", "2303.18144": "- 2023-03-31, **Siamese DETR**, Zeren Chen et.al., Paper: [http://arxiv.org/abs/2303.18144v1](http://arxiv.org/abs/2303.18144v1)\n", "2303.18101": "- 2023-03-31, **INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields**, Julia Hindel et.al., Paper: [http://arxiv.org/abs/2303.18101v1](http://arxiv.org/abs/2303.18101v1)\n", "2303.18013": "- 2023-03-31, **LaCViT: A Label-aware Contrastive Training Framework for Vision Transformers**, Zijun Long et.al., Paper: [http://arxiv.org/abs/2303.18013v1](http://arxiv.org/abs/2303.18013v1)\n", "2303.17981": "- 2023-03-31, **Knowledge Distillation for Feature Extraction in Underwater VSLAM**, Jinghe Yang et.al., Paper: [http://arxiv.org/abs/2303.17981v1](http://arxiv.org/abs/2303.17981v1), Code: **[https://github.com/jinghe-mel/ufen-slam](https://github.com/jinghe-mel/ufen-slam)**\n", "2303.17896": "- 2023-03-31, **Exploring the Limits of Deep Image Clustering using Pretrained Models**, Nikolas Adaloglou et.al., Paper: [http://arxiv.org/abs/2303.17896v1](http://arxiv.org/abs/2303.17896v1)\n", "2303.17688": "- 2023-03-30, **Learning Garment DensePose for Robust Warping in Virtual Try-On**, Aiyu Cui et.al., Paper: [http://arxiv.org/abs/2303.17688v1](http://arxiv.org/abs/2303.17688v1)\n", "2303.17636": "- 2023-03-30, **Whether and When does Endoscopy Domain Pretraining Make Sense?**, Dominik Bati\u0107 et.al., Paper: [http://arxiv.org/abs/2303.17636v1](http://arxiv.org/abs/2303.17636v1)\n", "2304.01194": "- 2023-04-03, **Burstormer: Burst Image Restoration and Enhancement Transformer**, Akshay Dudhane et.al., Paper: [http://arxiv.org/abs/2304.01194v1](http://arxiv.org/abs/2304.01194v1), Code: **[https://github.com/akshaydudhane16/burstormer](https://github.com/akshaydudhane16/burstormer)**\n", "2304.00906": "- 2023-04-03, **ScandEval: A Benchmark for Scandinavian Natural Language Processing**, Dan Saattrup Nielsen et.al., Paper: [http://arxiv.org/abs/2304.00906v1](http://arxiv.org/abs/2304.00906v1), Code: **[https://github.com/scandeval/scandeval.github.io](https://github.com/scandeval/scandeval.github.io)**\n", "2304.00869": "- 2023-04-03, **GreekBART: The First Pretrained Greek Sequence-to-Sequence Model**, Iakovos Evdaimon et.al., Paper: [http://arxiv.org/abs/2304.00869v1](http://arxiv.org/abs/2304.00869v1)\n", "2304.00792": "- 2023-04-03, **Few-shot Fine-tuning is All You Need for Source-free Domain Adaptation**, Suho Lee et.al., Paper: [http://arxiv.org/abs/2304.00792v1](http://arxiv.org/abs/2304.00792v1), Code: **[https://github.com/daintlab/fewshot-sfda](https://github.com/daintlab/fewshot-sfda)**\n", "2304.00719": "- 2023-04-03, **Multi-Modal Representation Learning with Text-Driven Soft Masks**, Jaeyoo Park et.al., Paper: [http://arxiv.org/abs/2304.00719v1](http://arxiv.org/abs/2304.00719v1)\n", "2304.00698": "- 2023-04-03, **A Post-Training Framework for Improving Heterogeneous Graph Neural Networks**, Cheng Yang et.al., Paper: [http://arxiv.org/abs/2304.00698v1](http://arxiv.org/abs/2304.00698v1)\n", "2304.00592": "- 2023-04-02, **PK-Chat: Pointer Network Guided Knowledge Driven Generative Dialogue Model**, Cheng Deng et.al., Paper: [http://arxiv.org/abs/2304.00592v1](http://arxiv.org/abs/2304.00592v1), Code: **[https://github.com/davendw49/PK-Chat](https://github.com/davendw49/PK-Chat)**\n", "2304.00571": "- 2023-04-02, **DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks**, Qiangqiang Wu et.al., Paper: [http://arxiv.org/abs/2304.00571v1](http://arxiv.org/abs/2304.00571v1), Code: **[https://github.com/jimmy-dq/dropmae](https://github.com/jimmy-dq/dropmae)**\n", "2304.00546": "- 2023-04-02, **Video Pretraining Advances 3D Deep Learning on Chest CT Tasks**, Alexander Ke et.al., Paper: [http://arxiv.org/abs/2304.00546v1](http://arxiv.org/abs/2304.00546v1), Code: **[https://github.com/rajpurkarlab/chest-ct-pretraining](https://github.com/rajpurkarlab/chest-ct-pretraining)**\n", "2304.00436": "- 2023-04-02, **Instance-level Trojan Attacks on Visual Question Answering via Adversarial Learning in Neuron Activation Space**, Yuwei Sun et.al., Paper: [http://arxiv.org/abs/2304.00436v1](http://arxiv.org/abs/2304.00436v1)\n", "2304.01961": "- 2023-04-04, **AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation**, Jheng-Hong Yang et.al., Paper: [http://arxiv.org/abs/2304.01961v1](http://arxiv.org/abs/2304.01961v1), Code: **[https://github.com/trec-atomic/atomic](https://github.com/trec-atomic/atomic)**\n", "2304.01597": "- 2023-04-04, **Unsupervised Improvement of Factual Knowledge in Language Models**, Nafis Sadeq et.al., Paper: [http://arxiv.org/abs/2304.01597v1](http://arxiv.org/abs/2304.01597v1), Code: **[https://github.com/intuit/wmlm](https://github.com/intuit/wmlm)**\n", "2304.01331": "- 2023-04-03, **Creating Custom Event Data Without Dictionaries: A Bag-of-Tricks**, Andrew Halterman et.al., Paper: [http://arxiv.org/abs/2304.01331v1](http://arxiv.org/abs/2304.01331v1), Code: **[https://github.com/philip-schrodt/ngec](https://github.com/philip-schrodt/ngec)**\n", "2304.02560": "- 2023-04-05, **VicTR: Video-conditioned Text Representations for Activity Recognition**, Kumara Kahatapitiya et.al., Paper: [http://arxiv.org/abs/2304.02560v1](http://arxiv.org/abs/2304.02560v1)\n", "2304.02265": "- 2023-04-05, **Deep Perceptual Similarity is Adaptable to Ambiguous Contexts**, Gustav Grund Pihlgren et.al., Paper: [http://arxiv.org/abs/2304.02265v1](http://arxiv.org/abs/2304.02265v1)\n", "2304.02263": "- 2023-04-05, **Towards Efficient Task-Driven Model Reprogramming with Foundation Models**, Shoukai Xu et.al., Paper: [http://arxiv.org/abs/2304.02263v1](http://arxiv.org/abs/2304.02263v1)\n", "2304.02160": "- 2023-04-04, **Pac-HuBERT: Self-Supervised Music Source Separation via Primitive Auditory Clustering and Hidden-Unit BERT**, Ke Chen et.al., Paper: [http://arxiv.org/abs/2304.02160v1](http://arxiv.org/abs/2304.02160v1)\n", "2304.02056": "- 2023-04-04, **Optimal operating MR contrast for brain ventricle parcellation**, Savannah P. Hays et.al., Paper: [http://arxiv.org/abs/2304.02056v1](http://arxiv.org/abs/2304.02056v1)\n", "2304.02052": "- 2023-04-04, **Online augmentation of learned grasp sequence policies for more adaptable and data-efficient in-hand manipulation**, Ethan K. Gordon et.al., Paper: [http://arxiv.org/abs/2304.02052v1](http://arxiv.org/abs/2304.02052v1)\n", "2304.03282": "- 2023-04-06, **Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention**, Mingyu Ding et.al., Paper: [http://arxiv.org/abs/2304.03282v1](http://arxiv.org/abs/2304.03282v1), Code: **[https://github.com/dingmyu/dependencyvit](https://github.com/dingmyu/dependencyvit)**\n", "2304.03262": "- 2023-04-06, **When do you need Chain-of-Thought Prompting for ChatGPT?**, Jiuhai Chen et.al., Paper: [http://arxiv.org/abs/2304.03262v1](http://arxiv.org/abs/2304.03262v1)\n", "2304.03153": "- 2023-04-06, **Zero-Shot Next-Item Recommendation using Large Pretrained Language Models**, Lei Wang et.al., Paper: [http://arxiv.org/abs/2304.03153v1](http://arxiv.org/abs/2304.03153v1)\n", "2304.03105": "- 2023-04-07, **Geometric-aware Pretraining for Vision-centric 3D Object Detection**, Linyan Huang et.al., Paper: [http://arxiv.org/abs/2304.03105v2](http://arxiv.org/abs/2304.03105v2), Code: **[https://github.com/opendrivelab/bevperception-survey-recipe](https://github.com/opendrivelab/bevperception-survey-recipe)**\n", "2304.02933": "- 2023-04-06, **Convolutional neural networks for crack detection on flexible road pavements**, Hermann Tapamo et.al., Paper: [http://arxiv.org/abs/2304.02933v1](http://arxiv.org/abs/2304.02933v1)\n", "2304.02931": "- 2023-04-06, **Mask Detection and Classification in Thermal Face Images**, Natalia Kowalczyk et.al., Paper: [http://arxiv.org/abs/2304.02931v1](http://arxiv.org/abs/2304.02931v1), Code: **[https://github.com/natkowalczyk/thermal-mask-classification-and-detection](https://github.com/natkowalczyk/thermal-mask-classification-and-detection)**\n", "2304.02853": "- 2023-04-06, **Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce**, Yang Jin et.al., Paper: [http://arxiv.org/abs/2304.02853v1](http://arxiv.org/abs/2304.02853v1)\n", "2304.02836": "- 2023-04-06, **Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures From Routine EHRs for Pulmonary Nodule Classification**, Thomas Z. Li et.al., Paper: [http://arxiv.org/abs/2304.02836v1](http://arxiv.org/abs/2304.02836v1)\n", "2304.02739": "- 2023-04-05, **Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks**, Md. Tanvir Rouf Shawon et.al., Paper: [http://arxiv.org/abs/2304.02739v1](http://arxiv.org/abs/2304.02739v1)\n", "2304.02724": "- 2023-04-05, **Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound**, Blake VanBerlo et.al., Paper: [http://arxiv.org/abs/2304.02724v1](http://arxiv.org/abs/2304.02724v1)\n", "2304.03760": "- 2023-04-07, **Zero-shot CT Field-of-view Completion with Unconditional Generative Diffusion Prior**, Kaiwen Xu et.al., Paper: [http://arxiv.org/abs/2304.03760v1](http://arxiv.org/abs/2304.03760v1)\n", "2304.03588": "- 2023-04-10, **Anomalous Sound Detection using Audio Representation with Machine ID based Contrastive Learning Pretraining**, Jian Guan et.al., Paper: [http://arxiv.org/abs/2304.03588v2](http://arxiv.org/abs/2304.03588v2)\n", "2304.03586": "- 2023-04-10, **Graph Attention for Automated Audio Captioning**, Feiyang Xiao et.al., Paper: [http://arxiv.org/abs/2304.03586v2](http://arxiv.org/abs/2304.03586v2), Code: **[https://github.com/littleflyingsheep/graphac](https://github.com/littleflyingsheep/graphac)**\n", "2304.03580": "- 2023-04-07, **Language-aware Multiple Datasets Detection Pretraining for DETRs**, Jing Hao et.al., Paper: [http://arxiv.org/abs/2304.03580v1](http://arxiv.org/abs/2304.03580v1)\n", "2304.03439": "- 2023-04-07, **Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4**, Hanmeng Liu et.al., Paper: [http://arxiv.org/abs/2304.03439v1](http://arxiv.org/abs/2304.03439v1), Code: **[https://github.com/csitfun/logiqa2.0](https://github.com/csitfun/logiqa2.0)**\n", "2304.03400": "- 2023-04-06, **RoSteALS: Robust Steganography using Autoencoder Latent Space**, Tu Bui et.al., Paper: [http://arxiv.org/abs/2304.03400v1](http://arxiv.org/abs/2304.03400v1), Code: **[https://github.com/tubui/rosteals](https://github.com/tubui/rosteals)**\n", "2304.03378": "- 2023-04-06, **Self-Supervised Video Similarity Learning**, Giorgos Kordopatis-Zilos et.al., Paper: [http://arxiv.org/abs/2304.03378v1](http://arxiv.org/abs/2304.03378v1), Code: **[https://github.com/gkordo/s2vs](https://github.com/gkordo/s2vs)**\n", "2304.03307": "- 2023-04-06, **Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting**, Syed Talal Wasim et.al., Paper: [http://arxiv.org/abs/2304.03307v1](http://arxiv.org/abs/2304.03307v1), Code: **[https://github.com/talalwasim/vita-clip](https://github.com/talalwasim/vita-clip)**\n", "2304.04704": "- 2023-04-10, **Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition**, Shuhuai Ren et.al., Paper: [http://arxiv.org/abs/2304.04704v1](http://arxiv.org/abs/2304.04704v1), Code: **[https://github.com/amazon-science/prompt-pretraining](https://github.com/amazon-science/prompt-pretraining)**\n", "2304.04703": "- 2023-04-10, **Transfer Learning for Low-Resource Sentiment Analysis**, Razhan Hameed et.al., Paper: [http://arxiv.org/abs/2304.04703v1](http://arxiv.org/abs/2304.04703v1), Code: **[https://github.com/hrazhan/sentiment](https://github.com/hrazhan/sentiment)**\n", "2304.04610": "- 2023-04-10, **Attention at SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS)**, Debashish Roy et.al., Paper: [http://arxiv.org/abs/2304.04610v1](http://arxiv.org/abs/2304.04610v1), Code: **[https://github.com/debashish05/explainable_detection_of_online_sexism](https://github.com/debashish05/explainable_detection_of_online_sexism)**\n", "2304.04507": "- 2023-04-10, **hist2RNA: An efficient deep learning architecture to predict gene expression from breast cancer histopathology images**, Raktim Kumar Mondol et.al., Paper: [http://arxiv.org/abs/2304.04507v1](http://arxiv.org/abs/2304.04507v1)\n", "2304.04395": "- 2023-04-10, **Instance Neural Radiance Field**, Benran Hu et.al., Paper: [http://arxiv.org/abs/2304.04395v1](http://arxiv.org/abs/2304.04395v1)\n", "2304.04394": "- 2023-04-10, **Leveraging Neural Representations for Audio Manipulation**, Scott H. Hawley et.al., Paper: [http://arxiv.org/abs/2304.04394v1](http://arxiv.org/abs/2304.04394v1)\n", "2304.04344": "- 2023-04-10, **Towards Real-time Text-driven Image Manipulation with Unconditional Diffusion Models**, Nikita Starodubcev et.al., Paper: [http://arxiv.org/abs/2304.04344v1](http://arxiv.org/abs/2304.04344v1), Code: **[https://github.com/quickjkee/eff-diff-edit](https://github.com/quickjkee/eff-diff-edit)**\n", "2304.04330": "- 2023-04-09, **Pretrained Embeddings for E-commerce Machine Learning: When it Fails and Why?**, Da Xu et.al., Paper: [http://arxiv.org/abs/2304.04330v1](http://arxiv.org/abs/2304.04330v1)\n", "2304.04099": "- 2023-04-08, **Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding**, Susik Yoon et.al., Paper: [http://arxiv.org/abs/2304.04099v1](http://arxiv.org/abs/2304.04099v1)\n", "2304.04026": "- 2023-04-08, **WikiGoldSK: Annotated Dataset, Baselines and Few-Shot Learning Experiments for Slovak Named Entity Recognition**, D\u00e1vid \u0160uba et.al., Paper: [http://arxiv.org/abs/2304.04026v1](http://arxiv.org/abs/2304.04026v1), Code: **[https://github.com/naiveneuron/wikigoldsk](https://github.com/naiveneuron/wikigoldsk)**\n", "2304.05369": "- 2023-04-11, **A surprisingly simple technique to control the pretraining bias for better transfer: Expand or Narrow your representation**, Florian Bordes et.al., Paper: [http://arxiv.org/abs/2304.05369v1](http://arxiv.org/abs/2304.05369v1)\n", "2304.05215": "- 2023-04-11, **A Billion-scale Foundation Model for Remote Sensing Images**, Keumgang Cha et.al., Paper: [http://arxiv.org/abs/2304.05215v1](http://arxiv.org/abs/2304.05215v1)\n", "2304.04962": "- 2023-04-11, **MRVM-NeRF: Mask-Based Pretraining for Neural Radiance Fields**, Ganlin Yang et.al., Paper: [http://arxiv.org/abs/2304.04962v1](http://arxiv.org/abs/2304.04962v1)\n", "2304.04947": "- 2023-04-11, **Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference**, Tao Lei et.al., Paper: [http://arxiv.org/abs/2304.04947v1](http://arxiv.org/abs/2304.04947v1)\n", "2304.06028": "- 2023-04-12, **RECLIP: Resource-efficient CLIP by Training with Small Images**, Runze Li et.al., Paper: [http://arxiv.org/abs/2304.06028v1](http://arxiv.org/abs/2304.06028v1)\n", "2304.06025": "- 2023-04-14, **DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion**, Johanna Karras et.al., Paper: [http://arxiv.org/abs/2304.06025v2](http://arxiv.org/abs/2304.06025v2)\n", "2304.05826": "- 2023-04-12, **HaDR: Applying Domain Randomization for Generating Synthetic Multimodal Dataset for Hand Instance Segmentation in Cluttered Industrial Environments**, Stefan Grushko et.al., Paper: [http://arxiv.org/abs/2304.05826v1](http://arxiv.org/abs/2304.05826v1)\n", "2304.05716": "- 2023-04-12, **Impact of Pseudo Depth on Open World Object Segmentation with Minimal User Guidance**, Robin Sch\u00f6n et.al., Paper: [http://arxiv.org/abs/2304.05716v1](http://arxiv.org/abs/2304.05716v1)\n", "2304.05600": "- 2023-04-12, **Looking Similar, Sounding Different: Leveraging Counterfactual Cross-Modal Pairs for Audiovisual Representation Learning**, Nikhil Singh et.al., Paper: [http://arxiv.org/abs/2304.05600v1](http://arxiv.org/abs/2304.05600v1)\n", "2304.06714": "- 2023-04-13, **Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction**, Hansheng Chen et.al., Paper: [http://arxiv.org/abs/2304.06714v1](http://arxiv.org/abs/2304.06714v1)\n", "2304.06708": "- 2023-04-13, **Verbs in Action: Improving verb understanding in video-language models**, Liliane Momeni et.al., Paper: [http://arxiv.org/abs/2304.06708v1](http://arxiv.org/abs/2304.06708v1)\n", "2304.06653": "- 2023-04-14, **G2T: A Simple but Effective Framework for Topic Modeling based on Pretrained Language Model and Community Detection**, Leihang Zhang et.al., Paper: [http://arxiv.org/abs/2304.06653v2](http://arxiv.org/abs/2304.06653v2)\n", "2304.06600": "- 2023-04-13, **Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation**, Mohit Sharma et.al., Paper: [http://arxiv.org/abs/2304.06600v1](http://arxiv.org/abs/2304.06600v1)\n", "2304.07193": "- 2023-04-14, **DINOv2: Learning Robust Visual Features without Supervision**, Maxime Oquab et.al., Paper: [http://arxiv.org/abs/2304.07193v1](http://arxiv.org/abs/2304.07193v1), Code: **[https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)**\n", "2304.07051": "- 2023-04-14, **The Second Monocular Depth Estimation Challenge**, Jaime Spencer et.al., Paper: [http://arxiv.org/abs/2304.07051v1](http://arxiv.org/abs/2304.07051v1)\n", "2304.06957": "- 2023-04-14, **MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation**, Jie Guo et.al., Paper: [http://arxiv.org/abs/2304.06957v1](http://arxiv.org/abs/2304.06957v1)\n", "2304.06939": "- 2023-04-14, **Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text**, Wanrong Zhu et.al., Paper: [http://arxiv.org/abs/2304.06939v1](http://arxiv.org/abs/2304.06939v1), Code: **[https://github.com/allenai/mmc4](https://github.com/allenai/mmc4)**\n", "2304.06911": "- 2023-04-14, **3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining**, Siming Yan et.al., Paper: [http://arxiv.org/abs/2304.06911v1](http://arxiv.org/abs/2304.06911v1)\n", "2304.06908": "- 2023-04-14, **Generating Adversarial Examples with Better Transferability via Masking Unimportant Parameters of Surrogate Model**, Dingcheng Yang et.al., Paper: [http://arxiv.org/abs/2304.06908v1](http://arxiv.org/abs/2304.06908v1)\n", "2304.06906": "- 2023-04-14, **Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding**, Yu-Qi Yang et.al., Paper: [http://arxiv.org/abs/2304.06906v1](http://arxiv.org/abs/2304.06906v1)\n", "2304.06857": "- 2023-04-17, **A Contrastive Method Based on Elevation Data for Remote Sensing with Scarce and High Level Semantic Labels**, Omar A. Casta\u00f1o-Idarraga et.al., Paper: [http://arxiv.org/abs/2304.06857v2](http://arxiv.org/abs/2304.06857v2)\n", "2304.06762": "- 2023-04-13, **Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study**, Boxin Wang et.al., Paper: [http://arxiv.org/abs/2304.06762v1](http://arxiv.org/abs/2304.06762v1), Code: **[https://github.com/NVIDIA/Megatron-LM](https://github.com/NVIDIA/Megatron-LM)**\n", "2304.08491": "- 2023-04-17, **Delving into Shape-aware Zero-shot Semantic Segmentation**, Xinyu Liu et.al., Paper: [http://arxiv.org/abs/2304.08491v1](http://arxiv.org/abs/2304.08491v1), Code: **[https://github.com/liuxinyv/sazs](https://github.com/liuxinyv/sazs)**\n", "2304.08486": "- 2023-04-17, **BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors**, Kathryn Wantlin et.al., Paper: [http://arxiv.org/abs/2304.08486v1](http://arxiv.org/abs/2304.08486v1), Code: **[https://github.com/rajpurkarlab/benchmd](https://github.com/rajpurkarlab/benchmd)**\n", "2304.08477": "- 2023-04-18, **Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation**, Jie An et.al., Paper: [http://arxiv.org/abs/2304.08477v2](http://arxiv.org/abs/2304.08477v2)\n", "2304.08446": "- 2023-04-18, **Inverse design of next-generation superconductors using data-driven deep generative models**, Daniel Wines et.al., Paper: [http://arxiv.org/abs/2304.08446v2](http://arxiv.org/abs/2304.08446v2)\n", "2304.08345": "- 2023-04-17, **VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset**, Sihan Chen et.al., Paper: [http://arxiv.org/abs/2304.08345v1](http://arxiv.org/abs/2304.08345v1), Code: **[https://github.com/TXH-mercury/VALOR](https://github.com/TXH-mercury/VALOR)**\n", "2304.08186": "- 2023-04-17, **Human Pose Estimation in Monocular Omnidirectional Top-View Images**, Jingrui Yu et.al., Paper: [http://arxiv.org/abs/2304.08186v1](http://arxiv.org/abs/2304.08186v1)\n", "2304.08069": "- 2023-04-17, **DETRs Beat YOLOs on Real-time Object Detection**, Wenyu Lv et.al., Paper: [http://arxiv.org/abs/2304.08069v1](http://arxiv.org/abs/2304.08069v1), Code: **[https://github.com/PaddlePaddle/PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)**\n", "2304.08014": "- 2023-04-17, **Self-Supervised Learning from Non-Object Centric Images with a Geometric Transformation Sensitive Architecture**, Taeho Kim Jong-Min Lee et.al., Paper: [http://arxiv.org/abs/2304.08014v1](http://arxiv.org/abs/2304.08014v1)\n", "2304.07969": "- 2023-04-17, **Learning to \"Segment Anything\" in Thermal Infrared Images through Knowledge Distillation with a Large Scale Dataset SATIR**, Junzhang Chen et.al., Paper: [http://arxiv.org/abs/2304.07969v1](http://arxiv.org/abs/2304.07969v1), Code: **[https://github.com/chenjzbuaa/satir](https://github.com/chenjzbuaa/satir)**\n", "2304.07880": "- 2023-04-16, **Sabi\u00e1: Portuguese Large Language Models**, Ramon Pires et.al., Paper: [http://arxiv.org/abs/2304.07880v1](http://arxiv.org/abs/2304.07880v1)\n", "2304.09151": "- 2023-04-18, **UniMax: Fairer and more Effective Language Sampling for Large-Scale Multilingual Pretraining**, Hyung Won Chung et.al., Paper: [http://arxiv.org/abs/2304.09151v1](http://arxiv.org/abs/2304.09151v1)\n", "2304.09050": "- 2023-04-18, **Decoding Neural Activity to Assess Individual Latent State in Ecologically Valid Contexts**, Stephen M. Gordon et.al., Paper: [http://arxiv.org/abs/2304.09050v1](http://arxiv.org/abs/2304.09050v1)\n", "2304.09042": "- 2023-04-18, **Adapter Learning in Pretrained Feature Extractor for Continual Learning of Diseases**, Wentao Zhang et.al., Paper: [http://arxiv.org/abs/2304.09042v1](http://arxiv.org/abs/2304.09042v1)\n", "2304.08991": "- 2023-04-18, **D2CSE: Difference-aware Deep continuous prompts for Contrastive Sentence Embeddings**, Hyunjae Lee et.al., Paper: [http://arxiv.org/abs/2304.08991v1](http://arxiv.org/abs/2304.08991v1)\n", "2304.08878": "- 2023-04-18, **Deep Collective Knowledge Distillation**, Jihyeon Seo et.al., Paper: [http://arxiv.org/abs/2304.08878v1](http://arxiv.org/abs/2304.08878v1)\n", "2304.08865": "- 2023-04-18, **Romanization-based Large-scale Adaptation of Multilingual Language Models**, Sukannya Purkayastha et.al., Paper: [http://arxiv.org/abs/2304.08865v1](http://arxiv.org/abs/2304.08865v1)\n", "2304.08799": "- 2023-04-19, **Self-Supervised 3D Action Representation Learning with Skeleton Cloud Colorization**, Siyuan Yang et.al., Paper: [http://arxiv.org/abs/2304.08799v2](http://arxiv.org/abs/2304.08799v2)\n", "2304.08782": "- 2023-04-18, **Sparks of GPTs in Edge Intelligence for Metaverse: Caching and Inference for Mobile AIGC Services**, Minrui Xu et.al., Paper: [http://arxiv.org/abs/2304.08782v1](http://arxiv.org/abs/2304.08782v1)\n", "2304.09513": "- 2023-04-19, **NetGPT: Generative Pretrained Transformer for Network Traffic**, Xuying Meng et.al., Paper: [http://arxiv.org/abs/2304.09513v1](http://arxiv.org/abs/2304.09513v1)\n", "2304.09433": "- 2023-04-20, **Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes**, Simran Arora et.al., Paper: [http://arxiv.org/abs/2304.09433v2](http://arxiv.org/abs/2304.09433v2), Code: **[https://github.com/hazyresearch/evaporate](https://github.com/hazyresearch/evaporate)**\n", "2304.10465": "- 2023-04-20, **Implicit Temporal Modeling with Learnable Alignment for Video Recognition**, Shuyuan Tu et.al., Paper: [http://arxiv.org/abs/2304.10465v1](http://arxiv.org/abs/2304.10465v1), Code: **[https://github.com/francis-rings/ila](https://github.com/francis-rings/ila)**\n", "2304.10447": "- 2023-04-20, **Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health**, Shaoxiong Ji et.al., Paper: [http://arxiv.org/abs/2304.10447v1](http://arxiv.org/abs/2304.10447v1)\n", "2304.10311": "- 2023-04-20, **Movie Box Office Prediction With Self-Supervised and Visually Grounded Pretraining**, Qin Chao et.al., Paper: [http://arxiv.org/abs/2304.10311v1](http://arxiv.org/abs/2304.10311v1)\n", "2304.10294": "- 2023-04-20, **OptoGPT: A Foundation Model for Inverse Design in Optical Multilayer Thin Film Structures**, Taigao Ma et.al., Paper: [http://arxiv.org/abs/2304.10294v1](http://arxiv.org/abs/2304.10294v1)\n", "2304.10263": "- 2023-04-20, **PREIM3D: 3D Consistent Precise Image Attribute Editing from a Single Image**, Jianhui Li et.al., Paper: [http://arxiv.org/abs/2304.10263v1](http://arxiv.org/abs/2304.10263v1)\n", "2304.10158": "- 2023-04-20, **Does Manipulating Tokenization Aid Cross-Lingual Transfer? A Study on POS Tagging for Non-Standardized Languages**, Verena Blaschke et.al., Paper: [http://arxiv.org/abs/2304.10158v1](http://arxiv.org/abs/2304.10158v1), Code: **[https://github.com/mainlp/convert-restaure-occitan](https://github.com/mainlp/convert-restaure-occitan)**\n", "2304.09915": "- 2023-04-19, **DCN-T: Dual Context Network with Transformer for Hyperspectral Image Classification**, Di Wang et.al., Paper: [http://arxiv.org/abs/2304.09915v1](http://arxiv.org/abs/2304.09915v1), Code: **[https://github.com/dotwang/dcn-t](https://github.com/dotwang/dcn-t)**\n", "2304.09874": "- 2023-04-19, **Domain Adaptable Self-supervised Representation Learning on Remote Sensing Satellite Imagery**, Muskaan Chopra et.al., Paper: [http://arxiv.org/abs/2304.09874v1](http://arxiv.org/abs/2304.09874v1), Code: **[https://github.com/muskaan712/domain-adaptable-self-supervised-representation-learning-on-remote-sensing-satellite-imagery](https://github.com/muskaan712/domain-adaptable-self-supervised-representation-learning-on-remote-sensing-satellite-imagery)**\n", "2304.10950": "- 2023-04-21, **Factored Neural Representation for Scene Understanding**, Yu-Shiang Wong et.al., Paper: [http://arxiv.org/abs/2304.10950v1](http://arxiv.org/abs/2304.10950v1)\n", "2304.10859": "- 2023-04-24, **Text2Time: Transformer-based Article Time Period Prediction**, Karthick Prasad Gunasekaran et.al., Paper: [http://arxiv.org/abs/2304.10859v2](http://arxiv.org/abs/2304.10859v2)\n", "2304.10824": "- 2023-04-21, **Rethinking Benchmarks for Cross-modal Image-text Retrieval**, Weijing Chen et.al., Paper: [http://arxiv.org/abs/2304.10824v1](http://arxiv.org/abs/2304.10824v1), Code: **[https://github.com/cwj1412/mscoco-flikcr30k_fg](https://github.com/cwj1412/mscoco-flikcr30k_fg)**\n", "2304.10769": "- 2023-04-21, **Deep Multiview Clustering by Contrasting Cluster Assignments**, Jie Chen et.al., Paper: [http://arxiv.org/abs/2304.10769v1](http://arxiv.org/abs/2304.10769v1), Code: **[https://github.com/chenjie20/cvcl](https://github.com/chenjie20/cvcl)**\n", "2304.10592": "- 2023-04-20, **MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models**, Deyao Zhu et.al., Paper: [http://arxiv.org/abs/2304.10592v1](http://arxiv.org/abs/2304.10592v1), Code: **[https://github.com/vision-cair/minigpt-4](https://github.com/vision-cair/minigpt-4)**\n", "2304.12239": "- 2023-04-24, **Uni-QSAR: an Auto-ML Tool for Molecular Property Prediction**, Zhifeng Gao et.al., Paper: [http://arxiv.org/abs/2304.12239v1](http://arxiv.org/abs/2304.12239v1)\n", "2304.12082": "- 2023-04-24, **Deep Audio-Visual Singing Voice Transcription based on Self-Supervised Learning Models**, Xiangming Gu et.al., Paper: [http://arxiv.org/abs/2304.12082v1](http://arxiv.org/abs/2304.12082v1)\n", "2304.11834": "- 2023-04-24, **Robust Tickets Can Transfer Better: Drawing More Transferable Subnetworks in Transfer Learning**, Yonggan Fu et.al., Paper: [http://arxiv.org/abs/2304.11834v1](http://arxiv.org/abs/2304.11834v1)\n", "2304.11381": "- 2023-04-22, **Incomplete Multimodal Learning for Remote Sensing Data Fusion**, Yuxing Chen et.al., Paper: [http://arxiv.org/abs/2304.11381v1](http://arxiv.org/abs/2304.11381v1)\n", "2304.11356": "- 2023-04-22, **Single-stage Multi-human Parsing via Point Sets and Center-based Offsets**, Jiaming Chu et.al., Paper: [http://arxiv.org/abs/2304.11356v1](http://arxiv.org/abs/2304.11356v1)\n", "2304.11330": "- 2023-04-22, **Self-supervised Learning by View Synthesis**, Shaoteng Liu et.al., Paper: [http://arxiv.org/abs/2304.11330v1](http://arxiv.org/abs/2304.11330v1)\n", "2304.11321": "- 2023-04-22, **EEE, Remediating the failure of machine learning models via a network-based optimization patch**, Ruiyuan Kang et.al., Paper: [http://arxiv.org/abs/2304.11321v1](http://arxiv.org/abs/2304.11321v1)\n", "2304.13001": "- 2023-04-25, **On the Generalization of Learned Structured Representations**, Andrea Dittadi et.al., Paper: [http://arxiv.org/abs/2304.13001v1](http://arxiv.org/abs/2304.13001v1)\n", "2304.12730": "- 2023-04-25, **CitePrompt: Using Prompts to Identify Citation Intent in Scientific Papers**, Avishek Lahiri et.al., Paper: [http://arxiv.org/abs/2304.12730v1](http://arxiv.org/abs/2304.12730v1), Code: **[https://github.com/avisheklahiri/citeprompt](https://github.com/avisheklahiri/citeprompt)**\n", "2304.12620": "- 2023-04-26, **Medical SAM Adapter: Adapting Segment Anything Model for Medical Image Segmentation**, Junde Wu et.al., Paper: [http://arxiv.org/abs/2304.12620v2](http://arxiv.org/abs/2304.12620v2)\n", "2304.12608": "- 2023-04-26, **OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification**, Lin Dengtian et.al., Paper: [http://arxiv.org/abs/2304.12608v2](http://arxiv.org/abs/2304.12608v2)\n", "2304.12528": "- 2023-04-25, **Model Conversion via Differentially Private Data-Free Distillation**, Bochao Liu et.al., Paper: [http://arxiv.org/abs/2304.12528v1](http://arxiv.org/abs/2304.12528v1)\n", "2304.12520": "- 2023-04-25, **Hint-Aug: Drawing Hints from Foundation Vision Transformers Towards Boosted Few-Shot Parameter-Efficient Tuning**, Zhongzhi Yu et.al., Paper: [http://arxiv.org/abs/2304.12520v1](http://arxiv.org/abs/2304.12520v1)\n", "2304.12519": "- 2023-04-25, **RenderDiffusion: Text Generation as Image Generation**, Junyi Li et.al., Paper: [http://arxiv.org/abs/2304.12519v1](http://arxiv.org/abs/2304.12519v1)\n", "2304.12410": "- 2023-04-24, **PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques**, Mohammed Sabry et.al., Paper: [http://arxiv.org/abs/2304.12410v1](http://arxiv.org/abs/2304.12410v1)\n", "2304.12400": "- 2023-04-24, **Generative Discovery of Novel Chemical Designs using Diffusion Modeling and Transformer Deep Neural Networks with Application to Deep Eutectic Solvents**, Rachel K. Luu et.al., Paper: [http://arxiv.org/abs/2304.12400v1](http://arxiv.org/abs/2304.12400v1)\n", "2304.13615": "- 2023-04-26, **Domain Adaptive and Generalizable Network Architectures and Training Strategies for Semantic Image Segmentation**, Lukas Hoyer et.al., Paper: [http://arxiv.org/abs/2304.13615v1](http://arxiv.org/abs/2304.13615v1), Code: **[https://github.com/lhoyer/hrda](https://github.com/lhoyer/hrda)**\n", "2304.13574": "- 2023-04-26, **Tissue Classification During Needle Insertion Using Self-Supervised Contrastive Learning and Optical Coherence Tomography**, Debayan Bhattacharya et.al., Paper: [http://arxiv.org/abs/2304.13574v1](http://arxiv.org/abs/2304.13574v1)\n", "2304.13277": "- 2023-04-26, **Self-Supervised Multi-Modal Sequential Recommendation**, Kunzhe Song et.al., Paper: [http://arxiv.org/abs/2304.13277v1](http://arxiv.org/abs/2304.13277v1)\n", "2304.13164": "- 2023-04-25, **Towards Compute-Optimal Transfer Learning**, Massimo Caccia et.al., Paper: [http://arxiv.org/abs/2304.13164v1](http://arxiv.org/abs/2304.13164v1)\n", "2304.13130": "- 2023-04-25, **Hypernymization of named entity-rich captions for grounding-based multi-modal pretraining**, Giacomo Nebbia et.al., Paper: [http://arxiv.org/abs/2304.13130v1](http://arxiv.org/abs/2304.13130v1)\n", "2304.13060": "- 2023-04-25, **Pretrain on just structure: Understanding linguistic inductive biases using transfer learning**, Isabel Papadimitriou et.al., Paper: [http://arxiv.org/abs/2304.13060v1](http://arxiv.org/abs/2304.13060v1)\n", "2304.14399": "- 2023-04-27, **We're Afraid Language Models Aren't Modeling Ambiguity**, Alisa Liu et.al., Paper: [http://arxiv.org/abs/2304.14399v1](http://arxiv.org/abs/2304.14399v1), Code: **[https://github.com/alisawuffles/ambient](https://github.com/alisawuffles/ambient)**\n", "2304.14189": "- 2023-04-27, **UIO at SemEval-2023 Task 12: Multilingual fine-tuning for sentiment classification in low-resource languages**, Egil R\u00f8nningstad et.al., Paper: [http://arxiv.org/abs/2304.14189v1](http://arxiv.org/abs/2304.14189v1)\n", "2304.14065": "- 2023-04-27, **Lightweight, Pre-trained Transformers for Remote Sensing Timeseries**, Gabriel Tseng et.al., Paper: [http://arxiv.org/abs/2304.14065v1](http://arxiv.org/abs/2304.14065v1), Code: **[https://github.com/nasaharvest/presto](https://github.com/nasaharvest/presto)**\n", "2304.13923": "- 2023-04-27, **Retrieval-based Knowledge Augmented Vision Language Pre-training**, Jiahua Rao et.al., Paper: [http://arxiv.org/abs/2304.13923v1](http://arxiv.org/abs/2304.13923v1)\n", "2304.13883": "- 2023-04-27, **Neural Keyphrase Generation: Analysis and Evaluation**, Tuhin Kundu et.al., Paper: [http://arxiv.org/abs/2304.13883v1](http://arxiv.org/abs/2304.13883v1)\n", "2304.13865": "- 2023-04-26, **highway2vec -- representing OpenStreetMap microregions with respect to their road network characteristics**, Kacper Le\u015bniara et.al., Paper: [http://arxiv.org/abs/2304.13865v1](http://arxiv.org/abs/2304.13865v1), Code: **[https://github.com/calychas/highway2vec](https://github.com/calychas/highway2vec)**\n", "2304.13840": "- 2023-04-26, **A Deep Learning Framework for Verilog Autocompletion Towards Design and Verification Automation**, Enrique Dehaerne et.al., Paper: [http://arxiv.org/abs/2304.13840v1](http://arxiv.org/abs/2304.13840v1)\n", "2304.13826": "- 2023-04-26, **Programmatically Grounded, Compositionally Generalizable Robotic Manipulation**, Renhao Wang et.al., Paper: [http://arxiv.org/abs/2304.13826v1](http://arxiv.org/abs/2304.13826v1)\n", "2304.13803": "- 2023-04-26, **Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models**, Haoqiang Kang et.al., Paper: [http://arxiv.org/abs/2304.13803v1](http://arxiv.org/abs/2304.13803v1)\n", "2304.14953": "- 2023-04-28, **CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data**, Micha\u0142 Turski et.al., Paper: [http://arxiv.org/abs/2304.14953v1](http://arxiv.org/abs/2304.14953v1), Code: **[https://github.com/applicaai/ccpdf](https://github.com/applicaai/ccpdf)**\n", "2304.14745": "- 2023-04-28, **Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain**, Annerose Eichel et.al., Paper: [http://arxiv.org/abs/2304.14745v1](http://arxiv.org/abs/2304.14745v1), Code: **[https://github.com/anneroseeichel/eacl2023_made-of-steel](https://github.com/anneroseeichel/eacl2023_made-of-steel)**\n", "2304.14571": "- 2023-04-28, **DIAMANT: Dual Image-Attention Map Encoders For Medical Image Segmentation**, Yousef Yeganeh et.al., Paper: [http://arxiv.org/abs/2304.14571v1](http://arxiv.org/abs/2304.14571v1)\n", "2304.14540": "- 2023-04-27, **Greybox Penetration Testing on Cloud Access Control with IAM Modeling and Deep Reinforcement Learning**, Yang Hu et.al., Paper: [http://arxiv.org/abs/2304.14540v1](http://arxiv.org/abs/2304.14540v1)\n", "2304.14460": "- 2023-04-27, **Gradient-based Maximally Interfered Retrieval for Domain Incremental 3D Object Detection**, Barza Nisar et.al., Paper: [http://arxiv.org/abs/2304.14460v1](http://arxiv.org/abs/2304.14460v1), Code: **[https://github.com/trailab/gmir](https://github.com/trailab/gmir)**\n", "2305.00875": "- 2023-05-01, **Interpreting Pretrained Source-code Models using Neuron Redundancy Analyses**, Arushi Sharma et.al., Paper: [http://arxiv.org/abs/2305.00875v1](http://arxiv.org/abs/2305.00875v1)\n", "2305.00426": "- 2023-04-30, **Transfer of knowledge among instruments in automatic music transcription**, Micha\u0142 Le\u015b et.al., Paper: [http://arxiv.org/abs/2305.00426v1](http://arxiv.org/abs/2305.00426v1)\n", "2305.00385": "- 2023-04-30, **Cross-Shaped Windows Transformer with Self-supervised Pretraining for Clinically Significant Prostate Cancer Detection in Bi-parametric MRI**, Yuheng Li et.al., Paper: [http://arxiv.org/abs/2305.00385v1](http://arxiv.org/abs/2305.00385v1)\n", "2305.00132": "- 2023-04-29, **LD-GAN: Low-Dimensional Generative Adversarial Network for Spectral Image Generation with Variance Regularization**, Emmanuel Martinez et.al., Paper: [http://arxiv.org/abs/2305.00132v1](http://arxiv.org/abs/2305.00132v1), Code: **[https://github.com/hdspgroup/LD-GAN](https://github.com/hdspgroup/LD-GAN)**\n", "2305.00115": "- 2023-04-28, **Towards Better Domain Adaptation for Self-supervised Models: A Case Study of Child ASR**, Ruchao Fan et.al., Paper: [http://arxiv.org/abs/2305.00115v1](http://arxiv.org/abs/2305.00115v1)\n", "2305.00090": "- 2023-04-28, **NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language Selection for Low-Resource Multilingual Sentiment Analysis**, Mingyang Wang et.al., Paper: [http://arxiv.org/abs/2305.00090v1](http://arxiv.org/abs/2305.00090v1)\n", "2305.00067": "- 2023-04-28, **Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features**, Nurislam Tursynbek et.al., Paper: [http://arxiv.org/abs/2305.00067v1](http://arxiv.org/abs/2305.00067v1)\n", "2305.01625": "- 2023-05-02, **Unlimiformer: Long-Range Transformers with Unlimited Length Input**, Amanda Bertsch et.al., Paper: [http://arxiv.org/abs/2305.01625v1](http://arxiv.org/abs/2305.01625v1), Code: **[https://github.com/abertsch72/unlimiformer](https://github.com/abertsch72/unlimiformer)**\n", "2305.01620": "- 2023-05-02, **A Study on the Integration of Pipeline and E2E SLU systems for Spoken Semantic Parsing toward STOP Quality Challenge**, Siddhant Arora et.al., Paper: [http://arxiv.org/abs/2305.01620v1](http://arxiv.org/abs/2305.01620v1)\n", "2305.01146": "- 2023-05-02, **RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models**, Dave Van Veen et.al., Paper: [http://arxiv.org/abs/2305.01146v1](http://arxiv.org/abs/2305.01146v1)\n", "2305.02310": "- 2023-05-03, **Real-Time Radiance Fields for Single-Image Portrait View Synthesis**, Alex Trevithick et.al., Paper: [http://arxiv.org/abs/2305.02310v1](http://arxiv.org/abs/2305.02310v1)\n", "2305.02265": "- 2023-05-05, **A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text**, Yunxin Li et.al., Paper: [http://arxiv.org/abs/2305.02265v2](http://arxiv.org/abs/2305.02265v2), Code: **[https://github.com/yunxinli/ndcr](https://github.com/yunxinli/ndcr)**\n", "2305.02160": "- 2023-05-03, **Explaining Language Models' Predictions with High-Impact Concepts**, Ruochen Zhao et.al., Paper: [http://arxiv.org/abs/2305.02160v1](http://arxiv.org/abs/2305.02160v1)\n", "2305.01810": "- 2023-05-02, **KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness**, Yichuan Li et.al., Paper: [http://arxiv.org/abs/2305.01810v1](http://arxiv.org/abs/2305.01810v1)\n", "2305.01711": "- 2023-05-02, **Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner**, Zhengxiang Shi et.al., Paper: [http://arxiv.org/abs/2305.01711v1](http://arxiv.org/abs/2305.01711v1), Code: **[https://github.com/zhengxiangshi/powerfulpromptft](https://github.com/zhengxiangshi/powerfulpromptft)**\n", "2305.01661": "- 2023-05-02, **SIA-FTP: A Spoken Instruction Aware Flight Trajectory Prediction Framework**, Dongyue Guo et.al., Paper: [http://arxiv.org/abs/2305.01661v1](http://arxiv.org/abs/2305.01661v1)\n", "2305.02981": "- 2023-05-04, **Adversarially-Guided Portrait Matting**, Sergej Chicherin et.al., Paper: [http://arxiv.org/abs/2305.02981v1](http://arxiv.org/abs/2305.02981v1), Code: **[https://github.com/chroneus/stylematte](https://github.com/chroneus/stylematte)**\n", "2305.02937": "- 2023-05-04, **End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders**, Jixuan Wang et.al., Paper: [http://arxiv.org/abs/2305.02937v1](http://arxiv.org/abs/2305.02937v1)\n", "2305.02927": "- 2023-05-04, **Forward-Forward Contrastive Learning**, Md. Atik Ahamed et.al., Paper: [http://arxiv.org/abs/2305.02927v1](http://arxiv.org/abs/2305.02927v1)\n", "2305.02607": "- 2023-05-04, **DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning**, Daniil Homskiy et.al., Paper: [http://arxiv.org/abs/2305.02607v1](http://arxiv.org/abs/2305.02607v1)\n", "2305.02593": "- 2023-05-04, **How to Choose Pretrained Handwriting Recognition Models for Single Writer Fine-Tuning**, Vittorio Pippi et.al., Paper: [http://arxiv.org/abs/2305.02593v1](http://arxiv.org/abs/2305.02593v1)\n", "2305.02382": "- 2023-05-03, **Learning to Detect Novel and Fine-Grained Acoustic Sequences Using Pretrained Audio Representations**, Vasudha Kowtha et.al., Paper: [http://arxiv.org/abs/2305.02382v1](http://arxiv.org/abs/2305.02382v1)\n", "2305.02364": "- 2023-05-03, **PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives**, Silin Gao et.al., Paper: [http://arxiv.org/abs/2305.02364v1](http://arxiv.org/abs/2305.02364v1), Code: **[https://github.com/silin159/peacok](https://github.com/silin159/peacok)**\n", "2305.02363": "- 2023-05-03, **Entity Tracking in Language Models**, Najoung Kim et.al., Paper: [http://arxiv.org/abs/2305.02363v1](http://arxiv.org/abs/2305.02363v1)\n", "2305.03726": "- 2023-05-05, **Otter: A Multi-Modal Model with In-Context Instruction Tuning**, Bo Li et.al., Paper: [http://arxiv.org/abs/2305.03726v1](http://arxiv.org/abs/2305.03726v1)\n", "2305.03689": "- 2023-05-05, **COLA: How to adapt vision-language models to Compose Objects Localized with Attributes?**, Arijit Ray et.al., Paper: [http://arxiv.org/abs/2305.03689v1](http://arxiv.org/abs/2305.03689v1)\n", "2305.03660": "- 2023-05-05, **Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models**, Mercy Ranjit et.al., Paper: [http://arxiv.org/abs/2305.03660v1](http://arxiv.org/abs/2305.03660v1)\n", "2305.03610": "- 2023-05-05, **Data Curation for Image Captioning with Text-to-Image Generative Models**, Wenyan Li et.al., Paper: [http://arxiv.org/abs/2305.03610v1](http://arxiv.org/abs/2305.03610v1)\n", "2305.03374": "- 2023-05-05, **DisenBooth: Disentangled Parameter-Efficient Tuning for Subject-Driven Text-to-Image Generation**, Hong Chen et.al., Paper: [http://arxiv.org/abs/2305.03374v1](http://arxiv.org/abs/2305.03374v1)\n", "2305.03319": "- 2023-05-05, **HiPool: Modeling Long Documents Using Graph Neural Networks**, Irene Li et.al., Paper: [http://arxiv.org/abs/2305.03319v1](http://arxiv.org/abs/2305.03319v1), Code: **[https://github.com/irenezihuili/hipool](https://github.com/irenezihuili/hipool)**\n", "2305.03130": "- 2023-05-04, **Chain-of-Skills: A Configurable Model for Open-domain Question Answering**, Kaixin Ma et.al., Paper: [http://arxiv.org/abs/2305.03130v1](http://arxiv.org/abs/2305.03130v1)\n", "2305.04749": "- 2023-05-08, **Toeplitz Neural Network for Sequence Modeling**, Zhen Qin et.al., Paper: [http://arxiv.org/abs/2305.04749v1](http://arxiv.org/abs/2305.04749v1), Code: **[https://github.com/opennlplab/tnn](https://github.com/opennlplab/tnn)**\n", "2305.04676": "- 2023-05-08, **Enhancing Knowledge Graph Construction Using Large Language Models**, Milena Trajanoska et.al., Paper: [http://arxiv.org/abs/2305.04676v1](http://arxiv.org/abs/2305.04676v1)\n", "2305.04582": "- 2023-05-08, **MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset**, Leonhard Hennig et.al., Paper: [http://arxiv.org/abs/2305.04582v1](http://arxiv.org/abs/2305.04582v1), Code: **[https://github.com/dfki-nlp/multitacred](https://github.com/dfki-nlp/multitacred)**\n", "2305.04530": "- 2023-05-08, **A Multi-Modal Context Reasoning Approach for Conditional Inference on Joint Textual and Visual Clues**, Yunxin Li et.al., Paper: [http://arxiv.org/abs/2305.04530v1](http://arxiv.org/abs/2305.04530v1), Code: **[https://github.com/yunxinli/multimodal-context-reasoning](https://github.com/yunxinli/multimodal-context-reasoning)**\n", "2305.04526": "- 2023-05-08, **SNT: Sharpness-Minimizing Network Transformation for Fast Compression-friendly Pretraining**, Jung Hwan Heo et.al., Paper: [http://arxiv.org/abs/2305.04526v1](http://arxiv.org/abs/2305.04526v1)\n", "2305.04508": "- 2023-05-08, **Retriever and Ranker Framework with Probabilistic Hard Negative Sampling for Code Search**, Hande Dong et.al., Paper: [http://arxiv.org/abs/2305.04508v1](http://arxiv.org/abs/2305.04508v1)\n", "2305.04493": "- 2023-05-08, **Token-level Fitting Issues of Seq2seq Models**, Guangsheng Bao et.al., Paper: [http://arxiv.org/abs/2305.04493v1](http://arxiv.org/abs/2305.04493v1)\n", "2305.04474": "- 2023-05-09, **Vision Langauge Pre-training by Contrastive Learning with Cross-Modal Similarity Regulation**, Chaoya Jiang et.al., Paper: [http://arxiv.org/abs/2305.04474v2](http://arxiv.org/abs/2305.04474v2)\n", "2305.04440": "- 2023-05-08, **Vision Transformer Off-the-Shelf: A Surprising Baseline for Few-Shot Class-Agnostic Counting**, Zhicheng Wang et.al., Paper: [http://arxiv.org/abs/2305.04440v1](http://arxiv.org/abs/2305.04440v1)\n", "2305.04430": "- 2023-05-08, **Breaking Through the Haze: An Advanced Non-Homogeneous Dehazing Method based on Fast Fourier Convolution and ConvNeXt**, Han Zhou et.al., Paper: [http://arxiv.org/abs/2305.04430v1](http://arxiv.org/abs/2305.04430v1), Code: **[https://github.com/zhouh115/dwt-ffc](https://github.com/zhouh115/dwt-ffc)**\n", "2305.05598": "- 2023-05-09, **Region-based Contrastive Pretraining for Medical Image Retrieval with Anatomic Query**, Ho Hin Lee et.al., Paper: [http://arxiv.org/abs/2305.05598v1](http://arxiv.org/abs/2305.05598v1)\n", "2305.05505": "- 2023-05-09, **Recursions Are All You Need: Towards Efficient Deep Unfolding Networks**, Rawwad Alhejaili et.al., Paper: [http://arxiv.org/abs/2305.05505v1](http://arxiv.org/abs/2305.05505v1), Code: **[https://github.com/rawwad-alhejaili/recursions-are-all-you-need](https://github.com/rawwad-alhejaili/recursions-are-all-you-need)**\n", "2305.05503": "- 2023-05-09, **BadCS: A Backdoor Attack Framework for Code search**, Shiyi Qi et.al., Paper: [http://arxiv.org/abs/2305.05503v1](http://arxiv.org/abs/2305.05503v1)\n", "2305.05496": "- 2023-05-09, **Exploiting Pseudo Image Captions for Multimodal Summarization**, Chaoya Jiang et.al., Paper: [http://arxiv.org/abs/2305.05496v1](http://arxiv.org/abs/2305.05496v1), Code: **[https://github.com/sitaproject/sita](https://github.com/sitaproject/sita)**\n", "2305.05461": "- 2023-05-09, **What is the best recipe for character-level encoder-only modelling?**, Kris Cao et.al., Paper: [http://arxiv.org/abs/2305.05461v1](http://arxiv.org/abs/2305.05461v1)\n", "2305.05370": "- 2023-05-09, **MSVQ: Self-Supervised Learning with Multiple Sample Views and Queues**, Chen Peng et.al., Paper: [http://arxiv.org/abs/2305.05370v1](http://arxiv.org/abs/2305.05370v1), Code: **[https://github.com/pc-cp/MSVQ](https://github.com/pc-cp/MSVQ)**\n", "2305.05352": "- 2023-05-09, **A Framework for Designing Foundation Model based Systems**, Qinghua Lu et.al., Paper: [http://arxiv.org/abs/2305.05352v1](http://arxiv.org/abs/2305.05352v1)\n", "2305.05321": "- 2023-05-09, **Application of Artificial Intelligence in the Classification of Microscopical Starch Images for Drug Formulation**, Marvellous Ajala et.al., Paper: [http://arxiv.org/abs/2305.05321v1](http://arxiv.org/abs/2305.05321v1)\n", "2305.05271": "- 2023-05-09, **Robust Acoustic and Semantic Contextual Biasing in Neural Transducers for Speech Recognition**, Xuandi Fu et.al., Paper: [http://arxiv.org/abs/2305.05271v1](http://arxiv.org/abs/2305.05271v1)\n", "2305.05208": "- 2023-05-09, **Boosting Visual-Language Models by Exploiting Hard Samples**, Haonan Wang et.al., Paper: [http://arxiv.org/abs/2305.05208v1](http://arxiv.org/abs/2305.05208v1)\n", "2305.06343": "- 2023-05-10, **Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs**, Roei Herzig et.al., Paper: [http://arxiv.org/abs/2305.06343v1](http://arxiv.org/abs/2305.06343v1)\n", "2305.06090": "- 2023-05-10, **XTab: Cross-table Pretraining for Tabular Transformers**, Bingzhao Zhu et.al., Paper: [http://arxiv.org/abs/2305.06090v1](http://arxiv.org/abs/2305.06090v1), Code: **[https://github.com/bingzhaozhu/xtab](https://github.com/bingzhaozhu/xtab)**\n", "2305.05959": "- 2023-05-10, **A Survey of Deep Code Search**, Yutao Xie et.al., Paper: [http://arxiv.org/abs/2305.05959v1](http://arxiv.org/abs/2305.05959v1)\n", "2305.05943": "- 2023-05-10, **Mover: Mask and Recovery based Facial Part Consistency Aware Method for Deepfake Video Detection**, Juan Hu et.al., Paper: [http://arxiv.org/abs/2305.05943v1](http://arxiv.org/abs/2305.05943v1)\n", "2305.05873": "- 2023-05-10, **SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds**, Qing Li et.al., Paper: [http://arxiv.org/abs/2305.05873v1](http://arxiv.org/abs/2305.05873v1), Code: **[https://github.com/leoqli/shs-net](https://github.com/leoqli/shs-net)**\n", "2305.05862": "- 2023-05-10, **Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks**, Xianzhi Li et.al., Paper: [http://arxiv.org/abs/2305.05862v1](http://arxiv.org/abs/2305.05862v1)\n", "2305.05858": "- 2023-05-10, **V\u0101rta: A Large-Scale Headline-Generation Dataset for Indic Languages**, Rahul Aralikatte et.al., Paper: [http://arxiv.org/abs/2305.05858v1](http://arxiv.org/abs/2305.05858v1), Code: **[https://github.com/rahular/varta](https://github.com/rahular/varta)**\n", "2305.07021": "- 2023-05-11, **Simple Token-Level Confidence Improves Caption Correctness**, Suzanne Petryk et.al., Paper: [http://arxiv.org/abs/2305.07021v1](http://arxiv.org/abs/2305.07021v1)\n", "2305.07016": "- 2023-05-11, **A General-Purpose Multilingual Document Encoder**, Onur Galo\u011flu et.al., Paper: [http://arxiv.org/abs/2305.07016v1](http://arxiv.org/abs/2305.07016v1), Code: **[https://github.com/ogaloglu/pre-training-multilingual-document-encoders](https://github.com/ogaloglu/pre-training-multilingual-document-encoders)**\n", "2305.07011": "- 2023-05-11, **Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers**, Dahun Kim et.al., Paper: [http://arxiv.org/abs/2305.07011v1](http://arxiv.org/abs/2305.07011v1)\n", "2305.06986": "- 2023-05-11, **Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks**, Eshaan Nichani et.al., Paper: [http://arxiv.org/abs/2305.06986v1](http://arxiv.org/abs/2305.06986v1)\n", "2305.06892": "- 2023-05-11, **IUST_NLP at SemEval-2023 Task 10: Explainable Detecting Sexism with Transformers and Task-adaptive Pretraining**, Hadiseh Mahmoudi et.al., Paper: [http://arxiv.org/abs/2305.06892v1](http://arxiv.org/abs/2305.06892v1)\n", "2305.06701": "- 2023-05-11, **Extending Audio Masked Autoencoders Toward Audio Restoration**, Zhi Zhong et.al., Paper: [http://arxiv.org/abs/2305.06701v1](http://arxiv.org/abs/2305.06701v1)\n", "2305.06671": "- 2023-05-11, **WeditGAN: Few-shot Image Generation via Latent Space Relocation**, Yuxuan Duan et.al., Paper: [http://arxiv.org/abs/2305.06671v1](http://arxiv.org/abs/2305.06671v1)\n", "2305.06566": "- 2023-05-11, **A First Look at LLM-Powered Generative News Recommendation**, Qijiong Liu et.al., Paper: [http://arxiv.org/abs/2305.06566v1](http://arxiv.org/abs/2305.06566v1), Code: **[https://github.com/jyonn/genre-requests](https://github.com/jyonn/genre-requests)**\n", "2305.06564": "- 2023-05-11, **Undercover Deepfakes: Detecting Fake Segments in Videos**, Sanjay Saha et.al., Paper: [http://arxiv.org/abs/2305.06564v1](http://arxiv.org/abs/2305.06564v1), Code: **[https://github.com/sanjaysaha1311/temporal-deepfake-segmentation](https://github.com/sanjaysaha1311/temporal-deepfake-segmentation)**\n", "2305.06530": "- 2023-05-11, **How Good are Commercial Large Language Models on African Languages?**, Jessica Ojo et.al., Paper: [http://arxiv.org/abs/2305.06530v1](http://arxiv.org/abs/2305.06530v1)\n", "2305.07558": "- 2023-05-12, **Measuring Progress in Fine-grained Vision-and-Language Understanding**, Emanuele Bugliarello et.al., Paper: [http://arxiv.org/abs/2305.07558v1](http://arxiv.org/abs/2305.07558v1), Code: **[https://github.com/e-bug/fine-grained-evals](https://github.com/e-bug/fine-grained-evals)**\n", "2305.07475": "- 2023-05-12, **Comprehensive Solution Program Centric Pretraining for Table-and-Text Hybrid Numerical Reasoning**, Qianying Liu et.al., Paper: [http://arxiv.org/abs/2305.07475v1](http://arxiv.org/abs/2305.07475v1)\n", "2305.07304": "- 2023-05-12, **CLIP-Count: Towards Text-Guided Zero-Shot Object Counting**, Ruixiang Jiang et.al., Paper: [http://arxiv.org/abs/2305.07304v1](http://arxiv.org/abs/2305.07304v1), Code: **[https://github.com/songrise/clip-count](https://github.com/songrise/clip-count)**\n", "2305.08685": "- 2023-05-15, **CLIP-VG: Self-paced Curriculum Adapting of CLIP via Exploiting Pseudo-Language Labels for Visual Grounding**, Linhui Xiao et.al., Paper: [http://arxiv.org/abs/2305.08685v1](http://arxiv.org/abs/2305.08685v1)\n", "2305.08596": "- 2023-05-15, **DarkBERT: A Language Model for the Dark Side of the Internet**, Youngjin Jin et.al., Paper: [http://arxiv.org/abs/2305.08596v1](http://arxiv.org/abs/2305.08596v1)\n", "2305.08414": "- 2023-05-15, **What's the Meaning of Superhuman Performance in Today's NLU?**, Simone Tedeschi et.al., Paper: [http://arxiv.org/abs/2305.08414v1](http://arxiv.org/abs/2305.08414v1)\n", "2305.08379": "- 2023-05-15, **TESS: Text-to-Text Self-Conditioned Simplex Diffusion**, Rabeeh Karimi Mahabadi et.al., Paper: [http://arxiv.org/abs/2305.08379v1](http://arxiv.org/abs/2305.08379v1)\n", "2305.08300": "- 2023-05-15, **\"Nothing Abnormal\": Disambiguating Medical Reports via Contrastive Knowledge Infusion**, Zexue He et.al., Paper: [http://arxiv.org/abs/2305.08300v1](http://arxiv.org/abs/2305.08300v1)\n", "2305.08283": "- 2023-05-15, **From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models**, Shangbin Feng et.al., Paper: [http://arxiv.org/abs/2305.08283v1](http://arxiv.org/abs/2305.08283v1)\n", "2305.08281": "- 2023-05-14, **FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge**, Shangbin Feng et.al., Paper: [http://arxiv.org/abs/2305.08281v1](http://arxiv.org/abs/2305.08281v1)\n", "2305.08264": "- 2023-05-14, **MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling**, Yu Song et.al., Paper: [http://arxiv.org/abs/2305.08264v1](http://arxiv.org/abs/2305.08264v1), Code: **[https://github.com/banglab-udem-mila/nlp4matsci-acl23](https://github.com/banglab-udem-mila/nlp4matsci-acl23)**\n", "2305.08238": "- 2023-05-14, **Evaluating the roughness of structure-property relationships using pretrained molecular representations**, David E. Graff et.al., Paper: [http://arxiv.org/abs/2305.08238v1](http://arxiv.org/abs/2305.08238v1)\n", "2305.08227": "- 2023-05-14, **DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement**, Hendrik Schr\u00f6ter et.al., Paper: [http://arxiv.org/abs/2305.08227v1](http://arxiv.org/abs/2305.08227v1)\n", "2305.09652": "- 2023-05-16, **The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation**, Mutian He et.al., Paper: [http://arxiv.org/abs/2305.09652v1](http://arxiv.org/abs/2305.09652v1)\n", "2305.09610": "- 2023-05-16, **Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow**, Denis Gudovskiy et.al., Paper: [http://arxiv.org/abs/2305.09610v1](http://arxiv.org/abs/2305.09610v1), Code: **[https://github.com/gudovskiy/flowenedet](https://github.com/gudovskiy/flowenedet)**\n", "2305.09458": "- 2023-05-16, **An Empirical Study on Google Research Football Multi-agent Scenarios**, Yan Song et.al., Paper: [http://arxiv.org/abs/2305.09458v1](http://arxiv.org/abs/2305.09458v1), Code: **[https://github.com/shanghai-digital-brain-laboratory/db-football](https://github.com/shanghai-digital-brain-laboratory/db-football)**\n", "2305.09400": "- 2023-05-16, **Consistent Multi-Granular Rationale Extraction for Explainable Multi-hop Fact Verification**, Jiasheng Si et.al., Paper: [http://arxiv.org/abs/2305.09400v1](http://arxiv.org/abs/2305.09400v1)\n", "2305.09141": "- 2023-05-16, **Deep Ensembling for Perceptual Image Quality Assessment**, Nisar Ahmed et.al., Paper: [http://arxiv.org/abs/2305.09141v1](http://arxiv.org/abs/2305.09141v1)\n", "2305.09057": "- 2023-05-15, **Self-Supervised Pretraining on Paired Sequences of fMRI Data for Transfer Learning to Brain Decoding Tasks**, Sean Paulsen et.al., Paper: [http://arxiv.org/abs/2305.09057v1](http://arxiv.org/abs/2305.09057v1)\n", "2305.10429": "- 2023-05-17, **DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining**, Sang Michael Xie et.al., Paper: [http://arxiv.org/abs/2305.10429v1](http://arxiv.org/abs/2305.10429v1)\n", "2305.10400": "- 2023-05-17, **What You See is What You Read? Improving Text-Image Alignment Evaluation**, Michal Yarom et.al., Paper: [http://arxiv.org/abs/2305.10400v1](http://arxiv.org/abs/2305.10400v1), Code: **[https://github.com/yonatanbitton/wysiwyr](https://github.com/yonatanbitton/wysiwyr)**\n", "2305.10231": "- 2023-05-17, **OpenSLU: A Unified, Modularized, and Extensible Toolkit for Spoken Language Understanding**, Libo Qin et.al., Paper: [http://arxiv.org/abs/2305.10231v1](http://arxiv.org/abs/2305.10231v1), Code: **[https://github.com/lightchen233/openslu](https://github.com/lightchen233/openslu)**\n", "2305.10160": "- 2023-05-17, **Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks**, Alon Jacovi et.al., Paper: [http://arxiv.org/abs/2305.10160v1](http://arxiv.org/abs/2305.10160v1)\n", "2305.10120": "- 2023-05-17, **Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models**, Alvin Heng et.al., Paper: [http://arxiv.org/abs/2305.10120v1](http://arxiv.org/abs/2305.10120v1)\n", "2305.10084": "- 2023-05-17, **CWD30: A Comprehensive and Holistic Dataset for Crop Weed Recognition in Precision Agriculture**, Talha Ilyas et.al., Paper: [http://arxiv.org/abs/2305.10084v1](http://arxiv.org/abs/2305.10084v1)\n", "2305.10077": "- 2023-05-17, **Dynamic Structural Brain Network Construction by Hierarchical Prototype Embedding GCN using T1-MRI**, Yilin Leng et.al., Paper: [http://arxiv.org/abs/2305.10077v1](http://arxiv.org/abs/2305.10077v1)\n", "2305.09900": "- 2023-05-17, **Equivariant Few-Shot Learning from Pretrained Models**, Sourya Basu et.al., Paper: [http://arxiv.org/abs/2305.09900v1](http://arxiv.org/abs/2305.09900v1)\n", "2305.11172": "- 2023-05-18, **ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities**, Peng Wang et.al., Paper: [http://arxiv.org/abs/2305.11172v1](http://arxiv.org/abs/2305.11172v1), Code: **[https://github.com/OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE)**\n", "2305.11164": "- 2023-05-18, **Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study**, Joel Casta\u00f1o et.al., Paper: [http://arxiv.org/abs/2305.11164v1](http://arxiv.org/abs/2305.11164v1)\n", "2305.11147": "- 2023-05-18, **UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild**, Can Qin et.al., Paper: [http://arxiv.org/abs/2305.11147v1](http://arxiv.org/abs/2305.11147v1)\n", "2305.11129": "- 2023-05-18, **mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences**, David Uthus et.al., Paper: [http://arxiv.org/abs/2305.11129v1](http://arxiv.org/abs/2305.11129v1)\n", "2305.11014": "- 2023-05-18, **Generalized Planning in PDDL Domains with Pretrained Large Language Models**, Tom Silver et.al., Paper: [http://arxiv.org/abs/2305.11014v1](http://arxiv.org/abs/2305.11014v1), Code: **[https://github.com/tomsilver/llm-genplan](https://github.com/tomsilver/llm-genplan)**\n", "2305.10998": "- 2023-05-18, **The Web Can Be Your Oyster for Improving Large Language Models**, Junyi Li et.al., Paper: [http://arxiv.org/abs/2305.10998v1](http://arxiv.org/abs/2305.10998v1)\n", "2305.10992": "- 2023-05-18, **How does the task complexity of masked pretraining objectives affect downstream performance?**, Atsuki Yamaguchi et.al., Paper: [http://arxiv.org/abs/2305.10992v1](http://arxiv.org/abs/2305.10992v1), Code: **[https://github.com/hitachi-nlp/mlm-probe-acl2023](https://github.com/hitachi-nlp/mlm-probe-acl2023)**\n", "2305.10889": "- 2023-05-18, **FLIGHT Mode On: A Feather-Light Network for Low-Light Image Enhancement**, Mustafa Ozcan et.al., Paper: [http://arxiv.org/abs/2305.10889v1](http://arxiv.org/abs/2305.10889v1)\n", "2305.10874": "- 2023-05-18, **VideoFactory: Swap Attention in Spatiotemporal Diffusions for Text-to-Video Generation**, Wenjing Wang et.al., Paper: [http://arxiv.org/abs/2305.10874v1](http://arxiv.org/abs/2305.10874v1)\n", "2305.10865": "- 2023-05-18, **Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning**, Wenhao Li et.al., Paper: [http://arxiv.org/abs/2305.10865v1](http://arxiv.org/abs/2305.10865v1)\n", "2305.11772": "- 2023-05-19, **Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes**, Aran Nayebi et.al., Paper: [http://arxiv.org/abs/2305.11772v1](http://arxiv.org/abs/2305.11772v1)\n", "2305.11569": "- 2023-05-19, **Language-Universal Phonetic Representation in Multilingual Speech Pretraining for Low-Resource Speech Recognition**, Siyuan Feng et.al., Paper: [http://arxiv.org/abs/2305.11569v1](http://arxiv.org/abs/2305.11569v1)\n", "2305.11504": "- 2023-05-19, **JOINEDTrans: Prior Guided Multi-task Transformer for Joint Optic Disc/Cup Segmentation and Fovea Detection**, Huaqing He et.al., Paper: [http://arxiv.org/abs/2305.11504v1](http://arxiv.org/abs/2305.11504v1)\n", "2305.11497": "- 2023-05-19, **TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding**, Chenchi Zhang et.al., Paper: [http://arxiv.org/abs/2305.11497v1](http://arxiv.org/abs/2305.11497v1)\n", "2305.11452": "- 2023-05-19, **ReDirTrans: Latent-to-Latent Translation for Gaze and Head Redirection**, Shiwei Jin et.al., Paper: [http://arxiv.org/abs/2305.11452v1](http://arxiv.org/abs/2305.11452v1)\n", "2305.11262": "- 2023-05-18, **CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models**, Jiaxu Zhao et.al., Paper: [http://arxiv.org/abs/2305.11262v1](http://arxiv.org/abs/2305.11262v1)\n", "2305.11242": "- 2023-05-18, **Comparing Biases and the Impact of Multilingual Training across Multiple Languages**, Sharon Levy et.al., Paper: [http://arxiv.org/abs/2305.11242v1](http://arxiv.org/abs/2305.11242v1)\n", "2305.11206": "- 2023-05-18, **LIMA: Less Is More for Alignment**, Chunting Zhou et.al., Paper: [http://arxiv.org/abs/2305.11206v1](http://arxiv.org/abs/2305.11206v1)\n", "2305.13302": "- 2023-05-22, **Language-Agnostic Bias Detection in Language Models**, Abdullatif K\u00f6ksal et.al., Paper: [http://arxiv.org/abs/2305.13302v1](http://arxiv.org/abs/2305.13302v1)\n", "2305.13195": "- 2023-05-22, **U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech**, Xin Jing et.al., Paper: [http://arxiv.org/abs/2305.13195v1](http://arxiv.org/abs/2305.13195v1)\n", "2305.13169": "- 2023-05-22, **A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity**, Shayne Longpre et.al., Paper: [http://arxiv.org/abs/2305.13169v1](http://arxiv.org/abs/2305.13169v1)\n", "2305.13086": "- 2023-05-22, **LMGQS: A Large-scale Dataset for Query-focused Summarization**, Ruochen Xu et.al., Paper: [http://arxiv.org/abs/2305.13086v1](http://arxiv.org/abs/2305.13086v1)\n", "2305.13009": "- 2023-05-22, **Textually Pretrained Speech Language Models**, Michael Hassid et.al., Paper: [http://arxiv.org/abs/2305.13009v1](http://arxiv.org/abs/2305.13009v1)\n", "2305.13002": "- 2023-05-22, **Rethinking Semi-supervised Learning with Language Models**, Zhengxiang Shi et.al., Paper: [http://arxiv.org/abs/2305.13002v1](http://arxiv.org/abs/2305.13002v1), Code: **[https://github.com/amzn/pretraining-or-self-training](https://github.com/amzn/pretraining-or-self-training)**\n", "2305.12964": "- 2023-05-22, **Text-based Person Search without Parallel Image-Text Data**, Yang Bai et.al., Paper: [http://arxiv.org/abs/2305.12964v1](http://arxiv.org/abs/2305.12964v1)\n", "2305.12816": "- 2023-05-22, **Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model**, Xiao Wang et.al., Paper: [http://arxiv.org/abs/2305.12816v1](http://arxiv.org/abs/2305.12816v1)\n", "2305.12766": "- 2023-05-22, **In-Context Learning of Large Language Models Explained as Kernel Regression**, Chi Han et.al., Paper: [http://arxiv.org/abs/2305.12766v1](http://arxiv.org/abs/2305.12766v1)\n", "2305.12712": "- 2023-05-22, **LEAN: Light and Efficient Audio Classification Network**, Shwetank Choudhary et.al., Paper: [http://arxiv.org/abs/2305.12712v1](http://arxiv.org/abs/2305.12712v1)\n", "2305.14343": "- 2023-05-23, **Video Prediction Models as Rewards for Reinforcement Learning**, Alejandro Escontrela et.al., Paper: [http://arxiv.org/abs/2305.14343v1](http://arxiv.org/abs/2305.14343v1)\n", "2305.14321": "- 2023-05-23, **ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and Text Embeddings**, William Brannon et.al., Paper: [http://arxiv.org/abs/2305.14321v1](http://arxiv.org/abs/2305.14321v1), Code: **[https://github.com/wwbrannon/congrat](https://github.com/wwbrannon/congrat)**\n", "2305.14314": "- 2023-05-23, **QLoRA: Efficient Finetuning of Quantized LLMs**, Tim Dettmers et.al., Paper: [http://arxiv.org/abs/2305.14314v1](http://arxiv.org/abs/2305.14314v1), Code: **[https://github.com/artidoro/qlora](https://github.com/artidoro/qlora)**\n", "2305.14281": "- 2023-05-23, **Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining**, Emanuele Bugliarello et.al., Paper: [http://arxiv.org/abs/2305.14281v1](http://arxiv.org/abs/2305.14281v1)\n", "2305.14268": "- 2023-05-23, **Masked Path Modeling for Vision-and-Language Navigation**, Zi-Yi Dou et.al., Paper: [http://arxiv.org/abs/2305.14268v1](http://arxiv.org/abs/2305.14268v1)\n", "2305.14218": "- 2023-05-24, **DUBLIN -- Document Understanding By Language-Image Network**, Kriti Aggarwal et.al., Paper: [http://arxiv.org/abs/2305.14218v2](http://arxiv.org/abs/2305.14218v2)\n", "2305.14201": "- 2023-05-23, **Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks**, Tiedong Liu et.al., Paper: [http://arxiv.org/abs/2305.14201v1](http://arxiv.org/abs/2305.14201v1)\n", "2305.14200": "- 2023-05-23, **Accessing Higher Dimensions for Unsupervised Word Translation**, Sida I. Wang et.al., Paper: [http://arxiv.org/abs/2305.14200v1](http://arxiv.org/abs/2305.14200v1)\n", "2305.14069": "- 2023-05-23, **Evaluating Factual Consistency of Summaries with Large Language Models**, Shiqi Chen et.al., Paper: [http://arxiv.org/abs/2305.14069v1](http://arxiv.org/abs/2305.14069v1), Code: **[https://github.com/sjtu-lit/llmeval_sum_factual](https://github.com/sjtu-lit/llmeval_sum_factual)**\n", "2305.14032": "- 2023-05-23, **Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on Respiratory Sound Classification**, Sangmin Bae et.al., Paper: [http://arxiv.org/abs/2305.14032v1](http://arxiv.org/abs/2305.14032v1), Code: **[https://github.com/raymin0223/patch-mix_contrastive_learning](https://github.com/raymin0223/patch-mix_contrastive_learning)**\n", "2305.15372": "- 2023-05-24, **What can generic neural networks learn from a child's visual experience?**, A. Emin Orhan et.al., Paper: [http://arxiv.org/abs/2305.15372v1](http://arxiv.org/abs/2305.15372v1)\n", "2305.15357": "- 2023-05-24, **Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution**, Yiyang Ma et.al., Paper: [http://arxiv.org/abs/2305.15357v1](http://arxiv.org/abs/2305.15357v1)\n", "2305.15328": "- 2023-05-24, **Visual Programming for Text-to-Image Generation and Evaluation**, Jaemin Cho et.al., Paper: [http://arxiv.org/abs/2305.15328v1](http://arxiv.org/abs/2305.15328v1)\n", "2305.15275": "- 2023-05-24, **Self-Evolution Learning for Discriminative Language Model Pretraining**, Qihuang Zhong et.al., Paper: [http://arxiv.org/abs/2305.15275v1](http://arxiv.org/abs/2305.15275v1)\n", "2305.15273": "- 2023-05-24, **Revisiting Token Dropping Strategy in Efficient BERT Pretraining**, Qihuang Zhong et.al., Paper: [http://arxiv.org/abs/2305.15273v1](http://arxiv.org/abs/2305.15273v1)\n", "2305.15272": "- 2023-05-24, **ViTMatte: Boosting Image Matting with Pretrained Plain Vision Transformers**, Jingfeng Yao et.al., Paper: [http://arxiv.org/abs/2305.15272v1](http://arxiv.org/abs/2305.15272v1), Code: **[https://github.com/hustvl/ViTMatte](https://github.com/hustvl/ViTMatte)**\n", "2305.15253": "- 2023-05-24, **Rethinking the Evaluation Protocol of Domain Generalization**, Han Yu et.al., Paper: [http://arxiv.org/abs/2305.15253v1](http://arxiv.org/abs/2305.15253v1)\n", "2305.15217": "- 2023-05-24, **L-CAD: Language-based Colorization with Any-level Descriptions**, Zheng Chang et.al., Paper: [http://arxiv.org/abs/2305.15217v1](http://arxiv.org/abs/2305.15217v1)\n", "2305.15099": "- 2023-05-24, **Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator**, Ziwei He et.al., Paper: [http://arxiv.org/abs/2305.15099v1](http://arxiv.org/abs/2305.15099v1)\n", "2305.15096": "- 2023-05-24, **Dynamic Masking Rate Schedules for MLM Pretraining**, Zachary Ankner et.al., Paper: [http://arxiv.org/abs/2305.15096v1](http://arxiv.org/abs/2305.15096v1)\n", "2305.16317": "- 2023-05-25, **Parallel Sampling of Diffusion Models**, Andy Shih et.al., Paper: [http://arxiv.org/abs/2305.16317v1](http://arxiv.org/abs/2305.16317v1), Code: **[https://github.com/AndyShih12/paradigms](https://github.com/AndyShih12/paradigms)**\n", "2305.16302": "- 2023-05-25, **Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages**, Shivanshu Gupta et.al., Paper: [http://arxiv.org/abs/2305.16302v1](http://arxiv.org/abs/2305.16302v1)\n", "2305.16289": "- 2023-05-25, **Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation**, Lisa Dunlap et.al., Paper: [http://arxiv.org/abs/2305.16289v1](http://arxiv.org/abs/2305.16289v1), Code: **[https://github.com/lisadunlap/alia](https://github.com/lisadunlap/alia)**\n", "2305.16213": "- 2023-05-25, **ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation**, Zhengyi Wang et.al., Paper: [http://arxiv.org/abs/2305.16213v1](http://arxiv.org/abs/2305.16213v1), Code: **[https://github.com/thu-ml/prolificdreamer](https://github.com/thu-ml/prolificdreamer)**\n", "2305.16199": "- 2023-05-26, **Diversity-Aware Coherence Loss for Improving Neural Topic Models**, Raymond Li et.al., Paper: [http://arxiv.org/abs/2305.16199v2](http://arxiv.org/abs/2305.16199v2), Code: **[https://github.com/raymondzmc/topic-model-diversity-aware-coherence-loss](https://github.com/raymondzmc/topic-model-diversity-aware-coherence-loss)**\n", "2305.16192": "- 2023-05-25, **Explainability Techniques for Chemical Language Models**, Stefan H\u00f6dl et.al., Paper: [http://arxiv.org/abs/2305.16192v1](http://arxiv.org/abs/2305.16192v1), Code: **[https://github.com/kachmanlab/chemical_language_model_explainer](https://github.com/kachmanlab/chemical_language_model_explainer)**\n", "2305.16130": "- 2023-05-25, **Language Models Implement Simple Word2Vec-style Vector Arithmetic**, Jack Merullo et.al., Paper: [http://arxiv.org/abs/2305.16130v1](http://arxiv.org/abs/2305.16130v1), Code: **[https://github.com/jmerullo/lm_vector_arithmetic](https://github.com/jmerullo/lm_vector_arithmetic)**\n", "2305.15971": "- 2023-05-25, **Knowledge Distillation for Neural Transducer-based Target-Speaker ASR: Exploiting Parallel Mixture/Single-Talker Speech Data**, Takafumi Moriya et.al., Paper: [http://arxiv.org/abs/2305.15971v1](http://arxiv.org/abs/2305.15971v1)\n", "2305.15905": "- 2023-05-25, **Latent Diffusion Model Based Foley Sound Generation System For DCASE Challenge 2023 Task 7**, Yi Yuan et.al., Paper: [http://arxiv.org/abs/2305.15905v1](http://arxiv.org/abs/2305.15905v1)\n", "2305.15798": "- 2023-05-25, **On Architectural Compression of Text-to-Image Diffusion Models**, Bo-Kyeong Kim et.al., Paper: [http://arxiv.org/abs/2305.15798v1](http://arxiv.org/abs/2305.15798v1)\n", "2305.17100": "- 2023-05-26, **BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks**, Kai Zhang et.al., Paper: [http://arxiv.org/abs/2305.17100v1](http://arxiv.org/abs/2305.17100v1), Code: **[https://github.com/taokz/biomedgpt](https://github.com/taokz/biomedgpt)**\n", "2305.17077": "- 2023-05-26, **Learning and Leveraging Verifiers to Improve Planning Capabilities of Pre-trained Language Models**, Daman Arora et.al., Paper: [http://arxiv.org/abs/2305.17077v1](http://arxiv.org/abs/2305.17077v1)\n", "2305.17050": "- 2023-05-26, **Exploiting Abstract Meaning Representation for Open-Domain Question Answering**, Cunxiang Wang et.al., Paper: [http://arxiv.org/abs/2305.17050v1](http://arxiv.org/abs/2305.17050v1)\n", "2305.17019": "- 2023-05-26, **Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering**, Siwei Wu et.al., Paper: [http://arxiv.org/abs/2305.17019v1](http://arxiv.org/abs/2305.17019v1)\n", "2305.17013": "- 2023-05-26, **D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias**, Sabit Hassan et.al., Paper: [http://arxiv.org/abs/2305.17013v1](http://arxiv.org/abs/2305.17013v1)\n", "2305.16999": "- 2023-05-29, **Three Towers: Flexible Contrastive Learning with Pretrained Image Models**, Jannik Kossen et.al., Paper: [http://arxiv.org/abs/2305.16999v2](http://arxiv.org/abs/2305.16999v2)\n", "2305.16985": "- 2023-05-26, **Inverse Dynamics Pretraining Learns Good Representations for Multitask Imitation**, David Brandfonbrener et.al., Paper: [http://arxiv.org/abs/2305.16985v1](http://arxiv.org/abs/2305.16985v1)\n", "2305.16954": "- 2023-05-26, **Compositional Generalization without Trees using Multiset Tagging and Latent Permutations**, Matthias Lindemann et.al., Paper: [http://arxiv.org/abs/2305.16954v1](http://arxiv.org/abs/2305.16954v1)\n", "2305.16934": "- 2023-05-26, **On Evaluating Adversarial Robustness of Large Vision-Language Models**, Yunqing Zhao et.al., Paper: [http://arxiv.org/abs/2305.16934v1](http://arxiv.org/abs/2305.16934v1), Code: **[https://github.com/yunqing-me/attackvlm](https://github.com/yunqing-me/attackvlm)**\n", "2305.16797": "- 2023-05-26, **Calibration of Transformer-based Models for Identifying Stress and Depression in Social Media**, Loukas Ilias et.al., Paper: [http://arxiv.org/abs/2305.16797v1](http://arxiv.org/abs/2305.16797v1)\n", "2305.18283": "- 2023-05-29, **CommonAccent: Exploring Large Acoustic Pretrained Models for Accent Classification Based on Common Voice**, Juan Zuluaga-Gomez et.al., Paper: [http://arxiv.org/abs/2305.18283v1](http://arxiv.org/abs/2305.18283v1), Code: **[https://github.com/speechbrain/speechbrain](https://github.com/speechbrain/speechbrain)**\n", "2305.18203": "- 2023-05-29, **Concept Decomposition for Visual Exploration and Inspiration**, Yael Vinker et.al., Paper: [http://arxiv.org/abs/2305.18203v1](http://arxiv.org/abs/2305.18203v1)\n", "2305.18149": "- 2023-05-29, **Multiscale Positive-Unlabeled Detection of AI-Generated Texts**, Yuchuan Tian et.al., Paper: [http://arxiv.org/abs/2305.18149v1](http://arxiv.org/abs/2305.18149v1), Code: **[https://github.com/huawei-noah/Efficient-Computing](https://github.com/huawei-noah/Efficient-Computing)**\n", "2305.18007": "- 2023-05-29, **Conditional Score Guidance for Text-Driven Image-to-Image Translation**, Hyunsoo Lee et.al., Paper: [http://arxiv.org/abs/2305.18007v1](http://arxiv.org/abs/2305.18007v1)\n", "2305.17968": "- 2023-05-29, **Data Augmentation for Low-Resource Keyphrase Generation**, Krishna Garg et.al., Paper: [http://arxiv.org/abs/2305.17968v1](http://arxiv.org/abs/2305.17968v1), Code: **[https://github.com/kgarg8/kpgen-lowres-data-aug](https://github.com/kgarg8/kpgen-lowres-data-aug)**\n", "2305.17817": "- 2023-05-28, **Transfer Learning for Power Outage Detection Task with Limited Training Data**, Olukunle Owolabi et.al., Paper: [http://arxiv.org/abs/2305.17817v1](http://arxiv.org/abs/2305.17817v1)\n", "2305.17719": "- 2023-05-28, **Adapting Language-Audio Models as Few-Shot Audio Learners**, Jinhua Liang et.al., Paper: [http://arxiv.org/abs/2305.17719v1](http://arxiv.org/abs/2305.17719v1)\n", "2305.17648": "- 2023-05-28, **Z-GMOT: Zero-shot Generic Multiple Object Tracking**, Kim Hoang Tran et.al., Paper: [http://arxiv.org/abs/2305.17648v1](http://arxiv.org/abs/2305.17648v1)\n", "2305.17540": "- 2023-05-30, **Learning from Children: Improving Image-Caption Pretraining via Curriculum**, Hammad A. Ayyubi et.al., Paper: [http://arxiv.org/abs/2305.17540v2](http://arxiv.org/abs/2305.17540v2), Code: **[https://github.com/hayyubi/cur_vl](https://github.com/hayyubi/cur_vl)**\n", "2305.17489": "- 2023-05-27, **Text-to-image Editing by Image Information Removal**, Zhongping Zhang et.al., Paper: [http://arxiv.org/abs/2305.17489v1](http://arxiv.org/abs/2305.17489v1)\n", "2305.19264": "- 2023-05-30, **Jointly Reparametrized Multi-Layer Adaptation for Efficient and Private Tuning**, Umang Gupta et.al., Paper: [http://arxiv.org/abs/2305.19264v1](http://arxiv.org/abs/2305.19264v1), Code: **[https://github.com/umgupta/jointly-reparametrized-finetuning](https://github.com/umgupta/jointly-reparametrized-finetuning)**\n", "2305.19201": "- 2023-05-30, **D\u00e4RF: Boosting Radiance Fields from Sparse Inputs with Monocular Depth Adaptation**, Jiuhn Song et.al., Paper: [http://arxiv.org/abs/2305.19201v1](http://arxiv.org/abs/2305.19201v1)\n", "2305.19165": "- 2023-05-30, **Strategic Reasoning with Language Models**, Kanishk Gandhi et.al., Paper: [http://arxiv.org/abs/2305.19165v1](http://arxiv.org/abs/2305.19165v1)\n", "2305.19164": "- 2023-05-30, **LANCE: Stress-testing Visual Models by Generating Language-guided Counterfactual Images**, Viraj Prabhu et.al., Paper: [http://arxiv.org/abs/2305.19164v1](http://arxiv.org/abs/2305.19164v1)\n", "2305.19092": "- 2023-05-30, **Together We Make Sense -- Learning Meta-Sense Embeddings from Pretrained Static Sense Embeddings**, Haochen Luo et.al., Paper: [http://arxiv.org/abs/2305.19092v1](http://arxiv.org/abs/2305.19092v1)\n", "2305.19066": "- 2023-05-30, **Nested Diffusion Processes for Anytime Image Generation**, Noam Elata et.al., Paper: [http://arxiv.org/abs/2305.19066v1](http://arxiv.org/abs/2305.19066v1), Code: **[https://github.com/noamelata/nesteddiffusion](https://github.com/noamelata/nesteddiffusion)**\n", "2305.18975": "- 2023-05-30, **Voice Conversion With Just Nearest Neighbors**, Matthew Baas et.al., Paper: [http://arxiv.org/abs/2305.18975v1](http://arxiv.org/abs/2305.18975v1), Code: **[https://github.com/bshall/knn-vc](https://github.com/bshall/knn-vc)**\n", "2305.18948": "- 2023-05-30, **Prompt-based Tuning of Transformer Models for Multi-Center Medical Image Segmentation**, Numan Saeed et.al., Paper: [http://arxiv.org/abs/2305.18948v1](http://arxiv.org/abs/2305.18948v1)\n", "2305.18915": "- 2023-05-30, **Empirical Sufficiency Lower Bounds for Language Modeling with Locally-Bootstrapped Semantic Structures**, Jakob Prange et.al., Paper: [http://arxiv.org/abs/2305.18915v1](http://arxiv.org/abs/2305.18915v1), Code: **[https://github.com/jakpra/sufficiencylowerbounds](https://github.com/jakpra/sufficiencylowerbounds)**\n", "2305.18869": "- 2023-05-30, **Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs**, Yingcong Li et.al., Paper: [http://arxiv.org/abs/2305.18869v1](http://arxiv.org/abs/2305.18869v1)\n", "2305.20087": "- 2023-06-01, **Too Large; Data Reduction for Vision-Language Pre-Training**, Alex Jinpeng Wang et.al., Paper: [http://arxiv.org/abs/2305.20087v2](http://arxiv.org/abs/2305.20087v2), Code: **[https://github.com/showlab/data-centric.vlp](https://github.com/showlab/data-centric.vlp)**\n", "2305.19998": "- 2023-05-31, **Efficient Shapley Values Estimation by Amortization for Text Classification**, Chenghao Yang et.al., Paper: [http://arxiv.org/abs/2305.19998v1](http://arxiv.org/abs/2305.19998v1), Code: **[https://github.com/yangalan123/amortized-interpretability](https://github.com/yangalan123/amortized-interpretability)**\n", "2305.19928": "- 2023-06-01, **A Global Context Mechanism for Sequence Labeling**, Conglei Xu et.al., Paper: [http://arxiv.org/abs/2305.19928v2](http://arxiv.org/abs/2305.19928v2), Code: **[https://github.com/conglei2xu/global-context-mechanism](https://github.com/conglei2xu/global-context-mechanism)**\n", "2305.19912": "- 2023-05-31, **Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data**, Xinze Li et.al., Paper: [http://arxiv.org/abs/2305.19912v1](http://arxiv.org/abs/2305.19912v1), Code: **[https://github.com/openmatch/openmatch](https://github.com/openmatch/openmatch)**\n", "2305.19847": "- 2023-05-31, **How Does Pretraining Improve Discourse-Aware Translation?**, Zhihong Huang et.al., Paper: [http://arxiv.org/abs/2305.19847v1](http://arxiv.org/abs/2305.19847v1)\n", "2305.19812": "- 2023-05-31, **A Survey of Label-Efficient Deep Learning for 3D Point Clouds**, Aoran Xiao et.al., Paper: [http://arxiv.org/abs/2305.19812v1](http://arxiv.org/abs/2305.19812v1), Code: **[https://github.com/xiaoaoran/3d_label_efficient_learning](https://github.com/xiaoaoran/3d_label_efficient_learning)**\n", "2305.19757": "- 2023-05-31, **Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios**, Malina Chichirau et.al., Paper: [http://arxiv.org/abs/2305.19757v1](http://arxiv.org/abs/2305.19757v1)\n", "2305.19698": "- 2023-05-31, **Investigation of the Robustness of Neural Density Fields**, Jonas Schuhmacher et.al., Paper: [http://arxiv.org/abs/2305.19698v1](http://arxiv.org/abs/2305.19698v1)\n", "2305.19684": "- 2023-05-31, **End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization**, Shohei Taniguchi et.al., Paper: [http://arxiv.org/abs/2305.19684v1](http://arxiv.org/abs/2305.19684v1), Code: **[https://github.com/ishohei220/unbiased_dbm](https://github.com/ishohei220/unbiased_dbm)**\n", "2305.19585": "- 2023-05-31, **LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction**, Jeremiah Milbauer et.al., Paper: [http://arxiv.org/abs/2305.19585v1](http://arxiv.org/abs/2305.19585v1)\n", "2306.00989": "- 2023-06-01, **Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles**, Chaitanya Ryali et.al., Paper: [http://arxiv.org/abs/2306.00989v1](http://arxiv.org/abs/2306.00989v1), Code: **[https://github.com/facebookresearch/hiera](https://github.com/facebookresearch/hiera)**\n", "2306.00987": "- 2023-06-01, **StyleGAN knows Normal, Depth, Albedo, and More**, Anand Bhattad et.al., Paper: [http://arxiv.org/abs/2306.00987v1](http://arxiv.org/abs/2306.00987v1)\n", "2306.00988": "- 2023-06-01, **Continual Learning for Abdominal Multi-Organ and Tumor Segmentation**, Yixiao Zhang et.al., Paper: [http://arxiv.org/abs/2306.00988v1](http://arxiv.org/abs/2306.00988v1), Code: **[https://github.com/mrgiovanni/continuallearning](https://github.com/mrgiovanni/continuallearning)**\n", "2306.00986": "- 2023-06-01, **Diffusion Self-Guidance for Controllable Image Generation**, Dave Epstein et.al., Paper: [http://arxiv.org/abs/2306.00986v1](http://arxiv.org/abs/2306.00986v1)\n", "2306.00942": "- 2023-06-01, **Train Offline, Test Online: A Real Robot Learning Benchmark**, Gaoyue Zhou et.al., Paper: [http://arxiv.org/abs/2306.00942v1](http://arxiv.org/abs/2306.00942v1), Code: **[https://github.com/AGI-Labs/toto_benchmark](https://github.com/AGI-Labs/toto_benchmark)**\n", "2306.00937": "- 2023-06-01, **STEVE-1: A Generative Model for Text-to-Behavior in Minecraft**, Shalev Lifshitz et.al., Paper: [http://arxiv.org/abs/2306.00937v1](http://arxiv.org/abs/2306.00937v1)\n", "2306.00931": "- 2023-06-01, **\"Let's not Quote out of Context\": Unified Vision-Language Pretraining for Context Assisted Image Captioning**, Abisek Rajakumar Kalarani et.al., Paper: [http://arxiv.org/abs/2306.00931v1](http://arxiv.org/abs/2306.00931v1)\n", "2306.00926": "- 2023-06-01, **Inserting Anybody in Diffusion Models via Celeb Basis**, Ge Yuan et.al., Paper: [http://arxiv.org/abs/2306.00926v1](http://arxiv.org/abs/2306.00926v1), Code: **[https://github.com/ygtxr1997/celebbasis](https://github.com/ygtxr1997/celebbasis)**\n", "2306.00830": "- 2023-06-01, **Adapting a ConvNeXt model to audio classification on AudioSet**, Thomas Pellegrini et.al., Paper: [http://arxiv.org/abs/2306.00830v1](http://arxiv.org/abs/2306.00830v1)\n", "2306.00826": "- 2023-06-01, **In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation**, Julian Bitterwolf et.al., Paper: [http://arxiv.org/abs/2306.00826v1](http://arxiv.org/abs/2306.00826v1), Code: **[https://github.com/j-cb/ninco](https://github.com/j-cb/ninco)**\n"}, "downstream": {"2209.06575": "- 2022-09-14, **Efficient multi-relational network representation using primes**, Konstantinos Bougiatiotis et.al., Paper: [http://arxiv.org/abs/2209.06575v1](http://arxiv.org/abs/2209.06575v1)\n", "2209.06515": "- 2022-09-15, **Learning to Evaluate Performance of Multi-modal Semantic Localization**, Zhiqiang Yuan et.al., Paper: [http://arxiv.org/abs/2209.06515v2](http://arxiv.org/abs/2209.06515v2), Code: **[https://github.com/xiaoyuan1996/semanticlocalizationmetrics](https://github.com/xiaoyuan1996/semanticlocalizationmetrics)**\n", "2209.06389": "- 2022-09-14, **Jointly Contrastive Representation Learning on Road Network and Trajectory**, Zhenyu Mao et.al., Paper: [http://arxiv.org/abs/2209.06389v1](http://arxiv.org/abs/2209.06389v1), Code: **[https://github.com/mzy94/jclrnt](https://github.com/mzy94/jclrnt)**\n", "2209.06243": "- 2022-09-13, **CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task**, Ricardo Rei et.al., Paper: [http://arxiv.org/abs/2209.06243v1](http://arxiv.org/abs/2209.06243v1)\n", "2209.06063": "- 2022-09-13, **Space-Efficient Random Walks on Streaming Graphs**, Serafeim Papadias et.al., Paper: [http://arxiv.org/abs/2209.06063v1](http://arxiv.org/abs/2209.06063v1), Code: **[https://github.com/spapadias/wharf](https://github.com/spapadias/wharf)**\n", "2209.06058": "- 2022-09-13, **Streaming End-to-End Multilingual Speech Recognition with Joint Language Identification**, Chao Zhang et.al., Paper: [http://arxiv.org/abs/2209.06058v1](http://arxiv.org/abs/2209.06058v1)\n", "2209.05972": "- 2022-09-13, **Don't Judge a Language Model by Its Last Layer: Contrastive Learning with Layer-Wise Attention Pooling**, Dongsuk Oh et.al., Paper: [http://arxiv.org/abs/2209.05972v1](http://arxiv.org/abs/2209.05972v1), Code: **[https://github.com/nlpods/layerattpooler](https://github.com/nlpods/layerattpooler)**\n", "2209.05168": "- 2022-09-12, **Manifold Rewiring for Unlabeled Imaging**, Valentin Debarnot et.al., Paper: [http://arxiv.org/abs/2209.05168v1](http://arxiv.org/abs/2209.05168v1)\n", "2209.04994": "- 2022-09-14, **Knowledge Base Question Answering: A Semantic Parsing Perspective**, Yu Gu et.al., Paper: [http://arxiv.org/abs/2209.04994v2](http://arxiv.org/abs/2209.04994v2)\n", "2209.04861": "- 2022-09-11, **Inverse Image Frequency for Long-tailed Image Recognition**, Konstantinos Panagiotis Alexandridis et.al., Paper: [http://arxiv.org/abs/2209.04861v1](http://arxiv.org/abs/2209.04861v1), Code: **[https://github.com/kostas1515/iif](https://github.com/kostas1515/iif)**\n", "2209.07526": "- 2022-09-15, **OmniVL:One Foundation Model for Image-Language and Video-Language Tasks**, Junke Wang et.al., Paper: [http://arxiv.org/abs/2209.07526v1](http://arxiv.org/abs/2209.07526v1)\n", "2209.07511": "- 2022-09-15, **Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models**, Manli Shu et.al., Paper: [http://arxiv.org/abs/2209.07511v1](http://arxiv.org/abs/2209.07511v1)\n", "2209.07302": "- 2022-09-15, **MVNet: Memory Assistance and Vocal Reinforcement Network for Speech Enhancement**, Jianrong Wang et.al., Paper: [http://arxiv.org/abs/2209.07302v1](http://arxiv.org/abs/2209.07302v1)\n", "2209.07125": "- 2022-09-15, **BadRes: Reveal the Backdoors through Residual Connection**, Mingrui He et.al., Paper: [http://arxiv.org/abs/2209.07125v1](http://arxiv.org/abs/2209.07125v1)\n", "2209.07118": "- 2022-09-15, **Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge**, Zhihong Chen et.al., Paper: [http://arxiv.org/abs/2209.07118v1](http://arxiv.org/abs/2209.07118v1)\n", "2209.07098": "- 2022-09-15, **Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training**, Zhihong Chen et.al., Paper: [http://arxiv.org/abs/2209.07098v1](http://arxiv.org/abs/2209.07098v1), Code: **[https://github.com/zhjohnchan/m3ae](https://github.com/zhjohnchan/m3ae)**\n", "2209.07007": "- 2022-09-15, **Gromov-Wasserstein Autoencoders**, Nao Nakagawa et.al., Paper: [http://arxiv.org/abs/2209.07007v1](http://arxiv.org/abs/2209.07007v1)\n", "2209.06971": "- 2022-09-14, **PointACL:Adversarial Contrastive Learning for Robust Point Clouds Representation under Adversarial Attack**, Junxuan Huang et.al., Paper: [http://arxiv.org/abs/2209.06971v1](http://arxiv.org/abs/2209.06971v1)\n", "2209.07798": "- 2022-09-16, **DBT-DMAE: An Effective Multivariate Time Series Pre-Train Model under Missing Data**, Kai Zhang et.al., Paper: [http://arxiv.org/abs/2209.07798v1](http://arxiv.org/abs/2209.07798v1)\n", "2209.07734": "- 2022-09-16, **CenterLineDet: Road Lane CenterLine Graph Detection With Vehicle-Mounted Sensors by Transformer for High-definition Map Creation**, Zhenhua Xu et.al., Paper: [http://arxiv.org/abs/2209.07734v1](http://arxiv.org/abs/2209.07734v1)\n", "2209.09130": "- 2022-09-19, **SAMP: A Toolkit for Model Inference with Self-Adaptive Mixed-Precision**, Rong Tian et.al., Paper: [http://arxiv.org/abs/2209.09130v1](http://arxiv.org/abs/2209.09130v1)\n", "2209.08996": "- 2022-09-19, **EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics**, Alberta Longhini et.al., Paper: [http://arxiv.org/abs/2209.08996v1](http://arxiv.org/abs/2209.08996v1)\n", "2209.08953": "- 2022-09-19, **Effective Adaptation in Multi-Task Co-Training for Unified Autonomous Driving**, Xiwen Liang et.al., Paper: [http://arxiv.org/abs/2209.08953v1](http://arxiv.org/abs/2209.08953v1)\n", "2209.08887": "- 2022-09-19, **Attentive Symmetric Autoencoder for Brain MRI Segmentation**, Junjia Huang et.al., Paper: [http://arxiv.org/abs/2209.08887v1](http://arxiv.org/abs/2209.08887v1), Code: **[https://github.com/lhaof/asa](https://github.com/lhaof/asa)**\n", "2209.08770": "- 2022-09-19, **S$^3$R: Self-supervised Spectral Regression for Hyperspectral Histopathology Image Classification**, Xingran Xie et.al., Paper: [http://arxiv.org/abs/2209.08770v1](http://arxiv.org/abs/2209.08770v1)\n", "2209.08655": "- 2022-09-18, **Enabling Conversational Interaction with Mobile UI using Large Language Models**, Bryan Wang et.al., Paper: [http://arxiv.org/abs/2209.08655v1](http://arxiv.org/abs/2209.08655v1)\n", "2209.08625": "- 2022-09-18, **Improving the Performance of DNN-based Software Services using Automated Layer Caching**, Mohammadamin Abedi et.al., Paper: [http://arxiv.org/abs/2209.08625v1](http://arxiv.org/abs/2209.08625v1)\n", "2209.08425": "- 2022-09-17, **Introspective Learning : A Two-Stage Approach for Inference in Neural Networks**, Mohit Prabhushankar et.al., Paper: [http://arxiv.org/abs/2209.08425v1](http://arxiv.org/abs/2209.08425v1), Code: **[https://github.com/olivesgatech/introspective-learning](https://github.com/olivesgatech/introspective-learning)**\n", "2209.08359": "- 2022-09-17, **From Disfluency Detection to Intent Detection and Slot Filling**, Mai Hoang Dao et.al., Paper: [http://arxiv.org/abs/2209.08359v1](http://arxiv.org/abs/2209.08359v1), Code: **[https://github.com/vinairesearch/phoatis_disfluency](https://github.com/vinairesearch/phoatis_disfluency)**\n", "2209.09024": "- 2022-09-16, **Dataset Inference for Self-Supervised Models**, Adam Dziedzic et.al., Paper: [http://arxiv.org/abs/2209.09024v1](http://arxiv.org/abs/2209.09024v1)\n", "2209.09815": "- 2022-09-20, **Integer Fine-tuning of Transformer-based Models**, Mohammadreza Tayaranian et.al., Paper: [http://arxiv.org/abs/2209.09815v1](http://arxiv.org/abs/2209.09815v1)\n", "2209.09760": "- 2022-09-20, **Dynamic Graph Message Passing Networks for Visual Recognition**, Li Zhang et.al., Paper: [http://arxiv.org/abs/2209.09760v1](http://arxiv.org/abs/2209.09760v1), Code: **[https://github.com/fudan-zvg/dgmn2](https://github.com/fudan-zvg/dgmn2)**\n", "2209.10150": "- 2022-09-21, **RNGDet++: Road Network Graph Detection by Transformer with Instance Segmentation and Multi-scale Features Enhancement**, Zhenhua Xu et.al., Paper: [http://arxiv.org/abs/2209.10150v1](http://arxiv.org/abs/2209.10150v1)\n", "2209.10126": "- 2022-09-21, **Exploring Modulated Detection Transformer as a Tool for Action Recognition in Videos**, Tom\u00e1s Crisol et.al., Paper: [http://arxiv.org/abs/2209.10126v1](http://arxiv.org/abs/2209.10126v1), Code: **[https://github.com/bhi-research/ava_mdetr](https://github.com/bhi-research/ava_mdetr)**\n", "2209.10099": "- 2022-09-19, **On the benefits of self-taught learning for brain decoding**, Elodie Germani et.al., Paper: [http://arxiv.org/abs/2209.10099v1](http://arxiv.org/abs/2209.10099v1)\n", "2209.10986": "- 2022-09-22, **Learning to Simulate Realistic LiDARs**, Benoit Guillard et.al., Paper: [http://arxiv.org/abs/2209.10986v1](http://arxiv.org/abs/2209.10986v1)\n", "2209.10951": "- 2022-09-22, **An Information Minimization Based Contrastive Learning Model for Unsupervised Sentence Embeddings Learning**, Shaobin Chen et.al., Paper: [http://arxiv.org/abs/2209.10951v1](http://arxiv.org/abs/2209.10951v1), Code: **[https://github.com/bin199/informin-cl](https://github.com/bin199/informin-cl)**\n", "2209.10817": "- 2022-09-22, **SQ-SLAM: Monocular Semantic SLAM Based on Superquadric Object Representation**, Xiao Han et.al., Paper: [http://arxiv.org/abs/2209.10817v1](http://arxiv.org/abs/2209.10817v1)\n", "2209.10801": "- 2022-09-22, **STING: Self-attention based Time-series Imputation Networks using GAN**, Eunkyu Oh et.al., Paper: [http://arxiv.org/abs/2209.10801v1](http://arxiv.org/abs/2209.10801v1)\n", "2209.10623": "- 2022-09-21, **SW-VAE: Weakly Supervised Learn Disentangled Representation Via Latent Factor Swapping**, Jiageng Zhu et.al., Paper: [http://arxiv.org/abs/2209.10623v1](http://arxiv.org/abs/2209.10623v1)\n", "2209.11673": "- 2022-09-23, **Image-to-Image Translation for Autonomous Driving from Coarsely-Aligned Image Pairs**, Youya Xia et.al., Paper: [http://arxiv.org/abs/2209.11673v1](http://arxiv.org/abs/2209.11673v1)\n", "2209.11336": "- 2022-09-22, **UNav: An Infrastructure-Independent Vision-Based Navigation System for People with Blindness and Low vision**, Anbang Yang et.al., Paper: [http://arxiv.org/abs/2209.11336v1](http://arxiv.org/abs/2209.11336v1)\n", "2209.11233": "- 2022-09-22, **Assessing Robustness of EEG Representations under Data-shifts via Latent Space and Uncertainty Analysis**, Neeraj Wagh et.al., Paper: [http://arxiv.org/abs/2209.11233v1](http://arxiv.org/abs/2209.11233v1)\n", "2209.11252": "- 2022-09-22, **XF2T: Cross-lingual Fact-to-Text Generation for Low-Resource Languages**, Shivprasad Sagare et.al., Paper: [http://arxiv.org/abs/2209.11252v1](http://arxiv.org/abs/2209.11252v1)\n", "2209.12892": "- 2022-09-26, **Learning to Learn with Generative Models of Neural Network Checkpoints**, William Peebles et.al., Paper: [http://arxiv.org/abs/2209.12892v1](http://arxiv.org/abs/2209.12892v1), Code: **[https://github.com/wpeebles/g.pt](https://github.com/wpeebles/g.pt)**\n", "2209.12244": "- 2022-09-25, **Multimodal Learning with Channel-Mixing and Masked Autoencoder on Facial Action Unit Detection**, Xiang Zhang et.al., Paper: [http://arxiv.org/abs/2209.12244v1](http://arxiv.org/abs/2209.12244v1)\n", "2209.12157": "- 2022-09-25, **Dive into Self-Supervised Learning for Medical Image Analysis: Data, Models and Tasks**, Chuyan Zhang et.al., Paper: [http://arxiv.org/abs/2209.12157v1](http://arxiv.org/abs/2209.12157v1), Code: **[https://github.com/chuyan99/medical-ssl](https://github.com/chuyan99/medical-ssl)**\n", "2209.12074": "- 2022-09-24, **Self-supervised Learning for Unintentional Action Prediction**, Olga Zatsarynna et.al., Paper: [http://arxiv.org/abs/2209.12074v1](http://arxiv.org/abs/2209.12074v1)\n", "2209.12029": "- 2022-09-24, **Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation**, Kang Xu et.al., Paper: [http://arxiv.org/abs/2209.12029v1](http://arxiv.org/abs/2209.12029v1)\n", "2209.13586": "- 2022-09-27, **Learning-Based Dimensionality Reduction for Computing Compact and Effective Local Feature Descriptors**, Hao Dong et.al., Paper: [http://arxiv.org/abs/2209.13586v1](http://arxiv.org/abs/2209.13586v1), Code: **[https://github.com/prbonn/descriptor-dr](https://github.com/prbonn/descriptor-dr)**\n", "2209.13583": "- 2022-09-27, **Learning State-Aware Visual Representations from Audible Interactions**, Himangi Mittal et.al., Paper: [http://arxiv.org/abs/2209.13583v1](http://arxiv.org/abs/2209.13583v1), Code: **[https://github.com/HimangiM/RepLAI](https://github.com/HimangiM/RepLAI)**\n", "2209.13502": "- 2022-09-27, **Visual Object Tracking in First Person Vision**, Matteo Dunnhofer et.al., Paper: [http://arxiv.org/abs/2209.13502v1](http://arxiv.org/abs/2209.13502v1)\n", "2209.13430": "- 2022-09-27, **UniCLIP: Unified Framework for Contrastive Language-Image Pre-training**, Janghyeon Lee et.al., Paper: [http://arxiv.org/abs/2209.13430v1](http://arxiv.org/abs/2209.13430v1)\n", "2209.13274": "- 2022-09-27, **Orbeez-SLAM: A Real-time Monocular Visual SLAM with ORB Features and NeRF-realized Mapping**, Chi-Ming Chung et.al., Paper: [http://arxiv.org/abs/2209.13274v1](http://arxiv.org/abs/2209.13274v1)\n", "2209.13258": "- 2022-09-28, **OSDP: Optimal Sharded Data Parallel for Distributed Deep Learning**, Youhe Jiang et.al., Paper: [http://arxiv.org/abs/2209.13258v2](http://arxiv.org/abs/2209.13258v2), Code: **[https://github.com/youhe-jiang/optimalshardeddataparallel](https://github.com/youhe-jiang/optimalshardeddataparallel)**\n", "2209.13042": "- 2022-09-26, **Learning Self-Supervised Representations from Vision and Touch for Active Sliding Perception of Deformable Surfaces**, Justin Kerr et.al., Paper: [http://arxiv.org/abs/2209.13042v1](http://arxiv.org/abs/2209.13042v1)\n", "2209.12943": "- 2022-09-26, **Towards Simple and Efficient Task-Adaptive Pre-training for Text Classification**, Arnav Ladkat et.al., Paper: [http://arxiv.org/abs/2209.12943v1](http://arxiv.org/abs/2209.12943v1)\n", "2209.14205": "- 2022-09-28, **Prompt-driven efficient Open-set Semi-supervised Learning**, Haoran Li et.al., Paper: [http://arxiv.org/abs/2209.14205v1](http://arxiv.org/abs/2209.14205v1)\n", "2209.14150": "- 2022-09-28, **Speech Enhancement Using Self-Supervised Pre-Trained Model and Vector Quantization**, Xiao-Ying Zhao et.al., Paper: [http://arxiv.org/abs/2209.14150v1](http://arxiv.org/abs/2209.14150v1)\n", "2209.15007": "- 2022-09-29, **Understanding Collapse in Non-Contrastive Learning**, Alexander C. Li et.al., Paper: [http://arxiv.org/abs/2209.15007v1](http://arxiv.org/abs/2209.15007v1), Code: **[https://github.com/alexlioralexli/noncontrastive-ssl](https://github.com/alexlioralexli/noncontrastive-ssl)**\n", "2209.14884": "- 2022-09-29, **Joint Embedding Self-Supervised Learning in the Kernel Regime**, Bobak T. Kiani et.al., Paper: [http://arxiv.org/abs/2209.14884v1](http://arxiv.org/abs/2209.14884v1)\n", "2209.14764": "- 2022-09-29, **Model Zoos: A Dataset of Diverse Populations of Neural Network Models**, Konstantin Sch\u00fcrholt et.al., Paper: [http://arxiv.org/abs/2209.14764v1](http://arxiv.org/abs/2209.14764v1)\n", "2209.14733": "- 2022-09-29, **Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights**, Konstantin Sch\u00fcrholt et.al., Paper: [http://arxiv.org/abs/2209.14733v1](http://arxiv.org/abs/2209.14733v1)\n", "2209.14667": "- 2022-09-29, **Domain-aware Self-supervised Pre-training for Label-Efficient Meme Analysis**, Shivam Sharma et.al., Paper: [http://arxiv.org/abs/2209.14667v1](http://arxiv.org/abs/2209.14667v1)\n", "2209.14472": "- 2022-09-28, **medigan: A Python Library of Pretrained Generative Models for Enriched Data Access in Medical Imaging**, Richard Osuala et.al., Paper: [http://arxiv.org/abs/2209.14472v1](http://arxiv.org/abs/2209.14472v1), Code: **[https://github.com/richardobi/medigan](https://github.com/richardobi/medigan)**\n", "2209.15575": "- 2022-09-30, **Match to Win: Analysing Sequences Lengths for Efficient Self-supervised Learning in Speech and Audio**, Yan Gao et.al., Paper: [http://arxiv.org/abs/2209.15575v1](http://arxiv.org/abs/2209.15575v1)\n", "2209.15529": "- 2022-09-30, **TT-NF: Tensor Train Neural Fields**, Anton Obukhov et.al., Paper: [http://arxiv.org/abs/2209.15529v1](http://arxiv.org/abs/2209.15529v1), Code: **[https://github.com/toshas/ttnf](https://github.com/toshas/ttnf)**\n", "2209.15404": "- 2022-09-30, **An information-theoretic approach to unsupervised keypoint representation learning**, Ali Younes et.al., Paper: [http://arxiv.org/abs/2209.15404v1](http://arxiv.org/abs/2209.15404v1)\n", "2209.15321": "- 2022-09-30, **Leveraging variational autoencoders for multiple data imputation**, Breeshey Roskams-Hieter et.al., Paper: [http://arxiv.org/abs/2209.15321v1](http://arxiv.org/abs/2209.15321v1)\n", "2209.15240": "- 2022-09-30, **Prompt Tuning for Graph Neural Networks**, Taoran Fang et.al., Paper: [http://arxiv.org/abs/2209.15240v1](http://arxiv.org/abs/2209.15240v1)\n", "2209.15210": "- 2022-09-30, **Multi-Prompt Alignment for Multi-source Unsupervised Domain Adaptation**, Haoran Chen et.al., Paper: [http://arxiv.org/abs/2209.15210v1](http://arxiv.org/abs/2209.15210v1)\n", "2209.15205": "- 2022-09-30, **ASPiRe:Adaptive Skill Priors for Reinforcement Learning**, Mengda Xu et.al., Paper: [http://arxiv.org/abs/2209.15205v1](http://arxiv.org/abs/2209.15205v1)\n", "2209.15189": "- 2022-09-30, **Learning by Distilling Context**, Charlie Snell et.al., Paper: [http://arxiv.org/abs/2209.15189v1](http://arxiv.org/abs/2209.15189v1)\n", "2209.15168": "- 2022-09-30, **Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification**, Muhammad ElNokrashy et.al., Paper: [http://arxiv.org/abs/2209.15168v1](http://arxiv.org/abs/2209.15168v1)\n", "2209.15167": "- 2022-09-30, **An empirical study of weakly supervised audio tagging embeddings for general audio representations**, Heinrich Dinkel et.al., Paper: [http://arxiv.org/abs/2209.15167v1](http://arxiv.org/abs/2209.15167v1)\n", "2210.01115": "- 2022-10-03, **Language-Aware Soft Prompting for Vision & Language Foundation Models**, Adrian Bulat et.al., Paper: [http://arxiv.org/abs/2210.01115v1](http://arxiv.org/abs/2210.01115v1)\n", "2210.01075": "- 2022-10-04, **Decompiling x86 Deep Neural Network Executables**, Zhibo Liu et.al., Paper: [http://arxiv.org/abs/2210.01075v2](http://arxiv.org/abs/2210.01075v2)\n", "2210.01000": "- 2022-10-03, **Mutual Information Learned Classifiers: an Information-theoretic Viewpoint of Training Deep Learning Classification Systems**, Jirong Yi et.al., Paper: [http://arxiv.org/abs/2210.01000v1](http://arxiv.org/abs/2210.01000v1)\n", "2210.00825": "- 2022-10-03, **Self-omics: A Self-supervised Learning Framework for Multi-omics Cancer Data**, Sayed Hashim et.al., Paper: [http://arxiv.org/abs/2210.00825v1](http://arxiv.org/abs/2210.00825v1), Code: **[https://github.com/hashimsayed0/self-omics](https://github.com/hashimsayed0/self-omics)**\n", "2210.00788": "- 2022-10-03, **Towards a Unified View on Visual Parameter-Efficient Transfer Learning**, Bruce X. B. Yu et.al., Paper: [http://arxiv.org/abs/2210.00788v1](http://arxiv.org/abs/2210.00788v1), Code: **[https://github.com/bruceyo/V-PETL](https://github.com/bruceyo/V-PETL)**\n", "2210.00729": "- 2022-10-03, **Deep Spatial Domain Generalization**, Dazhou Yu et.al., Paper: [http://arxiv.org/abs/2210.00729v1](http://arxiv.org/abs/2210.00729v1), Code: **[https://github.com/dyu62/deep-domain-generalization](https://github.com/dyu62/deep-domain-generalization)**\n", "2210.00498": "- 2022-10-02, **EUCLID: Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model**, Yifu Yuan et.al., Paper: [http://arxiv.org/abs/2210.00498v1](http://arxiv.org/abs/2210.00498v1)\n", "2210.00185": "- 2022-10-01, **Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks**, Zhenhailong Wang et.al., Paper: [http://arxiv.org/abs/2210.00185v1](http://arxiv.org/abs/2210.00185v1), Code: **[https://github.com/mikewangwzhl/zemi](https://github.com/mikewangwzhl/zemi)**\n", "2210.00055": "- 2022-09-30, **$MaskTune$: Mitigating Spurious Correlations by Forcing to Explore**, Saeid Asgari Taghanaki et.al., Paper: [http://arxiv.org/abs/2210.00055v1](http://arxiv.org/abs/2210.00055v1), Code: **[https://github.com/aliasgharkhani/masktune](https://github.com/aliasgharkhani/masktune)**\n", "2210.00036": "- 2022-10-04, **Differentially Private Bias-Term only Fine-tuning of Foundation Models**, Zhiqi Bu et.al., Paper: [http://arxiv.org/abs/2210.00036v2](http://arxiv.org/abs/2210.00036v2)\n", "2210.01383": "- 2022-10-04, **Generalizing Bayesian Optimization with Decision-theoretic Entropies**, Willie Neiswanger et.al., Paper: [http://arxiv.org/abs/2210.01383v1](http://arxiv.org/abs/2210.01383v1)\n", "2210.01240": "- 2022-10-03, **Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought**, Abulhair Saparov et.al., Paper: [http://arxiv.org/abs/2210.01240v1](http://arxiv.org/abs/2210.01240v1)\n", "2210.01185": "- 2022-10-03, **ContraGen: Effective Contrastive Learning For Causal Language Model**, Nihal Jain et.al., Paper: [http://arxiv.org/abs/2210.01185v1](http://arxiv.org/abs/2210.01185v1)\n", "2210.02390": "- 2022-10-05, **Variational prompt tuning improves generalization of vision-language models**, Mohammad Mahdi Derakhshani et.al., Paper: [http://arxiv.org/abs/2210.02390v1](http://arxiv.org/abs/2210.02390v1)\n", "2210.02077": "- 2022-10-05, **Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders**, Youngwan Lee et.al., Paper: [http://arxiv.org/abs/2210.02077v1](http://arxiv.org/abs/2210.02077v1)\n", "2210.02075": "- 2022-10-05, **On the Learning Mechanisms in Physical Reasoning**, Shiqian Li et.al., Paper: [http://arxiv.org/abs/2210.02075v1](http://arxiv.org/abs/2210.02075v1)\n", "2210.02016": "- 2022-10-05, **Multi-task Self-supervised Graph Neural Networks Enable Stronger Task Generalization**, Mingxuan Ju et.al., Paper: [http://arxiv.org/abs/2210.02016v1](http://arxiv.org/abs/2210.02016v1)\n", "2210.01820": "- 2022-10-04, **MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models**, Chenglin Yang et.al., Paper: [http://arxiv.org/abs/2210.01820v1](http://arxiv.org/abs/2210.01820v1)\n", "2210.03117": "- 2022-10-06, **MaPLe: Multi-modal Prompt Learning**, Muhammad Uzair Khattak et.al., Paper: [http://arxiv.org/abs/2210.03117v1](http://arxiv.org/abs/2210.03117v1), Code: **[https://github.com/muzairkhattak/multimodal-prompt-learning](https://github.com/muzairkhattak/multimodal-prompt-learning)**\n", "2210.02989": "- 2022-10-07, **SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data**, Ching-Yun Ko et.al., Paper: [http://arxiv.org/abs/2210.02989v2](http://arxiv.org/abs/2210.02989v2)\n", "2210.02969": "- 2022-10-06, **Guess the Instruction! Making Language Models Stronger Zero-Shot Learners**, Seonghyeon Ye et.al., Paper: [http://arxiv.org/abs/2210.02969v1](http://arxiv.org/abs/2210.02969v1), Code: **[https://github.com/seonghyeonye/flipped-learning](https://github.com/seonghyeonye/flipped-learning)**\n", "2210.02938": "- 2022-10-06, **Debiasing isn't enough! -- On the Effectiveness of Debiasing MLMs and their Social Biases in Downstream Tasks**, Masahiro Kaneko et.al., Paper: [http://arxiv.org/abs/2210.02938v1](http://arxiv.org/abs/2210.02938v1)\n", "2210.02914": "- 2022-10-06, **Generative Entity Typing with Curriculum Learning**, Siyu Yuan et.al., Paper: [http://arxiv.org/abs/2210.02914v1](http://arxiv.org/abs/2210.02914v1), Code: **[https://github.com/siyuyuan/get](https://github.com/siyuyuan/get)**\n", "2210.02849": "- 2022-10-06, **XDoc: Unified Pre-training for Cross-Format Document Understanding**, Jingye Chen et.al., Paper: [http://arxiv.org/abs/2210.02849v1](http://arxiv.org/abs/2210.02849v1)\n", "2210.02768": "- 2022-10-06, **Distilling Task-specific Logical Rules from Large Pre-trained Models**, Tao Chen et.al., Paper: [http://arxiv.org/abs/2210.02768v1](http://arxiv.org/abs/2210.02768v1)\n", "2210.02595": "- 2022-10-05, **Exploration of A Self-Supervised Speech Model: A Study on Emotional Corpora**, Yuanchao Li et.al., Paper: [http://arxiv.org/abs/2210.02595v1](http://arxiv.org/abs/2210.02595v1)\n", "2210.02511": "- 2022-10-05, **TartanCalib: Iterative Wide-Angle Lens Calibration using Adaptive SubPixel Refinement of AprilTags**, Bardienus P Duisterhof et.al., Paper: [http://arxiv.org/abs/2210.02511v1](http://arxiv.org/abs/2210.02511v1)\n", "2210.03378": "- 2022-10-07, **UU-Tax at SemEval-2022 Task 3: Improving the generalizability of language models for taxonomy classification through data augmentation**, Injy Sarhan et.al., Paper: [http://arxiv.org/abs/2210.03378v1](http://arxiv.org/abs/2210.03378v1), Code: **[https://github.com/is5882/uu-tax](https://github.com/is5882/uu-tax)**\n", "2210.03372": "- 2022-10-07, **Pre-trained Adversarial Perturbations**, Yuanhao Ban et.al., Paper: [http://arxiv.org/abs/2210.03372v1](http://arxiv.org/abs/2210.03372v1), Code: **[https://github.com/banyuanhao/pap](https://github.com/banyuanhao/pap)**\n", "2210.03353": "- 2022-10-07, **The Lifecycle of \"Facts\": A Survey of Social Bias in Knowledge Graphs**, Angelie Kraft et.al., Paper: [http://arxiv.org/abs/2210.03353v1](http://arxiv.org/abs/2210.03353v1)\n", "2210.03347": "- 2022-10-07, **Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding**, Kenton Lee et.al., Paper: [http://arxiv.org/abs/2210.03347v1](http://arxiv.org/abs/2210.03347v1)\n", "2210.03319": "- 2022-10-07, **Robust Unsupervised Cross-Lingual Word Embedding using Domain Flow Interpolation**, Liping Tang et.al., Paper: [http://arxiv.org/abs/2210.03319v1](http://arxiv.org/abs/2210.03319v1)\n", "2210.03265": "- 2022-10-07, **Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision Tasks**, Yen-Cheng Liu et.al., Paper: [http://arxiv.org/abs/2210.03265v1](http://arxiv.org/abs/2210.03265v1)\n", "2210.03221": "- 2022-10-06, **Q-LSTM Language Model -- Decentralized Quantum Multilingual Pre-Trained Language Model for Privacy Protection**, Shuyue Stella Li et.al., Paper: [http://arxiv.org/abs/2210.03221v1](http://arxiv.org/abs/2210.03221v1)\n", "2210.04834": "- 2022-10-11, **Knowledge Distillation Transfer Sets and their Impact on Downstream NLU Tasks**, Charith Peris et.al., Paper: [http://arxiv.org/abs/2210.04834v2](http://arxiv.org/abs/2210.04834v2)\n", "2210.04525": "- 2022-10-11, **SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup Training**, Dan Qiao et.al., Paper: [http://arxiv.org/abs/2210.04525v2](http://arxiv.org/abs/2210.04525v2), Code: **[https://github.com/noise-learning/selfmix](https://github.com/noise-learning/selfmix)**\n", "2210.04457": "- 2022-10-10, **XPrompt: Exploring the Extreme of Prompt Tuning**, Fang Ma et.al., Paper: [http://arxiv.org/abs/2210.04457v1](http://arxiv.org/abs/2210.04457v1)\n", "2210.04382": "- 2022-10-10, **Parameter-Efficient Tuning with Special Token Adaptation**, Xiaoocong Yang et.al., Paper: [http://arxiv.org/abs/2210.04382v1](http://arxiv.org/abs/2210.04382v1), Code: **[https://github.com/luka-group/pasta](https://github.com/luka-group/pasta)**\n", "2210.04246": "- 2022-10-09, **Improve Transformer Pre-Training with Decoupled Directional Relative Position Encoding and Representation Differentiations**, Haojie Zhang et.al., Paper: [http://arxiv.org/abs/2210.04246v1](http://arxiv.org/abs/2210.04246v1)\n", "2210.04176": "- 2022-10-09, **Non-intrusive Load Monitoring based on Self-supervised Learning**, Shuyi Chen et.al., Paper: [http://arxiv.org/abs/2210.04176v1](http://arxiv.org/abs/2210.04176v1)\n", "2210.04154": "- 2022-10-09, **Self-supervised Video Representation Learning with Motion-Aware Masked Autoencoders**, Haosen Yang et.al., Paper: [http://arxiv.org/abs/2210.04154v1](http://arxiv.org/abs/2210.04154v1), Code: **[https://github.com/happy-hsy/motionmae](https://github.com/happy-hsy/motionmae)**\n", "2210.04135": "- 2022-10-09, **VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment**, Shraman Pramanick et.al., Paper: [http://arxiv.org/abs/2210.04135v1](http://arxiv.org/abs/2210.04135v1)\n", "2210.04105": "- 2022-10-08, **KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding**, Shangbin Feng et.al., Paper: [http://arxiv.org/abs/2210.04105v1](http://arxiv.org/abs/2210.04105v1)\n", "2210.04076": "- 2022-10-08, **Robustness of Unsupervised Representation Learning without Labels**, Aleksandar Petrov et.al., Paper: [http://arxiv.org/abs/2210.04076v1](http://arxiv.org/abs/2210.04076v1), Code: **[https://github.com/aleksandarpetrov/unsupervised-robustness](https://github.com/aleksandarpetrov/unsupervised-robustness)**\n", "2210.05643": "- 2022-10-11, **A Kernel-Based View of Language Model Fine-Tuning**, Sadhika Malladi et.al., Paper: [http://arxiv.org/abs/2210.05643v1](http://arxiv.org/abs/2210.05643v1), Code: **[https://github.com/princeton-nlp/lm-kernel-ft](https://github.com/princeton-nlp/lm-kernel-ft)**\n", "2210.05638": "- 2022-10-11, **APSNet: Attention Based Point Cloud Sampling**, Yang Ye et.al., Paper: [http://arxiv.org/abs/2210.05638v1](http://arxiv.org/abs/2210.05638v1), Code: **[https://github.com/yangyeeee/apsnet](https://github.com/yangyeeee/apsnet)**\n", "2210.05519": "- 2022-10-11, **Robust and Controllable Object-Centric Learning through Energy-based Models**, Ruixiang Zhang et.al., Paper: [http://arxiv.org/abs/2210.05519v1](http://arxiv.org/abs/2210.05519v1)\n", "2210.05513": "- 2022-10-11, **ViFiCon: Vision and Wireless Association Via Self-Supervised Contrastive Learning**, Nicholas Meegan et.al., Paper: [http://arxiv.org/abs/2210.05513v1](http://arxiv.org/abs/2210.05513v1)\n", "2210.05506": "- 2022-10-11, **Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration**, Matteo Paltenghi et.al., Paper: [http://arxiv.org/abs/2210.05506v1](http://arxiv.org/abs/2210.05506v1)\n", "2210.05335": "- 2022-10-11, **MAP: Modality-Agnostic Uncertainty-Aware Vision-Language Pre-training Model**, Yatai Ji et.al., Paper: [http://arxiv.org/abs/2210.05335v1](http://arxiv.org/abs/2210.05335v1), Code: **[https://github.com/iigroup/map](https://github.com/iigroup/map)**\n", "2210.05248": "- 2022-10-11, **Self-supervised debiasing using low rank regularization**, Geon Yeong Park et.al., Paper: [http://arxiv.org/abs/2210.05248v1](http://arxiv.org/abs/2210.05248v1)\n", "2210.05211": "- 2022-10-11, **A Win-win Deal: Towards Sparse and Robust Pre-trained Language Models**, Yuanxin Liu et.al., Paper: [http://arxiv.org/abs/2210.05211v1](http://arxiv.org/abs/2210.05211v1), Code: **[https://github.com/llyx97/sparse-and-robust-plm](https://github.com/llyx97/sparse-and-robust-plm)**\n", "2210.05117": "- 2022-10-11, **DA-VSR: Domain Adaptable Volumetric Super-Resolution For Medical Images**, Cheng Peng et.al., Paper: [http://arxiv.org/abs/2210.05117v1](http://arxiv.org/abs/2210.05117v1)\n", "2210.05102": "- 2022-10-11, **COMBO: Pre-Training Representations of Binary Code Using Contrastive Learning**, Yifan Zhang et.al., Paper: [http://arxiv.org/abs/2210.05102v1](http://arxiv.org/abs/2210.05102v1)\n", "2210.06466": "- 2022-10-12, **Prompt Generation Networks for Efficient Adaptation of Frozen Vision Transformers**, Jochem Loedeman et.al., Paper: [http://arxiv.org/abs/2210.06466v1](http://arxiv.org/abs/2210.06466v1), Code: **[https://github.com/jochemloedeman/pgn](https://github.com/jochemloedeman/pgn)**\n", "2210.06257": "- 2022-10-12, **What can we learn about a generated image corrupting its latent representation?**, Agnieszka Tomczak et.al., Paper: [http://arxiv.org/abs/2210.06257v1](http://arxiv.org/abs/2210.06257v1)\n", "2210.06230": "- 2022-10-12, **Quasi-symbolic explanatory NLI via disentanglement: A geometrical examination**, Yingji Zhang et.al., Paper: [http://arxiv.org/abs/2210.06230v1](http://arxiv.org/abs/2210.06230v1)\n", "2210.06210": "- 2022-10-12, **Pruning Pre-trained Language Models Without Fine-Tuning**, Ting Jiang et.al., Paper: [http://arxiv.org/abs/2210.06210v1](http://arxiv.org/abs/2210.06210v1)\n", "2210.06155": "- 2022-10-12, **ERNIE-Layout: Layout Knowledge Enhanced Pre-training for Visually-rich Document Understanding**, Qiming Peng et.al., Paper: [http://arxiv.org/abs/2210.06155v1](http://arxiv.org/abs/2210.06155v1), Code: **[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)**\n", "2210.06068": "- 2022-10-12, **Using Massive Multilingual Pre-Trained Language Models Towards Real Zero-Shot Neural Machine Translation in Clinical Domain**, Lifeng Han et.al., Paper: [http://arxiv.org/abs/2210.06068v1](http://arxiv.org/abs/2210.06068v1)\n", "2210.06063": "- 2022-10-12, **ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters**, Heyuan Yao et.al., Paper: [http://arxiv.org/abs/2210.06063v1](http://arxiv.org/abs/2210.06063v1)\n", "2210.05883": "- 2022-10-12, **AD-DROP: Attribution-Driven Dropout for Robust Language Model Fine-Tuning**, Tao Yang et.al., Paper: [http://arxiv.org/abs/2210.05883v1](http://arxiv.org/abs/2210.05883v1), Code: **[https://github.com/taoyang225/ad-drop](https://github.com/taoyang225/ad-drop)**\n", "2210.05861": "- 2022-10-12, **SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models**, Ziyi Wu et.al., Paper: [http://arxiv.org/abs/2210.05861v1](http://arxiv.org/abs/2210.05861v1)\n", "2210.05780": "- 2022-10-11, **Cross-Lingual Speaker Identification Using Distant Supervision**, Ben Zhou et.al., Paper: [http://arxiv.org/abs/2210.05780v1](http://arxiv.org/abs/2210.05780v1), Code: **[https://github.com/slash0bz/speaker-identification](https://github.com/slash0bz/speaker-identification)**\n", "2210.07199": "- 2022-10-13, **Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild**, Kaifeng Zhang et.al., Paper: [http://arxiv.org/abs/2210.07199v1](http://arxiv.org/abs/2210.07199v1)\n", "2210.07189": "- 2022-10-14, **On Compressing Sequences for Self-Supervised Speech Models**, Yen Meng et.al., Paper: [http://arxiv.org/abs/2210.07189v2](http://arxiv.org/abs/2210.07189v2)\n", "2210.07185": "- 2022-10-13, **On the Utility of Self-supervised Models for Prosody-related Tasks**, Guan-Ting Lin et.al., Paper: [http://arxiv.org/abs/2210.07185v1](http://arxiv.org/abs/2210.07185v1), Code: **[https://github.com/jsalt-2022-ssl/superb-prosody](https://github.com/jsalt-2022-ssl/superb-prosody)**\n", "2210.07128": "- 2022-10-13, **Language Models of Code are Few-Shot Commonsense Learners**, Aman Madaan et.al., Paper: [http://arxiv.org/abs/2210.07128v1](http://arxiv.org/abs/2210.07128v1), Code: **[https://github.com/madaan/cocogen](https://github.com/madaan/cocogen)**\n", "2210.07041": "- 2022-10-13, **Spontaneous Emerging Preference in Two-tower Language Model**, Zhengqi He et.al., Paper: [http://arxiv.org/abs/2210.07041v1](http://arxiv.org/abs/2210.07041v1)\n", "2210.06891": "- 2022-10-13, **An Experiment Design Paradigm using Joint Feature Selection and Task Optimization**, Stefano B. Blumberg et.al., Paper: [http://arxiv.org/abs/2210.06891v1](http://arxiv.org/abs/2210.06891v1)\n", "2210.06475": "- 2022-10-13, **Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models**, Sourya Basu et.al., Paper: [http://arxiv.org/abs/2210.06475v1](http://arxiv.org/abs/2210.06475v1)\n", "2210.06824": "- 2022-10-14, **An Empirical Study on Finding Spans**, Weiwei Gu et.al., Paper: [http://arxiv.org/abs/2210.06824v2](http://arxiv.org/abs/2210.06824v2)\n", "2210.06702": "- 2022-10-13, **A Mixture of Surprises for Unsupervised Reinforcement Learning**, Andrew Zhao et.al., Paper: [http://arxiv.org/abs/2210.06702v1](http://arxiv.org/abs/2210.06702v1), Code: **[https://github.com/leaplabthu/moss](https://github.com/leaplabthu/moss)**\n", "2210.06656": "- 2022-10-13, **Knowledge-grounded Dialog State Tracking**, Dian Yu et.al., Paper: [http://arxiv.org/abs/2210.06656v1](http://arxiv.org/abs/2210.06656v1)\n", "2210.07978": "- 2022-10-14, **Improving generalizability of distilled self-supervised speech processing models under distorted settings**, Kuan-Po Huang et.al., Paper: [http://arxiv.org/abs/2210.07978v1](http://arxiv.org/abs/2210.07978v1), Code: **[https://github.com/nobel861017/distort-robust-distilssl](https://github.com/nobel861017/distort-robust-distilssl)**\n", "2210.07862": "- 2022-10-14, **Unsupervised Dense Nuclei Detection and Segmentation with Prior Self-activation Map For Histology Images**, Pingyi Chen et.al., Paper: [http://arxiv.org/abs/2210.07862v1](http://arxiv.org/abs/2210.07862v1), Code: **[https://github.com/cpystan/prior-self-activation-map](https://github.com/cpystan/prior-self-activation-map)**\n", "2210.07795": "- 2022-10-14, **EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning**, Tiannan Wang et.al., Paper: [http://arxiv.org/abs/2210.07795v1](http://arxiv.org/abs/2210.07795v1)\n", "2210.07715": "- 2022-10-14, **Not All Neighbors Are Worth Attending to: Graph Selective Attention Networks for Semi-supervised Learning**, Tiantian He et.al., Paper: [http://arxiv.org/abs/2210.07715v1](http://arxiv.org/abs/2210.07715v1)\n", "2210.07565": "- 2022-10-14, **Multi-Task Pre-Training of Modular Prompt for Few-Shot Learning**, Tianxiang Sun et.al., Paper: [http://arxiv.org/abs/2210.07565v1](http://arxiv.org/abs/2210.07565v1)\n", "2210.07543": "- 2022-10-14, **Watermarking Pre-trained Language Models with Backdooring**, Chenxi Gu et.al., Paper: [http://arxiv.org/abs/2210.07543v1](http://arxiv.org/abs/2210.07543v1)\n", "2210.07426": "- 2022-10-17, **Skill-Based Reinforcement Learning with Intrinsic Reward Matching**, Ademi Adeniji et.al., Paper: [http://arxiv.org/abs/2210.07426v2](http://arxiv.org/abs/2210.07426v2), Code: **[https://github.com/ademiadeniji/irm](https://github.com/ademiadeniji/irm)**\n", "2210.07413": "- 2022-10-13, **Invariance-adapted decomposition and Lasso-type contrastive learning**, Masanori Koyama et.al., Paper: [http://arxiv.org/abs/2210.07413v1](http://arxiv.org/abs/2210.07413v1)\n", "2210.07347": "- 2022-10-13, **Disentanglement of Correlated Factors via Hausdorff Factorized Support**, Karsten Roth et.al., Paper: [http://arxiv.org/abs/2210.07347v1](http://arxiv.org/abs/2210.07347v1)\n", "2210.07340": "- 2022-10-13, **LEAVES: Learning Views for Time-Series Data in Contrastive Learning**, Han Yu et.al., Paper: [http://arxiv.org/abs/2210.07340v1](http://arxiv.org/abs/2210.07340v1)\n", "2210.09304": "- 2022-10-17, **Non-Contrastive Learning Meets Language-Image Pre-Training**, Jinghao Zhou et.al., Paper: [http://arxiv.org/abs/2210.09304v1](http://arxiv.org/abs/2210.09304v1)\n", "2210.08901": "- 2022-10-17, **Contrastive Language-Image Pre-Training with Knowledge Graphs**, Xuran Pan et.al., Paper: [http://arxiv.org/abs/2210.08901v1](http://arxiv.org/abs/2210.08901v1)\n", "2210.08859": "- 2022-10-17, **Social Biases in Automatic Evaluation Metrics for NLG**, Mingqi Gao et.al., Paper: [http://arxiv.org/abs/2210.08859v1](http://arxiv.org/abs/2210.08859v1)\n", "2210.08675": "- 2022-10-17, **SGRAM: Improving Scene Graph Parsing via Abstract Meaning Representation**, Woo Suk Choi et.al., Paper: [http://arxiv.org/abs/2210.08675v1](http://arxiv.org/abs/2210.08675v1)\n", "2210.08573": "- 2022-10-16, **DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models**, Yueqin Yin et.al., Paper: [http://arxiv.org/abs/2210.08573v1](http://arxiv.org/abs/2210.08573v1)\n", "2210.08458": "- 2022-10-16, **Learning Self-Regularized Adversarial Views for Self-Supervised Vision Transformers**, Tao Tang et.al., Paper: [http://arxiv.org/abs/2210.08458v1](http://arxiv.org/abs/2210.08458v1), Code: **[https://github.com/trent-tangtao/autoview](https://github.com/trent-tangtao/autoview)**\n", "2210.08402": "- 2022-10-16, **LAION-5B: An open large-scale dataset for training next generation image-text models**, Christoph Schuhmann et.al., Paper: [http://arxiv.org/abs/2210.08402v1](http://arxiv.org/abs/2210.08402v1)\n", "2210.08362": "- 2022-10-15, **PAR: Political Actor Representation Learning with Social Context and Expert Knowledge**, Shangbin Feng et.al., Paper: [http://arxiv.org/abs/2210.08362v1](http://arxiv.org/abs/2210.08362v1)\n", "2210.08284": "- 2022-10-15, **AraLegal-BERT: A pretrained language model for Arabic Legal text**, Muhammad AL-Qurishi et.al., Paper: [http://arxiv.org/abs/2210.08284v1](http://arxiv.org/abs/2210.08284v1)\n", "2210.08258": "- 2022-10-15, **Handling missing values in healthcare data: A systematic review of deep learning-based imputation techniques**, Mingxuan Liu et.al., Paper: [http://arxiv.org/abs/2210.08258v1](http://arxiv.org/abs/2210.08258v1)\n", "2210.09658": "- 2022-10-18, **ROSE: Robust Selective Fine-tuning for Pre-trained Language Models**, Lan Jiang et.al., Paper: [http://arxiv.org/abs/2210.09658v1](http://arxiv.org/abs/2210.09658v1), Code: **[https://github.com/jiangllan/rose](https://github.com/jiangllan/rose)**\n", "2210.09643": "- 2022-10-18, **Improving Adversarial Robustness by Contrastive Guided Diffusion Process**, Yidong Ouyang et.al., Paper: [http://arxiv.org/abs/2210.09643v1](http://arxiv.org/abs/2210.09643v1)\n", "2210.09566": "- 2022-10-18, **Simple Emergent Action Representations from Multi-Task Policy Training**, Pu Hua et.al., Paper: [http://arxiv.org/abs/2210.09566v1](http://arxiv.org/abs/2210.09566v1)\n", "2210.09559": "- 2022-10-18, **Unsupervised Inference of Data-Driven Discourse Structures using a Tree Auto-Encoder**, Patrick Huber et.al., Paper: [http://arxiv.org/abs/2210.09559v1](http://arxiv.org/abs/2210.09559v1)\n", "2210.09550": "- 2022-10-18, **Probing Cross-modal Semantics Alignment Capability from the Textual Perspective**, Zheng Ma et.al., Paper: [http://arxiv.org/abs/2210.09550v1](http://arxiv.org/abs/2210.09550v1)\n", "2210.09506": "- 2022-10-18, **No Pairs Left Behind: Improving Metric Learning with Regularized Triplet Objective**, A. Ali Heydari et.al., Paper: [http://arxiv.org/abs/2210.09506v1](http://arxiv.org/abs/2210.09506v1)\n", "2210.09459": "- 2022-10-17, **Extensible Proxy for Efficient NAS**, Yuhong Li et.al., Paper: [http://arxiv.org/abs/2210.09459v1](http://arxiv.org/abs/2210.09459v1), Code: **[https://github.com/leeyeehoo/gennas-zero](https://github.com/leeyeehoo/gennas-zero)**\n", "2210.09338": "- 2022-10-19, **Deep Bidirectional Language-Knowledge Graph Pretraining**, Michihiro Yasunaga et.al., Paper: [http://arxiv.org/abs/2210.09338v2](http://arxiv.org/abs/2210.09338v2), Code: **[https://github.com/michiyasunaga/dragon](https://github.com/michiyasunaga/dragon)**\n", "2210.10716": "- 2022-10-19, **CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion**, Philippe Weinzaepfel et.al., Paper: [http://arxiv.org/abs/2210.10716v1](http://arxiv.org/abs/2210.10716v1)\n", "2210.10630": "- 2022-10-19, **Irregularly-Sampled Time Series Modeling with Spline Networks**, Marin Bilo\u0161 et.al., Paper: [http://arxiv.org/abs/2210.10630v1](http://arxiv.org/abs/2210.10630v1)\n", "2210.10626": "- 2022-10-19, **HAVANA: Hard negAtiVe sAmples aware self-supervised coNtrastive leArning for Airborne laser scanning point clouds semantic segmentation**, Yunsheng Zhang et.al., Paper: [http://arxiv.org/abs/2210.10626v1](http://arxiv.org/abs/2210.10626v1)\n", "2210.10615": "- 2022-10-19, **A Unified View of Masked Image Modeling**, Zhiliang Peng et.al., Paper: [http://arxiv.org/abs/2210.10615v1](http://arxiv.org/abs/2210.10615v1)\n", "2210.10602": "- 2022-10-19, **NGEP: A Graph-based Event Planning Framework for Story Generation**, Chen Tang et.al., Paper: [http://arxiv.org/abs/2210.10602v1](http://arxiv.org/abs/2210.10602v1), Code: **[https://github.com/tangg555/ngep-eventplan](https://github.com/tangg555/ngep-eventplan)**\n", "2210.10592": "- 2022-10-19, **DyTed: Disentangling Temporal Invariance and Fluctuations in Dynamic Graph Representation Learning**, Kaike Zhang et.al., Paper: [http://arxiv.org/abs/2210.10592v1](http://arxiv.org/abs/2210.10592v1)\n", "2210.10537": "- 2022-10-19, **Online LiDAR-Camera Extrinsic Parameters Self-checking**, Pengjin Wei et.al., Paper: [http://arxiv.org/abs/2210.10537v1](http://arxiv.org/abs/2210.10537v1), Code: **[https://github.com/opencalib/lidar2camera_self-check](https://github.com/opencalib/lidar2camera_self-check)**\n", "2210.10533": "- 2022-10-19, **Deep-based quality assessment of medical images through domain adaptation**, Marouane Tliba et.al., Paper: [http://arxiv.org/abs/2210.10533v1](http://arxiv.org/abs/2210.10533v1)\n", "2210.10486": "- 2022-10-19, **Cross-Modal Fusion Distillation for Fine-Grained Sketch-Based Image Retrieval**, Abhra Chaudhuri et.al., Paper: [http://arxiv.org/abs/2210.10486v1](http://arxiv.org/abs/2210.10486v1)\n", "2210.10194": "- 2022-10-18, **Rethinking Prototypical Contrastive Learning through Alignment, Uniformity and Correlation**, Shentong Mo et.al., Paper: [http://arxiv.org/abs/2210.10194v1](http://arxiv.org/abs/2210.10194v1)\n", "2210.11470": "- 2022-10-20, **i-MAE: Are Latent Representations in Masked Autoencoders Linearly Separable?**, Kevin Zhang et.al., Paper: [http://arxiv.org/abs/2210.11470v1](http://arxiv.org/abs/2210.11470v1), Code: **[https://github.com/vision-learning-acceleration-lab/i-mae](https://github.com/vision-learning-acceleration-lab/i-mae)**\n", "2210.11464": "- 2022-10-20, **Self-Supervised Learning via Maximum Entropy Coding**, Xin Liu et.al., Paper: [http://arxiv.org/abs/2210.11464v1](http://arxiv.org/abs/2210.11464v1), Code: **[https://github.com/xinliu20/mec](https://github.com/xinliu20/mec)**\n", "2210.11456": "- 2022-10-20, **MixMask: Revisiting Masked Siamese Self-supervised Learning in Asymmetric Distance**, Kirill Vishniakov et.al., Paper: [http://arxiv.org/abs/2210.11456v1](http://arxiv.org/abs/2210.11456v1)\n", "2210.11292": "- 2022-10-21, **Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts**, Xiangyang Liu et.al., Paper: [http://arxiv.org/abs/2210.11292v2](http://arxiv.org/abs/2210.11292v2)\n", "2210.11179": "- 2022-10-20, **Multi-hypothesis 3D human pose estimation metrics favor miscalibrated distributions**, Pawe\u0142 A. Pierzchlewicz et.al., Paper: [http://arxiv.org/abs/2210.11179v1](http://arxiv.org/abs/2210.11179v1), Code: **[https://github.com/sinzlab/cgnf](https://github.com/sinzlab/cgnf)**\n", "2210.11082": "- 2022-10-20, **Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning**, Xiaoyi Chen et.al., Paper: [http://arxiv.org/abs/2210.11082v1](http://arxiv.org/abs/2210.11082v1)\n", "2210.11065": "- 2022-10-20, **MovieCLIP: Visual Scene Recognition in Movies**, Digbalay Bose et.al., Paper: [http://arxiv.org/abs/2210.11065v1](http://arxiv.org/abs/2210.11065v1)\n", "2210.11016": "- 2022-10-20, **Towards Sustainable Self-supervised Learning**, Shanghua Gao et.al., Paper: [http://arxiv.org/abs/2210.11016v1](http://arxiv.org/abs/2210.11016v1)\n", "2210.11006": "- 2022-10-20, **SimpleClick: Interactive Image Segmentation with Simple Vision Transformers**, Qin Liu et.al., Paper: [http://arxiv.org/abs/2210.11006v1](http://arxiv.org/abs/2210.11006v1), Code: **[https://github.com/uncbiag/simpleclick](https://github.com/uncbiag/simpleclick)**\n", "2210.10951": "- 2022-10-20, **Automatic Document Selection for Efficient Encoder Pretraining**, Yukun Feng et.al., Paper: [http://arxiv.org/abs/2210.10951v1](http://arxiv.org/abs/2210.10951v1)\n", "2210.12135": "- 2022-10-21, **Geometric Sparse Coding in Wasserstein Space**, Marshall Mueller et.al., Paper: [http://arxiv.org/abs/2210.12135v1](http://arxiv.org/abs/2210.12135v1)\n", "2210.11929": "- 2022-10-21, **LiteVL: Efficient Video-Language Learning with Enhanced Spatial-Temporal Modeling**, Dongsheng Chen et.al., Paper: [http://arxiv.org/abs/2210.11929v1](http://arxiv.org/abs/2210.11929v1)\n", "2210.11753": "- 2022-10-21, **TransLIST: A Transformer-Based Linguistically Informed Sanskrit Tokenizer**, Jivnesh Sandhan et.al., Paper: [http://arxiv.org/abs/2210.11753v1](http://arxiv.org/abs/2210.11753v1), Code: **[https://github.com/rsingha108/translist](https://github.com/rsingha108/translist)**\n", "2210.11723": "- 2022-10-21, **Evidence of Vocal Tract Articulation in Self-Supervised Learning of Speech**, Cheol Jun Cho et.al., Paper: [http://arxiv.org/abs/2210.11723v1](http://arxiv.org/abs/2210.11723v1)\n", "2210.11590": "- 2022-10-20, **XC: Exploring Quantitative Use Cases for Explanations in 3D Object Detection**, Sunsheng Gu et.al., Paper: [http://arxiv.org/abs/2210.11590v1](http://arxiv.org/abs/2210.11590v1), Code: **[https://github.com/sunshenggu/xc_eval_pcdet](https://github.com/sunshenggu/xc_eval_pcdet)**\n", "2210.11522": "- 2022-10-20, **Composing Ensembles of Pre-trained Models via Iterative Consensus**, Shuang Li et.al., Paper: [http://arxiv.org/abs/2210.11522v1](http://arxiv.org/abs/2210.11522v1)\n", "2210.13086": "- 2022-10-24, **Legal-Tech Open Diaries: Lesson learned on how to develop and deploy light-weight models in the era of humongous Language Models**, Stelios Maroudas et.al., Paper: [http://arxiv.org/abs/2210.13086v1](http://arxiv.org/abs/2210.13086v1)\n", "2210.13030": "- 2022-10-24, **Self-supervised Rewiring of Pre-trained Speech Encoders: Towards Faster Fine-tuning with Less Labels in Speech Processing**, Hao Yang et.al., Paper: [http://arxiv.org/abs/2210.13030v1](http://arxiv.org/abs/2210.13030v1)\n", "2210.12928": "- 2022-10-24, **GFlowOut: Dropout with Generative Flow Networks**, Dianbo Liu et.al., Paper: [http://arxiv.org/abs/2210.12928v1](http://arxiv.org/abs/2210.12928v1)\n", "2210.12719": "- 2022-10-23, **Learning General World Models in a Handful of Reward-Free Deployments**, Yingchen Xu et.al., Paper: [http://arxiv.org/abs/2210.12719v1](http://arxiv.org/abs/2210.12719v1)\n", "2210.12696": "- 2022-10-23, **On the Transformation of Latent Space in Fine-Tuned NLP Models**, Nadir Durrani et.al., Paper: [http://arxiv.org/abs/2210.12696v1](http://arxiv.org/abs/2210.12696v1)\n", "2210.12682": "- 2022-10-23, **Photo-realistic Neural Domain Randomization**, Sergey Zakharov et.al., Paper: [http://arxiv.org/abs/2210.12682v1](http://arxiv.org/abs/2210.12682v1)\n", "2210.12587": "- 2022-10-23, **Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning**, Xiangyu Peng et.al., Paper: [http://arxiv.org/abs/2210.12587v1](http://arxiv.org/abs/2210.12587v1)\n", "2210.12582": "- 2022-10-23, **Language Model Pre-Training with Sparse Latent Typing**, Liliang Ren et.al., Paper: [http://arxiv.org/abs/2210.12582v1](http://arxiv.org/abs/2210.12582v1)\n", "2210.12548": "- 2022-10-22, **JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network for Multi-contrast MRI**, Lin Zhao et.al., Paper: [http://arxiv.org/abs/2210.12548v1](http://arxiv.org/abs/2210.12548v1)\n", "2210.12540": "- 2022-10-22, **EntityCS: Improving Zero-Shot Cross-lingual Transfer with Entity-Centric Code Switching**, Chenxi Whitehouse et.al., Paper: [http://arxiv.org/abs/2210.12540v1](http://arxiv.org/abs/2210.12540v1)\n", "2210.14199": "- 2022-10-25, **Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models**, Hong Liu et.al., Paper: [http://arxiv.org/abs/2210.14199v1](http://arxiv.org/abs/2210.14199v1)\n", "2210.13805": "- 2022-10-25, **Improving Speech Representation Learning via Speech-level and Phoneme-level Masking Approach**, Xulong Zhang et.al., Paper: [http://arxiv.org/abs/2210.13805v1](http://arxiv.org/abs/2210.13805v1)\n", "2210.13797": "- 2022-10-25, **MAROAM: Map-based Radar SLAM through Two-step Feature Selection**, Dequan Wang et.al., Paper: [http://arxiv.org/abs/2210.13797v1](http://arxiv.org/abs/2210.13797v1)\n", "2210.13774": "- 2022-10-25, **From Points to Functions: Infinite-dimensional Representations in Diffusion Models**, Sarthak Mittal et.al., Paper: [http://arxiv.org/abs/2210.13774v1](http://arxiv.org/abs/2210.13774v1), Code: **[https://github.com/sarthmit/traj_drl](https://github.com/sarthmit/traj_drl)**\n", "2210.13673": "- 2022-10-25, **Evaluating Parameter Efficient Learning for Generation**, Peng Xu et.al., Paper: [http://arxiv.org/abs/2210.13673v1](http://arxiv.org/abs/2210.13673v1)\n", "2210.13591": "- 2022-10-24, **Learning by Hallucinating: Vision-Language Pre-training with Weak Supervision**, Tzu-Jui Julius Wang et.al., Paper: [http://arxiv.org/abs/2210.13591v1](http://arxiv.org/abs/2210.13591v1)\n", "2210.14891": "- 2022-10-27, **Broken Neural Scaling Laws**, Ethan Caballero et.al., Paper: [http://arxiv.org/abs/2210.14891v2](http://arxiv.org/abs/2210.14891v2), Code: **[https://github.com/ethancaballero/broken_neural_scaling_laws](https://github.com/ethancaballero/broken_neural_scaling_laws)**\n", "2210.14803": "- 2022-10-26, **Don't Prompt, Search! Mining-based Zero-Shot Learning with Language Models**, Mozes van de Kar et.al., Paper: [http://arxiv.org/abs/2210.14803v1](http://arxiv.org/abs/2210.14803v1)\n", "2210.14712": "- 2022-10-26, **Bloom Library: Multimodal Datasets in 300+ Languages for a Variety of Downstream Tasks**, Colin Leong et.al., Paper: [http://arxiv.org/abs/2210.14712v1](http://arxiv.org/abs/2210.14712v1)\n", "2210.14606": "- 2022-10-26, **Analyzing Multi-Task Learning for Abstractive Text Summarization**, Frederic Kirstein et.al., Paper: [http://arxiv.org/abs/2210.14606v1](http://arxiv.org/abs/2210.14606v1)\n", "2210.14562": "- 2022-10-26, **FairCLIP: Social Bias Elimination based on Attribute Prototype Learning and Representation Neutralization**, Junyang Wang et.al., Paper: [http://arxiv.org/abs/2210.14562v1](http://arxiv.org/abs/2210.14562v1)\n", "2210.14493": "- 2022-10-26, **AVES: Animal Vocalization Encoder based on Self-Supervision**, Masato Hagiwara et.al., Paper: [http://arxiv.org/abs/2210.14493v1](http://arxiv.org/abs/2210.14493v1), Code: **[https://github.com/earthspecies/aves](https://github.com/earthspecies/aves)**\n", "2210.14446": "- 2022-10-27, **Smart Speech Segmentation using Acousto-Linguistic Features with look-ahead**, Piyush Behre et.al., Paper: [http://arxiv.org/abs/2210.14446v2](http://arxiv.org/abs/2210.14446v2)\n", "2210.14330": "- 2022-10-25, **A single-cell gene expression language model**, William Connell et.al., Paper: [http://arxiv.org/abs/2210.14330v1](http://arxiv.org/abs/2210.14330v1), Code: **[https://github.com/keiserlab/exceiver](https://github.com/keiserlab/exceiver)**\n", "2210.15386": "- 2022-10-27, **Opening the Black Box of wav2vec Feature Encoder**, Kwanghee Choi et.al., Paper: [http://arxiv.org/abs/2210.15386v1](http://arxiv.org/abs/2210.15386v1), Code: **[https://github.com/juice500ml/unbox-w2v-convnet](https://github.com/juice500ml/unbox-w2v-convnet)**\n", "2210.15310": "- 2022-10-27, **Learning Music Representations with wav2vec 2.0**, Alessandro Ragano et.al., Paper: [http://arxiv.org/abs/2210.15310v1](http://arxiv.org/abs/2210.15310v1)\n", "2210.15138": "- 2022-10-27, **Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models**, Chaofan Ma et.al., Paper: [http://arxiv.org/abs/2210.15138v1](http://arxiv.org/abs/2210.15138v1)\n", "2210.15120": "- 2022-10-27, **Federated Graph Representation Learning using Self-Supervision**, Susheel Suresh et.al., Paper: [http://arxiv.org/abs/2210.15120v1](http://arxiv.org/abs/2210.15120v1)\n", "2210.15075": "- 2022-10-26, **IDEAL: Improved DEnse locAL Contrastive Learning for Semi-Supervised Medical Image Segmentation**, Hritam Basak et.al., Paper: [http://arxiv.org/abs/2210.15075v1](http://arxiv.org/abs/2210.15075v1)\n", "2210.15034": "- 2022-10-26, **InfoShape: Task-Based Neural Data Shaping via Mutual Information**, Homa Esfahanizadeh et.al., Paper: [http://arxiv.org/abs/2210.15034v1](http://arxiv.org/abs/2210.15034v1), Code: **[https://github.com/billywu1029/mine-pytorch](https://github.com/billywu1029/mine-pytorch)**\n", "2210.14975": "- 2022-10-26, **MABEL: Attenuating Gender Bias using Textual Entailment Data**, Jacqueline He et.al., Paper: [http://arxiv.org/abs/2210.14975v1](http://arxiv.org/abs/2210.14975v1), Code: **[https://github.com/princeton-nlp/mabel](https://github.com/princeton-nlp/mabel)**\n", "2210.15445": "- 2022-10-26, **Efficient Use of Large Pre-Trained Models for Low Resource ASR**, Peter Vieting et.al., Paper: [http://arxiv.org/abs/2210.15445v1](http://arxiv.org/abs/2210.15445v1)\n", "2210.16032": "- 2022-10-28, **Parameter-efficient transfer learning of pre-trained Transformer models for speaker verification using adapters**, Junyi Peng et.al., Paper: [http://arxiv.org/abs/2210.16032v1](http://arxiv.org/abs/2210.16032v1)\n", "2210.15988": "- 2022-10-28, **Spectrograms Are Sequences of Patches**, Leyi Zhao et.al., Paper: [http://arxiv.org/abs/2210.15988v1](http://arxiv.org/abs/2210.15988v1), Code: **[https://github.com/annihi1ation/patchifier-neo](https://github.com/annihi1ation/patchifier-neo)**\n", "2210.15972": "- 2022-10-28, **Contextual Learning in Fourier Complex Field for VHR Remote Sensing Images**, Yan Zhang et.al., Paper: [http://arxiv.org/abs/2210.15972v1](http://arxiv.org/abs/2210.15972v1), Code: **[https://github.com/gao-xiyuan/fct](https://github.com/gao-xiyuan/fct)**\n", "2210.15944": "- 2022-10-28, **RoChBert: Towards Robust BERT Fine-tuning for Chinese**, Zihan Zhang et.al., Paper: [http://arxiv.org/abs/2210.15944v1](http://arxiv.org/abs/2210.15944v1), Code: **[https://github.com/zzh-z/rochbert](https://github.com/zzh-z/rochbert)**\n", "2210.15904": "- 2022-10-28, **Self-Supervised Learning with Multi-View Rendering for 3D Point Cloud Analysis**, Bach Tran et.al., Paper: [http://arxiv.org/abs/2210.15904v1](http://arxiv.org/abs/2210.15904v1), Code: **[https://github.com/vinairesearch/selfsup_pcd](https://github.com/vinairesearch/selfsup_pcd)**\n", "2210.15828": "- 2022-10-28, **On the Role of Visual Context in Enriching Music Representations**, Kleanthis Avramidis et.al., Paper: [http://arxiv.org/abs/2210.15828v1](http://arxiv.org/abs/2210.15828v1)\n", "2210.15701": "- 2022-10-27, **Do Pre-trained Models Benefit Equally in Continual Learning?**, Kuan-Ying Lee et.al., Paper: [http://arxiv.org/abs/2210.15701v1](http://arxiv.org/abs/2210.15701v1), Code: **[https://github.com/eric11220/pretrained-models-in-cl](https://github.com/eric11220/pretrained-models-in-cl)**\n", "2210.17497": "- 2022-10-31, **Leveraging Pre-trained Models for Failure Analysis Triplets Generation**, Kenneth Ezukwoke et.al., Paper: [http://arxiv.org/abs/2210.17497v1](http://arxiv.org/abs/2210.17497v1)\n", "2210.17451": "- 2022-11-02, **AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning**, Yaqing Wang et.al., Paper: [http://arxiv.org/abs/2210.17451v2](http://arxiv.org/abs/2210.17451v2)\n", "2210.17340": "- 2022-10-31, **MatKG: The Largest Knowledge Graph in Materials Science -- Entities, Relations, and Link Prediction through Graph Representation Learning**, Vineeth Venugopal et.al., Paper: [http://arxiv.org/abs/2210.17340v1](http://arxiv.org/abs/2210.17340v1)\n", "2210.17142": "- 2022-10-31, **Towards Relation-centered Pooling and Convolution for Heterogeneous Graph Learning Networks**, Tiehua Zhang et.al., Paper: [http://arxiv.org/abs/2210.17142v1](http://arxiv.org/abs/2210.17142v1), Code: **[https://github.com/BUPT-GAMMA/OpenHGNN](https://github.com/BUPT-GAMMA/OpenHGNN)**\n", "2210.17127": "- 2022-10-31, **Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change**, Zhaochen Su et.al., Paper: [http://arxiv.org/abs/2210.17127v1](http://arxiv.org/abs/2210.17127v1), Code: **[https://github.com/zhaochen0110/lmlm](https://github.com/zhaochen0110/lmlm)**\n", "2210.17052": "- 2022-10-31, **DUEL: Adaptive Duplicate Elimination on Working Memory for Self-Supervised Learning**, Won-Seok Choi et.al., Paper: [http://arxiv.org/abs/2210.17052v1](http://arxiv.org/abs/2210.17052v1)\n", "2210.17016": "- 2022-11-01, **Wespeaker: A Research and Production oriented Speaker Embedding Learning Toolkit**, Hongji Wang et.al., Paper: [http://arxiv.org/abs/2210.17016v2](http://arxiv.org/abs/2210.17016v2)\n", "2210.16906": "- 2022-10-30, **DyG2Vec: Representation Learning for Dynamic Graphs with Self-Supervision**, Mohammad Ali Alomrani et.al., Paper: [http://arxiv.org/abs/2210.16906v1](http://arxiv.org/abs/2210.16906v1)\n", "2210.16901": "- 2022-10-30, **Foreign Object Debris Detection for Airport Pavement Images based on Self-supervised Localization and Vision Transformer**, Travis Munyer et.al., Paper: [http://arxiv.org/abs/2210.16901v1](http://arxiv.org/abs/2210.16901v1)\n", "2210.16838": "- 2022-10-30, **Counterfactual Data Augmentation via Perspective Transition for Open-Domain Dialogues**, Jiao Ou et.al., Paper: [http://arxiv.org/abs/2210.16838v1](http://arxiv.org/abs/2210.16838v1), Code: **[https://github.com/ictnlp/capt](https://github.com/ictnlp/capt)**\n", "2211.00509": "- 2022-11-01, **Self-Supervised Intensity-Event Stereo Matching**, Jinjin Gu et.al., Paper: [http://arxiv.org/abs/2211.00509v1](http://arxiv.org/abs/2211.00509v1)\n", "2211.00151": "- 2022-10-31, **A Close Look into the Calibration of Pre-trained Language Models**, Yangyi Chen et.al., Paper: [http://arxiv.org/abs/2211.00151v1](http://arxiv.org/abs/2211.00151v1), Code: **[https://github.com/lifan-yuan/plmcalibration](https://github.com/lifan-yuan/plmcalibration)**\n", "2211.00119": "- 2022-11-03, **Active Learning of Non-semantic Speech Tasks with Pretrained Models**, Harlin Lee et.al., Paper: [http://arxiv.org/abs/2211.00119v2](http://arxiv.org/abs/2211.00119v2)\n", "2211.00099": "- 2022-10-31, **UmeTrack: Unified multi-view end-to-end hand tracking for VR**, Shangchen Han et.al., Paper: [http://arxiv.org/abs/2211.00099v1](http://arxiv.org/abs/2211.00099v1)\n", "2211.01244": "- 2022-11-02, **EquiMod: An Equivariance Module to Improve Self-Supervised Learning**, Alexandre Devillers et.al., Paper: [http://arxiv.org/abs/2211.01244v1](http://arxiv.org/abs/2211.01244v1)\n", "2211.01110": "- 2022-11-02, **AU-PD: An Arbitrary-size and Uniform Downsampling Framework for Point Clouds**, Peng Zhang et.al., Paper: [http://arxiv.org/abs/2211.01110v1](http://arxiv.org/abs/2211.01110v1)\n", "2211.00869": "- 2022-11-02, **Title2Event: Benchmarking Open Event Extraction with a Large-scale Chinese Title Dataset**, Haolin Deng et.al., Paper: [http://arxiv.org/abs/2211.00869v1](http://arxiv.org/abs/2211.00869v1)\n", "2211.00849": "- 2022-11-02, **P$^3$OVD: Fine-grained Visual-Text Prompt-Driven Self-Training for Open-Vocabulary Object Detection**, Yanxin Long et.al., Paper: [http://arxiv.org/abs/2211.00849v1](http://arxiv.org/abs/2211.00849v1)\n", "2211.02043": "- 2022-11-03, **Could Giant Pretrained Image Models Extract Universal Representations?**, Yutong Lin et.al., Paper: [http://arxiv.org/abs/2211.02043v1](http://arxiv.org/abs/2211.02043v1)\n", "2211.01993": "- 2022-11-03, **Probing Statistical Representations For End-To-End ASR**, Anna Ollerenshaw et.al., Paper: [http://arxiv.org/abs/2211.01993v1](http://arxiv.org/abs/2211.01993v1)\n", "2211.01756": "- 2022-11-03, **Speech-based emotion recognition with self-supervised models using attentive channel-wise correlations and label smoothing**, Sofoklis Kakouros et.al., Paper: [http://arxiv.org/abs/2211.01756v1](http://arxiv.org/abs/2211.01756v1)\n", "2211.01722": "- 2022-11-03, **Hybrid-SD ($\\text{H}_{\\text{SD}}$) : A new hybrid evaluation metric for automatic speech recognition tasks**, Zitha Sasindran et.al., Paper: [http://arxiv.org/abs/2211.01722v1](http://arxiv.org/abs/2211.01722v1)\n", "2211.01642": "- 2022-11-03, **Fine-Tuning Pre-Trained Language Models Effectively by Optimizing Subnetworks Adaptively**, Haojie Zhang et.al., Paper: [http://arxiv.org/abs/2211.01642v1](http://arxiv.org/abs/2211.01642v1)\n", "2211.01587": "- 2022-11-03, **Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation**, Yanyang Li et.al., Paper: [http://arxiv.org/abs/2211.01587v1](http://arxiv.org/abs/2211.01587v1)\n", "2211.01446": "- 2022-11-02, **FUNCK: Information Funnels and Bottlenecks for Invariant Representation Learning**, Jo\u00e3o Machado de Freitas et.al., Paper: [http://arxiv.org/abs/2211.01446v1](http://arxiv.org/abs/2211.01446v1)\n", "2211.02377": "- 2022-11-04, **Black-box Coreset Variational Inference**, Dionysis Manousakas et.al., Paper: [http://arxiv.org/abs/2211.02377v1](http://arxiv.org/abs/2211.02377v1), Code: **[https://github.com/facebookresearch/blackbox-coresets-vi](https://github.com/facebookresearch/blackbox-coresets-vi)**\n", "2211.02332": "- 2022-11-04, **Once-for-All Sequence Compression for Self-Supervised Speech Models**, Hsuan-Jui Chen et.al., Paper: [http://arxiv.org/abs/2211.02332v1](http://arxiv.org/abs/2211.02332v1)\n", "2211.02284": "- 2022-11-04, **Unsupervised Visual Representation Learning via Mutual Information Regularized Assignment**, Dong Hoon Lee et.al., Paper: [http://arxiv.org/abs/2211.02284v1](http://arxiv.org/abs/2211.02284v1), Code: **[https://github.com/movinghoon/mira](https://github.com/movinghoon/mira)**\n", "2211.02234": "- 2022-11-04, **A Latent Space Model for HLA Compatibility Networks in Kidney Transplantation**, Zhipeng Huang et.al., Paper: [http://arxiv.org/abs/2211.02234v1](http://arxiv.org/abs/2211.02234v1)\n", "2211.02227": "- 2022-11-04, **Integrated Parameter-Efficient Tuning for General-Purpose Audio Models**, Ju-ho Kim et.al., Paper: [http://arxiv.org/abs/2211.02227v1](http://arxiv.org/abs/2211.02227v1)\n", "2211.02219": "- 2022-11-04, **Understanding and Mitigating Overfitting in Prompt Tuning for Vision-Language Models**, Chengcheng Ma et.al., Paper: [http://arxiv.org/abs/2211.02219v1](http://arxiv.org/abs/2211.02219v1)\n", "2211.02145": "- 2022-11-03, **FactorMatte: Redefining Video Matting for Re-Composition Tasks**, Zeqi Gu et.al., Paper: [http://arxiv.org/abs/2211.02145v1](http://arxiv.org/abs/2211.02145v1)\n", "2211.02077": "- 2022-11-03, **Scaling Multimodal Pre-Training via Cross-Modality Gradient Harmonization**, Junru Wu et.al., Paper: [http://arxiv.org/abs/2211.02077v1](http://arxiv.org/abs/2211.02077v1)\n", "2211.03782": "- 2022-11-07, **On minimal variations for unsupervised representation learning**, Vivien Cabannes et.al., Paper: [http://arxiv.org/abs/2211.03782v1](http://arxiv.org/abs/2211.03782v1)\n", "2211.03536": "- 2022-11-07, **Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces**, Jiahang Cao et.al., Paper: [http://arxiv.org/abs/2211.03536v1](http://arxiv.org/abs/2211.03536v1)\n", "2211.03521": "- 2022-11-07, **C3PO: Learning to Achieve Arbitrary Goals via Massively Entropic Pretraining**, Alexis Jacq et.al., Paper: [http://arxiv.org/abs/2211.03521v1](http://arxiv.org/abs/2211.03521v1)\n", "2211.03495": "- 2022-11-07, **How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers**, Michael Hassid et.al., Paper: [http://arxiv.org/abs/2211.03495v1](http://arxiv.org/abs/2211.03495v1), Code: **[https://github.com/schwartz-lab-nlp/papa](https://github.com/schwartz-lab-nlp/papa)**\n", "2211.03263": "- 2022-11-07, **AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages**, Bonaventure F. P. Dossou et.al., Paper: [http://arxiv.org/abs/2211.03263v1](http://arxiv.org/abs/2211.03263v1), Code: **[https://github.com/bonaventuredossou/mlm_al](https://github.com/bonaventuredossou/mlm_al)**\n", "2211.03186": "- 2022-11-06, **Momentum-based Weight Interpolation of Strong Zero-Shot Models for Continual Learning**, Zafir Stojanovski et.al., Paper: [http://arxiv.org/abs/2211.03186v1](http://arxiv.org/abs/2211.03186v1)\n", "2211.03162": "- 2022-11-06, **ProtoX: Explaining a Reinforcement Learning Agent via Prototyping**, Ronilo J. Ragodos et.al., Paper: [http://arxiv.org/abs/2211.03162v1](http://arxiv.org/abs/2211.03162v1)\n", "2211.03154": "- 2022-11-06, **On the Domain Adaptation and Generalization of Pretrained Language Models: A Survey**, Xu Guo et.al., Paper: [http://arxiv.org/abs/2211.03154v1](http://arxiv.org/abs/2211.03154v1)\n", "2211.03000": "- 2022-11-06, **Distilling Representations from GAN Generator via Squeeze and Span**, Yu Yang et.al., Paper: [http://arxiv.org/abs/2211.03000v1](http://arxiv.org/abs/2211.03000v1)\n", "2211.02956": "- 2022-11-05, **Privacy-Preserving Models for Legal Natural Language Processing**, Ying Yin et.al., Paper: [http://arxiv.org/abs/2211.02956v1](http://arxiv.org/abs/2211.02956v1)\n", "2211.04215": "- 2022-11-08, **Active Relation Discovery: Towards General and Label-aware Open Relation Extraction**, Yangning Li et.al., Paper: [http://arxiv.org/abs/2211.04215v1](http://arxiv.org/abs/2211.04215v1)\n", "2211.03959": "- 2022-11-08, **Pretraining in Deep Reinforcement Learning: A Survey**, Zhihui Xie et.al., Paper: [http://arxiv.org/abs/2211.03959v1](http://arxiv.org/abs/2211.03959v1)\n", "2211.03929": "- 2022-11-08, **Comparative layer-wise analysis of self-supervised speech models**, Ankita Pasad et.al., Paper: [http://arxiv.org/abs/2211.03929v1](http://arxiv.org/abs/2211.03929v1)\n", "2211.03831": "- 2022-11-07, **Multi-Head Adapter Routing for Data-Efficient Fine-Tuning**, Lucas Caccia et.al., Paper: [http://arxiv.org/abs/2211.03831v1](http://arxiv.org/abs/2211.03831v1)\n", "2211.04446": "- 2022-11-07, **Private Set Generation with Discriminative Information**, Dingfan Chen et.al., Paper: [http://arxiv.org/abs/2211.04446v1](http://arxiv.org/abs/2211.04446v1), Code: **[https://github.com/dingfanchen/private-set](https://github.com/dingfanchen/private-set)**\n", "2211.04861": "- 2022-11-09, **ERNIE-UniX2: A Unified Cross-lingual Cross-modal Framework for Understanding and Generation**, Bin Shan et.al., Paper: [http://arxiv.org/abs/2211.04861v1](http://arxiv.org/abs/2211.04861v1)\n", "2211.04598": "- 2022-11-08, **Reducing Down(stream)time: Pretraining Molecular GNNs using Heterogeneous AI Accelerators**, Jenna A. Bilbrey et.al., Paper: [http://arxiv.org/abs/2211.04598v1](http://arxiv.org/abs/2211.04598v1), Code: **[https://github.com/pnnl/downstream_mol_gnn](https://github.com/pnnl/downstream_mol_gnn)**\n", "2211.04557": "- 2022-11-08, **Estimation of Appearance and Occupancy Information in Birds Eye View from Surround Monocular Images**, Sarthak Sharma et.al., Paper: [http://arxiv.org/abs/2211.04557v1](http://arxiv.org/abs/2211.04557v1)\n", "2211.05781": "- 2022-11-10, **Demystify Transformers & Convolutions in Modern Image Deep Networks**, Jifeng Dai et.al., Paper: [http://arxiv.org/abs/2211.05781v1](http://arxiv.org/abs/2211.05781v1), Code: **[https://github.com/opengvlab/stm-evaluation](https://github.com/opengvlab/stm-evaluation)**\n", "2211.05778": "- 2022-11-10, **InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions**, Wenhai Wang et.al., Paper: [http://arxiv.org/abs/2211.05778v1](http://arxiv.org/abs/2211.05778v1), Code: **[https://github.com/opengvlab/internimage](https://github.com/opengvlab/internimage)**\n", "2211.05717": "- 2022-11-11, **Privacy-Preserving Machine Learning for Collaborative Data Sharing via Auto-encoder Latent Space Embeddings**, Ana Mar\u00eda Quintero-Ossa et.al., Paper: [http://arxiv.org/abs/2211.05717v2](http://arxiv.org/abs/2211.05717v2)\n", "2211.05698": "- 2022-11-10, **Probabilistic thermal stability prediction through sparsity promoting transformer representation**, Yevgen Zainchkovskyy et.al., Paper: [http://arxiv.org/abs/2211.05698v1](http://arxiv.org/abs/2211.05698v1)\n", "2211.05442": "- 2022-11-10, **Self-supervised learning of audio representations using angular contrastive loss**, Shanshan Wang et.al., Paper: [http://arxiv.org/abs/2211.05442v1](http://arxiv.org/abs/2211.05442v1), Code: **[https://github.com/shanwangshan/Self_supervised_ACL](https://github.com/shanwangshan/Self_supervised_ACL)**\n", "2211.05414": "- 2022-11-10, **ADEPT: A DEbiasing PrompT Framework**, Ke Yang et.al., Paper: [http://arxiv.org/abs/2211.05414v1](http://arxiv.org/abs/2211.05414v1)\n", "2211.05371": "- 2022-11-10, **MSDT: Masked Language Model Scoring Defense in Text Domain**, Jaechul Roh et.al., Paper: [http://arxiv.org/abs/2211.05371v1](http://arxiv.org/abs/2211.05371v1), Code: **[https://github.com/jcroh0508/msdt](https://github.com/jcroh0508/msdt)**\n", "2211.05304": "- 2022-11-10, **Contrastive Self-Supervised Learning for Skeleton Representations**, Nico Lingg et.al., Paper: [http://arxiv.org/abs/2211.05304v1](http://arxiv.org/abs/2211.05304v1)\n", "2211.05222": "- 2022-11-09, **ViSE: Vision-Based 3D Real-Time Shape Estimation of Continuously Deformable Robots**, Hehui Zheng et.al., Paper: [http://arxiv.org/abs/2211.05222v1](http://arxiv.org/abs/2211.05222v1), Code: **[https://github.com/srl-ethz/vise](https://github.com/srl-ethz/vise)**\n", "2211.05213": "- 2022-11-09, **Flaky Performances when Pretraining on Relational Databases**, Shengchao Liu et.al., Paper: [http://arxiv.org/abs/2211.05213v1](http://arxiv.org/abs/2211.05213v1)\n", "2211.06378": "- 2022-11-11, **A Multimodal Embedding-Based Approach to Industry Classification in Financial Markets**, Rian Dolphin et.al., Paper: [http://arxiv.org/abs/2211.06378v1](http://arxiv.org/abs/2211.06378v1)\n", "2211.06163": "- 2022-11-11, **Dual Complementary Dynamic Convolution for Image Recognition**, Longbin Yan et.al., Paper: [http://arxiv.org/abs/2211.06163v1](http://arxiv.org/abs/2211.06163v1)\n", "2211.06083": "- 2022-11-11, **Token Transformer: Can class token help window-based transformer build better long-range interactions?**, Jiawei Mao et.al., Paper: [http://arxiv.org/abs/2211.06083v1](http://arxiv.org/abs/2211.06083v1)\n", "2211.06023": "- 2022-11-11, **Soft-Landing Strategy for Alleviating the Task Discrepancy Problem in Temporal Action Localization Tasks**, Hyolim Kang et.al., Paper: [http://arxiv.org/abs/2211.06023v1](http://arxiv.org/abs/2211.06023v1)\n", "2211.05994": "- 2022-11-11, **A Survey of Knowledge-Enhanced Pre-trained Language Models**, Linmei Hu et.al., Paper: [http://arxiv.org/abs/2211.05994v1](http://arxiv.org/abs/2211.05994v1)\n", "2211.05987": "- 2022-11-11, **CCPrompt: Counterfactual Contrastive Prompt-Tuning for Many-Class Classification**, Yang Li et.al., Paper: [http://arxiv.org/abs/2211.05987v1](http://arxiv.org/abs/2211.05987v1)\n", "2211.05943": "- 2022-11-11, **Deep equilibrium models as estimators for continuous latent variables**, Russell Tsuchida et.al., Paper: [http://arxiv.org/abs/2211.05943v1](http://arxiv.org/abs/2211.05943v1), Code: **[https://github.com/russelltsuchida/ped](https://github.com/russelltsuchida/ped)**\n", "2211.07636": "- 2022-11-14, **EVA: Exploring the Limits of Masked Visual Representation Learning at Scale**, Yuxin Fang et.al., Paper: [http://arxiv.org/abs/2211.07636v1](http://arxiv.org/abs/2211.07636v1), Code: **[https://github.com/baaivision/eva](https://github.com/baaivision/eva)**\n", "2211.07254": "- 2022-11-14, **The Role of Local Alignment and Uniformity in Image-Text Contrastive Learning on Medical Images**, Philip M\u00fcller et.al., Paper: [http://arxiv.org/abs/2211.07254v1](http://arxiv.org/abs/2211.07254v1)\n", "2211.07210": "- 2022-11-14, **Grafting Pre-trained Models for Multimodal Headline Generation**, Lingfeng Qiao et.al., Paper: [http://arxiv.org/abs/2211.07210v1](http://arxiv.org/abs/2211.07210v1)\n", "2211.06841": "- 2022-11-13, **Point-DAE: Denoising Autoencoders for Self-supervised Point Cloud Learning**, Yabin Zhang et.al., Paper: [http://arxiv.org/abs/2211.06841v1](http://arxiv.org/abs/2211.06841v1)\n", "2211.06627": "- 2022-11-12, **MARLIN: Masked Autoencoder for facial video Representation LearnINg**, Zhixi Cai et.al., Paper: [http://arxiv.org/abs/2211.06627v1](http://arxiv.org/abs/2211.06627v1), Code: **[https://github.com/ControlNet/MARLIN](https://github.com/ControlNet/MARLIN)**\n", "2211.06562": "- 2022-11-12, **Improving the Robustness of DistilHuBERT to Unseen Noisy Conditions via Data Augmentation, Curriculum Learning, and Multi-Task Enhancement**, Heitor R. Guimar\u00e3es et.al., Paper: [http://arxiv.org/abs/2211.06562v1](http://arxiv.org/abs/2211.06562v1)\n", "2211.06545": "- 2022-11-12, **Self-Supervised Graph Structure Refinement for Graph Neural Networks**, Jianan Zhao et.al., Paper: [http://arxiv.org/abs/2211.06545v1](http://arxiv.org/abs/2211.06545v1)\n", "2211.06470": "- 2022-11-11, **More Generalized and Personalized Unsupervised Representation Learning In A Distributed System**, Yuewei Yang et.al., Paper: [http://arxiv.org/abs/2211.06470v1](http://arxiv.org/abs/2211.06470v1)\n", "2211.07430": "- 2022-11-11, **The Far Side of Failure: Investigating the Impact of Speech Recognition Errors on Subsequent Dementia Classification**, Changye Li et.al., Paper: [http://arxiv.org/abs/2211.07430v1](http://arxiv.org/abs/2211.07430v1), Code: **[https://github.com/linguisticanomalies/paradox-asr](https://github.com/linguisticanomalies/paradox-asr)**\n", "2211.08203": "- 2022-11-15, **The Dependence on Frequency of Word Embedding Similarity Measures**, Francisco Valentini et.al., Paper: [http://arxiv.org/abs/2211.08203v1](http://arxiv.org/abs/2211.08203v1)\n", "2211.08112": "- 2022-11-15, **An Efficient Active Learning Pipeline for Legal Text Classification**, Sepideh Mamooler et.al., Paper: [http://arxiv.org/abs/2211.08112v1](http://arxiv.org/abs/2211.08112v1)\n", "2211.08016": "- 2022-11-15, **Contextual Transformer for Offline Meta Reinforcement Learning**, Runji Lin et.al., Paper: [http://arxiv.org/abs/2211.08016v1](http://arxiv.org/abs/2211.08016v1)\n", "2211.08234": "- 2022-11-13, **Build generally reusable agent-environment interaction models**, Jun Jin et.al., Paper: [http://arxiv.org/abs/2211.08234v1](http://arxiv.org/abs/2211.08234v1)\n", "2211.09085": "- 2022-11-16, **Galactica: A Large Language Model for Science**, Ross Taylor et.al., Paper: [http://arxiv.org/abs/2211.09085v1](http://arxiv.org/abs/2211.09085v1), Code: **[https://github.com/paperswithcode/galai](https://github.com/paperswithcode/galai)**\n", "2211.09022": "- 2022-11-16, **Region Proposal Network Pre-Training Helps Label-Efficient Object Detection**, Linus Ericsson et.al., Paper: [http://arxiv.org/abs/2211.09022v1](http://arxiv.org/abs/2211.09022v1)\n", "2211.08987": "- 2022-11-16, **TSMind: Alibaba and Soochow University's Submission to the WMT22 Translation Suggestion Task**, Xin Ge et.al., Paper: [http://arxiv.org/abs/2211.08987v1](http://arxiv.org/abs/2211.08987v1)\n", "2211.08658": "- 2022-11-16, **Consistent Direct Time-of-Flight Video Depth Super-Resolution**, Zhanghao Sun et.al., Paper: [http://arxiv.org/abs/2211.08658v1](http://arxiv.org/abs/2211.08658v1)\n", "2211.09013": "- 2022-11-15, **Masked Reconstruction Contrastive Learning with Information Bottleneck Principle**, Ziwen Liu et.al., Paper: [http://arxiv.org/abs/2211.09013v1](http://arxiv.org/abs/2211.09013v1)\n", "2211.08975": "- 2022-11-15, **Region Embedding with Intra and Inter-View Contrastive Learning**, Liang Zhang et.al., Paper: [http://arxiv.org/abs/2211.08975v1](http://arxiv.org/abs/2211.08975v1), Code: **[https://github.com/liang-ntu/techinical_report_remvc](https://github.com/liang-ntu/techinical_report_remvc)**\n", "2211.09808": "- 2022-11-17, **Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks**, Hao Li et.al., Paper: [http://arxiv.org/abs/2211.09808v1](http://arxiv.org/abs/2211.09808v1), Code: **[https://github.com/fundamentalvision/Uni-Perceiver](https://github.com/fundamentalvision/Uni-Perceiver)**\n", "2211.09799": "- 2022-11-17, **CAE v2: Context Autoencoder with CLIP Target**, Xinyu Zhang et.al., Paper: [http://arxiv.org/abs/2211.09799v1](http://arxiv.org/abs/2211.09799v1)\n", "2211.09790": "- 2022-11-17, **ConStruct-VL: Data-Free Continual Structured VL Concepts Learning**, James Seale Smith et.al., Paper: [http://arxiv.org/abs/2211.09790v1](http://arxiv.org/abs/2211.09790v1)\n", "2211.09510": "- 2022-11-17, **Self-supervised Trajectory Representation Learning with Temporal Regularities and Travel Semantics**, Jiawei Jiang et.al., Paper: [http://arxiv.org/abs/2211.09510v1](http://arxiv.org/abs/2211.09510v1), Code: **[https://github.com/aptx1231/start](https://github.com/aptx1231/start)**\n", "2211.09359": "- 2022-11-17, **How to Fine-Tune Vision Models with SGD**, Ananya Kumar et.al., Paper: [http://arxiv.org/abs/2211.09359v1](http://arxiv.org/abs/2211.09359v1)\n", "2211.09233": "- 2022-11-16, **Prompt Tuning for Parameter-efficient Medical Image Segmentation**, Marc Fischer et.al., Paper: [http://arxiv.org/abs/2211.09233v1](http://arxiv.org/abs/2211.09233v1), Code: **[https://github.com/marcdcfischer/punet](https://github.com/marcdcfischer/punet)**\n", "2211.09771": "- 2022-11-16, **Boosting Object Representation Learning via Motion and Object Continuity**, Quentin Delfosse et.al., Paper: [http://arxiv.org/abs/2211.09771v1](http://arxiv.org/abs/2211.09771v1), Code: **[https://github.com/k4ntz/moc](https://github.com/k4ntz/moc)**\n", "2211.10408": "- 2022-11-18, **Improved Cross-view Completion Pre-training for Stereo Matching**, Philippe Weinzaepfel et.al., Paper: [http://arxiv.org/abs/2211.10408v1](http://arxiv.org/abs/2211.10408v1)\n", "2211.10277": "- 2022-11-18, **Task Residual for Tuning Vision-Language Models**, Tao Yu et.al., Paper: [http://arxiv.org/abs/2211.10277v1](http://arxiv.org/abs/2211.10277v1), Code: **[https://github.com/geekyutao/taskres](https://github.com/geekyutao/taskres)**\n", "2211.10177": "- 2022-11-18, **Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth Information**, Ahmed Ben Saad et.al., Paper: [http://arxiv.org/abs/2211.10177v1](http://arxiv.org/abs/2211.10177v1)\n", "2211.10105": "- 2022-11-18, **$\u03b1$ DARTS Once More: Enhancing Differentiable Architecture Search by Masked Image Modeling**, Bicheng Guo et.al., Paper: [http://arxiv.org/abs/2211.10105v1](http://arxiv.org/abs/2211.10105v1)\n", "2211.10103": "- 2022-11-18, **Let's Enhance: A Deep Learning Approach to Extreme Deblurring of Text Images**, Theophil Trippe et.al., Paper: [http://arxiv.org/abs/2211.10103v1](http://arxiv.org/abs/2211.10103v1), Code: **[https://github.com/theophil-trippe/HDC_TUBerlin_version_1](https://github.com/theophil-trippe/HDC_TUBerlin_version_1)**\n", "2211.10030": "- 2022-11-18, **Contrastive Knowledge Graph Error Detection**, Qinggang Zhang et.al., Paper: [http://arxiv.org/abs/2211.10030v1](http://arxiv.org/abs/2211.10030v1), Code: **[https://github.com/qing145/caged](https://github.com/qing145/caged)**\n", "2211.10023": "- 2022-11-18, **LiSnowNet: Real-time Snow Removal for LiDAR Point Cloud**, Ming-Yuan Yu et.al., Paper: [http://arxiv.org/abs/2211.10023v1](http://arxiv.org/abs/2211.10023v1)\n", "2211.09949": "- 2022-11-17, **Compressing Transformer-based self-supervised models for speech processing**, Tzu-Quan Lin et.al., Paper: [http://arxiv.org/abs/2211.09949v1](http://arxiv.org/abs/2211.09949v1)\n", "2211.09944": "- 2022-11-17, **MelHuBERT: A simplified HuBERT on Mel spectrogram**, Tzu-Quan Lin et.al., Paper: [http://arxiv.org/abs/2211.09944v1](http://arxiv.org/abs/2211.09944v1)\n", "2211.09861": "- 2022-11-17, **Self-Supervised Visual Representation Learning via Residual Momentum**, Trung X. Pham et.al., Paper: [http://arxiv.org/abs/2211.09861v1](http://arxiv.org/abs/2211.09861v1)\n", "2211.11720": "- 2022-11-22, **Multitask Vision-Language Prompt Tuning**, Sheng Shen et.al., Paper: [http://arxiv.org/abs/2211.11720v2](http://arxiv.org/abs/2211.11720v2), Code: **[https://github.com/sincerass/mvlpt](https://github.com/sincerass/mvlpt)**\n", "2211.11711": "- 2022-11-22, **CLAWSAT: Towards Both Robust and Accurate Code Models**, Jinghan Jia et.al., Paper: [http://arxiv.org/abs/2211.11711v2](http://arxiv.org/abs/2211.11711v2)\n", "2211.11635": "- 2022-11-21, **Understanding and Improving Visual Prompting: A Label-Mapping Perspective**, Aochuan Chen et.al., Paper: [http://arxiv.org/abs/2211.11635v1](http://arxiv.org/abs/2211.11635v1), Code: **[https://github.com/optml-group/ilm-vp](https://github.com/optml-group/ilm-vp)**\n", "2211.11596": "- 2022-11-21, **Forecasting Unobserved Node States with spatio-temporal Graph Neural Networks**, Andreas Roth et.al., Paper: [http://arxiv.org/abs/2211.11596v1](http://arxiv.org/abs/2211.11596v1)\n", "2211.11418": "- 2022-11-21, **L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for Devanagari based Hindi and Marathi Languages**, Raviraj Joshi et.al., Paper: [http://arxiv.org/abs/2211.11418v1](http://arxiv.org/abs/2211.11418v1)\n", "2211.11363": "- 2022-11-21, **CBEAF-Adapting: Enhanced Continual Pretraining for Building Chinese Biomedical Language Model**, Yongyu Yan et.al., Paper: [http://arxiv.org/abs/2211.11363v1](http://arxiv.org/abs/2211.11363v1)\n", "2211.11354": "- 2022-11-21, **Object-level 3D Semantic Mapping using a Network of Smart Edge Sensors**, Julian Hau et.al., Paper: [http://arxiv.org/abs/2211.11354v1](http://arxiv.org/abs/2211.11354v1)\n", "2211.11275": "- 2022-11-21, **VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for Speech Representation Learning**, Qiushi Zhu et.al., Paper: [http://arxiv.org/abs/2211.11275v1](http://arxiv.org/abs/2211.11275v1)\n", "2211.11202": "- 2022-11-21, **FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields**, Hao Zhang et.al., Paper: [http://arxiv.org/abs/2211.11202v1](http://arxiv.org/abs/2211.11202v1)\n", "2211.11049": "- 2022-11-20, **Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues**, Shivani Kumar et.al., Paper: [http://arxiv.org/abs/2211.11049v1](http://arxiv.org/abs/2211.11049v1)\n", "2211.12500": "- 2022-11-22, **Person Image Synthesis via Denoising Diffusion Model**, Ankan Kumar Bhunia et.al., Paper: [http://arxiv.org/abs/2211.12500v1](http://arxiv.org/abs/2211.12500v1), Code: **[https://github.com/ankanbhunia/PIDM](https://github.com/ankanbhunia/PIDM)**\n", "2211.12100": "- 2022-11-22, **Simulating Human Gaze with Neural Visual Attention**, Leo Schwinn et.al., Paper: [http://arxiv.org/abs/2211.12100v1](http://arxiv.org/abs/2211.12100v1)\n", "2211.12032": "- 2022-11-23, **PointCMC: Cross-Modal Multi-Scale Correspondences Learning for Point Cloud Understanding**, Honggu Zhou et.al., Paper: [http://arxiv.org/abs/2211.12032v2](http://arxiv.org/abs/2211.12032v2)\n", "2211.11799": "- 2022-11-21, **Unsupervised extraction, labelling and clustering of segments from clinical notes**, Petr Zelina et.al., Paper: [http://arxiv.org/abs/2211.11799v1](http://arxiv.org/abs/2211.11799v1), Code: **[https://github.com/zepzep/clinical-notes-extraction](https://github.com/zepzep/clinical-notes-extraction)**\n", "2211.12986": "- 2022-11-23, **Physics-informed neural networks for pathloss prediction**, Steffen Limmer et.al., Paper: [http://arxiv.org/abs/2211.12986v1](http://arxiv.org/abs/2211.12986v1)\n", "2211.12944": "- 2022-11-23, **SS-CXR: Multitask Representation Learning using Self Supervised Pre-training from Chest X-Rays**, Syed Muhammad Anwar et.al., Paper: [http://arxiv.org/abs/2211.12944v1](http://arxiv.org/abs/2211.12944v1)\n", "2211.12821": "- 2022-11-23, **Explainable AI for Pre-Trained Code Models: What Do They Learn? When They Do Not Work?**, Ahmad Haji Mohammadkhani et.al., Paper: [http://arxiv.org/abs/2211.12821v1](http://arxiv.org/abs/2211.12821v1)\n", "2211.12740": "- 2022-11-23, **Masked Autoencoding for Scalable and Generalizable Decision Making**, Fangchen Liu et.al., Paper: [http://arxiv.org/abs/2211.12740v1](http://arxiv.org/abs/2211.12740v1), Code: **[https://github.com/fangchenliu/maskdp_public](https://github.com/fangchenliu/maskdp_public)**\n", "2211.12739": "- 2022-11-23, **Texts as Images in Prompt Tuning for Multi-Label Image Recognition**, Zixian Guo et.al., Paper: [http://arxiv.org/abs/2211.12739v1](http://arxiv.org/abs/2211.12739v1), Code: **[https://github.com/guozix/tai-dpt](https://github.com/guozix/tai-dpt)**\n", "2211.12677": "- 2022-11-23, **Word-Level Representation From Bytes For Language Modeling**, Chu-Tak Lee et.al., Paper: [http://arxiv.org/abs/2211.12677v1](http://arxiv.org/abs/2211.12677v1)\n", "2211.14050": "- 2022-11-25, **A Semi-supervised Learning Approach for B-line Detection in Lung Ultrasound Images**, Tianqi Yang et.al., Paper: [http://arxiv.org/abs/2211.14050v1](http://arxiv.org/abs/2211.14050v1)\n", "2211.14049": "- 2022-11-25, **Task-Oriented Communication for Edge Video Analytics**, Jiawei Shao et.al., Paper: [http://arxiv.org/abs/2211.14049v1](http://arxiv.org/abs/2211.14049v1)\n", "2211.13977": "- 2022-11-25, **CLIP-ReID: Exploiting Vision-Language Model for Image Re-Identification without Concrete Text Labels**, Siyuan Li et.al., Paper: [http://arxiv.org/abs/2211.13977v1](http://arxiv.org/abs/2211.13977v1)\n", "2211.13972": "- 2022-11-25, **Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome Homogenization?**, Rishi Bommasani et.al., Paper: [http://arxiv.org/abs/2211.13972v1](http://arxiv.org/abs/2211.13972v1)\n", "2211.13956": "- 2022-11-25, **Learning General Audio Representations with Large-Scale Training of Patchout Audio Transformers**, Khaled Koutini et.al., Paper: [http://arxiv.org/abs/2211.13956v1](http://arxiv.org/abs/2211.13956v1), Code: **[https://github.com/kkoutini/passt_hear21](https://github.com/kkoutini/passt_hear21)**\n", "2211.13856": "- 2022-11-25, **WSSL: Weighted Self-supervised Learning Framework For Image-inpainting**, Shubham Gupta et.al., Paper: [http://arxiv.org/abs/2211.13856v1](http://arxiv.org/abs/2211.13856v1), Code: **[https://github.com/IamShubhamGupto/WSSL-Weighted-Self-Supervised-Learning-for-Image-Inpainting](https://github.com/IamShubhamGupto/WSSL-Weighted-Self-Supervised-Learning-for-Image-Inpainting)**\n", "2211.13815": "- 2022-11-24, **Using Selective Masking as a Bridge between Pre-training and Fine-tuning**, Tanish Lad et.al., Paper: [http://arxiv.org/abs/2211.13815v1](http://arxiv.org/abs/2211.13815v1)\n", "2211.13490": "- 2022-11-24, **Pose-disentangled Contrastive Learning for Self-supervised Facial Representation**, Yuanyuan Liu et.al., Paper: [http://arxiv.org/abs/2211.13490v1](http://arxiv.org/abs/2211.13490v1)\n", "2211.13437": "- 2022-11-24, **Seeing What You Miss: Vision-Language Pre-training with Semantic Completion Learning**, Yatai Ji et.al., Paper: [http://arxiv.org/abs/2211.13437v1](http://arxiv.org/abs/2211.13437v1)\n", "2211.13350": "- 2022-11-23, **Choreographer: Learning and Adapting Skills in Imagination**, Pietro Mazzaglia et.al., Paper: [http://arxiv.org/abs/2211.13350v1](http://arxiv.org/abs/2211.13350v1)\n", "2211.15660": "- 2022-11-28, **Satlas: A Large-Scale, Multi-Task Dataset for Remote Sensing Image Understanding**, Favyen Bastani et.al., Paper: [http://arxiv.org/abs/2211.15660v1](http://arxiv.org/abs/2211.15660v1)\n", "2211.15593": "- 2022-11-28, **GPT-Neo for commonsense reasoning-a theoretical and practical lens**, Rohan Kashyap et.al., Paper: [http://arxiv.org/abs/2211.15593v1](http://arxiv.org/abs/2211.15593v1)\n", "2211.14958": "- 2022-11-27, **MGDoc: Pre-training with Multi-granular Hierarchy for Document Image Understanding**, Zilong Wang et.al., Paper: [http://arxiv.org/abs/2211.14958v1](http://arxiv.org/abs/2211.14958v1)\n", "2211.14954": "- 2022-11-27, **Topic Segmentation in the Wild: Towards Segmentation of Semi-structured & Unstructured Chats**, Reshmi Ghosh et.al., Paper: [http://arxiv.org/abs/2211.14954v1](http://arxiv.org/abs/2211.14954v1)\n", "2211.14813": "- 2022-11-27, **SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation**, Huaishao Luo et.al., Paper: [http://arxiv.org/abs/2211.14813v1](http://arxiv.org/abs/2211.14813v1)\n", "2211.14777": "- 2022-11-27, **Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models**, Lei Wang et.al., Paper: [http://arxiv.org/abs/2211.14777v1](http://arxiv.org/abs/2211.14777v1), Code: **[https://github.com/maehcm/aet](https://github.com/maehcm/aet)**\n", "2211.14719": "- 2022-11-27, **BadPrompt: Backdoor Attacks on Continuous Prompts**, Xiangrui Cai et.al., Paper: [http://arxiv.org/abs/2211.14719v1](http://arxiv.org/abs/2211.14719v1), Code: **[https://github.com/paperspapers/badprompt](https://github.com/paperspapers/badprompt)**\n", "2211.14666": "- 2022-11-26, **Synergies Between Disentanglement and Sparsity: a Multi-Task Learning Perspective**, S\u00e9bastien Lachapelle et.al., Paper: [http://arxiv.org/abs/2211.14666v1](http://arxiv.org/abs/2211.14666v1)\n", "2211.14654": "- 2022-11-26, **Unsupervised Wildfire Change Detection based on Contrastive Learning**, Beichen Zhang et.al., Paper: [http://arxiv.org/abs/2211.14654v1](http://arxiv.org/abs/2211.14654v1)\n", "2211.16398": "- 2022-11-30, **Self-Supervised Mental Disorder Classifiers via Time Reversal**, Zafar Iqbal et.al., Paper: [http://arxiv.org/abs/2211.16398v2](http://arxiv.org/abs/2211.16398v2)\n", "2211.16349": "- 2022-11-29, **BARTSmiles: Generative Masked Language Models for Molecular Representations**, Gayane Chilingaryan et.al., Paper: [http://arxiv.org/abs/2211.16349v1](http://arxiv.org/abs/2211.16349v1), Code: **[https://github.com/yerevann/bartsmiles](https://github.com/yerevann/bartsmiles)**\n", "2211.16327": "- 2022-11-29, **On the power of foundation models**, Yang Yuan et.al., Paper: [http://arxiv.org/abs/2211.16327v1](http://arxiv.org/abs/2211.16327v1)\n", "2211.16175": "- 2022-11-29, **Context-Aware Robust Fine-Tuning**, Xiaofeng Mao et.al., Paper: [http://arxiv.org/abs/2211.16175v1](http://arxiv.org/abs/2211.16175v1)\n", "2211.16141": "- 2022-11-29, **Mind the Gap: Scanner-induced domain shifts pose challenges for representation learning in histopathology**, Frauke Wilm et.al., Paper: [http://arxiv.org/abs/2211.16141v1](http://arxiv.org/abs/2211.16141v1)\n", "2211.16103": "- 2022-11-29, **Text Representation Enrichment Utilizing Graph based Approaches: Stock Market Technical Analysis Case Study**, Sara Salamat et.al., Paper: [http://arxiv.org/abs/2211.16103v1](http://arxiv.org/abs/2211.16103v1)\n", "2211.16044": "- 2022-11-29, **Model Extraction Attack against Self-supervised Speech Models**, Tsu-Yuan Hsu et.al., Paper: [http://arxiv.org/abs/2211.16044v1](http://arxiv.org/abs/2211.16044v1)\n", "2211.15992": "- 2022-11-29, **MoDA: Map style transfer for self-supervised Domain Adaptation of embodied agents**, Eun Sun Lee et.al., Paper: [http://arxiv.org/abs/2211.15992v1](http://arxiv.org/abs/2211.15992v1)\n", "2211.15977": "- 2022-11-29, **One is All: Bridging the Gap Between Neural Radiance Fields Architectures with Progressive Volume Distillation**, Shuangkang Fang et.al., Paper: [http://arxiv.org/abs/2211.15977v1](http://arxiv.org/abs/2211.15977v1), Code: **[https://github.com/megvii-research/AAAI2023-PVD](https://github.com/megvii-research/AAAI2023-PVD)**\n", "2211.17228": "- 2022-11-30, **AIO-P: Expanding Neural Performance Predictors Beyond Image Classification**, Keith G. Mills et.al., Paper: [http://arxiv.org/abs/2211.17228v1](http://arxiv.org/abs/2211.17228v1), Code: **[https://github.com/Ascend-Research/AIO-P](https://github.com/Ascend-Research/AIO-P)**\n", "2211.17135": "- 2022-11-30, **BudgetLongformer: Can we Cheaply Pretrain a SotA Legal Language Model From Scratch?**, Joel Niklaus et.al., Paper: [http://arxiv.org/abs/2211.17135v1](http://arxiv.org/abs/2211.17135v1)\n", "2211.16853": "- 2022-11-30, **Revisiting text decomposition methods for NLI-based factuality scoring of summaries**, John Glover et.al., Paper: [http://arxiv.org/abs/2211.16853v1](http://arxiv.org/abs/2211.16853v1)\n", "2211.16696": "- 2022-12-01, **Automated anomaly-aware 3D segmentation of bones and cartilages in knee MR images from the Osteoarthritis Initiative**, Boyeong Woo et.al., Paper: [http://arxiv.org/abs/2211.16696v2](http://arxiv.org/abs/2211.16696v2), Code: **[https://github.com/wooboyeong/anomaly-aware-3d-segmentation](https://github.com/wooboyeong/anomaly-aware-3d-segmentation)**\n", "2211.16634": "- 2022-11-29, **SPARTAN: Sparse Hierarchical Memory for Parameter-Efficient Transformers**, Ameet Deshpande et.al., Paper: [http://arxiv.org/abs/2211.16634v1](http://arxiv.org/abs/2211.16634v1), Code: **[https://github.com/princeton-nlp/spartan](https://github.com/princeton-nlp/spartan)**\n", "2211.16632": "- 2022-11-29, **Hierarchical Transformer for Survival Prediction Using Multimodality Whole Slide Images and Genomics**, Chunyuan Li et.al., Paper: [http://arxiv.org/abs/2211.16632v1](http://arxiv.org/abs/2211.16632v1), Code: **[https://github.com/chunyuan1/himt](https://github.com/chunyuan1/himt)**\n", "2212.00794": "- 2022-12-01, **Scaling Language-Image Pre-training via Masking**, Yanghao Li et.al., Paper: [http://arxiv.org/abs/2212.00794v1](http://arxiv.org/abs/2212.00794v1)\n", "2212.00192": "- 2022-12-01, **AUG-FedPrompt: Practical Few-shot Federated NLP with Data-augmented Prompts**, Dongqi Cai et.al., Paper: [http://arxiv.org/abs/2212.00192v1](http://arxiv.org/abs/2212.00192v1)\n", "2212.00072": "- 2022-11-30, **Rethinking Causality-driven Robot Tool Segmentation with Temporal Constraints**, Hao Ding et.al., Paper: [http://arxiv.org/abs/2212.00072v1](http://arxiv.org/abs/2212.00072v1)\n", "2212.01340": "- 2022-12-02, **Moving Beyond Downstream Task Accuracy for Information Retrieval Benchmarking**, Keshav Santhanam et.al., Paper: [http://arxiv.org/abs/2212.01340v1](http://arxiv.org/abs/2212.01340v1)\n", "2212.01141": "- 2022-12-02, **MHCCL: Masked Hierarchical Cluster-wise Contrastive Learning for Multivariate Time Series**, Qianwen Meng et.al., Paper: [http://arxiv.org/abs/2212.01141v1](http://arxiv.org/abs/2212.01141v1)\n", "2212.01032": "- 2022-12-02, **General Framework for Self-Supervised Model Priming for Parameter-Efficient Fine-tuning**, Shih-Cheng Huang et.al., Paper: [http://arxiv.org/abs/2212.01032v1](http://arxiv.org/abs/2212.01032v1)\n", "2212.01282": "- 2022-12-01, **CHAPTER: Exploiting Convolutional Neural Network Adapters for Self-supervised Speech Models**, Zih-Ching Chen et.al., Paper: [http://arxiv.org/abs/2212.01282v1](http://arxiv.org/abs/2212.01282v1)\n", "2302.08500": "- 2023-02-16, **Auditing large language models: a three-layered approach**, Jakob M\u00f6kander et.al., Paper: [http://arxiv.org/abs/2302.08500v1](http://arxiv.org/abs/2302.08500v1)\n", "2302.08366": "- 2023-02-16, **Defect Transfer GAN: Diverse Defect Synthesis for Data Augmentation**, Ruyu Wang et.al., Paper: [http://arxiv.org/abs/2302.08366v1](http://arxiv.org/abs/2302.08366v1)\n", "2302.08362": "- 2023-02-16, **Conversation Style Transfer using Few-Shot Learning**, Shamik Roy et.al., Paper: [http://arxiv.org/abs/2302.08362v1](http://arxiv.org/abs/2302.08362v1)\n", "2302.08357": "- 2023-02-16, **Boundary Guided Mixing Trajectory for Semantic Control with Diffusion Models**, Ye Zhu et.al., Paper: [http://arxiv.org/abs/2302.08357v1](http://arxiv.org/abs/2302.08357v1)\n", "2302.08106": "- 2023-02-16, **Towards Efficient Visual Adaption via Structural Re-parameterization**, Gen Luo et.al., Paper: [http://arxiv.org/abs/2302.08106v1](http://arxiv.org/abs/2302.08106v1), Code: **[https://github.com/luogen1996/repadapter](https://github.com/luogen1996/repadapter)**\n", "2302.08043": "- 2023-02-16, **GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks**, Zemin Liu et.al., Paper: [http://arxiv.org/abs/2302.08043v1](http://arxiv.org/abs/2302.08043v1)\n", "2302.07937": "- 2023-02-15, **The Expressive Power of Tuning Only the Norm Layers**, Angeliki Giannou et.al., Paper: [http://arxiv.org/abs/2302.07937v1](http://arxiv.org/abs/2302.07937v1)\n", "2302.07912": "- 2023-02-15, **Meeting the Needs of Low-Resource Languages: The Value of Automatic Alignments via Pretrained Models**, Abteen Ebrahimi et.al., Paper: [http://arxiv.org/abs/2302.07912v1](http://arxiv.org/abs/2302.07912v1)\n", "2302.07778": "- 2023-02-15, **Measuring the Instability of Fine-Tuning**, Yupei Du et.al., Paper: [http://arxiv.org/abs/2302.07778v1](http://arxiv.org/abs/2302.07778v1), Code: **[https://github.com/nlpsoc/instability_measurement](https://github.com/nlpsoc/instability_measurement)**\n", "2302.07077": "- 2023-02-14, **Multi-Source Contrastive Learning from Musical Audio**, Christos Garoufis et.al., Paper: [http://arxiv.org/abs/2302.07077v1](http://arxiv.org/abs/2302.07077v1), Code: **[https://github.com/cgaroufis/mscol_smc23](https://github.com/cgaroufis/mscol_smc23)**\n", "2302.09018": "- 2023-02-17, **Self-supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences**, Yujie Zhou et.al., Paper: [http://arxiv.org/abs/2302.09018v1](http://arxiv.org/abs/2302.09018v1)\n", "2302.08840": "- 2023-02-17, **Learnable Topological Features for Phylogenetic Inference via Graph Neural Networks**, Cheng Zhang et.al., Paper: [http://arxiv.org/abs/2302.08840v1](http://arxiv.org/abs/2302.08840v1), Code: **[https://github.com/zcrabbit/vbpi-gnn](https://github.com/zcrabbit/vbpi-gnn)**\n", "2302.08672": "- 2023-02-17, **Multimodal Subtask Graph Generation from Instructional Videos**, Yunseok Jang et.al., Paper: [http://arxiv.org/abs/2302.08672v1](http://arxiv.org/abs/2302.08672v1)\n", "2302.08582": "- 2023-02-16, **Pretraining Language Models with Human Preferences**, Tomasz Korbak et.al., Paper: [http://arxiv.org/abs/2302.08582v1](http://arxiv.org/abs/2302.08582v1)\n", "2302.10167": "- 2023-02-20, **Cross-domain Compositing with Pretrained Diffusion Models**, Roy Hachnochi et.al., Paper: [http://arxiv.org/abs/2302.10167v1](http://arxiv.org/abs/2302.10167v1), Code: **[https://github.com/cross-domain-compositing/cross-domain-compositing](https://github.com/cross-domain-compositing/cross-domain-compositing)**\n", "2302.10035": "- 2023-02-20, **Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey**, Xiao Wang et.al., Paper: [http://arxiv.org/abs/2302.10035v1](http://arxiv.org/abs/2302.10035v1), Code: **[https://github.com/wangxiao5791509/multimodal_bigmodels_survey](https://github.com/wangxiao5791509/multimodal_bigmodels_survey)**\n", "2302.10007": "- 2023-02-20, **On the Metrics for Evaluating Monocular Depth Estimation**, Akhil Gurram et.al., Paper: [http://arxiv.org/abs/2302.10007v1](http://arxiv.org/abs/2302.10007v1)\n", "2302.09736": "- 2023-02-20, **STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training**, Weihong Zhong et.al., Paper: [http://arxiv.org/abs/2302.09736v1](http://arxiv.org/abs/2302.09736v1)\n", "2302.09696": "- 2023-02-19, **An Efficient and Robust Method for Chest X-Ray Rib Suppression that Improves Pulmonary Abnormality Diagnosis**, Di Xu et.al., Paper: [http://arxiv.org/abs/2302.09696v1](http://arxiv.org/abs/2302.09696v1)\n", "2302.09590": "- 2023-02-19, **Accelerated Video Annotation driven by Deep Detector and Tracker**, Eric Price et.al., Paper: [http://arxiv.org/abs/2302.09590v1](http://arxiv.org/abs/2302.09590v1), Code: **[https://github.com/robot-perception-group/smarter-labelme](https://github.com/robot-perception-group/smarter-labelme)**\n", "2302.09579": "- 2023-02-19, **Evaluating Representations with Readout Model Switching**, Yazhe Li et.al., Paper: [http://arxiv.org/abs/2302.09579v1](http://arxiv.org/abs/2302.09579v1)\n", "2302.09486": "- 2023-02-19, **LC-NeRF: Local Controllable Face Generation in Neural Randiance Field**, Wenyang Zhou et.al., Paper: [http://arxiv.org/abs/2302.09486v1](http://arxiv.org/abs/2302.09486v1)\n", "2302.09458": "- 2023-02-19, **Learning Language Representations with Logical Inductive Bias**, Jianshu Chen et.al., Paper: [http://arxiv.org/abs/2302.09458v1](http://arxiv.org/abs/2302.09458v1)\n", "2302.09437": "- 2023-02-18, **RobustDistiller: Compressing Universal Speech Representations for Enhanced Environment Robustness**, Heitor R. Guimar\u00e3es et.al., Paper: [http://arxiv.org/abs/2302.09437v1](http://arxiv.org/abs/2302.09437v1)\n", "2302.10633": "- 2023-02-21, **Generalization Bounds for Adversarial Contrastive Learning**, Xin Zou et.al., Paper: [http://arxiv.org/abs/2302.10633v1](http://arxiv.org/abs/2302.10633v1)\n", "2302.10414": "- 2023-02-21, **Improving Scene Text Image Super-Resolution via Dual Prior Modulation Network**, Shipeng Zhu et.al., Paper: [http://arxiv.org/abs/2302.10414v1](http://arxiv.org/abs/2302.10414v1), Code: **[https://github.com/jdfxzzy/dpmn](https://github.com/jdfxzzy/dpmn)**\n", "2302.10390": "- 2023-02-21, **DrasCLR: A Self-supervised Framework of Learning Disease-related and Anatomy-specific Representation for 3D Medical Images**, Ke Yu et.al., Paper: [http://arxiv.org/abs/2302.10390v1](http://arxiv.org/abs/2302.10390v1)\n", "2302.11529": "- 2023-02-22, **Modular Deep Learning**, Jonas Pfeiffer et.al., Paper: [http://arxiv.org/abs/2302.11529v1](http://arxiv.org/abs/2302.11529v1)\n", "2302.11520": "- 2023-02-22, **Guiding Large Language Models via Directional Stimulus Prompting**, Zekun Li et.al., Paper: [http://arxiv.org/abs/2302.11520v1](http://arxiv.org/abs/2302.11520v1)\n", "2302.11352": "- 2023-02-22, **X-TRA: Improving Chest X-ray Tasks with Cross-Modal Retrieval Augmentation**, Tom van Sonsbeek et.al., Paper: [http://arxiv.org/abs/2302.11352v1](http://arxiv.org/abs/2302.11352v1)\n", "2302.11349": "- 2023-02-22, **Steerable Equivariant Representation Learning**, Sangnie Bhardwaj et.al., Paper: [http://arxiv.org/abs/2302.11349v1](http://arxiv.org/abs/2302.11349v1)\n", "2302.11313": "- 2023-02-22, **Time-varying Signals Recovery via Graph Neural Networks**, Jhon A. Castro-Correa et.al., Paper: [http://arxiv.org/abs/2302.11313v1](http://arxiv.org/abs/2302.11313v1)\n", "2302.11205": "- 2023-02-22, **Contrastive Representation Learning for Acoustic Parameter Estimation**, Philipp G\u00f6tz et.al., Paper: [http://arxiv.org/abs/2302.11205v1](http://arxiv.org/abs/2302.11205v1)\n", "2302.11091": "- 2023-02-22, **GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation Learning Method**, Xing Tang et.al., Paper: [http://arxiv.org/abs/2302.11091v1](http://arxiv.org/abs/2302.11091v1), Code: **[https://github.com/xt-55/GTRL](https://github.com/xt-55/GTRL)**\n", "2302.11084": "- 2023-02-22, **Distribution Normalization: An \"Effortless\" Test-Time Augmentation for Contrastively Learned Visual-language Models**, Yifei Zhou et.al., Paper: [http://arxiv.org/abs/2302.11084v1](http://arxiv.org/abs/2302.11084v1), Code: **[https://github.com/fengyuli2002/distribution-normalization](https://github.com/fengyuli2002/distribution-normalization)**\n", "2302.11002": "- 2023-02-21, **Learning Physical Models that Can Respect Conservation Laws**, Derek Hansen et.al., Paper: [http://arxiv.org/abs/2302.11002v1](http://arxiv.org/abs/2302.11002v1), Code: **[https://github.com/amazon-science/probconserv](https://github.com/amazon-science/probconserv)**\n", "2302.12066": "- 2023-02-23, **Teaching CLIP to Count to Ten**, Roni Paiss et.al., Paper: [http://arxiv.org/abs/2302.12066v1](http://arxiv.org/abs/2302.12066v1)\n", "2302.12052": "- 2023-02-23, **Attention Mechanism for Contrastive Learning in GAN-based Image-to-Image Translation**, Hanzhen Zhang et.al., Paper: [http://arxiv.org/abs/2302.12052v1](http://arxiv.org/abs/2302.12052v1)\n", "2302.11814": "- 2023-02-23, **FTM: A Frame-level Timeline Modeling Method for Temporal Graph Representation Learning**, Bowen Cao et.al., Paper: [http://arxiv.org/abs/2302.11814v1](http://arxiv.org/abs/2302.11814v1), Code: **[https://github.com/yeeeqichen/ftm](https://github.com/yeeeqichen/ftm)**\n", "2302.12007": "- 2023-02-22, **DMMG: Dual Min-Max Games for Self-Supervised Skeleton-Based Action Recognition**, Shannan Guan et.al., Paper: [http://arxiv.org/abs/2302.12007v1](http://arxiv.org/abs/2302.12007v1)\n", "2302.12813": "- 2023-02-24, **Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback**, Baolin Peng et.al., Paper: [http://arxiv.org/abs/2302.12813v1](http://arxiv.org/abs/2302.12813v1)\n", "2302.12712": "- 2023-02-24, **Amortised Invariance Learning for Contrastive Self-Supervision**, Ruchika Chavhan et.al., Paper: [http://arxiv.org/abs/2302.12712v1](http://arxiv.org/abs/2302.12712v1)\n", "2302.12617": "- 2023-02-24, **Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains**, Jingwei Zhang et.al., Paper: [http://arxiv.org/abs/2302.12617v1](http://arxiv.org/abs/2302.12617v1)\n", "2302.12597": "- 2023-02-24, **Active Velocity Estimation using Light Curtains via Self-Supervised Multi-Armed Bandits**, Siddharth Ancha et.al., Paper: [http://arxiv.org/abs/2302.12597v1](http://arxiv.org/abs/2302.12597v1)\n", "2302.12505": "- 2023-02-24, **Spatial Bias for Attention-free Non-local Neural Networks**, Junhyung Go et.al., Paper: [http://arxiv.org/abs/2302.12505v1](http://arxiv.org/abs/2302.12505v1)\n", "2302.12449": "- 2023-02-24, **SGL-PT: A Strong Graph Learner with Graph Prompt Tuning**, Yun Zhu et.al., Paper: [http://arxiv.org/abs/2302.12449v1](http://arxiv.org/abs/2302.12449v1)\n", "2302.12441": "- 2023-02-24, **MUX-PLMs: Pre-training Language Models with Data Multiplexing**, Vishvak Murahari et.al., Paper: [http://arxiv.org/abs/2302.12441v1](http://arxiv.org/abs/2302.12441v1), Code: **[https://github.com/princeton-nlp/datamux-pretraining](https://github.com/princeton-nlp/datamux-pretraining)**\n", "2302.12383": "- 2023-02-24, **Generalization Analysis for Contrastive Representation Learning**, Yunwen Lei et.al., Paper: [http://arxiv.org/abs/2302.12383v1](http://arxiv.org/abs/2302.12383v1)\n", "2302.12343": "- 2023-02-23, **CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models**, Denis Jered McInerney et.al., Paper: [http://arxiv.org/abs/2302.12343v1](http://arxiv.org/abs/2302.12343v1)\n", "2302.14007": "- 2023-02-27, **Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training**, Ziyu Guo et.al., Paper: [http://arxiv.org/abs/2302.14007v1](http://arxiv.org/abs/2302.14007v1)\n", "2302.13869": "- 2023-02-27, **EDMAE: An Efficient Decoupled Masked Autoencoder for Standard View Identification in Pediatric Echocardiography**, Yiman Liu et.al., Paper: [http://arxiv.org/abs/2302.13869v1](http://arxiv.org/abs/2302.13869v1)\n", "2302.13661": "- 2023-02-27, **Using Auxiliary Tasks In Multimodal Fusion Of Wav2vec 2.0 And BERT For Multimodal Emotion Recognition**, Dekai Sun et.al., Paper: [http://arxiv.org/abs/2302.13661v1](http://arxiv.org/abs/2302.13661v1)\n", "2302.13435": "- 2023-02-26, **Scalable Weight Reparametrization for Efficient Transfer Learning**, Byeonggeun Kim et.al., Paper: [http://arxiv.org/abs/2302.13435v1](http://arxiv.org/abs/2302.13435v1)\n", "2302.13221": "- 2023-02-26, **Data-Centric AI: Deep Generative Differentiable Feature Selection via Discrete Subsetting as Continuous Embedding Space Optimization**, Xiao Meng et.al., Paper: [http://arxiv.org/abs/2302.13221v1](http://arxiv.org/abs/2302.13221v1)\n", "2302.12977": "- 2023-02-25, **Fair Attribute Completion on Graph with Missing Attributes**, Dongliang Guo et.al., Paper: [http://arxiv.org/abs/2302.12977v1](http://arxiv.org/abs/2302.12977v1), Code: **[https://github.com/donglgcn/fairac](https://github.com/donglgcn/fairac)**\n", "2302.14431": "- 2023-02-28, **Efficient Masked Autoencoders with Self-Consistency**, Zhaowen Li et.al., Paper: [http://arxiv.org/abs/2302.14431v1](http://arxiv.org/abs/2302.14431v1)\n", "2302.14338": "- 2023-03-01, **Turning a CLIP Model into a Scene Text Detector**, Wenwen Yu et.al., Paper: [http://arxiv.org/abs/2302.14338v2](http://arxiv.org/abs/2302.14338v2)\n", "2302.14306": "- 2023-02-28, **CLR-GAM: Contrastive Point Cloud Learning with Guided Augmentation and Feature Mapping**, Srikanth Malla et.al., Paper: [http://arxiv.org/abs/2302.14306v1](http://arxiv.org/abs/2302.14306v1)\n", "2302.14225": "- 2023-02-28, **Weighted Sampling for Masked Language Modeling**, Linhan Zhang et.al., Paper: [http://arxiv.org/abs/2302.14225v1](http://arxiv.org/abs/2302.14225v1)\n", "2302.14132": "- 2023-02-27, **Structured Pruning of Self-Supervised Pre-trained Models for Speech Recognition and Understanding**, Yifan Peng et.al., Paper: [http://arxiv.org/abs/2302.14132v1](http://arxiv.org/abs/2302.14132v1)\n", "2303.00733": "- 2023-03-01, **SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks**, Kai-Wei Chang et.al., Paper: [http://arxiv.org/abs/2303.00733v1](http://arxiv.org/abs/2303.00733v1)\n", "2303.00690": "- 2023-03-01, **Rethinking Efficient Tuning Methods from a Unified Perspective**, Zeyinzi Jiang et.al., Paper: [http://arxiv.org/abs/2303.00690v1](http://arxiv.org/abs/2303.00690v1)\n", "2303.00403": "- 2023-03-01, **Can representation learning for multimodal image registration be improved by supervision of intermediate layers?**, Elisabeth Wetzer et.al., Paper: [http://arxiv.org/abs/2303.00403v1](http://arxiv.org/abs/2303.00403v1)\n", "2303.00289": "- 2023-03-01, **StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training**, Yuechen Yu et.al., Paper: [http://arxiv.org/abs/2303.00289v1](http://arxiv.org/abs/2303.00289v1), Code: **[https://github.com/PaddlePaddle/VIMER/tree/main/StrucTexT/v2](https://github.com/PaddlePaddle/VIMER/tree/main/StrucTexT/v2)**\n", "2303.00233": "- 2023-03-01, **Single-Cell Multimodal Prediction via Transformers**, Wenzhuo Tang et.al., Paper: [http://arxiv.org/abs/2303.00233v1](http://arxiv.org/abs/2303.00233v1), Code: **[https://github.com/omicsml/scmoformer](https://github.com/omicsml/scmoformer)**\n", "2303.00106": "- 2023-02-28, **The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning**, Zhenmei Shi et.al., Paper: [http://arxiv.org/abs/2303.00106v1](http://arxiv.org/abs/2303.00106v1), Code: **[https://github.com/zhmeishi/trade-off_contrastive_learning](https://github.com/zhmeishi/trade-off_contrastive_learning)**\n", "2303.01421": "- 2023-03-02, **Semiparametric Language Models Are Scalable Continual Learners**, Guangyue Peng et.al., Paper: [http://arxiv.org/abs/2303.01421v1](http://arxiv.org/abs/2303.01421v1)\n", "2303.01384": "- 2023-03-02, **DAVA: Disentangling Adversarial Variational Autoencoder**, Benjamin Estermann et.al., Paper: [http://arxiv.org/abs/2303.01384v1](http://arxiv.org/abs/2303.01384v1), Code: **[https://github.com/besterma/dava](https://github.com/besterma/dava)**\n", "2303.01289": "- 2023-03-03, **Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning**, Rundong Luo et.al., Paper: [http://arxiv.org/abs/2303.01289v2](http://arxiv.org/abs/2303.01289v2), Code: **[https://github.com/pku-ml/dynacl](https://github.com/pku-ml/dynacl)**\n", "2303.01034": "- 2023-03-02, **Multi-Task Self-Supervised Time-Series Representation Learning**, Heejeong Choi et.al., Paper: [http://arxiv.org/abs/2303.01034v1](http://arxiv.org/abs/2303.01034v1)\n", "2303.01030": "- 2023-03-02, **Node Embedding from Hamiltonian Information Propagation in Graph Neural Networks**, Qiyu Kang et.al., Paper: [http://arxiv.org/abs/2303.01030v1](http://arxiv.org/abs/2303.01030v1)\n", "2303.01986": "- 2023-03-03, **Towards Democratizing Joint-Embedding Self-Supervised Learning**, Florian Bordes et.al., Paper: [http://arxiv.org/abs/2303.01986v1](http://arxiv.org/abs/2303.01986v1)\n", "2303.01672": "- 2023-03-03, **Self-supervised Learning for Gastrointestinal Pathologies Endoscopy Image Classification with Triplet Loss**, Tai Nguyen-D-P et.al., Paper: [http://arxiv.org/abs/2303.01672v1](http://arxiv.org/abs/2303.01672v1)\n", "2303.01566": "- 2023-03-02, **On the Provable Advantage of Unsupervised Pretraining**, Jiawei Ge et.al., Paper: [http://arxiv.org/abs/2303.01566v1](http://arxiv.org/abs/2303.01566v1)\n", "2303.01543": "- 2023-03-02, **Decision-Oriented Learning with Differentiable Submodular Maximization for Vehicle Routing Problem**, Guangyao Shi et.al., Paper: [http://arxiv.org/abs/2303.01543v1](http://arxiv.org/abs/2303.01543v1)\n", "2303.03127": "- 2023-03-06, **ST-KeyS: Self-Supervised Transformer for Keyword Spotting in Historical Handwritten Documents**, Sana Khamekhem Jemni et.al., Paper: [http://arxiv.org/abs/2303.03127v1](http://arxiv.org/abs/2303.03127v1)\n", "2303.03037": "- 2023-03-06, **EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning**, Monish R. Nallapareddy et.al., Paper: [http://arxiv.org/abs/2303.03037v1](http://arxiv.org/abs/2303.03037v1)\n", "2303.02995": "- 2023-03-06, **HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention**, Shijie Geng et.al., Paper: [http://arxiv.org/abs/2303.02995v1](http://arxiv.org/abs/2303.02995v1), Code: **[https://github.com/jeykigung/hiclip](https://github.com/jeykigung/hiclip)**\n", "2303.02982": "- 2023-03-06, **CLIP-guided Prototype Modulating for Few-shot Action Recognition**, Xiang Wang et.al., Paper: [http://arxiv.org/abs/2303.02982v1](http://arxiv.org/abs/2303.02982v1), Code: **[https://github.com/alibaba-mmai-research/clip-fsar](https://github.com/alibaba-mmai-research/clip-fsar)**\n", "2303.02936": "- 2023-03-06, **UniHCP: A Unified Model for Human-Centric Perceptions**, Yuanzheng Ci et.al., Paper: [http://arxiv.org/abs/2303.02936v1](http://arxiv.org/abs/2303.02936v1)\n", "2303.02861": "- 2023-03-06, **Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning**, Zhen Wang et.al., Paper: [http://arxiv.org/abs/2303.02861v1](http://arxiv.org/abs/2303.02861v1)\n", "2303.02860": "- 2023-03-06, **A Multi-Grained Self-Interpretable Symbolic-Neural Model For Single/Multi-Labeled Text Classification**, Xiang Hu et.al., Paper: [http://arxiv.org/abs/2303.02860v1](http://arxiv.org/abs/2303.02860v1), Code: **[https://github.com/ant-research/structuredlm_rtdt](https://github.com/ant-research/structuredlm_rtdt)**\n", "2303.02760": "- 2023-03-05, **Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes**, Xuan Ju et.al., Paper: [http://arxiv.org/abs/2303.02760v1](http://arxiv.org/abs/2303.02760v1)\n", "2303.02552": "- 2023-03-05, **An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry**, Wenxin Jiang et.al., Paper: [http://arxiv.org/abs/2303.02552v1](http://arxiv.org/abs/2303.02552v1)\n", "2303.02416": "- 2023-03-04, **PixMIM: Rethinking Pixel Reconstruction in Masked Image Modeling**, Yuan Liu et.al., Paper: [http://arxiv.org/abs/2303.02416v1](http://arxiv.org/abs/2303.02416v1), Code: **[https://github.com/open-mmlab/mmselfsup](https://github.com/open-mmlab/mmselfsup)**\n", "2303.04105": "- 2023-03-07, **Introspective Cross-Attention Probing for Lightweight Transfer of Pre-trained Models**, Yonatan Dukler et.al., Paper: [http://arxiv.org/abs/2303.04105v1](http://arxiv.org/abs/2303.04105v1)\n", "2303.03965": "- 2023-03-07, **Comparing 3D deformations between longitudinal daily CBCT acquisitions using CNN for head and neck radiotherapy toxicity prediction**, William Trung Le et.al., Paper: [http://arxiv.org/abs/2303.03965v1](http://arxiv.org/abs/2303.03965v1)\n", "2303.03717": "- 2023-03-07, **Improving Self-Supervised Learning for Audio Representations by Feature Diversity and Decorrelation**, Bac Nguyen et.al., Paper: [http://arxiv.org/abs/2303.03717v1](http://arxiv.org/abs/2303.03717v1)\n", "2303.03679": "- 2023-03-07, **MAST: Masked Augmentation Subspace Training for Generalizable Self-Supervised Priors**, Chen Huang et.al., Paper: [http://arxiv.org/abs/2303.03679v1](http://arxiv.org/abs/2303.03679v1)\n", "2303.03657": "- 2023-03-07, **Self-FiLM: Conditioning GANs with self-supervised representations for bandwidth extension based speaker recognition**, Saurabh Kataria et.al., Paper: [http://arxiv.org/abs/2303.03657v1](http://arxiv.org/abs/2303.03657v1)\n", "2303.04603": "- 2023-03-08, **Learning Enhancement From Degradation: A Diffusion Model For Fundus Image Enhancement**, Puijin Cheng et.al., Paper: [http://arxiv.org/abs/2303.04603v1](http://arxiv.org/abs/2303.04603v1), Code: **[https://github.com/qtacierp/led](https://github.com/qtacierp/led)**\n", "2303.04360": "- 2023-03-08, **Does Synthetic Data Generation of LLMs Help Clinical Text Mining?**, Ruixiang Tang et.al., Paper: [http://arxiv.org/abs/2303.04360v1](http://arxiv.org/abs/2303.04360v1)\n", "2303.04338": "- 2023-03-08, **Provable Pathways: Learning Multiple Tasks over Multiple Paths**, Yingcong Li et.al., Paper: [http://arxiv.org/abs/2303.04338v1](http://arxiv.org/abs/2303.04338v1)\n", "2303.04291": "- 2023-03-07, **Diffusion in the Dark: A Diffusion Model for Low-Light Text Recognition**, Cindy M. Nguyen et.al., Paper: [http://arxiv.org/abs/2303.04291v1](http://arxiv.org/abs/2303.04291v1)\n", "2303.05475": "- 2023-03-09, **Mimic before Reconstruct: Enhancing Masked Autoencoders with Feature Mimicking**, Peng Gao et.al., Paper: [http://arxiv.org/abs/2303.05475v1](http://arxiv.org/abs/2303.05475v1), Code: **[https://github.com/alpha-vl/convmae](https://github.com/alpha-vl/convmae)**\n", "2303.05313": "- 2023-03-09, **Replacement as a Self-supervision for Fine-grained Vision-language Pre-training**, Lisai Zhang et.al., Paper: [http://arxiv.org/abs/2303.05313v1](http://arxiv.org/abs/2303.05313v1)\n", "2303.05308": "- 2023-03-09, **SpyroPose: Importance Sampling Pyramids for Object Pose Distribution Estimation in SE(3)**, Rasmus Laurvig Haugaard et.al., Paper: [http://arxiv.org/abs/2303.05308v1](http://arxiv.org/abs/2303.05308v1)\n", "2303.05266": "- 2023-03-09, **From Visual Prompt Learning to Zero-Shot Transfer: Mapping Is All You Need**, Ziqing Yang et.al., Paper: [http://arxiv.org/abs/2303.05266v1](http://arxiv.org/abs/2303.05266v1)\n", "2303.05231": "- 2023-03-09, **Structure-Aware Group Discrimination with Adaptive-View Graph Encoder: A Fast Graph Contrastive Learning Framework**, Zhenshuo Zhang et.al., Paper: [http://arxiv.org/abs/2303.05231v1](http://arxiv.org/abs/2303.05231v1)\n", "2303.04998": "- 2023-03-09, **Rethinking Visual Prompt Learning as Masked Visual Token Modeling**, Ning Liao et.al., Paper: [http://arxiv.org/abs/2303.04998v1](http://arxiv.org/abs/2303.04998v1)\n", "2303.06121": "- 2023-03-10, **Ignorance is Bliss: Robust Control via Information Gating**, Manan Tomar et.al., Paper: [http://arxiv.org/abs/2303.06121v1](http://arxiv.org/abs/2303.06121v1)\n", "2303.05952": "- 2023-03-10, **Understanding and Constructing Latent Modality Structures in Multi-modal Representation Learning**, Qian Jiang et.al., Paper: [http://arxiv.org/abs/2303.05952v1](http://arxiv.org/abs/2303.05952v1)\n", "2303.05707": "- 2023-03-10, **MuLTI: Efficient Video-and-Language Understanding with MultiWay-Sampler and Multiple Choice Modeling**, Jiaqi Xu et.al., Paper: [http://arxiv.org/abs/2303.05707v1](http://arxiv.org/abs/2303.05707v1)\n", "2303.05675": "- 2023-03-10, **HumanBench: Towards General Human-centric Perception with Projector Assisted Pretraining**, Shixiang Tang et.al., Paper: [http://arxiv.org/abs/2303.05675v1](http://arxiv.org/abs/2303.05675v1)\n", "2303.07338": "- 2023-03-13, **Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need**, Da-Wei Zhou et.al., Paper: [http://arxiv.org/abs/2303.07338v1](http://arxiv.org/abs/2303.07338v1), Code: **[https://github.com/zhoudw-zdw/revisitingcil](https://github.com/zhoudw-zdw/revisitingcil)**\n", "2303.07320": "- 2023-03-13, **Model-tuning Via Prompts Makes NLP Models Adversarially Robust**, Mrigank Raman et.al., Paper: [http://arxiv.org/abs/2303.07320v1](http://arxiv.org/abs/2303.07320v1)\n", "2303.07240": "- 2023-03-13, **PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents**, Weixiong Lin et.al., Paper: [http://arxiv.org/abs/2303.07240v1](http://arxiv.org/abs/2303.07240v1)\n", "2303.07104": "- 2023-03-13, **xASTNN: Improved Code Representations for Industrial Practice**, Zhiwei Xu et.al., Paper: [http://arxiv.org/abs/2303.07104v1](http://arxiv.org/abs/2303.07104v1)\n", "2303.06982": "- 2023-03-13, **Analysing the Masked predictive coding training criterion for pre-training a Speech Representation Model**, Hemant Yadav et.al., Paper: [http://arxiv.org/abs/2303.06982v1](http://arxiv.org/abs/2303.06982v1)\n", "2303.06965": "- 2023-03-14, **Uni-RXN: A Unified Framework Bridging the Gap between Chemical Reaction Pretraining and Conditional Molecule Generation**, Bo Qiang et.al., Paper: [http://arxiv.org/abs/2303.06965v2](http://arxiv.org/abs/2303.06965v2), Code: **[https://github.com/qiangbo1222/uni-rxn-official](https://github.com/qiangbo1222/uni-rxn-official)**\n", "2303.06911": "- 2023-03-13, **ViM: Vision Middleware for Unified Downstream Transferring**, Yutong Feng et.al., Paper: [http://arxiv.org/abs/2303.06911v1](http://arxiv.org/abs/2303.06911v1)\n", "2303.06721": "- 2023-03-12, **Knowledge-integrated AutoEncoder Model**, Teddy Lazebnik et.al., Paper: [http://arxiv.org/abs/2303.06721v1](http://arxiv.org/abs/2303.06721v1)\n", "2303.06628": "- 2023-03-12, **Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models**, Zangwei Zheng et.al., Paper: [http://arxiv.org/abs/2303.06628v1](http://arxiv.org/abs/2303.06628v1), Code: **[https://github.com/thunderbeee/zscl](https://github.com/thunderbeee/zscl)**\n", "2303.06596": "- 2023-03-12, **Amodal Intra-class Instance Segmentation: New Dataset and Benchmark**, Jiayang Ao et.al., Paper: [http://arxiv.org/abs/2303.06596v1](http://arxiv.org/abs/2303.06596v1)\n", "2303.08138": "- 2023-03-14, **Diversity-Aware Meta Visual Prompting**, Qidong Huang et.al., Paper: [http://arxiv.org/abs/2303.08138v1](http://arxiv.org/abs/2303.08138v1), Code: **[https://github.com/shikiw/dam-vp](https://github.com/shikiw/dam-vp)**\n", "2303.07910": "- 2023-03-14, **Revisit Parameter-Efficient Transfer Learning: A Two-Stage Paradigm**, Hengyuan Zhao et.al., Paper: [http://arxiv.org/abs/2303.07910v1](http://arxiv.org/abs/2303.07910v1)\n", "2303.07902": "- 2023-03-14, **BLAT: Bootstrapping Language-Audio Pre-training based on AudioSet Tag-guided Synthetic Data**, Xuenan Xu et.al., Paper: [http://arxiv.org/abs/2303.07902v1](http://arxiv.org/abs/2303.07902v1)\n", "2303.07895": "- 2023-03-14, **The Learnability of In-Context Learning**, Noam Wies et.al., Paper: [http://arxiv.org/abs/2303.07895v1](http://arxiv.org/abs/2303.07895v1)\n", "2303.07709": "- 2023-03-14, **3D Face Arbitrary Style Transfer**, Xiangwen Deng et.al., Paper: [http://arxiv.org/abs/2303.07709v1](http://arxiv.org/abs/2303.07709v1)\n", "2303.07700": "- 2023-03-14, **PATS: Patch Area Transportation with Subdivision for Local Feature Matching**, Junjie Ni et.al., Paper: [http://arxiv.org/abs/2303.07700v1](http://arxiv.org/abs/2303.07700v1)\n", "2303.07615": "- 2023-03-14, **Variation of Gender Biases in Visual Recognition Models Before and After Finetuning**, Jaspreet Ranjit et.al., Paper: [http://arxiv.org/abs/2303.07615v1](http://arxiv.org/abs/2303.07615v1)\n", "2303.07598": "- 2023-03-14, **AdPE: Adversarial Positional Embeddings for Pretraining Vision Transformers via MAE+**, Xiao Wang et.al., Paper: [http://arxiv.org/abs/2303.07598v1](http://arxiv.org/abs/2303.07598v1), Code: **[https://github.com/maple-research-lab/AdPE](https://github.com/maple-research-lab/AdPE)**\n", "2303.07519": "- 2023-03-15, **Architext: Language-Driven Generative Architecture Design**, Theodoros Galanos et.al., Paper: [http://arxiv.org/abs/2303.07519v2](http://arxiv.org/abs/2303.07519v2)\n", "2303.08817": "- 2023-03-16, **DeepMIM: Deep Supervision for Masked Image Modeling**, Sucheng Ren et.al., Paper: [http://arxiv.org/abs/2303.08817v2](http://arxiv.org/abs/2303.08817v2), Code: **[https://github.com/oliverrensu/deepmim](https://github.com/oliverrensu/deepmim)**\n", "2303.08811": "- 2023-03-15, **Relax, it doesn't matter how you get there: A new self-supervised approach for multi-timescale behavior analysis**, Mehdi Azabou et.al., Paper: [http://arxiv.org/abs/2303.08811v1](http://arxiv.org/abs/2303.08811v1)\n", "2303.08685": "- 2023-03-15, **Making Vision Transformers Efficient from A Token Sparsification View**, Shuning Chang et.al., Paper: [http://arxiv.org/abs/2303.08685v1](http://arxiv.org/abs/2303.08685v1)\n", "2303.08566": "- 2023-03-15, **Sensitivity-Aware Visual Parameter-Efficient Tuning**, Haoyu He et.al., Paper: [http://arxiv.org/abs/2303.08566v1](http://arxiv.org/abs/2303.08566v1), Code: **[https://github.com/ziplab/spt](https://github.com/ziplab/spt)**\n", "2303.08562": "- 2023-03-15, **MGA: Medical generalist agent through text-guided knowledge transformation**, Weijian Huang et.al., Paper: [http://arxiv.org/abs/2303.08562v1](http://arxiv.org/abs/2303.08562v1)\n", "2303.08452": "- 2023-03-15, **Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection**, Cosmin I Bercea et.al., Paper: [http://arxiv.org/abs/2303.08452v1](http://arxiv.org/abs/2303.08452v1)\n", "2303.08446": "- 2023-03-15, **Task-specific Fine-tuning via Variational Information Bottleneck for Weakly-supervised Pathology Whole Slide Image Classification**, Honglin Li et.al., Paper: [http://arxiv.org/abs/2303.08446v1](http://arxiv.org/abs/2303.08446v1)\n", "2303.08438": "- 2023-03-15, **Learning Accurate Template Matching with Differentiable Coarse-to-Fine Correspondence Refinement**, Zhirui Gao et.al., Paper: [http://arxiv.org/abs/2303.08438v1](http://arxiv.org/abs/2303.08438v1), Code: **[https://github.com/zhirui-gao/deep-template-matching](https://github.com/zhirui-gao/deep-template-matching)**\n", "2303.08403": "- 2023-03-15, **DualFair: Fair Representation Learning at Both Group and Individual Levels via Contrastive Self-supervision**, Sungwon Han et.al., Paper: [http://arxiv.org/abs/2303.08403v1](http://arxiv.org/abs/2303.08403v1), Code: **[https://github.com/sungwon-han/dualfair](https://github.com/sungwon-han/dualfair)**\n", "2303.08216": "- 2023-03-14, **Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection**, Nikhil J. Dhinagar et.al., Paper: [http://arxiv.org/abs/2303.08216v1](http://arxiv.org/abs/2303.08216v1)\n", "2303.09347": "- 2023-03-16, **CSSL-MHTR: Continual Self-Supervised Learning for Scalable Multi-script Handwritten Text Recognition**, Marwa Dhiaf et.al., Paper: [http://arxiv.org/abs/2303.09347v1](http://arxiv.org/abs/2303.09347v1)\n", "2303.09165": "- 2023-03-16, **A New Benchmark: On the Utility of Synthetic Data with Blender for Bare Supervised Learning and Downstream Domain Adaptation**, Hui Tang et.al., Paper: [http://arxiv.org/abs/2303.09165v1](http://arxiv.org/abs/2303.09165v1), Code: **[https://github.com/huitangtang/on_the_utility_of_synthetic_data](https://github.com/huitangtang/on_the_utility_of_synthetic_data)**\n", "2303.09079": "- 2023-03-16, **SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning**, Mengxin Zheng et.al., Paper: [http://arxiv.org/abs/2303.09079v1](http://arxiv.org/abs/2303.09079v1)\n", "2303.09046": "- 2023-03-16, **Self-Supervised Visual Representation Learning on Food Images**, Andrew Peng et.al., Paper: [http://arxiv.org/abs/2303.09046v1](http://arxiv.org/abs/2303.09046v1)\n", "2303.09005": "- 2023-03-16, **Conditional Synthetic Food Image Generation**, Wenjin Fu et.al., Paper: [http://arxiv.org/abs/2303.09005v1](http://arxiv.org/abs/2303.09005v1)\n", "2303.08983": "- 2023-03-15, **Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement**, Fartash Faghri et.al., Paper: [http://arxiv.org/abs/2303.08983v1](http://arxiv.org/abs/2303.08983v1)\n", "2303.08934": "- 2023-03-15, **PTMTorrent: A Dataset for Mining Open-source Pre-trained Model Packages**, Wenxin Jiang et.al., Paper: [http://arxiv.org/abs/2303.08934v1](http://arxiv.org/abs/2303.08934v1)\n", "2303.08928": "- 2023-03-15, **Applying unsupervised keyphrase methods on concepts extracted from discharge sheets**, Hoda Memarzadeh et.al., Paper: [http://arxiv.org/abs/2303.08928v1](http://arxiv.org/abs/2303.08928v1)\n", "2303.08914": "- 2023-03-15, **MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge**, Wei Lin et.al., Paper: [http://arxiv.org/abs/2303.08914v1](http://arxiv.org/abs/2303.08914v1), Code: **[https://github.com/wlin-at/maxi](https://github.com/wlin-at/maxi)**\n", "2303.08863": "- 2023-03-15, **Class-Guided Image-to-Image Diffusion: Cell Painting from Brightfield Images with Class Labels**, Jan Oscar Cross-Zamirski et.al., Paper: [http://arxiv.org/abs/2303.08863v1](http://arxiv.org/abs/2303.08863v1)\n", "2303.10151": "- 2023-03-17, **Toward Super-Resolution for Appearance-Based Gaze Estimation**, Galen O'Shea et.al., Paper: [http://arxiv.org/abs/2303.10151v1](http://arxiv.org/abs/2303.10151v1)\n", "2303.10070": "- 2023-03-17, **A Unified Continual Learning Framework with General Parameter-Efficient Tuning**, Qiankun Gao et.al., Paper: [http://arxiv.org/abs/2303.10070v1](http://arxiv.org/abs/2303.10070v1), Code: **[https://github.com/gqk/lae](https://github.com/gqk/lae)**\n", "2303.09639": "- 2023-03-16, **Neural Architecture Search for Effective Teacher-Student Knowledge Transfer in Language Models**, Aashka Trivedi et.al., Paper: [http://arxiv.org/abs/2303.09639v1](http://arxiv.org/abs/2303.09639v1)\n", "2303.11296": "- 2023-03-20, **Attribute-preserving Face Dataset Anonymization via Latent Code Optimization**, Simone Barattin et.al., Paper: [http://arxiv.org/abs/2303.11296v1](http://arxiv.org/abs/2303.11296v1), Code: **[https://github.com/chi0tzp/falco](https://github.com/chi0tzp/falco)**\n", "2303.11162": "- 2023-03-20, **Picture that Sketch: Photorealistic Image Generation from Abstract Sketches**, Subhadeep Koley et.al., Paper: [http://arxiv.org/abs/2303.11162v1](http://arxiv.org/abs/2303.11162v1)\n", "2303.11135": "- 2023-03-20, **TWINS: A Fine-Tuning Framework for Improved Transferability of Adversarial Robustness and Generalization**, Ziquan Liu et.al., Paper: [http://arxiv.org/abs/2303.11135v1](http://arxiv.org/abs/2303.11135v1), Code: **[https://github.com/ziquanliu/cvpr2023-twins](https://github.com/ziquanliu/cvpr2023-twins)**\n", "2303.11101": "- 2023-03-20, **Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning**, Sungnyun Kim et.al., Paper: [http://arxiv.org/abs/2303.11101v1](http://arxiv.org/abs/2303.11101v1)\n", "2303.11005": "- 2023-03-20, **Controllable Ancient Chinese Lyrics Generation Based on Phrase Prototype Retrieving**, Li Yi et.al., Paper: [http://arxiv.org/abs/2303.11005v1](http://arxiv.org/abs/2303.11005v1)\n", "2303.10845": "- 2023-03-20, **PanGu-\u03a3: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing**, Xiaozhe Ren et.al., Paper: [http://arxiv.org/abs/2303.10845v1](http://arxiv.org/abs/2303.10845v1)\n", "2303.10800": "- 2023-03-20, **A Global Model Approach to Robust Few-Shot SAR Automatic Target Recognition**, Nathan Inkawhich et.al., Paper: [http://arxiv.org/abs/2303.10800v1](http://arxiv.org/abs/2303.10800v1)\n", "2303.10512": "- 2023-03-18, **Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning**, Qingru Zhang et.al., Paper: [http://arxiv.org/abs/2303.10512v1](http://arxiv.org/abs/2303.10512v1)\n", "2303.10464": "- 2023-03-18, **SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models**, Vithursan Thangarasa et.al., Paper: [http://arxiv.org/abs/2303.10464v1](http://arxiv.org/abs/2303.10464v1)\n", "2303.10431": "- 2023-03-18, **DeAR: Debiasing Vision-Language Models with Additive Residuals**, Ashish Seth et.al., Paper: [http://arxiv.org/abs/2303.10431v1](http://arxiv.org/abs/2303.10431v1)\n", "2303.11837": "- 2023-03-21, **Self-supervised learning of a tailored Convolutional Auto Encoder for histopathological prostate grading**, Zahra Tabatabaei et.al., Paper: [http://arxiv.org/abs/2303.11837v1](http://arxiv.org/abs/2303.11837v1)\n", "2303.11643": "- 2023-03-21, **Manipulating Transfer Learning for Property Inference**, Yulong Tian et.al., Paper: [http://arxiv.org/abs/2303.11643v1](http://arxiv.org/abs/2303.11643v1), Code: **[https://github.com/yulongt23/transfer-inference](https://github.com/yulongt23/transfer-inference)**\n", "2303.11637": "- 2023-03-21, **Equiangular Basis Vectors**, Yang Shen et.al., Paper: [http://arxiv.org/abs/2303.11637v1](http://arxiv.org/abs/2303.11637v1), Code: **[https://github.com/njust-vipgroup/equiangular-basis-vectors](https://github.com/njust-vipgroup/equiangular-basis-vectors)**\n", "2303.11568": "- 2023-03-21, **Large AI Models in Health Informatics: Applications, Challenges, and the Future**, Jianing Qiu et.al., Paper: [http://arxiv.org/abs/2303.11568v1](http://arxiv.org/abs/2303.11568v1)\n", "2303.11339": "- 2023-03-20, **FedMAE: Federated Self-Supervised Learning with One-Block Masked Auto-Encoder**, Nan Yang et.al., Paper: [http://arxiv.org/abs/2303.11339v1](http://arxiv.org/abs/2303.11339v1)\n", "2303.12786": "- 2023-03-22, **FeatureNeRF: Learning Generalizable NeRFs by Distilling Foundation Models**, Jianglong Ye et.al., Paper: [http://arxiv.org/abs/2303.12786v1](http://arxiv.org/abs/2303.12786v1)\n", "2303.12417": "- 2023-03-22, **CLIP^2: Contrastive Language-Image-Point Pretraining from Real-World Point Cloud Data**, Yihan Zeng et.al., Paper: [http://arxiv.org/abs/2303.12417v1](http://arxiv.org/abs/2303.12417v1)\n", "2303.12400": "- 2023-03-22, **UMC: A Unified Bandwidth-efficient and Multi-resolution based Collaborative Perception Framework**, Tianhang Wang et.al., Paper: [http://arxiv.org/abs/2303.12400v1](http://arxiv.org/abs/2303.12400v1)\n", "2303.12381": "- 2023-03-22, **GSQAS: Graph Self-supervised Quantum Architecture Search**, Zhimin He et.al., Paper: [http://arxiv.org/abs/2303.12381v1](http://arxiv.org/abs/2303.12381v1)\n", "2303.12364": "- 2023-03-22, **ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions**, Maurice Rupp et.al., Paper: [http://arxiv.org/abs/2303.12364v1](http://arxiv.org/abs/2303.12364v1), Code: **[https://github.com/ZhiGroup/Med-BERT](https://github.com/ZhiGroup/Med-BERT)**\n", "2303.12314": "- 2023-03-22, **Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization**, Kaihang Pan et.al., Paper: [http://arxiv.org/abs/2303.12314v1](http://arxiv.org/abs/2303.12314v1)\n", "2303.12313": "- 2023-03-22, **Distribution Aligned Diffusion and Prototype-guided network for Unsupervised Domain Adaptive Segmentation**, Haipeng Zhou et.al., Paper: [http://arxiv.org/abs/2303.12313v1](http://arxiv.org/abs/2303.12313v1)\n", "2303.12247": "- 2023-03-22, **Exploring the Benefits of Visual Prompting in Differential Privacy**, Yizhe Li et.al., Paper: [http://arxiv.org/abs/2303.12247v1](http://arxiv.org/abs/2303.12247v1)\n", "2303.12214": "- 2023-03-21, **Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning**, Jingwei Zhang et.al., Paper: [http://arxiv.org/abs/2303.12214v1](http://arxiv.org/abs/2303.12214v1)\n", "2303.12157": "- 2023-03-21, **Learning a Depth Covariance Function**, Eric Dexheimer et.al., Paper: [http://arxiv.org/abs/2303.12157v1](http://arxiv.org/abs/2303.12157v1)\n", "2303.13412": "- 2023-03-23, **Low-Light Image Enhancement by Learning Contrastive Representations in Spatial and Frequency Domains**, Yi Huang et.al., Paper: [http://arxiv.org/abs/2303.13412v1](http://arxiv.org/abs/2303.13412v1)\n", "2303.13283": "- 2023-03-23, **Visual-Language Prompt Tuning with Knowledge-guided Context Optimization**, Hantao Yao et.al., Paper: [http://arxiv.org/abs/2303.13283v1](http://arxiv.org/abs/2303.13283v1), Code: **[https://github.com/htyao89/kgcoop](https://github.com/htyao89/kgcoop)**\n", "2303.13269": "- 2023-03-23, **Disguise without Disruption: Utility-Preserving Face De-Identification**, Zikui Cai et.al., Paper: [http://arxiv.org/abs/2303.13269v1](http://arxiv.org/abs/2303.13269v1)\n", "2303.13220": "- 2023-03-23, **Parameter-Efficient Sparse Retrievers and Rerankers using Adapters**, Vaishali Pal et.al., Paper: [http://arxiv.org/abs/2303.13220v1](http://arxiv.org/abs/2303.13220v1), Code: **[https://github.com/naver/splade](https://github.com/naver/splade)**\n", "2303.13217": "- 2023-03-25, **Fairness-guided Few-shot Prompting for Large Language Models**, Huan Ma et.al., Paper: [http://arxiv.org/abs/2303.13217v2](http://arxiv.org/abs/2303.13217v2), Code: **[https://github.com/mahuanaaa/g_fair_prompting](https://github.com/mahuanaaa/g_fair_prompting)**\n", "2303.13100": "- 2023-03-23, **PointGame: Geometrically and Adaptively Masked Auto-Encoder on Point Clouds**, Yun Liu et.al., Paper: [http://arxiv.org/abs/2303.13100v1](http://arxiv.org/abs/2303.13100v1)\n", "2303.13009": "- 2023-03-23, **MELTR: Meta Loss Transformer for Learning to Fine-tune Video Foundation Models**, Dohwan Ko et.al., Paper: [http://arxiv.org/abs/2303.13009v1](http://arxiv.org/abs/2303.13009v1), Code: **[https://github.com/mlvlab/MELTR](https://github.com/mlvlab/MELTR)**\n", "2303.14191": "- 2023-03-24, **Masked Scene Contrast: A Scalable Framework for Unsupervised 3D Representation Learning**, Xiaoyang Wu et.al., Paper: [http://arxiv.org/abs/2303.14191v1](http://arxiv.org/abs/2303.14191v1), Code: **[https://github.com/Pointcept/Pointcept](https://github.com/Pointcept/Pointcept)**\n", "2303.13913": "- 2023-03-24, **GarmentTracking: Category-Level Garment Pose Tracking**, Han Xue et.al., Paper: [http://arxiv.org/abs/2303.13913v1](http://arxiv.org/abs/2303.13913v1)\n", "2303.13818": "- 2023-03-27, **Prior-RadGraphFormer: A Prior-Knowledge-Enhanced Transformer for Generating Radiology Graphs from X-Rays**, Yiheng Xiong et.al., Paper: [http://arxiv.org/abs/2303.13818v2](http://arxiv.org/abs/2303.13818v2)\n", "2303.13739": "- 2023-03-24, **MoWE: Mixture of Weather Experts for Multiple Adverse Weather Removal**, Yulin Luo et.al., Paper: [http://arxiv.org/abs/2303.13739v1](http://arxiv.org/abs/2303.13739v1)\n", "2303.13606": "- 2023-03-23, **Adaptive Similarity Bootstrapping for Self-Distillation**, Tim Lebailly et.al., Paper: [http://arxiv.org/abs/2303.13606v1](http://arxiv.org/abs/2303.13606v1)\n", "2303.15422": "- 2023-03-27, **KPEval: Towards Fine-grained Semantic-based Evaluation of Keyphrase Extraction and Generation Systems**, Di Wu et.al., Paper: [http://arxiv.org/abs/2303.15422v1](http://arxiv.org/abs/2303.15422v1)\n", "2303.15233": "- 2023-03-27, **Text-to-Image Diffusion Models are Zero-Shot Classifiers**, Kevin Clark et.al., Paper: [http://arxiv.org/abs/2303.15233v1](http://arxiv.org/abs/2303.15233v1)\n", "2303.15104": "- 2023-03-27, **Generalizable Local Feature Pre-training for Deformable Shape Analysis**, Souhaib Attaiki et.al., Paper: [http://arxiv.org/abs/2303.15104v1](http://arxiv.org/abs/2303.15104v1), Code: **[https://github.com/pvnieo/vader](https://github.com/pvnieo/vader)**\n", "2303.14865": "- 2023-03-27, **Revisiting Multimodal Representation in Contrastive Learning: From Patch and Token Embeddings to Finite Discrete Tokens**, Yuxiao Chen et.al., Paper: [http://arxiv.org/abs/2303.14865v1](http://arxiv.org/abs/2303.14865v1)\n", "2303.14777": "- 2023-03-26, **Query Generation based on Generative Adversarial Networks**, Weihua Sun et.al., Paper: [http://arxiv.org/abs/2303.14777v1](http://arxiv.org/abs/2303.14777v1)\n", "2303.14773": "- 2023-03-26, **BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning**, Changdae Oh et.al., Paper: [http://arxiv.org/abs/2303.14773v1](http://arxiv.org/abs/2303.14773v1), Code: **[https://github.com/changdaeoh/blackvip](https://github.com/changdaeoh/blackvip)**\n", "2303.14576": "- 2023-03-25, **Automatic Generation of Multiple-Choice Questions**, Cheng Zhang et.al., Paper: [http://arxiv.org/abs/2303.14576v1](http://arxiv.org/abs/2303.14576v1)\n", "2303.14480": "- 2023-03-25, **GANTEE: Generative Adversatial Network for Taxonomy Entering Evaluation**, Zhouhong Gu et.al., Paper: [http://arxiv.org/abs/2303.14480v1](http://arxiv.org/abs/2303.14480v1)\n", "2303.14465": "- 2023-03-25, **Equivariant Similarity for Vision-Language Foundation Models**, Tan Wang et.al., Paper: [http://arxiv.org/abs/2303.14465v1](http://arxiv.org/abs/2303.14465v1), Code: **[https://github.com/wangt-cn/eqben](https://github.com/wangt-cn/eqben)**\n", "2303.14425": "- 2023-03-25, **Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining**, Zhouhong Gu et.al., Paper: [http://arxiv.org/abs/2303.14425v1](http://arxiv.org/abs/2303.14425v1)\n", "2303.16198": "- 2023-03-28, **Forecasting localized weather impacts on vegetation as seen from space with meteo-guided video prediction**, Vitus Benson et.al., Paper: [http://arxiv.org/abs/2303.16198v1](http://arxiv.org/abs/2303.16198v1), Code: **[https://github.com/earthnet2021/earthnet-models-pytorch](https://github.com/earthnet2021/earthnet-models-pytorch)**\n", "2303.16133": "- 2023-03-28, **Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models**, Adyasha Maharana et.al., Paper: [http://arxiv.org/abs/2303.16133v1](http://arxiv.org/abs/2303.16133v1), Code: **[https://github.com/adymaharana/cococon](https://github.com/adymaharana/cococon)**\n", "2303.16039": "- 2023-03-28, **Exploring Natural Language Processing Methods for Interactive Behaviour Modelling**, Guanhua Zhang et.al., Paper: [http://arxiv.org/abs/2303.16039v1](http://arxiv.org/abs/2303.16039v1)\n", "2303.15747": "- 2023-03-28, **TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns**, Soma Onishi et.al., Paper: [http://arxiv.org/abs/2303.15747v1](http://arxiv.org/abs/2303.15747v1)\n", "2303.15702": "- 2023-03-28, **Distributed Graph Embedding with Information-Oriented Random Walks**, Peng Fang et.al., Paper: [http://arxiv.org/abs/2303.15702v1](http://arxiv.org/abs/2303.15702v1), Code: **[https://github.com/rocmfang/distger](https://github.com/rocmfang/distger)**\n", "2303.15619": "- 2023-03-27, **Typhoon: Towards an Effective Task-Specific Masking Strategy for Pre-trained Language Models**, Muhammed Shahir Abdurrahman et.al., Paper: [http://arxiv.org/abs/2303.15619v1](http://arxiv.org/abs/2303.15619v1)\n", "2303.16839": "- 2023-03-30, **MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks**, Weicheng Kuo et.al., Paper: [http://arxiv.org/abs/2303.16839v2](http://arxiv.org/abs/2303.16839v2)\n", "2303.16727": "- 2023-03-29, **VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking**, Limin Wang et.al., Paper: [http://arxiv.org/abs/2303.16727v1](http://arxiv.org/abs/2303.16727v1)\n", "2303.16666": "- 2023-03-29, **SC-VAE: Sparse Coding-based Variational Autoencoder**, Pan Xiao et.al., Paper: [http://arxiv.org/abs/2303.16666v1](http://arxiv.org/abs/2303.16666v1)\n", "2303.16611": "- 2023-03-29, **4D Facial Expression Diffusion Model**, Kaifeng Zou et.al., Paper: [http://arxiv.org/abs/2303.16611v1](http://arxiv.org/abs/2303.16611v1), Code: **[https://github.com/zoukaifeng/4dfm](https://github.com/zoukaifeng/4dfm)**\n", "2303.16570": "- 2023-03-29, **Point2Vec for Self-Supervised Representation Learning on Point Clouds**, Karim Abou Zeid et.al., Paper: [http://arxiv.org/abs/2303.16570v1](http://arxiv.org/abs/2303.16570v1)\n", "2303.16500": "- 2023-03-29, **AirLine: Efficient Learnable Line Detection with Local Edge Voting**, Xiao Lin et.al., Paper: [http://arxiv.org/abs/2303.16500v1](http://arxiv.org/abs/2303.16500v1), Code: **[https://github.com/sair-lab/airline](https://github.com/sair-lab/airline)**\n", "2303.16458": "- 2023-03-29, **When to Pre-Train Graph Neural Networks? An Answer from Data Generation Perspective!**, Yuxuan Cao et.al., Paper: [http://arxiv.org/abs/2303.16458v1](http://arxiv.org/abs/2303.16458v1)\n", "2303.16341": "- 2023-03-28, **Spatiotemporally Discriminative Video-Language Pre-Training with Text Grounding**, Yuanhao Xiong et.al., Paper: [http://arxiv.org/abs/2303.16341v1](http://arxiv.org/abs/2303.16341v1)\n", "2303.16203": "- 2023-03-29, **Your Diffusion Model is Secretly a Zero-Shot Classifier**, Alexander C. Li et.al., Paper: [http://arxiv.org/abs/2303.16203v2](http://arxiv.org/abs/2303.16203v2), Code: **[https://github.com/diffusion-classifier/diffusion-classifier](https://github.com/diffusion-classifier/diffusion-classifier)**\n", "2303.17602": "- 2023-03-30, **Beyond Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks**, Weihua Chen et.al., Paper: [http://arxiv.org/abs/2303.17602v1](http://arxiv.org/abs/2303.17602v1), Code: **[https://github.com/tinyvision/SOLIDER](https://github.com/tinyvision/SOLIDER)**\n", "2303.17561": "- 2023-03-30, **SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger**, Yuting Gao et.al., Paper: [http://arxiv.org/abs/2303.17561v1](http://arxiv.org/abs/2303.17561v1)\n", "2303.17169": "- 2023-03-30, **Task-Oriented Multi-Modal Mutual Leaning for Vision-Language Models**, Sifan Long et.al., Paper: [http://arxiv.org/abs/2303.17169v1](http://arxiv.org/abs/2303.17169v1)\n", "2303.17152": "- 2023-03-30, **Mixed Autoencoder for Self-supervised Visual Representation Learning**, Kai Chen et.al., Paper: [http://arxiv.org/abs/2303.17152v1](http://arxiv.org/abs/2303.17152v1)\n", "2303.17051": "- 2023-03-29, **Transductive few-shot adapters for medical image segmentation**, Julio Silva-Rodr\u00edguez et.al., Paper: [http://arxiv.org/abs/2303.17051v1](http://arxiv.org/abs/2303.17051v1), Code: **[https://github.com/jusiro/fewshot-finetuning](https://github.com/jusiro/fewshot-finetuning)**\n", "2303.16990": "- 2023-03-29, **What, when, and where? -- Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions**, Brian Chen et.al., Paper: [http://arxiv.org/abs/2303.16990v1](http://arxiv.org/abs/2303.16990v1)\n", "2303.18232": "- 2023-03-31, **DIME-FM: DIstilling Multimodal and Efficient Foundation Models**, Ximeng Sun et.al., Paper: [http://arxiv.org/abs/2303.18232v1](http://arxiv.org/abs/2303.18232v1)\n", "2303.18219": "- 2023-03-31, **SemHint-MD: Learning from Noisy Semantic Labels for Self-Supervised Monocular Depth Estimation**, Shan Lin et.al., Paper: [http://arxiv.org/abs/2303.18219v1](http://arxiv.org/abs/2303.18219v1)\n", "2303.18181": "- 2023-03-31, **A Closer Look at Parameter-Efficient Tuning in Diffusion Models**, Chendong Xiang et.al., Paper: [http://arxiv.org/abs/2303.18181v1](http://arxiv.org/abs/2303.18181v1)\n", "2303.18101": "- 2023-03-31, **INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields**, Julia Hindel et.al., Paper: [http://arxiv.org/abs/2303.18101v1](http://arxiv.org/abs/2303.18101v1)\n", "2303.18013": "- 2023-03-31, **LaCViT: A Label-aware Contrastive Training Framework for Vision Transformers**, Zijun Long et.al., Paper: [http://arxiv.org/abs/2303.18013v1](http://arxiv.org/abs/2303.18013v1)\n", "2303.17743": "- 2023-03-30, **FairGen: Towards Fair Graph Generation**, Lecheng Zheng et.al., Paper: [http://arxiv.org/abs/2303.17743v1](http://arxiv.org/abs/2303.17743v1)\n", "2303.17644": "- 2023-03-30, **Vision-Language Modelling For Radiological Imaging and Reports In The Low Data Regime**, Rhydian Windsor et.al., Paper: [http://arxiv.org/abs/2303.17644v1](http://arxiv.org/abs/2303.17644v1)\n", "2303.17636": "- 2023-03-30, **Whether and When does Endoscopy Domain Pretraining Make Sense?**, Dominik Bati\u0107 et.al., Paper: [http://arxiv.org/abs/2303.17636v1](http://arxiv.org/abs/2303.17636v1)\n", "2304.01195": "- 2023-04-03, **Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Refinement**, Xiangyang Zhu et.al., Paper: [http://arxiv.org/abs/2304.01195v1](http://arxiv.org/abs/2304.01195v1), Code: **[https://github.com/yangyangyang127/ape](https://github.com/yangyangyang127/ape)**\n", "2304.00719": "- 2023-04-03, **Multi-Modal Representation Learning with Text-Driven Soft Masks**, Jaeyoo Park et.al., Paper: [http://arxiv.org/abs/2304.00719v1](http://arxiv.org/abs/2304.00719v1)\n", "2304.00717": "- 2023-04-03, **MiniRBT: A Two-stage Distilled Small Chinese Pre-trained Model**, Xin Yao et.al., Paper: [http://arxiv.org/abs/2304.00717v1](http://arxiv.org/abs/2304.00717v1)\n", "2304.00685": "- 2023-04-03, **Vision-Language Models for Vision Tasks: A Survey**, Jingyi Zhang et.al., Paper: [http://arxiv.org/abs/2304.00685v1](http://arxiv.org/abs/2304.00685v1)\n", "2304.00634": "- 2023-04-02, **MMT: A Multilingual and Multi-Topic Indian Social Media Dataset**, Dwip Dalal et.al., Paper: [http://arxiv.org/abs/2304.00634v1](http://arxiv.org/abs/2304.00634v1)\n", "2304.00590": "- 2023-04-02, **Learning Similarity between Scene Graphs and Images with Transformers**, Yuren Cong et.al., Paper: [http://arxiv.org/abs/2304.00590v1](http://arxiv.org/abs/2304.00590v1)\n", "2304.00571": "- 2023-04-02, **DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks**, Qiangqiang Wu et.al., Paper: [http://arxiv.org/abs/2304.00571v1](http://arxiv.org/abs/2304.00571v1), Code: **[https://github.com/jimmy-dq/dropmae](https://github.com/jimmy-dq/dropmae)**\n", "2304.00570": "- 2023-04-02, **FedFTN: Personalized Federated Learning with Deep Feature Transformation Network for Multi-institutional Low-count PET Denoising**, Bo Zhou et.al., Paper: [http://arxiv.org/abs/2304.00570v1](http://arxiv.org/abs/2304.00570v1), Code: **[https://github.com/bbbbbbzhou/fedftn](https://github.com/bbbbbbzhou/fedftn)**\n", "2304.00395": "- 2023-04-01, **Towards Understanding the Mechanism of Contrastive Learning via Similarity Structure: A Theoretical Analysis**, Hiroki Waida et.al., Paper: [http://arxiv.org/abs/2304.00395v1](http://arxiv.org/abs/2304.00395v1)\n", "2304.00325": "- 2023-04-01, **SVT: Supertoken Video Transformer for Efficient Video Understanding**, Chenbin Pan et.al., Paper: [http://arxiv.org/abs/2304.00325v1](http://arxiv.org/abs/2304.00325v1)\n", "2304.02010": "- 2023-04-04, **Multi-Level Contrastive Learning for Dense Prediction Task**, Qiushan Guo et.al., Paper: [http://arxiv.org/abs/2304.02010v1](http://arxiv.org/abs/2304.02010v1), Code: **[https://github.com/guoqiushan/mcl](https://github.com/guoqiushan/mcl)**\n", "2304.01933": "- 2023-04-04, **LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models**, Zhiqiang Hu et.al., Paper: [http://arxiv.org/abs/2304.01933v1](http://arxiv.org/abs/2304.01933v1), Code: **[https://github.com/agi-edgerunners/llm-adapters](https://github.com/agi-edgerunners/llm-adapters)**\n", "2304.01612": "- 2023-04-04, **EDeR: A Dataset for Exploring Dependency Relations Between Events**, Ruiqi Li et.al., Paper: [http://arxiv.org/abs/2304.01612v1](http://arxiv.org/abs/2304.01612v1), Code: **[https://github.com/richielee93/eder](https://github.com/richielee93/eder)**\n", "2304.01559": "- 2023-04-04, **G2PTL: A Pre-trained Model for Delivery Address and its Applications in Logistics System**, Lixia Wu et.al., Paper: [http://arxiv.org/abs/2304.01559v1](http://arxiv.org/abs/2304.01559v1)\n", "2304.01507": "- 2023-04-06, **RARE: Robust Masked Graph Autoencoder**, Wenxuan Tu et.al., Paper: [http://arxiv.org/abs/2304.01507v2](http://arxiv.org/abs/2304.01507v2)\n", "2304.01506": "- 2023-04-04, **OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting**, Xiao He et.al., Paper: [http://arxiv.org/abs/2304.01506v1](http://arxiv.org/abs/2304.01506v1), Code: **[https://github.com/xiao-he/oneshotstl](https://github.com/xiao-he/oneshotstl)**\n", "2304.01489": "- 2023-04-04, **Improved Visual Fine-tuning with Natural Language Supervision**, Junyang Wang et.al., Paper: [http://arxiv.org/abs/2304.01489v1](http://arxiv.org/abs/2304.01489v1)\n", "2304.01391": "- 2023-04-03, **Counterfactual Learning on Graphs: A Survey**, Zhimeng Guo et.al., Paper: [http://arxiv.org/abs/2304.01391v1](http://arxiv.org/abs/2304.01391v1), Code: **[https://github.com/timelovercc/awesome-graph-causal-learning](https://github.com/timelovercc/awesome-graph-causal-learning)**\n", "2304.01290": "- 2023-04-03, **A Simple Approach for General Task-Oriented Picking using Placing constraints**, Jen-Wei Wang et.al., Paper: [http://arxiv.org/abs/2304.01290v1](http://arxiv.org/abs/2304.01290v1)\n", "2304.02633": "- 2023-04-05, **HNeRV: A Hybrid Neural Representation for Videos**, Hao Chen et.al., Paper: [http://arxiv.org/abs/2304.02633v1](http://arxiv.org/abs/2304.02633v1), Code: **[https://github.com/haochen-rye/hnerv](https://github.com/haochen-rye/hnerv)**\n", "2304.02549": "- 2023-04-05, **Self-Supervised Siamese Autoencoders**, Friederike Baier et.al., Paper: [http://arxiv.org/abs/2304.02549v1](http://arxiv.org/abs/2304.02549v1)\n", "2304.02263": "- 2023-04-05, **Towards Efficient Task-Driven Model Reprogramming with Foundation Models**, Shoukai Xu et.al., Paper: [http://arxiv.org/abs/2304.02263v1](http://arxiv.org/abs/2304.02263v1)\n", "2304.02255": "- 2023-04-05, **Topology-Guided Multi-Class Cell Context Generation for Digital Pathology**, Shahira Abousamra et.al., Paper: [http://arxiv.org/abs/2304.02255v1](http://arxiv.org/abs/2304.02255v1)\n", "2304.03156": "- 2023-04-06, **Patch-wise Features for Blur Image Classification**, Sri Charan Kattamuru et.al., Paper: [http://arxiv.org/abs/2304.03156v1](http://arxiv.org/abs/2304.03156v1)\n", "2304.02932": "- 2023-04-06, **Quantifying and Defending against Privacy Threats on Federated Knowledge Graph Embedding**, Yuke Hu et.al., Paper: [http://arxiv.org/abs/2304.02932v1](http://arxiv.org/abs/2304.02932v1)\n", "2304.02853": "- 2023-04-06, **Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce**, Yang Jin et.al., Paper: [http://arxiv.org/abs/2304.02853v1](http://arxiv.org/abs/2304.02853v1)\n", "2304.02724": "- 2023-04-05, **Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound**, Blake VanBerlo et.al., Paper: [http://arxiv.org/abs/2304.02724v1](http://arxiv.org/abs/2304.02724v1)\n", "2304.03767": "- 2023-04-07, **Embodied Concept Learner: Self-supervised Learning of Concepts and Mapping through Instruction Following**, Mingyu Ding et.al., Paper: [http://arxiv.org/abs/2304.03767v1](http://arxiv.org/abs/2304.03767v1)\n", "2304.03659": "- 2023-04-07, **Probing Conceptual Understanding of Large Visual-Language Models**, Madeline Chantry Schiappa et.al., Paper: [http://arxiv.org/abs/2304.03659v1](http://arxiv.org/abs/2304.03659v1)\n", "2304.03650": "- 2023-04-07, **A Cross-Scale Hierarchical Transformer with Correspondence-Augmented Attention for inferring Bird's-Eye-View Semantic Segmentation**, Naiyu Fang et.al., Paper: [http://arxiv.org/abs/2304.03650v1](http://arxiv.org/abs/2304.03650v1)\n", "2304.03609": "- 2023-04-07, **Revisiting Automated Prompting: Are We Actually Doing Better?**, Yulin Zhou et.al., Paper: [http://arxiv.org/abs/2304.03609v1](http://arxiv.org/abs/2304.03609v1)\n", "2304.03526": "- 2023-04-07, **Lift3D: Synthesize 3D Training Data by Lifting 2D GAN to 3D Generative Radiance Field**, Leheng Li et.al., Paper: [http://arxiv.org/abs/2304.03526v1](http://arxiv.org/abs/2304.03526v1)\n", "2304.04512": "- 2023-04-10, **Defense-Prefix for Preventing Typographic Attacks on CLIP**, Hiroki Azuma et.al., Paper: [http://arxiv.org/abs/2304.04512v1](http://arxiv.org/abs/2304.04512v1)\n", "2304.04468": "- 2023-04-12, **Toward Cohort Intelligence: A Universal Cohort Representation Learning Framework for Electronic Health Record Analysis**, Changshuo Liu et.al., Paper: [http://arxiv.org/abs/2304.04468v3](http://arxiv.org/abs/2304.04468v3)\n", "2304.04399": "- 2023-04-10, **CAVL: Learning Contrastive and Adaptive Representations of Vision and Language**, Shentong Mo et.al., Paper: [http://arxiv.org/abs/2304.04399v1](http://arxiv.org/abs/2304.04399v1)\n", "2304.04391": "- 2023-04-10, **CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs**, Arvindh Arun et.al., Paper: [http://arxiv.org/abs/2304.04391v1](http://arxiv.org/abs/2304.04391v1)\n", "2304.04364": "- 2023-04-10, **ITportrait: Image-Text Coupled 3D Portrait Domain Adaptation**, Xiangwen Deng et.al., Paper: [http://arxiv.org/abs/2304.04364v1](http://arxiv.org/abs/2304.04364v1)\n", "2304.04330": "- 2023-04-09, **Pretrained Embeddings for E-commerce Machine Learning: When it Fails and Why?**, Da Xu et.al., Paper: [http://arxiv.org/abs/2304.04330v1](http://arxiv.org/abs/2304.04330v1)\n", "2304.04275": "- 2023-04-09, **Filling out the missing gaps: Time Series Imputation with Semi-Supervised Learning**, Karan Aggarwal et.al., Paper: [http://arxiv.org/abs/2304.04275v1](http://arxiv.org/abs/2304.04275v1)\n", "2304.04231": "- 2023-04-09, **CrowdCLIP: Unsupervised Crowd Counting via Vision-Language Model**, Dingkang Liang et.al., Paper: [http://arxiv.org/abs/2304.04231v1](http://arxiv.org/abs/2304.04231v1), Code: **[https://github.com/dk-liang/crowdclip](https://github.com/dk-liang/crowdclip)**\n", "2304.04193": "- 2023-04-09, **Extractive Summarization via ChatGPT for Faithful Summary Generation**, Haopeng Zhang et.al., Paper: [http://arxiv.org/abs/2304.04193v1](http://arxiv.org/abs/2304.04193v1)\n", "2304.04175": "- 2023-04-09, **Token Boosting for Robust Self-Supervised Visual Transformer Pre-training**, Tianjiao Li et.al., Paper: [http://arxiv.org/abs/2304.04175v1](http://arxiv.org/abs/2304.04175v1)\n", "2304.05369": "- 2023-04-11, **A surprisingly simple technique to control the pretraining bias for better transfer: Expand or Narrow your representation**, Florian Bordes et.al., Paper: [http://arxiv.org/abs/2304.05369v1](http://arxiv.org/abs/2304.05369v1)\n", "2304.05216": "- 2023-04-11, **Towards Efficient Fine-tuning of Pre-trained Code Models: An Experimental Study and Beyond**, Ensheng Shi et.al., Paper: [http://arxiv.org/abs/2304.05216v1](http://arxiv.org/abs/2304.05216v1), Code: **[https://github.com/deepsoftwareanalytics/telly](https://github.com/deepsoftwareanalytics/telly)**\n", "2304.05215": "- 2023-04-11, **A Billion-scale Foundation Model for Remote Sensing Images**, Keumgang Cha et.al., Paper: [http://arxiv.org/abs/2304.05215v1](http://arxiv.org/abs/2304.05215v1)\n", "2304.05055": "- 2023-04-11, **A Comprehensive Survey on Deep Graph Representation Learning**, Wei Ju et.al., Paper: [http://arxiv.org/abs/2304.05055v1](http://arxiv.org/abs/2304.05055v1)\n", "2304.05051": "- 2023-04-11, **FashionSAP: Symbols and Attributes Prompt for Fine-grained Fashion Vision-Language Pre-training**, Yunpeng Han et.al., Paper: [http://arxiv.org/abs/2304.05051v1](http://arxiv.org/abs/2304.05051v1), Code: **[https://github.com/hssip/fashionsap](https://github.com/hssip/fashionsap)**\n", "2304.05040": "- 2023-04-11, **Unsupervised out-of-distribution detection for safer robotically-guided retinal microsurgery**, Alain Jungo et.al., Paper: [http://arxiv.org/abs/2304.05040v1](http://arxiv.org/abs/2304.05040v1)\n", "2304.04782": "- 2023-04-10, **Reinforcement Learning from Passive Data via Latent Intentions**, Dibya Ghosh et.al., Paper: [http://arxiv.org/abs/2304.04782v1](http://arxiv.org/abs/2304.04782v1), Code: **[https://github.com/dibyaghosh/icvf_release](https://github.com/dibyaghosh/icvf_release)**\n", "2304.05974": "- 2023-04-12, **Regularizing Contrastive Predictive Coding for Speech Applications**, Saurabhchand Bhati et.al., Paper: [http://arxiv.org/abs/2304.05974v1](http://arxiv.org/abs/2304.05974v1)\n", "2304.05783": "- 2023-04-13, **Measuring Gender Bias in West Slavic Language Models**, Sandra Martinkov\u00e1 et.al., Paper: [http://arxiv.org/abs/2304.05783v2](http://arxiv.org/abs/2304.05783v2)\n", "2304.05716": "- 2023-04-12, **Impact of Pseudo Depth on Open World Object Segmentation with Minimal User Guidance**, Robin Sch\u00f6n et.al., Paper: [http://arxiv.org/abs/2304.05716v1](http://arxiv.org/abs/2304.05716v1)\n", "2304.05653": "- 2023-04-12, **CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks**, Yi Li et.al., Paper: [http://arxiv.org/abs/2304.05653v1](http://arxiv.org/abs/2304.05653v1), Code: **[https://github.com/xmed-lab/clip_surgery](https://github.com/xmed-lab/clip_surgery)**\n", "2304.05642": "- 2023-04-12, **Global Prompt Cell: A Portable Control Module for Effective Prompt**, Chi Liu et.al., Paper: [http://arxiv.org/abs/2304.05642v1](http://arxiv.org/abs/2304.05642v1)\n", "2304.05620": "- 2023-04-12, **NutritionVerse-Thin: An Optimized Strategy for Enabling Improved Rendering of 3D Thin Food Models**, Chi-en Amy Tai et.al., Paper: [http://arxiv.org/abs/2304.05620v1](http://arxiv.org/abs/2304.05620v1)\n", "2304.05554": "- 2023-04-12, **Learning Transferable Pedestrian Representation from Multimodal Information Supervision**, Liping Bao et.al., Paper: [http://arxiv.org/abs/2304.05554v1](http://arxiv.org/abs/2304.05554v1)\n", "2304.05511": "- 2023-04-11, **Training Large Language Models Efficiently with Sparsity and Dataflow**, Venkat Srinivasan et.al., Paper: [http://arxiv.org/abs/2304.05511v1](http://arxiv.org/abs/2304.05511v1)\n", "2304.06708": "- 2023-04-13, **Verbs in Action: Improving verb understanding in video-language models**, Liliane Momeni et.al., Paper: [http://arxiv.org/abs/2304.06708v1](http://arxiv.org/abs/2304.06708v1)\n", "2304.06446": "- 2023-04-14, **SpectFormer: Frequency and Attention is what you need in a Vision Transformer**, Badri N. Patro et.al., Paper: [http://arxiv.org/abs/2304.06446v2](http://arxiv.org/abs/2304.06446v2)\n", "2304.06306": "- 2023-04-13, **Efficient Multimodal Fusion via Interactive Prompting**, Yaowei Li et.al., Paper: [http://arxiv.org/abs/2304.06306v1](http://arxiv.org/abs/2304.06306v1)\n", "2304.06061": "- 2023-04-12, **CLIP-Guided Vision-Language Pre-training for Question Answering in 3D Scenes**, Maria Parelli et.al., Paper: [http://arxiv.org/abs/2304.06061v1](http://arxiv.org/abs/2304.06061v1), Code: **[https://github.com/alexdelitzas/3d-vqa](https://github.com/alexdelitzas/3d-vqa)**\n", "2304.07258": "- 2023-04-14, **Learn What Is Possible, Then Choose What Is Best: Disentangling One-To-Many Relations in Language Through Text-based Games**, Benjamin Towle et.al., Paper: [http://arxiv.org/abs/2304.07258v1](http://arxiv.org/abs/2304.07258v1), Code: **[https://github.com/benjamintowle/pasa](https://github.com/benjamintowle/pasa)**\n", "2304.07221": "- 2023-04-14, **Instance-aware Dynamic Prompt Tuning for Pre-trained Point Cloud Models**, Yaohua Zha et.al., Paper: [http://arxiv.org/abs/2304.07221v1](http://arxiv.org/abs/2304.07221v1), Code: **[https://github.com/zyh16143998882/IDPT](https://github.com/zyh16143998882/IDPT)**\n", "2304.07099": "- 2023-04-14, **Prior based Sampling for Adaptive LiDAR**, Amit Shomer et.al., Paper: [http://arxiv.org/abs/2304.07099v1](http://arxiv.org/abs/2304.07099v1)\n", "2304.06906": "- 2023-04-14, **Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding**, Yu-Qi Yang et.al., Paper: [http://arxiv.org/abs/2304.06906v1](http://arxiv.org/abs/2304.06906v1)\n", "2304.06857": "- 2023-04-17, **A Contrastive Method Based on Elevation Data for Remote Sensing with Scarce and High Level Semantic Labels**, Omar A. Casta\u00f1o-Idarraga et.al., Paper: [http://arxiv.org/abs/2304.06857v2](http://arxiv.org/abs/2304.06857v2)\n", "2304.06798": "- 2023-04-13, **On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence**, Gengchen Mai et.al., Paper: [http://arxiv.org/abs/2304.06798v1](http://arxiv.org/abs/2304.06798v1)\n", "2304.06762": "- 2023-04-13, **Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study**, Boxin Wang et.al., Paper: [http://arxiv.org/abs/2304.06762v1](http://arxiv.org/abs/2304.06762v1), Code: **[https://github.com/NVIDIA/Megatron-LM](https://github.com/NVIDIA/Megatron-LM)**\n", "2304.08442": "- 2023-04-17, **The MiniPile Challenge for Data-Efficient Language Models**, Jean Kaddour et.al., Paper: [http://arxiv.org/abs/2304.08442v1](http://arxiv.org/abs/2304.08442v1)\n", "2304.08386": "- 2023-04-17, **Progressive Visual Prompt Learning with Contrastive Feature Re-formation**, Chen Xu et.al., Paper: [http://arxiv.org/abs/2304.08386v1](http://arxiv.org/abs/2304.08386v1)\n", "2304.08345": "- 2023-04-17, **VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset**, Sihan Chen et.al., Paper: [http://arxiv.org/abs/2304.08345v1](http://arxiv.org/abs/2304.08345v1), Code: **[https://github.com/TXH-mercury/VALOR](https://github.com/TXH-mercury/VALOR)**\n", "2304.08285": "- 2023-04-17, **DIALITE: Discover, Align and Integrate Open Data Tables**, Aamod Khatiwada et.al., Paper: [http://arxiv.org/abs/2304.08285v1](http://arxiv.org/abs/2304.08285v1)\n", "2304.08204": "- 2023-04-17, **Learning Geometry-aware Representations by Sketching**, Hyundo Lee et.al., Paper: [http://arxiv.org/abs/2304.08204v1](http://arxiv.org/abs/2304.08204v1)\n", "2304.07919": "- 2023-04-16, **Chain of Thought Prompt Tuning in Vision Language Models**, Jiaxin Ge et.al., Paper: [http://arxiv.org/abs/2304.07919v1](http://arxiv.org/abs/2304.07919v1)\n", "2304.07862": "- 2023-04-16, **PBNR: Prompt-based News Recommender System**, Xinyi Li et.al., Paper: [http://arxiv.org/abs/2304.07862v1](http://arxiv.org/abs/2304.07862v1)\n", "2304.07829": "- 2023-04-16, **Automated Self-Admitted Technical Debt Tracking at Commit-Level: A Language-independent Approach**, Mohammad Sadegh Sheikhaei et.al., Paper: [http://arxiv.org/abs/2304.07829v1](http://arxiv.org/abs/2304.07829v1)\n", "2304.07718": "- 2023-04-16, **Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value**, Yongchan Kwon et.al., Paper: [http://arxiv.org/abs/2304.07718v1](http://arxiv.org/abs/2304.07718v1)\n", "2304.07686": "- 2023-04-16, **Autoencoders with Intrinsic Dimension Constraints for Learning Low Dimensional Image Representations**, Jianzhang Zheng et.al., Paper: [http://arxiv.org/abs/2304.07686v1](http://arxiv.org/abs/2304.07686v1)\n", "2304.09148": "- 2023-04-19, **SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More**, Tianrun Chen et.al., Paper: [http://arxiv.org/abs/2304.09148v2](http://arxiv.org/abs/2304.09148v2)\n", "2304.09121": "- 2023-04-18, **Fast Neural Scene Flow**, Xueqian Li et.al., Paper: [http://arxiv.org/abs/2304.09121v1](http://arxiv.org/abs/2304.09121v1)\n", "2304.09068": "- 2023-04-18, **METAM: Goal-Oriented Data Discovery**, Sainyam Galhotra et.al., Paper: [http://arxiv.org/abs/2304.09068v1](http://arxiv.org/abs/2304.09068v1)\n", "2304.09010": "- 2023-04-19, **CF-VAE: Causal Disentangled Representation Learning with VAE and Causal Flows**, Di Fan et.al., Paper: [http://arxiv.org/abs/2304.09010v2](http://arxiv.org/abs/2304.09010v2)\n", "2304.09670": "- 2023-04-19, **CMID: A Unified Self-Supervised Learning Framework for Remote Sensing Image Understanding**, Dilxat Muhtar et.al., Paper: [http://arxiv.org/abs/2304.09670v1](http://arxiv.org/abs/2304.09670v1), Code: **[https://github.com/NJU-LHRS/official-CMID](https://github.com/NJU-LHRS/official-CMID)**\n", "2304.09649": "- 2023-04-19, **BRENT: Bidirectional Retrieval Enhanced Norwegian Transformer**, Lucas Georges Gabriel Charpentier et.al., Paper: [http://arxiv.org/abs/2304.09649v1](http://arxiv.org/abs/2304.09649v1)\n", "2304.09595": "- 2023-04-19, **AdapterGNN: Efficient Delta Tuning Improves Generalization Ability in Graph Neural Networks**, Shengrui Li et.al., Paper: [http://arxiv.org/abs/2304.09595v1](http://arxiv.org/abs/2304.09595v1)\n", "2304.09582": "- 2023-04-19, **Is ChatGPT Equipped with Emotional Dialogue Capabilities?**, Weixiang Zhao et.al., Paper: [http://arxiv.org/abs/2304.09582v1](http://arxiv.org/abs/2304.09582v1)\n", "2304.09560": "- 2023-04-19, **An Offline Metric for the Debiasedness of Click Models**, Romain Deffayet et.al., Paper: [http://arxiv.org/abs/2304.09560v1](http://arxiv.org/abs/2304.09560v1), Code: **[https://github.com/philipphager/cmip](https://github.com/philipphager/cmip)**\n", "2304.09552": "- 2023-04-19, **Denoising Cosine Similarity: A Theory-Driven Approach for Efficient Representation Learning**, Takumi Nakagawa et.al., Paper: [http://arxiv.org/abs/2304.09552v1](http://arxiv.org/abs/2304.09552v1)\n", "2304.09513": "- 2023-04-19, **NetGPT: Generative Pretrained Transformer for Network Traffic**, Xuying Meng et.al., Paper: [http://arxiv.org/abs/2304.09513v1](http://arxiv.org/abs/2304.09513v1)\n", "2304.09438": "- 2023-04-19, **Contrastive Learning based Semantic Communication for Wireless Image Transmission**, Shunpu Tang et.al., Paper: [http://arxiv.org/abs/2304.09438v1](http://arxiv.org/abs/2304.09438v1)\n", "2304.09433": "- 2023-04-20, **Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes**, Simran Arora et.al., Paper: [http://arxiv.org/abs/2304.09433v2](http://arxiv.org/abs/2304.09433v2), Code: **[https://github.com/hazyresearch/evaporate](https://github.com/hazyresearch/evaporate)**\n", "2304.09412": "- 2023-04-19, **hDesigner: Real-Time Haptic Feedback Pattern Designer**, Snehesh Shrestha et.al., Paper: [http://arxiv.org/abs/2304.09412v1](http://arxiv.org/abs/2304.09412v1)\n", "2304.10520": "- 2023-04-20, **Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget**, Johannes Lehner et.al., Paper: [http://arxiv.org/abs/2304.10520v1](http://arxiv.org/abs/2304.10520v1), Code: **[https://github.com/ml-jku/mae-ct](https://github.com/ml-jku/mae-ct)**\n", "2304.10354": "- 2023-04-20, **Prompt-Learning for Cross-Lingual Relation Extraction**, Chiaming Hsu et.al., Paper: [http://arxiv.org/abs/2304.10354v1](http://arxiv.org/abs/2304.10354v1), Code: **[https://github.com/hsu-chia-ming/prompt-xre](https://github.com/hsu-chia-ming/prompt-xre)**\n", "2304.10316": "- 2023-04-20, **Search-Map-Search: A Frame Selection Paradigm for Action Recognition**, Mingjun Zhao et.al., Paper: [http://arxiv.org/abs/2304.10316v1](http://arxiv.org/abs/2304.10316v1)\n", "2304.10294": "- 2023-04-20, **OptoGPT: A Foundation Model for Inverse Design in Optical Multilayer Thin Film Structures**, Taigao Ma et.al., Paper: [http://arxiv.org/abs/2304.10294v1](http://arxiv.org/abs/2304.10294v1)\n", "2304.10253": "- 2023-04-20, **A data augmentation perspective on diffusion models and retrieval**, Max F. Burg et.al., Paper: [http://arxiv.org/abs/2304.10253v1](http://arxiv.org/abs/2304.10253v1)\n", "2304.10226": "- 2023-04-20, **Domain Generalization for Mammographic Image Analysis via Contrastive Learning**, Zheren Li et.al., Paper: [http://arxiv.org/abs/2304.10226v1](http://arxiv.org/abs/2304.10226v1)\n", "2304.10013": "- 2023-04-19, **HTNet: Dynamic WLAN Performance Prediction using Heterogenous Temporal GNN**, Hongkuan Zhou et.al., Paper: [http://arxiv.org/abs/2304.10013v1](http://arxiv.org/abs/2304.10013v1)\n", "2304.09874": "- 2023-04-19, **Domain Adaptable Self-supervised Representation Learning on Remote Sensing Satellite Imagery**, Muskaan Chopra et.al., Paper: [http://arxiv.org/abs/2304.09874v1](http://arxiv.org/abs/2304.09874v1), Code: **[https://github.com/muskaan712/domain-adaptable-self-supervised-representation-learning-on-remote-sensing-satellite-imagery](https://github.com/muskaan712/domain-adaptable-self-supervised-representation-learning-on-remote-sensing-satellite-imagery)**\n", "2304.10941": "- 2023-04-21, **Deep Metric Learning Assisted by Intra-variance in A Semi-supervised View of Learning**, Liu Pingping et.al., Paper: [http://arxiv.org/abs/2304.10941v1](http://arxiv.org/abs/2304.10941v1)\n", "2304.10880": "- 2023-04-21, **Med-Tuning: Exploring Parameter-Efficient Transfer Learning for Medical Volumetric Segmentation**, Wenxuan Wang et.al., Paper: [http://arxiv.org/abs/2304.10880v1](http://arxiv.org/abs/2304.10880v1)\n", "2304.10808": "- 2023-04-21, **Downstream Task-Oriented Neural Tokenizer Optimization with Vocabulary Restriction as Post Processing**, Tatsuya Hiraoka et.al., Paper: [http://arxiv.org/abs/2304.10808v1](http://arxiv.org/abs/2304.10808v1)\n", "2304.10782": "- 2023-04-21, **Contrastive Language, Action, and State Pre-training for Robot Learning**, Krishan Rana et.al., Paper: [http://arxiv.org/abs/2304.10782v1](http://arxiv.org/abs/2304.10782v1)\n", "2304.12036": "- 2023-04-25, **Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness**, Hogun Park et.al., Paper: [http://arxiv.org/abs/2304.12036v2](http://arxiv.org/abs/2304.12036v2)\n", "2304.11846": "- 2023-04-24, **Grad-PU: Arbitrary-Scale Point Cloud Upsampling via Gradient Descent with Learned Distance Functions**, Yun He et.al., Paper: [http://arxiv.org/abs/2304.11846v1](http://arxiv.org/abs/2304.11846v1), Code: **[https://github.com/yunhe20/grad-pu](https://github.com/yunhe20/grad-pu)**\n", "2304.11834": "- 2023-04-24, **Robust Tickets Can Transfer Better: Drawing More Transferable Subnetworks in Transfer Learning**, Yonggan Fu et.al., Paper: [http://arxiv.org/abs/2304.11834v1](http://arxiv.org/abs/2304.11834v1)\n", "2304.11812": "- 2023-04-24, **NoiseTrans: Point Cloud Denoising with Transformers**, Guangzhe Hou et.al., Paper: [http://arxiv.org/abs/2304.11812v1](http://arxiv.org/abs/2304.11812v1)\n", "2304.11718": "- 2023-04-23, **No Free Lunch in Self Supervised Representation Learning**, Ihab Bendidi et.al., Paper: [http://arxiv.org/abs/2304.11718v1](http://arxiv.org/abs/2304.11718v1)\n", "2304.11658": "- 2023-04-23, **Capturing Fine-grained Semantics in Contrastive Graph Representation Learning**, Lin Shu et.al., Paper: [http://arxiv.org/abs/2304.11658v1](http://arxiv.org/abs/2304.11658v1)\n", "2304.11523": "- 2023-04-23, **TransFlow: Transformer as Flow Learner**, Yawen Lu et.al., Paper: [http://arxiv.org/abs/2304.11523v1](http://arxiv.org/abs/2304.11523v1)\n", "2304.11472": "- 2023-04-22, **A Comparative Study of Pre-trained Speech and Audio Embeddings for Speech Emotion Recognition**, Orchid Chetia Phukan et.al., Paper: [http://arxiv.org/abs/2304.11472v1](http://arxiv.org/abs/2304.11472v1)\n", "2304.11330": "- 2023-04-22, **Self-supervised Learning by View Synthesis**, Shaoteng Liu et.al., Paper: [http://arxiv.org/abs/2304.11330v1](http://arxiv.org/abs/2304.11330v1)\n", "2304.11241": "- 2023-04-21, **AutoNeRF: Training Implicit Scene Representations with Autonomous Agents**, Pierre Marza et.al., Paper: [http://arxiv.org/abs/2304.11241v1](http://arxiv.org/abs/2304.11241v1)\n", "2304.13017": "- 2023-04-25, **DuETT: Dual Event Time Transformer for Electronic Health Records**, Alex Labach et.al., Paper: [http://arxiv.org/abs/2304.13017v1](http://arxiv.org/abs/2304.13017v1), Code: **[https://github.com/layer6ai-labs/duett](https://github.com/layer6ai-labs/duett)**\n", "2304.13001": "- 2023-04-25, **On the Generalization of Learned Structured Representations**, Andrea Dittadi et.al., Paper: [http://arxiv.org/abs/2304.13001v1](http://arxiv.org/abs/2304.13001v1)\n", "2304.12535": "- 2023-04-25, **Img2Vec: A Teacher of High Token-Diversity Helps Masked AutoEncoders**, Heng Pan et.al., Paper: [http://arxiv.org/abs/2304.12535v1](http://arxiv.org/abs/2304.12535v1)\n", "2304.12528": "- 2023-04-25, **Model Conversion via Differentially Private Data-Free Distillation**, Bochao Liu et.al., Paper: [http://arxiv.org/abs/2304.12528v1](http://arxiv.org/abs/2304.12528v1)\n", "2304.12520": "- 2023-04-25, **Hint-Aug: Drawing Hints from Foundation Vision Transformers Towards Boosted Few-Shot Parameter-Efficient Tuning**, Zhongzhi Yu et.al., Paper: [http://arxiv.org/abs/2304.12520v1](http://arxiv.org/abs/2304.12520v1)\n", "2304.12507": "- 2023-04-25, **Learning Task-Specific Strategies for Accelerated MRI**, Zihui Wu et.al., Paper: [http://arxiv.org/abs/2304.12507v1](http://arxiv.org/abs/2304.12507v1)\n", "2304.12455": "- 2023-04-24, **Unsupervised Style-based Explicit 3D Face Reconstruction from Single Image**, Heng Yu et.al., Paper: [http://arxiv.org/abs/2304.12455v1](http://arxiv.org/abs/2304.12455v1)\n", "2304.12410": "- 2023-04-24, **PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques**, Mohammed Sabry et.al., Paper: [http://arxiv.org/abs/2304.12410v1](http://arxiv.org/abs/2304.12410v1)\n", "2304.13723": "- 2023-04-26, **A Control-Centric Benchmark for Video Prediction**, Stephen Tian et.al., Paper: [http://arxiv.org/abs/2304.13723v1](http://arxiv.org/abs/2304.13723v1), Code: **[https://github.com/s-tian/vp2](https://github.com/s-tian/vp2)**\n", "2304.13712": "- 2023-04-27, **Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond**, Jingfeng Yang et.al., Paper: [http://arxiv.org/abs/2304.13712v2](http://arxiv.org/abs/2304.13712v2), Code: **[https://github.com/mooler0410/llmspracticalguide](https://github.com/mooler0410/llmspracticalguide)**\n", "2304.13639": "- 2023-04-26, **PVP: Pre-trained Visual Parameter-Efficient Tuning**, Zhao Song et.al., Paper: [http://arxiv.org/abs/2304.13639v1](http://arxiv.org/abs/2304.13639v1)\n", "2304.13567": "- 2023-04-26, **Impact of Position Bias on Language Models in Token Classification**, Mehdi Ben Amor et.al., Paper: [http://arxiv.org/abs/2304.13567v1](http://arxiv.org/abs/2304.13567v1)\n", "2304.13195": "- 2023-04-25, **Connector 0.5: A unified framework for graph representation learning**, Thanh Sang Nguyen et.al., Paper: [http://arxiv.org/abs/2304.13195v1](http://arxiv.org/abs/2304.13195v1), Code: **[https://github.com/nslab-cuk/connector](https://github.com/nslab-cuk/connector)**\n", "2304.13164": "- 2023-04-25, **Towards Compute-Optimal Transfer Learning**, Massimo Caccia et.al., Paper: [http://arxiv.org/abs/2304.13164v1](http://arxiv.org/abs/2304.13164v1)\n", "2304.13089": "- 2023-04-25, **Objectives Matter: Understanding the Impact of Self-Supervised Objectives on Vision Transformer Representations**, Shashank Shekhar et.al., Paper: [http://arxiv.org/abs/2304.13089v1](http://arxiv.org/abs/2304.13089v1)\n", "2304.14381": "- 2023-04-28, **$\u03c0$-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation**, Chengyue Wu et.al., Paper: [http://arxiv.org/abs/2304.14381v2](http://arxiv.org/abs/2304.14381v2)\n", "2304.13923": "- 2023-04-27, **Retrieval-based Knowledge Augmented Vision Language Pre-training**, Jiahua Rao et.al., Paper: [http://arxiv.org/abs/2304.13923v1](http://arxiv.org/abs/2304.13923v1)\n", "2304.13840": "- 2023-04-26, **A Deep Learning Framework for Verilog Autocompletion Towards Design and Verification Automation**, Enrique Dehaerne et.al., Paper: [http://arxiv.org/abs/2304.13840v1](http://arxiv.org/abs/2304.13840v1)\n", "2304.14204": "- 2023-04-26, **Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining**, Bingqian Lin et.al., Paper: [http://arxiv.org/abs/2304.14204v1](http://arxiv.org/abs/2304.14204v1)\n", "2304.14880": "- 2023-04-28, **SGAligner : 3D Scene Alignment with Scene Graphs**, Sayan Deb Sarkar et.al., Paper: [http://arxiv.org/abs/2304.14880v1](http://arxiv.org/abs/2304.14880v1), Code: **[https://github.com/sayands/sgaligner](https://github.com/sayands/sgaligner)**\n", "2304.14736": "- 2023-04-28, **Differentiable Sensor Layouts for End-to-End Learning of Task-Specific Camera Parameters**, Hendrik Sommerhoff et.al., Paper: [http://arxiv.org/abs/2304.14736v1](http://arxiv.org/abs/2304.14736v1)\n", "2304.14593": "- 2023-04-28, **Deep Graph Reprogramming**, Yongcheng Jing et.al., Paper: [http://arxiv.org/abs/2304.14593v1](http://arxiv.org/abs/2304.14593v1)\n", "2305.00866": "- 2023-05-01, **Attack-SAM: Towards Evaluating Adversarial Robustness of Segment Anything Model**, Chenshuang Zhang et.al., Paper: [http://arxiv.org/abs/2305.00866v1](http://arxiv.org/abs/2305.00866v1)\n", "2305.00729": "- 2023-05-01, **What Do Self-Supervised Vision Transformers Learn?**, Namuk Park et.al., Paper: [http://arxiv.org/abs/2305.00729v1](http://arxiv.org/abs/2305.00729v1), Code: **[https://github.com/naver-ai/cl-vs-mim](https://github.com/naver-ai/cl-vs-mim)**\n", "2305.00603": "- 2023-04-30, **Consolidator: Mergeable Adapter with Grouped Connections for Visual Adaptation**, Tianxiang Hao et.al., Paper: [http://arxiv.org/abs/2305.00603v1](http://arxiv.org/abs/2305.00603v1)\n", "2305.00593": "- 2023-04-30, **Reliable Gradient-free and Likelihood-free Prompt Tuning**, Maohao Shen et.al., Paper: [http://arxiv.org/abs/2305.00593v1](http://arxiv.org/abs/2305.00593v1), Code: **[https://github.com/maohaos2/SBI_LLM](https://github.com/maohaos2/SBI_LLM)**\n", "2305.00434": "- 2023-04-30, **EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction**, Burak Ercan et.al., Paper: [http://arxiv.org/abs/2305.00434v1](http://arxiv.org/abs/2305.00434v1), Code: **[https://github.com/ercanburak/EVREAL](https://github.com/ercanburak/EVREAL)**\n", "2305.00385": "- 2023-04-30, **Cross-Shaped Windows Transformer with Self-supervised Pretraining for Clinically Significant Prostate Cancer Detection in Bi-parametric MRI**, Yuheng Li et.al., Paper: [http://arxiv.org/abs/2305.00385v1](http://arxiv.org/abs/2305.00385v1)\n", "2305.00374": "- 2023-04-30, **Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization**, Xilie Xu et.al., Paper: [http://arxiv.org/abs/2305.00374v1](http://arxiv.org/abs/2305.00374v1)\n", "2305.00350": "- 2023-04-29, **POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models**, Korawat Tanwisuth et.al., Paper: [http://arxiv.org/abs/2305.00350v1](http://arxiv.org/abs/2305.00350v1), Code: **[https://github.com/korawat-tanwisuth/pouf](https://github.com/korawat-tanwisuth/pouf)**\n", "2305.00201": "- 2023-04-29, **Instruction-ViT: Multi-Modal Prompts for Instruction Learning in ViT**, Zhenxiang Xiao et.al., Paper: [http://arxiv.org/abs/2305.00201v1](http://arxiv.org/abs/2305.00201v1)\n", "2305.00118": "- 2023-04-28, **Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4**, Kent K. Chang et.al., Paper: [http://arxiv.org/abs/2305.00118v1](http://arxiv.org/abs/2305.00118v1), Code: **[https://github.com/bamman-group/gpt4-books](https://github.com/bamman-group/gpt4-books)**\n", "2305.01616": "- 2023-05-02, **FreeLM: Fine-Tuning-Free Language Model**, Xiang Li et.al., Paper: [http://arxiv.org/abs/2305.01616v1](http://arxiv.org/abs/2305.01616v1)\n", "2305.01323": "- 2023-05-02, **Turning Flowchart into Dialog: Plan-based Data Augmentation for Low-Resource Flowchart-grounded Troubleshooting Dialogs**, Haolan Zhan et.al., Paper: [http://arxiv.org/abs/2305.01323v1](http://arxiv.org/abs/2305.01323v1)\n", "2305.01211": "- 2023-05-02, **MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset**, Tobias Brugger et.al., Paper: [http://arxiv.org/abs/2305.01211v1](http://arxiv.org/abs/2305.01211v1), Code: **[https://github.com/tobiasbrugger/multilegalsbd](https://github.com/tobiasbrugger/multilegalsbd)**\n", "2305.01138": "- 2023-05-02, **High-Fidelity Image Synthesis from Pulmonary Nodule Lesion Maps using Semantic Diffusion Model**, Xuan Zhao et.al., Paper: [http://arxiv.org/abs/2305.01138v1](http://arxiv.org/abs/2305.01138v1)\n", "2305.02317": "- 2023-05-03, **Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings**, Daniel Rose et.al., Paper: [http://arxiv.org/abs/2305.02317v1](http://arxiv.org/abs/2305.02317v1)\n", "2305.02297": "- 2023-05-03, **Making the Most of What You Have: Adapting Pre-trained Visual Language Models in the Low-data Regime**, Chuhan Zhang et.al., Paper: [http://arxiv.org/abs/2305.02297v1](http://arxiv.org/abs/2305.02297v1)\n", "2305.02279": "- 2023-05-03, **Learngene: Inheriting Condensed Knowledge from the Ancestry Model to Descendant Models**, Qiufeng Wang et.al., Paper: [http://arxiv.org/abs/2305.02279v1](http://arxiv.org/abs/2305.02279v1)\n", "2305.02239": "- 2023-05-03, **The Benefits of Label-Description Training for Zero-Shot Text Classification**, Lingyu Gao et.al., Paper: [http://arxiv.org/abs/2305.02239v1](http://arxiv.org/abs/2305.02239v1), Code: **[https://github.com/lingyugao/labeldesctraining](https://github.com/lingyugao/labeldesctraining)**\n", "2305.01810": "- 2023-05-02, **KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness**, Yichuan Li et.al., Paper: [http://arxiv.org/abs/2305.01810v1](http://arxiv.org/abs/2305.01810v1)\n", "2305.01711": "- 2023-05-02, **Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner**, Zhengxiang Shi et.al., Paper: [http://arxiv.org/abs/2305.01711v1](http://arxiv.org/abs/2305.01711v1), Code: **[https://github.com/zhengxiangshi/powerfulpromptft](https://github.com/zhengxiangshi/powerfulpromptft)**\n", "2305.02578": "- 2023-05-04, **Prompt-ICM: A Unified Framework towards Image Coding for Machines with Task-driven Prompts**, Ruoyu Feng et.al., Paper: [http://arxiv.org/abs/2305.02578v1](http://arxiv.org/abs/2305.02578v1)\n", "2305.02577": "- 2023-05-04, **Text Reading Order in Uncontrolled Conditions by Sparse Graph Segmentation**, Renshen Wang et.al., Paper: [http://arxiv.org/abs/2305.02577v1](http://arxiv.org/abs/2305.02577v1)\n", "2305.02374": "- 2023-05-03, **A Novel Plagiarism Detection Approach Combining BERT-based Word Embedding, Attention-based LSTMs and an Improved Differential Evolution Algorithm**, Seyed Vahid Moravvej et.al., Paper: [http://arxiv.org/abs/2305.02374v1](http://arxiv.org/abs/2305.02374v1)\n", "2305.03648": "- 2023-05-05, **On the Effectiveness of Equivariant Regularization for Robust Online Continual Learning**, Lorenzo Bonicelli et.al., Paper: [http://arxiv.org/abs/2305.03648v1](http://arxiv.org/abs/2305.03648v1)\n", "2305.03433": "- 2023-05-05, **Towards Applying Powerful Large AI Models in Classroom Teaching: Opportunities, Challenges and Prospects**, Kehui Tan et.al., Paper: [http://arxiv.org/abs/2305.03433v1](http://arxiv.org/abs/2305.03433v1)\n", "2305.03289": "- 2023-05-05, **BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks**, Zihan Guan et.al., Paper: [http://arxiv.org/abs/2305.03289v1](http://arxiv.org/abs/2305.03289v1)\n", "2305.03267": "- 2023-05-05, **Forecasting Inter-Destination Tourism Flow via a Hybrid Deep Learning Model**, Hanxi Fang et.al., Paper: [http://arxiv.org/abs/2305.03267v1](http://arxiv.org/abs/2305.03267v1)\n", "2305.03125": "- 2023-05-04, **Multimodal Understanding Through Correlation Maximization and Minimization**, Yifeng Shi et.al., Paper: [http://arxiv.org/abs/2305.03125v1](http://arxiv.org/abs/2305.03125v1)\n", "2305.03518": "- 2023-05-04, **Black-box Prompt Tuning with Subspace Learning**, Yuanhang Zheng et.al., Paper: [http://arxiv.org/abs/2305.03518v1](http://arxiv.org/abs/2305.03518v1)\n", "2305.03513": "- 2023-05-03, **ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs**, Yucheng Shi et.al., Paper: [http://arxiv.org/abs/2305.03513v1](http://arxiv.org/abs/2305.03513v1)\n", "2305.04868": "- 2023-05-08, **SignBERT+: Hand-model-aware Self-supervised Pre-training for Sign Language Understanding**, Hezhen Hu et.al., Paper: [http://arxiv.org/abs/2305.04868v1](http://arxiv.org/abs/2305.04868v1)\n", "2305.04757": "- 2023-05-08, **Augmented Large Language Models with Parametric Knowledge Guiding**, Ziyang Luo et.al., Paper: [http://arxiv.org/abs/2305.04757v1](http://arxiv.org/abs/2305.04757v1)\n", "2305.04749": "- 2023-05-08, **Toeplitz Neural Network for Sequence Modeling**, Zhen Qin et.al., Paper: [http://arxiv.org/abs/2305.04749v1](http://arxiv.org/abs/2305.04749v1), Code: **[https://github.com/opennlplab/tnn](https://github.com/opennlplab/tnn)**\n", "2305.04673": "- 2023-05-09, **PreCog: Exploring the Relation between Memorization and Performance in Pre-trained Language Models**, Leonardo Ranaldi et.al., Paper: [http://arxiv.org/abs/2305.04673v2](http://arxiv.org/abs/2305.04673v2)\n", "2305.04658": "- 2023-05-08, **CSGCL: Community-Strength-Enhanced Graph Contrastive Learning**, Han Chen et.al., Paper: [http://arxiv.org/abs/2305.04658v1](http://arxiv.org/abs/2305.04658v1), Code: **[https://github.com/hanchen-hust/csgcl](https://github.com/hanchen-hust/csgcl)**\n", "2305.04573": "- 2023-05-08, **HiFi: High-Information Attention Heads Hold for Parameter-Efficient Model Adaptation**, Anchun Gui et.al., Paper: [http://arxiv.org/abs/2305.04573v1](http://arxiv.org/abs/2305.04573v1)\n", "2305.04557": "- 2023-05-08, **Toward Adversarial Training on Contextualized Language Representation**, Hongqiu Wu et.al., Paper: [http://arxiv.org/abs/2305.04557v1](http://arxiv.org/abs/2305.04557v1), Code: **[https://github.com/gingasan/creat](https://github.com/gingasan/creat)**\n", "2305.04477": "- 2023-05-08, **Behavior Contrastive Learning for Unsupervised Skill Discovery**, Rushuai Yang et.al., Paper: [http://arxiv.org/abs/2305.04477v1](http://arxiv.org/abs/2305.04477v1), Code: **[https://github.com/rooshy-yang/becl](https://github.com/rooshy-yang/becl)**\n", "2305.04410": "- 2023-05-08, **WSFE: Wasserstein Sub-graph Feature Encoder for Effective User Segmentation in Collaborative Filtering**, Yankai Chen et.al., Paper: [http://arxiv.org/abs/2305.04410v1](http://arxiv.org/abs/2305.04410v1)\n", "2305.04294": "- 2023-05-07, **PELE scores: Pelvic X-ray Landmark Detection by Pelvis Extraction and Enhancement**, Zhen Huang et.al., Paper: [http://arxiv.org/abs/2305.04294v1](http://arxiv.org/abs/2305.04294v1)\n", "2305.05661": "- 2023-05-09, **ShapeCoder: Discovering Abstractions for Visual Programs from Unstructured Primitives**, R. Kenny Jones et.al., Paper: [http://arxiv.org/abs/2305.05661v1](http://arxiv.org/abs/2305.05661v1), Code: **[https://github.com/rkjones4/shapecoder](https://github.com/rkjones4/shapecoder)**\n", "2305.05640": "- 2023-05-10, **Representation Learning for Person or Entity-centric Knowledge Graphs: An Application in Healthcare**, Christos Theodoropoulos et.al., Paper: [http://arxiv.org/abs/2305.05640v2](http://arxiv.org/abs/2305.05640v2), Code: **[https://github.com/ibm/hspo-ontology](https://github.com/ibm/hspo-ontology)**\n", "2305.05443": "- 2023-05-09, **An Exploration into the Performance of Unsupervised Cross-Task Speech Representations for \"In the Wild'' Edge Applications**, Heitor Guimar\u00e3es et.al., Paper: [http://arxiv.org/abs/2305.05443v1](http://arxiv.org/abs/2305.05443v1)\n", "2305.05126": "- 2023-05-09, **Comparing Foundation Models using Data Kernels**, Brandon Duderstadt et.al., Paper: [http://arxiv.org/abs/2305.05126v1](http://arxiv.org/abs/2305.05126v1)\n", "2305.05098": "- 2023-05-09, **Who Needs Decoders? Efficient Estimation of Sequence-level Attributes**, Yassir Fathullah et.al., Paper: [http://arxiv.org/abs/2305.05098v1](http://arxiv.org/abs/2305.05098v1)\n", "2305.06324": "- 2023-05-10, **Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception**, Hassan Akbari et.al., Paper: [http://arxiv.org/abs/2305.06324v1](http://arxiv.org/abs/2305.06324v1)\n", "2305.06221": "- 2023-05-10, **Multi-Prompt with Depth Partitioned Cross-Modal Learning**, Yiqi Wang et.al., Paper: [http://arxiv.org/abs/2305.06221v1](http://arxiv.org/abs/2305.06221v1), Code: **[https://github.com/wangyiqi/pmpo](https://github.com/wangyiqi/pmpo)**\n", "2305.06212": "- 2023-05-10, **Privacy-Preserving Prompt Tuning for Large Language Model Services**, Yansong Li et.al., Paper: [http://arxiv.org/abs/2305.06212v1](http://arxiv.org/abs/2305.06212v1)\n", "2305.05968": "- 2023-05-10, **Investigating Forgetting in Pre-Trained Representations Through Continual Learning**, Yun Luo et.al., Paper: [http://arxiv.org/abs/2305.05968v1](http://arxiv.org/abs/2305.05968v1)\n", "2305.06720": "- 2023-05-11, **Bi-level Dynamic Learning for Jointly Multi-modality Image Fusion and Beyond**, Zhu Liu et.al., Paper: [http://arxiv.org/abs/2305.06720v1](http://arxiv.org/abs/2305.06720v1)\n", "2305.06701": "- 2023-05-11, **Extending Audio Masked Autoencoders Toward Audio Restoration**, Zhi Zhong et.al., Paper: [http://arxiv.org/abs/2305.06701v1](http://arxiv.org/abs/2305.06701v1)\n", "2305.06500": "- 2023-05-11, **InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning**, Wenliang Dai et.al., Paper: [http://arxiv.org/abs/2305.06500v1](http://arxiv.org/abs/2305.06500v1), Code: **[https://github.com/salesforce/lavis](https://github.com/salesforce/lavis)**\n", "2305.07358": "- 2023-05-12, **Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters**, Xinyun Zhang et.al., Paper: [http://arxiv.org/abs/2305.07358v1](http://arxiv.org/abs/2305.07358v1)\n", "2305.07303": "- 2023-05-12, **Multi-Relational Hyperbolic Word Embeddings from Natural Language Definitions**, Marco Valentino et.al., Paper: [http://arxiv.org/abs/2305.07303v1](http://arxiv.org/abs/2305.07303v1)\n", "2305.07138": "- 2023-05-11, **Promise and Limitations of Supervised Optimal Transport-Based Graph Summarization via Information Theoretic Measures**, Sepideh Neshatfar et.al., Paper: [http://arxiv.org/abs/2305.07138v1](http://arxiv.org/abs/2305.07138v1)\n", "2305.08804": "- 2023-05-15, **Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text**, Hanieh Khorashadizadeh et.al., Paper: [http://arxiv.org/abs/2305.08804v1](http://arxiv.org/abs/2305.08804v1)\n", "2305.08551": "- 2023-05-15, **Enhancing Performance of Vision Transformers on Small Datasets through Local Inductive Bias Incorporation**, Ibrahim Batuhan Akkaya et.al., Paper: [http://arxiv.org/abs/2305.08551v1](http://arxiv.org/abs/2305.08551v1)\n", "2305.08386": "- 2023-05-15, **PLIP: Language-Image Pre-training for Person Representation Learning**, Jialong Zuo et.al., Paper: [http://arxiv.org/abs/2305.08386v1](http://arxiv.org/abs/2305.08386v1), Code: **[https://github.com/zplusdragon/plip](https://github.com/zplusdragon/plip)**\n", "2305.08381": "- 2023-05-15, **Mode Approximation Makes Good Vision-Language Prompts**, Haixin Wang et.al., Paper: [http://arxiv.org/abs/2305.08381v1](http://arxiv.org/abs/2305.08381v1), Code: **[https://github.com/willdreamer/aurora](https://github.com/willdreamer/aurora)**\n", "2305.08285": "- 2023-05-15, **Parameter-Efficient Fine-Tuning with Layer Pruning on Medical Report Summarization and Medical Dialogue Generation**, Yunqi Zhu et.al., Paper: [http://arxiv.org/abs/2305.08285v1](http://arxiv.org/abs/2305.08285v1), Code: **[https://github.com/zhuyunqi96/LoraLPrun](https://github.com/zhuyunqi96/LoraLPrun)**\n", "2305.08283": "- 2023-05-15, **From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models**, Shangbin Feng et.al., Paper: [http://arxiv.org/abs/2305.08283v1](http://arxiv.org/abs/2305.08283v1)\n", "2305.08273": "- 2023-05-14, **Decoupled Graph Neural Networks for Large Dynamic Graphs**, Yanping Zheng et.al., Paper: [http://arxiv.org/abs/2305.08273v1](http://arxiv.org/abs/2305.08273v1)\n", "2305.08252": "- 2023-05-14, **Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity**, Raman Dutt et.al., Paper: [http://arxiv.org/abs/2305.08252v1](http://arxiv.org/abs/2305.08252v1)\n", "2305.08196": "- 2023-05-14, **A Comprehensive Survey on Segment Anything Model for Vision and Beyond**, Chunhui Zhang et.al., Paper: [http://arxiv.org/abs/2305.08196v1](http://arxiv.org/abs/2305.08196v1), Code: **[https://github.com/liliu-avril/Awesome-Segment-Anything](https://github.com/liliu-avril/Awesome-Segment-Anything)**\n", "2305.08175": "- 2023-05-14, **An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions**, Yingtai Xiao et.al., Paper: [http://arxiv.org/abs/2305.08175v1](http://arxiv.org/abs/2305.08175v1)\n", "2305.09648": "- 2023-05-16, **Prompt-Tuning Decision Transformer with Preference Ranking**, Shengchao Hu et.al., Paper: [http://arxiv.org/abs/2305.09648v1](http://arxiv.org/abs/2305.09648v1)\n", "2305.09574": "- 2023-05-16, **UOR: Universal Backdoor Attacks on Pre-trained Language Models**, Wei Du et.al., Paper: [http://arxiv.org/abs/2305.09574v1](http://arxiv.org/abs/2305.09574v1)\n", "2305.09565": "- 2023-05-16, **Toward Falsifying Causal Graphs Using a Permutation-Based Test**, Elias Eulig et.al., Paper: [http://arxiv.org/abs/2305.09565v1](http://arxiv.org/abs/2305.09565v1)\n", "2305.09556": "- 2023-05-16, **Adapting Sentence Transformers for the Aviation Domain**, Liya Wang et.al., Paper: [http://arxiv.org/abs/2305.09556v1](http://arxiv.org/abs/2305.09556v1)\n", "2305.09360": "- 2023-05-17, **GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding**, Jia-Chen Gu et.al., Paper: [http://arxiv.org/abs/2305.09360v2](http://arxiv.org/abs/2305.09360v2), Code: **[https://github.com/JasonForJoy/MPC-BERT](https://github.com/JasonForJoy/MPC-BERT)**\n", "2305.09333": "- 2023-05-16, **Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image**, Yuzhou Peng et.al., Paper: [http://arxiv.org/abs/2305.09333v1](http://arxiv.org/abs/2305.09333v1)\n", "2305.09299": "- 2023-05-16, **UniS-MMC: Multimodal Classification via Unimodality-supervised Multimodal Contrastive Learning**, Heqing Zou et.al., Paper: [http://arxiv.org/abs/2305.09299v1](http://arxiv.org/abs/2305.09299v1)\n", "2305.09246": "- 2023-05-16, **Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning**, Hao Chen et.al., Paper: [http://arxiv.org/abs/2305.09246v1](http://arxiv.org/abs/2305.09246v1)\n", "2305.09235": "- 2023-05-16, **Synthetic data, real errors: how (not) to publish and use synthetic data**, Boris van Breugel et.al., Paper: [http://arxiv.org/abs/2305.09235v1](http://arxiv.org/abs/2305.09235v1)\n", "2305.09167": "- 2023-05-16, **Adversarial Speaker Disentanglement Using Unannotated External Data for Self-supervised Representation Based Voice Conversion**, Xintao Zhao et.al., Paper: [http://arxiv.org/abs/2305.09167v1](http://arxiv.org/abs/2305.09167v1)\n", "2305.10429": "- 2023-05-17, **DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining**, Sang Michael Xie et.al., Paper: [http://arxiv.org/abs/2305.10429v1](http://arxiv.org/abs/2305.10429v1)\n", "2305.10403": "- 2023-05-17, **PaLM 2 Technical Report**, Rohan Anil et.al., Paper: [http://arxiv.org/abs/2305.10403v1](http://arxiv.org/abs/2305.10403v1)\n", "2305.10329": "- 2023-05-17, **G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks**, Anchun Gui et.al., Paper: [http://arxiv.org/abs/2305.10329v1](http://arxiv.org/abs/2305.10329v1)\n", "2305.10252": "- 2023-05-17, **Sharpness & Shift-Aware Self-Supervised Learning**, Ngoc N. Tran et.al., Paper: [http://arxiv.org/abs/2305.10252v1](http://arxiv.org/abs/2305.10252v1)\n", "2305.10204": "- 2023-05-17, **Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection**, Shadi Iskander et.al., Paper: [http://arxiv.org/abs/2305.10204v1](http://arxiv.org/abs/2305.10204v1), Code: **[https://github.com/technion-cs-nlp/igbp_nonlinear-removal](https://github.com/technion-cs-nlp/igbp_nonlinear-removal)**\n", "2305.10084": "- 2023-05-17, **CWD30: A Comprehensive and Holistic Dataset for Crop Weed Recognition in Precision Agriculture**, Talha Ilyas et.al., Paper: [http://arxiv.org/abs/2305.10084v1](http://arxiv.org/abs/2305.10084v1)\n", "2305.10005": "- 2023-05-17, **DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning**, Alexander H. Liu et.al., Paper: [http://arxiv.org/abs/2305.10005v1](http://arxiv.org/abs/2305.10005v1)\n", "2305.09940": "- 2023-05-18, **OSDP: Optimal Sharded Data Parallel for Distributed Deep Learning**, Youhe Jiang et.al., Paper: [http://arxiv.org/abs/2305.09940v2](http://arxiv.org/abs/2305.09940v2)\n", "2305.09900": "- 2023-05-17, **Equivariant Few-Shot Learning from Pretrained Models**, Sourya Basu et.al., Paper: [http://arxiv.org/abs/2305.09900v1](http://arxiv.org/abs/2305.09900v1)\n", "2305.09802": "- 2023-05-16, **Sasha: creative goal-oriented reasoning in smart homes with large language models**, Evan King et.al., Paper: [http://arxiv.org/abs/2305.09802v1](http://arxiv.org/abs/2305.09802v1)\n", "2305.11092": "- 2023-05-18, **Universal Domain Adaptation from Foundation Models**, Bin Deng et.al., Paper: [http://arxiv.org/abs/2305.11092v1](http://arxiv.org/abs/2305.11092v1), Code: **[https://github.com/szubing/uniood](https://github.com/szubing/uniood)**\n", "2305.10992": "- 2023-05-18, **How does the task complexity of masked pretraining objectives affect downstream performance?**, Atsuki Yamaguchi et.al., Paper: [http://arxiv.org/abs/2305.10992v1](http://arxiv.org/abs/2305.10992v1), Code: **[https://github.com/hitachi-nlp/mlm-probe-acl2023](https://github.com/hitachi-nlp/mlm-probe-acl2023)**\n", "2305.10927": "- 2023-05-19, **Causal Document-Grounded Dialogue Pre-training**, Yingxiu Zhao et.al., Paper: [http://arxiv.org/abs/2305.10927v2](http://arxiv.org/abs/2305.10927v2)\n", "2305.10926": "- 2023-05-18, **HMSN: Hyperbolic Self-Supervised Learning by Clustering with Ideal Prototypes**, Aiden Durrant et.al., Paper: [http://arxiv.org/abs/2305.10926v1](http://arxiv.org/abs/2305.10926v1)\n", "2305.10869": "- 2023-05-19, **Free Lunch for Privacy Preserving Distributed Graph Learning**, Nimesh Agrawal et.al., Paper: [http://arxiv.org/abs/2305.10869v2](http://arxiv.org/abs/2305.10869v2)\n", "2305.10818": "- 2023-05-18, **Democratized Diffusion Language Model**, Nikita Balagansky et.al., Paper: [http://arxiv.org/abs/2305.10818v1](http://arxiv.org/abs/2305.10818v1)\n", "2305.10714": "- 2023-05-18, **Vision-Language Pre-training with Object Contrastive Learning for 3D Scene Understanding**, Taolin Zhang et.al., Paper: [http://arxiv.org/abs/2305.10714v1](http://arxiv.org/abs/2305.10714v1)\n", "2305.10683": "- 2023-05-18, **Paxion: Patching Action Knowledge in Video-Language Foundation Models**, Zhenhailong Wang et.al., Paper: [http://arxiv.org/abs/2305.10683v1](http://arxiv.org/abs/2305.10683v1), Code: **[https://github.com/mikewangwzhl/paxion](https://github.com/mikewangwzhl/paxion)**\n", "2305.10680": "- 2023-05-18, **Accurate and Reliable Confidence Estimation Based on Non-Autoregressive End-to-End Speech Recognition System**, Xian Shi et.al., Paper: [http://arxiv.org/abs/2305.10680v1](http://arxiv.org/abs/2305.10680v1)\n", "2305.10662": "- 2023-05-18, **Learning Differentially Private Probabilistic Models for Privacy-Preserving Image Generation**, Bochao Liu et.al., Paper: [http://arxiv.org/abs/2305.10662v1](http://arxiv.org/abs/2305.10662v1)\n", "2305.11834": "- 2023-05-19, **Pengi: An Audio Language Model for Audio Tasks**, Soham Deshmukh et.al., Paper: [http://arxiv.org/abs/2305.11834v1](http://arxiv.org/abs/2305.11834v1)\n", "2305.11769": "- 2023-05-19, **Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner**, Zikang Liu et.al., Paper: [http://arxiv.org/abs/2305.11769v1](http://arxiv.org/abs/2305.11769v1)\n", "2305.11497": "- 2023-05-19, **TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding**, Chenchi Zhang et.al., Paper: [http://arxiv.org/abs/2305.11497v1](http://arxiv.org/abs/2305.11497v1)\n", "2305.11487": "- 2023-05-19, **PointGPT: Auto-regressively Generative Pre-training from Point Clouds**, Guangyan Chen et.al., Paper: [http://arxiv.org/abs/2305.11487v1](http://arxiv.org/abs/2305.11487v1)\n", "2305.11449": "- 2023-05-19, **Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer with Fine-tuning Slow and Fast**, Yiduo Guo et.al., Paper: [http://arxiv.org/abs/2305.11449v1](http://arxiv.org/abs/2305.11449v1)\n", "2305.11414": "- 2023-05-19, **Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**, Sixing Yu et.al., Paper: [http://arxiv.org/abs/2305.11414v1](http://arxiv.org/abs/2305.11414v1)\n", "2305.13312": "- 2023-05-22, **Contextualising Implicit Representations for Semantic Tasks**, Theo W. Costain et.al., Paper: [http://arxiv.org/abs/2305.13312v1](http://arxiv.org/abs/2305.13312v1)\n", "2305.13128": "- 2023-05-22, **GSURE-Based Diffusion Model Training with Corrupted Data**, Bahjat Kawar et.al., Paper: [http://arxiv.org/abs/2305.13128v1](http://arxiv.org/abs/2305.13128v1), Code: **[https://github.com/bahjat-kawar/gsure-diffusion](https://github.com/bahjat-kawar/gsure-diffusion)**\n", "2305.13052": "- 2023-05-22, **Federated Learning of Medical Concepts Embedding using BEHRT**, Ofir Ben Shoham et.al., Paper: [http://arxiv.org/abs/2305.13052v1](http://arxiv.org/abs/2305.13052v1), Code: **[https://github.com/nadavlab/federatedbehrt](https://github.com/nadavlab/federatedbehrt)**\n", "2305.13016": "- 2023-05-22, **Iterative Forward Tuning Boosts In-context Learning in Language Models**, Jiaxi Yang et.al., Paper: [http://arxiv.org/abs/2305.13016v1](http://arxiv.org/abs/2305.13016v1)\n", "2305.12908": "- 2023-05-22, **Language Models for German Text Simplification: Overcoming Parallel Data Scarcity through Style-specific Pre-training**, Miriam Ansch\u00fctz et.al., Paper: [http://arxiv.org/abs/2305.12908v1](http://arxiv.org/abs/2305.12908v1), Code: **[https://github.com/miriull/language-models-german-simplification](https://github.com/miriull/language-models-german-simplification)**\n", "2305.12799": "- 2023-05-22, **Interactive Data Synthesis for Systematic Vision Adaptation via LLMs-AIGCs Collaboration**, Qifan Yu et.al., Paper: [http://arxiv.org/abs/2305.12799v1](http://arxiv.org/abs/2305.12799v1), Code: **[https://github.com/yuqifan1117/labal-anything-pipeline](https://github.com/yuqifan1117/labal-anything-pipeline)**\n", "2305.12717": "- 2023-05-22, **TADA: Efficient Task-Agnostic Domain Adaptation for Transformers**, Chia-Chien Hung et.al., Paper: [http://arxiv.org/abs/2305.12717v1](http://arxiv.org/abs/2305.12717v1), Code: **[https://github.com/boschresearch/tada](https://github.com/boschresearch/tada)**\n", "2305.12600": "- 2023-05-21, **PRODIGY: Enabling In-context Learning Over Graphs**, Qian Huang et.al., Paper: [http://arxiv.org/abs/2305.12600v1](http://arxiv.org/abs/2305.12600v1)\n", "2305.12599": "- 2023-05-21, **Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text**, Qiming Bao et.al., Paper: [http://arxiv.org/abs/2305.12599v1](http://arxiv.org/abs/2305.12599v1), Code: **[https://github.com/strong-ai-lab/logical-equivalence-driven-amr-data-augmentation-for-representation-learning](https://github.com/strong-ai-lab/logical-equivalence-driven-amr-data-augmentation-for-representation-learning)**\n", "2305.12445": "- 2023-05-21, **JNV Corpus: A Corpus of Japanese Nonverbal Vocalizations with Diverse Phrases and Emotions**, Detai Xin et.al., Paper: [http://arxiv.org/abs/2305.12445v1](http://arxiv.org/abs/2305.12445v1)\n", "2305.14334": "- 2023-05-23, **Diffusion Hyperfeatures: Searching Through Time and Space for Semantic Correspondence**, Grace Luo et.al., Paper: [http://arxiv.org/abs/2305.14334v1](http://arxiv.org/abs/2305.14334v1)\n", "2305.14321": "- 2023-05-23, **ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and Text Embeddings**, William Brannon et.al., Paper: [http://arxiv.org/abs/2305.14321v1](http://arxiv.org/abs/2305.14321v1), Code: **[https://github.com/wwbrannon/congrat](https://github.com/wwbrannon/congrat)**\n", "2305.14283": "- 2023-05-23, **Query Rewriting for Retrieval-Augmented Large Language Models**, Xinbei Ma et.al., Paper: [http://arxiv.org/abs/2305.14283v1](http://arxiv.org/abs/2305.14283v1)\n", "2305.14210": "- 2023-05-23, **Skill-Based Few-Shot Selection for In-Context Learning**, Shengnan An et.al., Paper: [http://arxiv.org/abs/2305.14210v1](http://arxiv.org/abs/2305.14210v1)\n", "2305.14171": "- 2023-05-23, **Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models**, Afra Amini et.al., Paper: [http://arxiv.org/abs/2305.14171v1](http://arxiv.org/abs/2305.14171v1)\n", "2305.14152": "- 2023-05-23, **Memory-Efficient Fine-Tuning of Compressed Large Language Models via sub-4-bit Integer Quantization**, Jeonghoon Kim et.al., Paper: [http://arxiv.org/abs/2305.14152v1](http://arxiv.org/abs/2305.14152v1)\n", "2305.14106": "- 2023-05-23, **Better Zero-Shot Reasoning with Self-Adaptive Prompting**, Xingchen Wan et.al., Paper: [http://arxiv.org/abs/2305.14106v1](http://arxiv.org/abs/2305.14106v1)\n", "2305.14070": "- 2023-05-23, **Assessing Linguistic Generalisation in Language Models: A Dataset for Brazilian Portuguese**, Rodrigo Wilkens et.al., Paper: [http://arxiv.org/abs/2305.14070v1](http://arxiv.org/abs/2305.14070v1)\n", "2305.14053": "- 2023-05-23, **Parts of Speech-Grounded Subspaces in Vision-Language Models**, James Oldfield et.al., Paper: [http://arxiv.org/abs/2305.14053v1](http://arxiv.org/abs/2305.14053v1), Code: **[https://github.com/james-oldfield/pos-subspaces](https://github.com/james-oldfield/pos-subspaces)**\n", "2305.14014": "- 2023-05-23, **CLIP4STR: A Simple Baseline for Scene Text Recognition with Pre-trained Vision-Language Model**, Shuai Zhao et.al., Paper: [http://arxiv.org/abs/2305.14014v1](http://arxiv.org/abs/2305.14014v1)\n", "2305.15387": "- 2023-05-24, **Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering**, Avi Caciularu et.al., Paper: [http://arxiv.org/abs/2305.15387v1](http://arxiv.org/abs/2305.15387v1)\n", "2305.15372": "- 2023-05-24, **What can generic neural networks learn from a child's visual experience?**, A. Emin Orhan et.al., Paper: [http://arxiv.org/abs/2305.15372v1](http://arxiv.org/abs/2305.15372v1)\n", "2305.15347": "- 2023-05-24, **A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence**, Junyi Zhang et.al., Paper: [http://arxiv.org/abs/2305.15347v1](http://arxiv.org/abs/2305.15347v1)\n", "2305.15273": "- 2023-05-24, **Revisiting Token Dropping Strategy in Efficient BERT Pretraining**, Qihuang Zhong et.al., Paper: [http://arxiv.org/abs/2305.15273v1](http://arxiv.org/abs/2305.15273v1)\n", "2305.15248": "- 2023-05-24, **Delving Deeper into Data Scaling in Masked Image Modeling**, Cheng-Ze Lu et.al., Paper: [http://arxiv.org/abs/2305.15248v1](http://arxiv.org/abs/2305.15248v1)\n", "2305.15212": "- 2023-05-24, **Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning**, Zhen-Ru Zhang et.al., Paper: [http://arxiv.org/abs/2305.15212v1](http://arxiv.org/abs/2305.15212v1)\n", "2305.15175": "- 2023-05-24, **Pre-training Multi-party Dialogue Models with Latent Discourse Inference**, Yiyang Li et.al., Paper: [http://arxiv.org/abs/2305.15175v1](http://arxiv.org/abs/2305.15175v1)\n", "2305.15044": "- 2023-05-24, **Is Summary Useful or Not? An Extrinsic Human Evaluation of Text Summaries on Downstream Tasks**, Xiao Pu et.al., Paper: [http://arxiv.org/abs/2305.15044v1](http://arxiv.org/abs/2305.15044v1)\n", "2305.15036": "- 2023-05-24, **Exploring Adapter-based Transfer Learning for Recommender Systems: Empirical Studies and Practical Insights**, Junchen Fu et.al., Paper: [http://arxiv.org/abs/2305.15036v1](http://arxiv.org/abs/2305.15036v1)\n", "2305.15010": "- 2023-05-24, **Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution**, Hongbo Zhang et.al., Paper: [http://arxiv.org/abs/2305.15010v1](http://arxiv.org/abs/2305.15010v1)\n", "2305.16304": "- 2023-05-25, **Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder**, Zheyuan Liu et.al., Paper: [http://arxiv.org/abs/2305.16304v1](http://arxiv.org/abs/2305.16304v1)\n", "2305.16272": "- 2023-05-25, **Incentivizing Honesty among Competitors in Collaborative Learning and Optimization**, Florian E. Dorner et.al., Paper: [http://arxiv.org/abs/2305.16272v1](http://arxiv.org/abs/2305.16272v1)\n", "2305.16174": "- 2023-05-25, **From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module**, Claudio Battiloro et.al., Paper: [http://arxiv.org/abs/2305.16174v1](http://arxiv.org/abs/2305.16174v1)\n", "2305.15862": "- 2023-05-25, **A Task-guided, Implicitly-searched and Meta-initialized Deep Model for Image Fusion**, Risheng Liu et.al., Paper: [http://arxiv.org/abs/2305.15862v1](http://arxiv.org/abs/2305.15862v1)\n", "2305.15811": "- 2023-05-26, **Unifying gradient regularization for Heterogeneous Graph Neural Networks**, Xiao Yang et.al., Paper: [http://arxiv.org/abs/2305.15811v2](http://arxiv.org/abs/2305.15811v2), Code: **[https://github.com/anonymous2nips2023/grug](https://github.com/anonymous2nips2023/grug)**\n", "2305.15805": "- 2023-05-25, **Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers**, Sotiris Anagnostidis et.al., Paper: [http://arxiv.org/abs/2305.15805v1](http://arxiv.org/abs/2305.15805v1)\n", "2305.15722": "- 2023-05-26, **Comparative Study of Pre-Trained BERT Models for Code-Mixed Hindi-English Data**, Aryan Patil et.al., Paper: [http://arxiv.org/abs/2305.15722v2](http://arxiv.org/abs/2305.15722v2)\n", "2305.15542": "- 2023-05-24, **Refocusing Is Key to Transfer Learning**, Baifeng Shi et.al., Paper: [http://arxiv.org/abs/2305.15542v1](http://arxiv.org/abs/2305.15542v1), Code: **[https://github.com/bfshi/toast](https://github.com/bfshi/toast)**\n", "2305.15538": "- 2023-05-24, **Post-processing Private Synthetic Data for Improving Utility on Selected Measures**, Hao Wang et.al., Paper: [http://arxiv.org/abs/2305.15538v1](http://arxiv.org/abs/2305.15538v1)\n", "2305.15488": "- 2023-05-24, **Foundational Models for Malware Embeddings Using Spatio-Temporal Parallel Convolutional Networks**, Dhruv Nandakumar et.al., Paper: [http://arxiv.org/abs/2305.15488v1](http://arxiv.org/abs/2305.15488v1)\n", "2305.17100": "- 2023-05-26, **BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks**, Kai Zhang et.al., Paper: [http://arxiv.org/abs/2305.17100v1](http://arxiv.org/abs/2305.17100v1), Code: **[https://github.com/taokz/biomedgpt](https://github.com/taokz/biomedgpt)**\n", "2305.17040": "- 2023-05-26, **A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks**, Jacob Abernethy et.al., Paper: [http://arxiv.org/abs/2305.17040v1](http://arxiv.org/abs/2305.17040v1)\n", "2305.16985": "- 2023-05-26, **Inverse Dynamics Pretraining Learns Good Representations for Multitask Imitation**, David Brandfonbrener et.al., Paper: [http://arxiv.org/abs/2305.16985v1](http://arxiv.org/abs/2305.16985v1)\n", "2305.16742": "- 2023-05-26, **Parameter-Efficient Fine-Tuning without Introducing New Latency**, Baohao Liao et.al., Paper: [http://arxiv.org/abs/2305.16742v1](http://arxiv.org/abs/2305.16742v1)\n", "2305.16642": "- 2023-05-26, **Improving Position Encoding of Transformers for Multivariate Time Series Classification**, Navid Mohammadi Foumani et.al., Paper: [http://arxiv.org/abs/2305.16642v1](http://arxiv.org/abs/2305.16642v1), Code: **[https://github.com/navidfoumani/convtran](https://github.com/navidfoumani/convtran)**\n", "2305.16597": "- 2023-05-26, **Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models**, Neal Lawton et.al., Paper: [http://arxiv.org/abs/2305.16597v1](http://arxiv.org/abs/2305.16597v1)\n", "2305.16572": "- 2023-05-26, **Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios**, Jiaxuan Li et.al., Paper: [http://arxiv.org/abs/2305.16572v1](http://arxiv.org/abs/2305.16572v1), Code: **[https://github.com/goldengua/counterfactual_inference_lm](https://github.com/goldengua/counterfactual_inference_lm)**\n", "2305.16474": "- 2023-05-25, **FairDP: Certified Fairness with Differential Privacy**, Khang Tran et.al., Paper: [http://arxiv.org/abs/2305.16474v1](http://arxiv.org/abs/2305.16474v1)\n", "2305.16444": "- 2023-05-25, **Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text**, Ashim Gupta et.al., Paper: [http://arxiv.org/abs/2305.16444v1](http://arxiv.org/abs/2305.16444v1)\n", "2305.16424": "- 2023-05-25, **SketchOGD: Memory-Efficient Continual Learning**, Benjamin Wright et.al., Paper: [http://arxiv.org/abs/2305.16424v1](http://arxiv.org/abs/2305.16424v1), Code: **[https://github.com/azizanlab/sketchogd](https://github.com/azizanlab/sketchogd)**\n", "2305.18283": "- 2023-05-29, **CommonAccent: Exploring Large Acoustic Pretrained Models for Accent Classification Based on Common Voice**, Juan Zuluaga-Gomez et.al., Paper: [http://arxiv.org/abs/2305.18283v1](http://arxiv.org/abs/2305.18283v1), Code: **[https://github.com/speechbrain/speechbrain](https://github.com/speechbrain/speechbrain)**\n", "2305.18108": "- 2023-05-29, **Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning**, Xuankai Chang et.al., Paper: [http://arxiv.org/abs/2305.18108v1](http://arxiv.org/abs/2305.18108v1)\n", "2305.17191": "- 2023-05-29, **MT-SLVR: Multi-Task Self-Supervised Learning for Transformation In(Variant) Representations**, Calum Heggan et.al., Paper: [http://arxiv.org/abs/2305.17191v1](http://arxiv.org/abs/2305.17191v1), Code: **[https://github.com/cheggan/mt-slvr](https://github.com/cheggan/mt-slvr)**\n", "2305.17903": "- 2023-05-30, **Deeply Coupled Cross-Modal Prompt Learning**, Xuejing Liu et.al., Paper: [http://arxiv.org/abs/2305.17903v2](http://arxiv.org/abs/2305.17903v2)\n", "2305.17871": "- 2023-05-29, **propnet: Propagating 2D Annotation to 3D Segmentation for Gastric Tumors on CT Scans**, Zifan Chen et.al., Paper: [http://arxiv.org/abs/2305.17871v1](http://arxiv.org/abs/2305.17871v1)\n", "2305.17826": "- 2023-05-28, **NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models**, Kai Mei et.al., Paper: [http://arxiv.org/abs/2305.17826v1](http://arxiv.org/abs/2305.17826v1)\n", "2305.17791": "- 2023-05-28, **LowDINO -- A Low Parameter Self Supervised Learning Model**, Sai Krishna Prathapaneni et.al., Paper: [http://arxiv.org/abs/2305.17791v1](http://arxiv.org/abs/2305.17791v1), Code: **[https://github.com/saikrishna-prathapaneni/LowDINO](https://github.com/saikrishna-prathapaneni/LowDINO)**\n", "2305.17691": "- 2023-05-28, **Plug-and-Play Knowledge Injection for Pre-trained Language Models**, Zhengyan Zhang et.al., Paper: [http://arxiv.org/abs/2305.17691v1](http://arxiv.org/abs/2305.17691v1), Code: **[https://github.com/thunlp/knowledge-plugin](https://github.com/thunlp/knowledge-plugin)**\n", "2305.17682": "- 2023-05-28, **One Network, Many Masks: Towards More Parameter-Efficient Transfer Learning**, Guangtao Zeng et.al., Paper: [http://arxiv.org/abs/2305.17682v1](http://arxiv.org/abs/2305.17682v1), Code: **[https://github.com/chaoscodes/propetl](https://github.com/chaoscodes/propetl)**\n", "2305.17660": "- 2023-05-28, **Plug-and-Play Document Modules for Pre-trained Models**, Chaojun Xiao et.al., Paper: [http://arxiv.org/abs/2305.17660v1](http://arxiv.org/abs/2305.17660v1), Code: **[https://github.com/thunlp/document-plugin](https://github.com/thunlp/document-plugin)**\n", "2305.18993": "- 2023-05-30, **ConES: Concept Embedding Search for Parameter Efficient Tuning Large Vision Language Models**, Huahui Yi et.al., Paper: [http://arxiv.org/abs/2305.18993v1](http://arxiv.org/abs/2305.18993v1)\n", "2305.18980": "- 2023-05-30, **Multi-modal Queried Object Detection in the Wild**, Yifan Xu et.al., Paper: [http://arxiv.org/abs/2305.18980v1](http://arxiv.org/abs/2305.18980v1), Code: **[https://github.com/yifanxu74/mq-det](https://github.com/yifanxu74/mq-det)**\n", "2305.18965": "- 2023-05-30, **Node Embedding from Neural Hamiltonian Orbits in Graph Neural Networks**, Qiyu Kang et.al., Paper: [http://arxiv.org/abs/2305.18965v1](http://arxiv.org/abs/2305.18965v1), Code: **[https://github.com/zknus/hamiltonian-gnn](https://github.com/zknus/hamiltonian-gnn)**\n", "2305.18888": "- 2023-05-30, **Contrastive Shapelet Learning for Unsupervised Multivariate Time Series Representation Learning**, Zhiyu Liang et.al., Paper: [http://arxiv.org/abs/2305.18888v1](http://arxiv.org/abs/2305.18888v1), Code: **[https://github.com/real2fish/csl](https://github.com/real2fish/csl)**\n", "2305.18829": "- 2023-05-30, **Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction**, Chen Min et.al., Paper: [http://arxiv.org/abs/2305.18829v1](http://arxiv.org/abs/2305.18829v1), Code: **[https://github.com/chaytonmin/occ-bev](https://github.com/chaytonmin/occ-bev)**\n", "2305.18721": "- 2023-05-30, **LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training for Document Understanding**, Yi Tu et.al., Paper: [http://arxiv.org/abs/2305.18721v1](http://arxiv.org/abs/2305.18721v1)\n", "2305.18668": "- 2023-05-30, **Fine-Grained is Too Coarse: A Novel Data-Centric Approach for Efficient Scene Graph Generation**, Neau Ma\u00eblic et.al., Paper: [http://arxiv.org/abs/2305.18668v1](http://arxiv.org/abs/2305.18668v1)\n", "2305.18552": "- 2023-05-29, **Learning Linear Groups in Neural Networks**, Emmanouil Theodosis et.al., Paper: [http://arxiv.org/abs/2305.18552v1](http://arxiv.org/abs/2305.18552v1)\n", "2305.18510": "- 2023-05-29, **RLAD: Reinforcement Learning from Pixels for Autonomous Driving in Urban Environments**, Daniel Coelho et.al., Paper: [http://arxiv.org/abs/2305.18510v1](http://arxiv.org/abs/2305.18510v1)\n", "2305.20091": "- 2023-05-31, **Humans in 4D: Reconstructing and Tracking Humans with Transformers**, Shubham Goel et.al., Paper: [http://arxiv.org/abs/2305.20091v1](http://arxiv.org/abs/2305.20091v1), Code: **[https://github.com/shubham-goel/4D-Humans](https://github.com/shubham-goel/4D-Humans)**\n", "2305.20087": "- 2023-06-01, **Too Large; Data Reduction for Vision-Language Pre-Training**, Alex Jinpeng Wang et.al., Paper: [http://arxiv.org/abs/2305.20087v2](http://arxiv.org/abs/2305.20087v2), Code: **[https://github.com/showlab/data-centric.vlp](https://github.com/showlab/data-centric.vlp)**\n", "2305.19915": "- 2023-05-31, **Data Augmentation Approaches for Source Code Models: A Survey**, Terry Yue Zhuo et.al., Paper: [http://arxiv.org/abs/2305.19915v1](http://arxiv.org/abs/2305.19915v1), Code: **[https://github.com/terryyz/dataaug4code](https://github.com/terryyz/dataaug4code)**\n", "2305.19903": "- 2023-05-31, **Improving Expressivity of GNNs with Subgraph-specific Factor Embedded Normalization**, Kaixuan Chen et.al., Paper: [http://arxiv.org/abs/2305.19903v1](http://arxiv.org/abs/2305.19903v1), Code: **[https://github.com/chenchkx/supernorm](https://github.com/chenchkx/supernorm)**\n", "2305.19847": "- 2023-05-31, **How Does Pretraining Improve Discourse-Aware Translation?**, Zhihong Huang et.al., Paper: [http://arxiv.org/abs/2305.19847v1](http://arxiv.org/abs/2305.19847v1)\n", "2305.19623": "- 2023-06-01, **Point-GCC: Universal Self-supervised 3D Scene Pre-training via Geometry-Color Contrast**, Guofan Fan et.al., Paper: [http://arxiv.org/abs/2305.19623v2](http://arxiv.org/abs/2305.19623v2)\n", "2305.19602": "- 2023-05-31, **Learning Music Sequence Representation from Text Supervision**, Tianyu Chen et.al., Paper: [http://arxiv.org/abs/2305.19602v1](http://arxiv.org/abs/2305.19602v1)\n", "2305.19523": "- 2023-05-31, **Explanations as Features: LLM-Based Features for Text-Attributed Graphs**, Xiaoxin He et.al., Paper: [http://arxiv.org/abs/2305.19523v1](http://arxiv.org/abs/2305.19523v1), Code: **[https://github.com/XiaoxinHe/TAPE](https://github.com/XiaoxinHe/TAPE)**\n", "2305.19466": "- 2023-05-31, **The Impact of Positional Encoding on Length Generalization in Transformers**, Amirhossein Kazemnejad et.al., Paper: [http://arxiv.org/abs/2305.19466v1](http://arxiv.org/abs/2305.19466v1), Code: **[https://github.com/mcgill-nlp/length-generalization](https://github.com/mcgill-nlp/length-generalization)**\n", "2305.19436": "- 2023-05-30, **Investigation of Higgs Boson Decaying to Di-muon, Dark Matter Produced in Association with a Higgs Boson Decaying to $b$-quarks and Unbinned Profiled Unfolding**, Jay Chan et.al., Paper: [http://arxiv.org/abs/2305.19436v1](http://arxiv.org/abs/2305.19436v1)\n", "2306.00618": "- 2023-06-01, **Effective Structured Prompting by Meta-Learning and Representative Verbalizer**, Weisen Jiang et.al., Paper: [http://arxiv.org/abs/2306.00618v1](http://arxiv.org/abs/2306.00618v1)\n", "2306.00559": "- 2023-06-01, **We never go out of Style: Motion Disentanglement by Subspace Decomposition of Latent Space**, Rishubh Parihar et.al., Paper: [http://arxiv.org/abs/2306.00559v1](http://arxiv.org/abs/2306.00559v1)\n", "2306.00452": "- 2023-06-01, **Speech Self-Supervised Representation Benchmarking: Are We Doing it Right?**, Salah Zaiem et.al., Paper: [http://arxiv.org/abs/2306.00452v1](http://arxiv.org/abs/2306.00452v1), Code: **[https://github.com/salah-zaiem/speechbrain-2](https://github.com/salah-zaiem/speechbrain-2)**\n", "2306.00424": "- 2023-06-01, **End-to-end Knowledge Retrieval with Multi-modal Queries**, Man Luo et.al., Paper: [http://arxiv.org/abs/2306.00424v1](http://arxiv.org/abs/2306.00424v1), Code: **[https://github.com/luomancs/remuq](https://github.com/luomancs/remuq)**\n", "2306.00258": "- 2023-06-01, **Towards Foundation Models for Scientific Machine Learning: Characterizing Scaling and Transfer Behavior**, Shashank Subramanian et.al., Paper: [http://arxiv.org/abs/2306.00258v1](http://arxiv.org/abs/2306.00258v1)\n", "2306.00253": "- 2023-06-01, **AfriNames: Most ASR models \"butcher\" African Names**, Tobi Olatunji et.al., Paper: [http://arxiv.org/abs/2306.00253v1](http://arxiv.org/abs/2306.00253v1)\n", "2306.00206": "- 2023-05-31, **Representation Reliability and Its Impact on Downstream Tasks**, Young-Jin Park et.al., Paper: [http://arxiv.org/abs/2306.00206v1](http://arxiv.org/abs/2306.00206v1)\n", "2306.00197": "- 2023-05-31, **SSL-CPCD: Self-supervised learning with composite pretext-class discrimination for improved generalisability in endoscopic image analysis**, Ziang Xu et.al., Paper: [http://arxiv.org/abs/2306.00197v1](http://arxiv.org/abs/2306.00197v1)\n", "2306.00183": "- 2023-05-31, **Diffused Redundancy in Pre-trained Representations**, Vedant Nanda et.al., Paper: [http://arxiv.org/abs/2306.00183v1](http://arxiv.org/abs/2306.00183v1)\n"}, "adaptor": {"2208.08503": "- 2022-09-16, **Learning with Local Gradients at the Edge**, Michael Lomnitz et.al., Paper: [http://arxiv.org/abs/2208.08503v2](http://arxiv.org/abs/2208.08503v2)\n", "2208.07012": "- 2022-08-15, **MM-GNN: Mix-Moment Graph Neural Network towards Modeling Neighborhood Feature Distribution**, Wendong Bi et.al., Paper: [http://arxiv.org/abs/2208.07012v1](http://arxiv.org/abs/2208.07012v1)\n", "2206.09202": "- 2022-06-18, **Camera Adaptation for Fundus-Image-Based CVD Risk Estimation**, Zhihong Lin et.al., Paper: [http://arxiv.org/abs/2206.09202v1](http://arxiv.org/abs/2206.09202v1), Code: **[https://github.com/linzhlalala/cvd-risk-based-on-retinal-fundus-images](https://github.com/linzhlalala/cvd-risk-based-on-retinal-fundus-images)**\n", "2206.05941": "- 2022-06-13, **Towards Universal Sequence Representation Learning for Recommender Systems**, Yupeng Hou et.al., Paper: [http://arxiv.org/abs/2206.05941v1](http://arxiv.org/abs/2206.05941v1), Code: **[https://github.com/rucaibox/unisrec](https://github.com/rucaibox/unisrec)**\n", "2205.12923": "- 2022-05-25, **Domain Adaptation for Object Detection using SE Adaptors and Center Loss**, Sushruth Nagesh et.al., Paper: [http://arxiv.org/abs/2205.12923v1](http://arxiv.org/abs/2205.12923v1), Code: **[https://github.com/shreyasrajesh/DA-Object-Detection](https://github.com/shreyasrajesh/DA-Object-Detection)**\n", "2205.10744": "- 2022-05-22, **All Birds with One Stone: Multi-task Text Classification for Efficient Inference with One Forward Pass**, Jiaxin Huang et.al., Paper: [http://arxiv.org/abs/2205.10744v1](http://arxiv.org/abs/2205.10744v1)\n", "2205.07211": "- 2022-05-15, **GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech Synthesis**, Rongjie Huang et.al., Paper: [http://arxiv.org/abs/2205.07211v1](http://arxiv.org/abs/2205.07211v1)\n", "2204.09212": "- 2022-04-21, **Primary accelerometer calibration with two-axis automatic positioning stage**, Wataru Kokuyama et.al., Paper: [http://arxiv.org/abs/2204.09212v2](http://arxiv.org/abs/2204.09212v2)\n", "2204.00170": "- 2022-04-01, **Universal Adaptor: Converting Mel-Spectrograms Between Different Configurations for Speech Synthesis**, Fan-Lin Wang et.al., Paper: [http://arxiv.org/abs/2204.00170v1](http://arxiv.org/abs/2204.00170v1), Code: **[https://github.com/BogiHsu/Universal-Adaptor](https://github.com/BogiHsu/Universal-Adaptor)**\n", "2203.14565": "- 2022-06-20, **Style-Guided Domain Adaptation for Face Presentation Attack Detection**, Young-Eun Kim et.al., Paper: [http://arxiv.org/abs/2203.14565v2](http://arxiv.org/abs/2203.14565v2)\n", "2209.07526": "- 2022-10-19, **OmniVL:One Foundation Model for Image-Language and Video-Language Tasks**, Junke Wang et.al., Paper: [http://arxiv.org/abs/2209.07526v2](http://arxiv.org/abs/2209.07526v2)\n", "2209.10804": "- 2022-09-22, **Controllable Accented Text-to-Speech Synthesis**, Rui Liu et.al., Paper: [http://arxiv.org/abs/2209.10804v1](http://arxiv.org/abs/2209.10804v1)\n", "2209.13925": "- 2022-09-28, **DeViT: Deformed Vision Transformers in Video Inpainting**, Jiayin Cai et.al., Paper: [http://arxiv.org/abs/2209.13925v1](http://arxiv.org/abs/2209.13925v1)\n", "2210.02254": "- 2022-10-05, **Granularity-aware Adaptation for Image Retrieval over Multiple Tasks**, Jon Almaz\u00e1n et.al., Paper: [http://arxiv.org/abs/2210.02254v1](http://arxiv.org/abs/2210.02254v1)\n", "2210.08475": "- 2022-10-16, **RedApt: An Adaptor for wav2vec 2 Encoding \\\\ Faster and Smaller Speech Translation without Quality Compromise**, Jinming Zhao et.al., Paper: [http://arxiv.org/abs/2210.08475v1](http://arxiv.org/abs/2210.08475v1)\n", "2211.02937": "- 2022-11-09, **Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback**, Xudong Zhang et.al., Paper: [http://arxiv.org/abs/2211.02937v2](http://arxiv.org/abs/2211.02937v2), Code: **[https://github.com/zhang-xd18/qcrnet](https://github.com/zhang-xd18/qcrnet)**\n", "2211.11031": "- 2023-01-30, **Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors**, Thomas Hartvigsen et.al., Paper: [http://arxiv.org/abs/2211.11031v2](http://arxiv.org/abs/2211.11031v2)\n", "2211.11018": "- 2022-11-20, **MagicVideo: Efficient Video Generation With Latent Diffusion Models**, Daquan Zhou et.al., Paper: [http://arxiv.org/abs/2211.11018v1](http://arxiv.org/abs/2211.11018v1)\n", "2211.15916": "- 2022-11-30, **BotSIM: An End-to-End Bot Simulation Toolkit for Commercial Task-Oriented Dialog Systems**, Guangsen Wang et.al., Paper: [http://arxiv.org/abs/2211.15916v2](http://arxiv.org/abs/2211.15916v2), Code: **[https://github.com/salesforce/botsim](https://github.com/salesforce/botsim)**\n", "2211.16208": "- 2022-12-08, **SLAN: Self-Locator Aided Network for Cross-Modal Understanding**, Jiang-Tian Zhai et.al., Paper: [http://arxiv.org/abs/2211.16208v2](http://arxiv.org/abs/2211.16208v2)\n", "2211.17046": "- 2022-11-30, **RAFT: Rationale adaptor for few-shot abusive language detection**, Punyajoy Saha et.al., Paper: [http://arxiv.org/abs/2211.17046v1](http://arxiv.org/abs/2211.17046v1)\n", "2212.00932": "- 2022-12-05, **ObjectStitch: Generative Object Compositing**, Yizhi Song et.al., Paper: [http://arxiv.org/abs/2212.00932v2](http://arxiv.org/abs/2212.00932v2)\n", "2302.07577": "- 2023-03-14, **Efficient Teacher: Semi-Supervised Object Detection for YOLOv5**, Bowen Xu et.al., Paper: [http://arxiv.org/abs/2302.07577v3](http://arxiv.org/abs/2302.07577v3), Code: **[https://github.com/AlibabaResearch/efficientteacher](https://github.com/AlibabaResearch/efficientteacher)**\n", "2302.06272": "- 2023-02-13, **Fabrication of a Low-Cost Real-Time Mobile ECG System for Health Monitoring**, Soheil Khooyooz et.al., Paper: [http://arxiv.org/abs/2302.06272v1](http://arxiv.org/abs/2302.06272v1)\n", "2301.02911": "- 2023-01-15, **Towards early prediction of neurodevelopmental disorders: Computational model for Face Touch and Self-adaptors in Infants**, Bruno Tafur et.al., Paper: [http://arxiv.org/abs/2301.02911v2](http://arxiv.org/abs/2301.02911v2)\n", "2301.00199": "- 2023-02-10, **Action Codes**, Frits Vaandrager et.al., Paper: [http://arxiv.org/abs/2301.00199v2](http://arxiv.org/abs/2301.00199v2)\n", "2302.08908": "- 2023-02-16, **LayoutDiffuse: Adapting Foundational Diffusion Models for Layout-to-Image Generation**, Jiaxin Cheng et.al., Paper: [http://arxiv.org/abs/2302.08908v1](http://arxiv.org/abs/2302.08908v1)\n", "2303.00448": "- 2023-04-03, **The style transformer with common knowledge optimization for image-text retrieval**, Wenrui Li et.al., Paper: [http://arxiv.org/abs/2303.00448v2](http://arxiv.org/abs/2303.00448v2)\n", "2303.01277": "- 2023-03-02, **Boosting Distributed Full-graph GNN Training with Asynchronous One-bit Communication**, Meng Zhang et.al., Paper: [http://arxiv.org/abs/2303.01277v1](http://arxiv.org/abs/2303.01277v1)\n", "2303.10070": "- 2023-03-17, **A Unified Continual Learning Framework with General Parameter-Efficient Tuning**, Qiankun Gao et.al., Paper: [http://arxiv.org/abs/2303.10070v1](http://arxiv.org/abs/2303.10070v1), Code: **[https://github.com/gqk/lae](https://github.com/gqk/lae)**\n", "2303.11114": "- 2023-03-20, **SeiT: Storage-Efficient Vision Training with Tokens Using 1% of Pixel Storage**, Song Park et.al., Paper: [http://arxiv.org/abs/2303.11114v1](http://arxiv.org/abs/2303.11114v1), Code: **[https://github.com/naver-ai/seit](https://github.com/naver-ai/seit)**\n", "2303.13072": "- 2023-04-05, **Beyond Universal Transformer: block reusing with adaptor in Transformer for automatic speech recognition**, Haoyu Tang et.al., Paper: [http://arxiv.org/abs/2303.13072v2](http://arxiv.org/abs/2303.13072v2)\n", "2303.14175": "- 2023-04-18, **Inherent Consistent Learning for Accurate Semi-supervised Medical Image Segmentation**, Ye Zhu et.al., Paper: [http://arxiv.org/abs/2303.14175v4](http://arxiv.org/abs/2303.14175v4), Code: **[https://github.com/zhuye98/icl](https://github.com/zhuye98/icl)**\n", "2303.15012": "- 2023-03-27, **3D-Aware Multi-Class Image-to-Image Translation with NeRFs**, Senmao Li et.al., Paper: [http://arxiv.org/abs/2303.15012v1](http://arxiv.org/abs/2303.15012v1), Code: **[https://github.com/sen-mao/3di2i-translation](https://github.com/sen-mao/3di2i-translation)**\n", "2303.16501": "- 2023-03-29, **AVFormer: Injecting Vision into Frozen Speech Models for Zero-Shot AV-ASR**, Paul Hongsuck Seo et.al., Paper: [http://arxiv.org/abs/2303.16501v1](http://arxiv.org/abs/2303.16501v1)\n", "2304.05255": "- 2023-04-11, **Density Map Distillation for Incremental Object Counting**, Chenshen Wu et.al., Paper: [http://arxiv.org/abs/2304.05255v1](http://arxiv.org/abs/2304.05255v1)\n", "2304.09114": "- 2023-04-17, **The Standard Problem**, Enrico Coiera et.al., Paper: [http://arxiv.org/abs/2304.09114v1](http://arxiv.org/abs/2304.09114v1)\n", "2305.04476": "- 2023-05-24, **AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment**, Ruiqi Li et.al., Paper: [http://arxiv.org/abs/2305.04476v4](http://arxiv.org/abs/2305.04476v4)\n", "2305.06236": "- 2023-05-10, **Radious: Unveiling the Enigma of Dental Radiology with BEIT Adaptor and Mask2Former in Semantic Segmentation**, Mohammad Mashayekhi et.al., Paper: [http://arxiv.org/abs/2305.06236v1](http://arxiv.org/abs/2305.06236v1)\n", "2305.12800": "- 2023-05-22, **Single Domain Dynamic Generalization for Iris Presentation Attack Detection**, Yachun Li et.al., Paper: [http://arxiv.org/abs/2305.12800v1](http://arxiv.org/abs/2305.12800v1)\n", "2305.15065": "- 2023-05-24, **Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning**, Ximing Lu et.al., Paper: [http://arxiv.org/abs/2305.15065v1](http://arxiv.org/abs/2305.15065v1)\n", "2305.18292": "- 2023-05-29, **Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models**, Yuchao Gu et.al., Paper: [http://arxiv.org/abs/2305.18292v1](http://arxiv.org/abs/2305.18292v1)\n", "2305.17732": "- 2023-06-01, **StyleS2ST: Zero-shot Style Transfer for Direct Speech-to-speech Translation**, Kun Song et.al., Paper: [http://arxiv.org/abs/2305.17732v2](http://arxiv.org/abs/2305.17732v2)\n"}, "retrieval": {}, "object detection": {"2209.06710": "- 2022-09-14, **Evaluating a GAN for enhancing camera simulation for robotics**, Asher Elmquist et.al., Paper: [http://arxiv.org/abs/2209.06710v1](http://arxiv.org/abs/2209.06710v1)\n", "2209.06535": "- 2022-09-14, **CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer**, Youngseok Kim et.al., Paper: [http://arxiv.org/abs/2209.06535v1](http://arxiv.org/abs/2209.06535v1)\n", "2209.06407": "- 2022-09-14, **Viewer-Centred Surface Completion for Unsupervised Domain Adaptation in 3D Object Detection**, Darren Tsai et.al., Paper: [http://arxiv.org/abs/2209.06407v1](http://arxiv.org/abs/2209.06407v1), Code: **[https://github.com/darrenjkt/SEE-VCN](https://github.com/darrenjkt/SEE-VCN)**\n", "2209.06399": "- 2022-09-14, **A Survey on Evolutionary Computation for Computer Vision and Image Analysis: Past, Present, and Future Trends**, Ying Bi et.al., Paper: [http://arxiv.org/abs/2209.06399v1](http://arxiv.org/abs/2209.06399v1)\n", "2209.05911": "- 2022-09-13, **Computer vision based vehicle tracking as a complementary and scalable approach to RFID tagging**, Pranav Kant Gaur et.al., Paper: [http://arxiv.org/abs/2209.05911v1](http://arxiv.org/abs/2209.05911v1)\n", "2209.06641": "- 2022-09-13, **CMR3D: Contextualized Multi-Stage Refinement for 3D Object Detection**, Dhanalaxmi Gaddam et.al., Paper: [http://arxiv.org/abs/2209.06641v1](http://arxiv.org/abs/2209.06641v1)\n", "2209.05687": "- 2022-09-13, **PSAQ-ViT V2: Towards Accurate and General Data-Free Quantization for Vision Transformers**, Zhikai Li et.al., Paper: [http://arxiv.org/abs/2209.05687v1](http://arxiv.org/abs/2209.05687v1), Code: **[https://github.com/zkkli/psaq-vit](https://github.com/zkkli/psaq-vit)**\n", "2209.05654": "- 2022-09-13, **ComplETR: Reducing the cost of annotations for object detection in dense scenes with vision transformers**, Achin Jain et.al., Paper: [http://arxiv.org/abs/2209.05654v1](http://arxiv.org/abs/2209.05654v1)\n", "2209.05588": "- 2022-09-12, **CenterFormer: Center-based Transformer for 3D Object Detection**, Zixiang Zhou et.al., Paper: [http://arxiv.org/abs/2209.05588v1](http://arxiv.org/abs/2209.05588v1), Code: **[https://github.com/tusimple/centerformer](https://github.com/tusimple/centerformer)**\n", "2209.06584": "- 2022-09-12, **One-Shot Doc Snippet Detection: Powering Search in Document Beyond Text**, Abhinav Java et.al., Paper: [http://arxiv.org/abs/2209.06584v1](http://arxiv.org/abs/2209.06584v1)\n", "2209.07419": "- 2022-09-15, **FFPA-Net: Efficient Feature Fusion with Projection Awareness for 3D Object Detection**, Chaokang Jiang et.al., Paper: [http://arxiv.org/abs/2209.07419v1](http://arxiv.org/abs/2209.07419v1)\n", "2209.07118": "- 2022-09-15, **Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge**, Zhihong Chen et.al., Paper: [http://arxiv.org/abs/2209.07118v1](http://arxiv.org/abs/2209.07118v1)\n", "2209.07061": "- 2022-09-15, **PROB-SLAM: Real-time Visual SLAM Based on Probabilistic Graph Optimization**, Xianwei Meng et.al., Paper: [http://arxiv.org/abs/2209.07061v1](http://arxiv.org/abs/2209.07061v1)\n", "2209.07042": "- 2022-09-15, **Efficient Perception, Planning, and Control Algorithms for Vision-Based Automated Vehicles**, Der-Hau Lee et.al., Paper: [http://arxiv.org/abs/2209.07042v1](http://arxiv.org/abs/2209.07042v1)\n", "2209.06967": "- 2022-09-14, **A novel illumination condition varied image dataset-Food Vision Dataset (FVD) for fair and reliable consumer acceptability predictions from food**, Swarna Sethu et.al., Paper: [http://arxiv.org/abs/2209.06967v1](http://arxiv.org/abs/2209.06967v1)\n", "2209.07888": "- 2022-09-16, **TwistSLAM++: Fusing multiple modalities for accurate dynamic semantic SLAM**, Mathieu Gonzalez et.al., Paper: [http://arxiv.org/abs/2209.07888v1](http://arxiv.org/abs/2209.07888v1)\n", "2209.07790": "- 2022-09-16, **A Large-scale Multiple-objective Method for Black-box Attack against Object Detection**, Siyuan Liang et.al., Paper: [http://arxiv.org/abs/2209.07790v1](http://arxiv.org/abs/2209.07790v1)\n", "2209.07753": "- 2022-09-16, **Code as Policies: Language Model Programs for Embodied Control**, Jacky Liang et.al., Paper: [http://arxiv.org/abs/2209.07753v1](http://arxiv.org/abs/2209.07753v1)\n", "2209.07735": "- 2022-09-16, **Enhance the Visual Representation via Discrete Adversarial Training**, Xiaofeng Mao et.al., Paper: [http://arxiv.org/abs/2209.07735v1](http://arxiv.org/abs/2209.07735v1), Code: **[https://github.com/alibaba/easyrobust](https://github.com/alibaba/easyrobust)**\n", "2209.07709": "- 2022-09-16, **LO-Det: Lightweight Oriented Object Detection in Remote Sensing Images**, Zhanchao Huang et.al., Paper: [http://arxiv.org/abs/2209.07709v1](http://arxiv.org/abs/2209.07709v1)\n", "2209.07601": "- 2022-09-15, **Towards Improving Calibration in Object Detection Under Domain Shift**, Muhammad Akhtar Munir et.al., Paper: [http://arxiv.org/abs/2209.07601v1](http://arxiv.org/abs/2209.07601v1)\n", "2209.08953": "- 2022-09-19, **Effective Adaptation in Multi-Task Co-Training for Unified Autonomous Driving**, Xiwen Liang et.al., Paper: [http://arxiv.org/abs/2209.08953v1](http://arxiv.org/abs/2209.08953v1)\n", "2209.08844": "- 2022-09-19, **A Dual-Cycled Cross-View Transformer Network for Unified Road Layout Estimation and 3D Object Detection in the Bird's-Eye-View**, Curie Kim et.al., Paper: [http://arxiv.org/abs/2209.08844v1](http://arxiv.org/abs/2209.08844v1)\n", "2209.08699": "- 2022-09-19, **An Adaptive Threshold for the Canny Edge Detection with Actor-Critic Algorithm**, Keong-Hun Choi et.al., Paper: [http://arxiv.org/abs/2209.08699v1](http://arxiv.org/abs/2209.08699v1)\n", "2209.08691": "- 2022-09-19, **MECCANO: A Multimodal Egocentric Dataset for Humans Behavior Understanding in the Industrial-like Domain**, Francesco Ragusa et.al., Paper: [http://arxiv.org/abs/2209.08691v1](http://arxiv.org/abs/2209.08691v1)\n", "2209.08538": "- 2022-09-18, **RDD2022: A multi-national image dataset for automatic Road Damage Detection**, Deeksha Arya et.al., Paper: [http://arxiv.org/abs/2209.08538v1](http://arxiv.org/abs/2209.08538v1)\n", "2209.08443": "- 2022-09-18, **HAPI: A Large-scale Longitudinal Dataset of Commercial ML API Predictions**, Lingjiao Chen et.al., Paper: [http://arxiv.org/abs/2209.08443v1](http://arxiv.org/abs/2209.08443v1)\n", "2209.08323": "- 2022-09-17, **RGB-Event Fusion for Moving Object Detection in Autonomous Driving**, Zhuyun Zhou et.al., Paper: [http://arxiv.org/abs/2209.08323v1](http://arxiv.org/abs/2209.08323v1)\n", "2209.08237": "- 2022-09-17, **Understanding the Impact of Image Quality and Distance of Objects to Object Detection Performance**, Yu Hao et.al., Paper: [http://arxiv.org/abs/2209.08237v1](http://arxiv.org/abs/2209.08237v1)\n", "2209.08162": "- 2022-09-16, **Uncertainty Quantification of Collaborative Detection for Self-Driving**, Sanbao Su et.al., Paper: [http://arxiv.org/abs/2209.08162v1](http://arxiv.org/abs/2209.08162v1)\n", "2209.09841": "- 2022-09-20, **Rethinking Data Augmentation in Knowledge Distillation for Object Detection**, Jiawei Liang et.al., Paper: [http://arxiv.org/abs/2209.09841v1](http://arxiv.org/abs/2209.09841v1)\n", "2209.09808": "- 2022-09-20, **Enhancing vehicle detection accuracy in thermal infrared images using multiple GANs**, Shivom Bhargava et.al., Paper: [http://arxiv.org/abs/2209.09808v1](http://arxiv.org/abs/2209.09808v1)\n", "2209.09760": "- 2022-09-20, **Dynamic Graph Message Passing Networks for Visual Recognition**, Li Zhang et.al., Paper: [http://arxiv.org/abs/2209.09760v1](http://arxiv.org/abs/2209.09760v1), Code: **[https://github.com/fudan-zvg/dgmn2](https://github.com/fudan-zvg/dgmn2)**\n", "2209.09486": "- 2022-09-20, **Self-supervised 3D Object Detection from Monocular Pseudo-LiDAR**, Curie Kim et.al., Paper: [http://arxiv.org/abs/2209.09486v1](http://arxiv.org/abs/2209.09486v1)\n", "2209.09475": "- 2022-09-20, **Revisiting Image Pyramid Structure for High Resolution Salient Object Detection**, Taehun Kim et.al., Paper: [http://arxiv.org/abs/2209.09475v1](http://arxiv.org/abs/2209.09475v1), Code: **[https://github.com/plemeri/inspyrenet](https://github.com/plemeri/inspyrenet)**\n", "2209.09464": "- 2022-09-20, **Rethinking Dimensionality Reduction in Grid-based 3D Object Detection**, Dihe Huang et.al., Paper: [http://arxiv.org/abs/2209.09464v1](http://arxiv.org/abs/2209.09464v1)\n", "2209.09407": "- 2022-09-20, **DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for Open-world Detection**, Lewei Yao et.al., Paper: [http://arxiv.org/abs/2209.09407v1](http://arxiv.org/abs/2209.09407v1)\n", "2209.09385": "- 2022-09-19, **LidarMultiNet: Towards a Unified Multi-task Network for LiDAR Perception**, Dongqiangzi Ye et.al., Paper: [http://arxiv.org/abs/2209.09385v1](http://arxiv.org/abs/2209.09385v1)\n", "2209.10471": "- 2022-09-21, **Sample, Crop, Track: Self-Supervised Mobile 3D Object Detection for Urban Driving LiDAR**, Sangyun Shin et.al., Paper: [http://arxiv.org/abs/2209.10471v1](http://arxiv.org/abs/2209.10471v1)\n", "2209.10391": "- 2022-09-21, **IoU-Enhanced Attention for End-to-End Task Specific Object Detection**, Jing Zhao et.al., Paper: [http://arxiv.org/abs/2209.10391v1](http://arxiv.org/abs/2209.10391v1)\n", "2209.10368": "- 2022-09-21, **Safety Metrics and Losses for Object Detection in Autonomous Driving**, Hsuan-Cheng Liao et.al., Paper: [http://arxiv.org/abs/2209.10368v1](http://arxiv.org/abs/2209.10368v1)\n", "2209.10248": "- 2022-09-21, **BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo**, Yinhao Li et.al., Paper: [http://arxiv.org/abs/2209.10248v1](http://arxiv.org/abs/2209.10248v1), Code: **[https://github.com/megvii-basedetection/bevstereo](https://github.com/megvii-basedetection/bevstereo)**\n", "2209.10158": "- 2022-09-21, **Position-Aware Relation Learning for RGB-Thermal Salient Object Detection**, Heng Zhou et.al., Paper: [http://arxiv.org/abs/2209.10158v1](http://arxiv.org/abs/2209.10158v1)\n", "2209.10151": "- 2022-09-21, **Review On Deep Learning Technique For Underwater Object Detection**, Radhwan Adnan Dakhil et.al., Paper: [http://arxiv.org/abs/2209.10151v1](http://arxiv.org/abs/2209.10151v1)\n", "2209.11228": "- 2022-09-22, **NamedMask: Distilling Segmenters from Complementary Foundation Models**, Gyungin Shin et.al., Paper: [http://arxiv.org/abs/2209.11228v1](http://arxiv.org/abs/2209.11228v1), Code: **[https://github.com/noelshin/namedmask](https://github.com/noelshin/namedmask)**\n", "2209.11117": "- 2022-09-22, **Quantum illumination with multiplexed photodetection**, Hao Yang et.al., Paper: [http://arxiv.org/abs/2209.11117v1](http://arxiv.org/abs/2209.11117v1)\n", "2209.10904": "- 2022-09-22, **AcroFOD: An Adaptive Method for Cross-domain Few-shot Object Detection**, Yipeng Gao et.al., Paper: [http://arxiv.org/abs/2209.10904v1](http://arxiv.org/abs/2209.10904v1), Code: **[https://github.com/hlings/acrofod](https://github.com/hlings/acrofod)**\n", "2209.10733": "- 2022-09-22, **FusionRCNN: LiDAR-Camera Fusion for Two-stage 3D Object Detection**, Xinli Xu et.al., Paper: [http://arxiv.org/abs/2209.10733v1](http://arxiv.org/abs/2209.10733v1)\n", "2209.10710": "- 2022-09-21, **Visual Localization and Mapping in Dynamic and Changing Environments**, Jo\u00e3o Carlos Virgolino Soares et.al., Paper: [http://arxiv.org/abs/2209.10710v1](http://arxiv.org/abs/2209.10710v1)\n", "2209.11704": "- 2022-09-23, **UAV-miniUGV Hybrid System for Hidden Area Exploration and Manipulation**, Durgakant Pushp et.al., Paper: [http://arxiv.org/abs/2209.11704v1](http://arxiv.org/abs/2209.11704v1)\n", "2209.11559": "- 2022-09-23, **Query-based Hard-Image Retrieval for Object Detection at Test Time**, Edward Ayers et.al., Paper: [http://arxiv.org/abs/2209.11559v1](http://arxiv.org/abs/2209.11559v1), Code: **[https://github.com/fiveai/hardest](https://github.com/fiveai/hardest)**\n", "2209.11459": "- 2022-09-23, **TeST: Test-time Self-Training under Distribution Shift**, Samarth Sinha et.al., Paper: [http://arxiv.org/abs/2209.11459v1](http://arxiv.org/abs/2209.11459v1)\n", "2209.12880": "- 2022-09-26, **Center Feature Fusion: Selective Multi-Sensor Fusion of Center-based Objects**, Philip Jacobson et.al., Paper: [http://arxiv.org/abs/2209.12880v1](http://arxiv.org/abs/2209.12880v1)\n", "2209.12866": "- 2022-09-26, **SAPA: Similarity-Aware Point Affiliation for Feature Upsampling**, Hao Lu et.al., Paper: [http://arxiv.org/abs/2209.12866v1](http://arxiv.org/abs/2209.12866v1), Code: **[https://github.com/poppinace/sapa](https://github.com/poppinace/sapa)**\n", "2209.12836": "- 2022-09-26, **Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps**, Yue Hu et.al., Paper: [http://arxiv.org/abs/2209.12836v1](http://arxiv.org/abs/2209.12836v1), Code: **[https://github.com/mediabrain-sjtu/where2comm](https://github.com/mediabrain-sjtu/where2comm)**\n", "2209.12729": "- 2022-09-27, **DeepFusion: A Robust and Modular 3D Object Detector for Lidars, Cameras and Radars**, Florian Drews et.al., Paper: [http://arxiv.org/abs/2209.12729v2](http://arxiv.org/abs/2209.12729v2)\n", "2209.12447": "- 2022-09-26, **YOLO v3: Visual and Real-Time Object Detection Model for Smart Surveillance Systems(3s)**, Kanyifeechukwu Jane Oguine et.al., Paper: [http://arxiv.org/abs/2209.12447v1](http://arxiv.org/abs/2209.12447v1)\n", "2209.12419": "- 2022-09-26, **Feature-based model selection for object detection from point cloud data**, Kairi Tokuda et.al., Paper: [http://arxiv.org/abs/2209.12419v1](http://arxiv.org/abs/2209.12419v1)\n", "2209.12386": "- 2022-09-26, **TAD: A Large-Scale Benchmark for Traffic Accidents Detection from Video Surveillance**, Yajun Xu et.al., Paper: [http://arxiv.org/abs/2209.12386v1](http://arxiv.org/abs/2209.12386v1), Code: **[https://github.com/yajunbaby/tad-benchmark](https://github.com/yajunbaby/tad-benchmark)**\n", "2209.11785": "- 2022-09-23, **Tiered Pruning for Efficient Differentialble Inference-Aware Neural Architecture Search**, S\u0142awomir Kierat et.al., Paper: [http://arxiv.org/abs/2209.11785v1](http://arxiv.org/abs/2209.11785v1)\n", "2209.13507": "- 2022-09-27, **CrossDTR: Cross-view and Depth-guided Transformers for 3D Object Detection**, Ching-Yu Tseng et.al., Paper: [http://arxiv.org/abs/2209.13507v1](http://arxiv.org/abs/2209.13507v1), Code: **[https://github.com/sty61010/crossdtr](https://github.com/sty61010/crossdtr)**\n", "2209.13499": "- 2022-09-27, **Critical Evaluation of LOCO dataset with Machine Learning**, Recep Savas et.al., Paper: [http://arxiv.org/abs/2209.13499v1](http://arxiv.org/abs/2209.13499v1)\n", "2209.13369": "- 2022-09-27, **OBBStacking: An Ensemble Method for Remote Sensing Object Detection**, Haoning Lin et.al., Paper: [http://arxiv.org/abs/2209.13369v1](http://arxiv.org/abs/2209.13369v1), Code: **[https://github.com/haoning724/obbstacking](https://github.com/haoning724/obbstacking)**\n", "2209.13353": "- 2022-09-27, **Suppress with a Patch: Revisiting Universal Adversarial Patch Attacks against Object Detection**, Svetlana Pavlitskaya et.al., Paper: [http://arxiv.org/abs/2209.13353v1](http://arxiv.org/abs/2209.13353v1)\n", "2209.13351": "- 2022-09-27, **SuperYOLO: Super Resolution Assisted Object Detection in Multimodal Remote Sensing Imagery**, Jiaqing Zhang et.al., Paper: [http://arxiv.org/abs/2209.13351v1](http://arxiv.org/abs/2209.13351v1), Code: **[https://github.com/icey-zhang/SuperYOLO](https://github.com/icey-zhang/SuperYOLO)**\n", "2209.13306": "- 2022-09-27, **Embracing Consistency: A One-Stage Approach for Spatio-Temporal Video Grounding**, Yang Jin et.al., Paper: [http://arxiv.org/abs/2209.13306v1](http://arxiv.org/abs/2209.13306v1), Code: **[https://github.com/jy0205/stcat](https://github.com/jy0205/stcat)**\n", "2209.13232": "- 2022-09-27, **A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective**, Chaoqi Chen et.al., Paper: [http://arxiv.org/abs/2209.13232v1](http://arxiv.org/abs/2209.13232v1)\n", "2209.13222": "- 2022-09-27, **View-aware Salient Object Detection for 360\u00b0 Omnidirectional Image**, Junjie Wu et.al., Paper: [http://arxiv.org/abs/2209.13222v1](http://arxiv.org/abs/2209.13222v1)\n", "2209.13202": "- 2022-09-27, **A Novel Dataset for Evaluating and Alleviating Domain Shift for Human Detection in Agricultural Fields**, Paraskevi Nousi et.al., Paper: [http://arxiv.org/abs/2209.13202v1](http://arxiv.org/abs/2209.13202v1), Code: **[https://github.com/opendr-eu/datasets](https://github.com/opendr-eu/datasets)**\n", "2209.13156": "- 2022-09-27, **Towards Multimodal Multitask Scene Understanding Models for Indoor Mobile Agents**, Yao-Hung Hubert Tsai et.al., Paper: [http://arxiv.org/abs/2209.13156v1](http://arxiv.org/abs/2209.13156v1)\n", "2209.14262": "- 2022-09-28, **A Survey on Physical Adversarial Attack in Computer Vision**, Donghua Wang et.al., Paper: [http://arxiv.org/abs/2209.14262v1](http://arxiv.org/abs/2209.14262v1)\n", "2209.14225": "- 2022-09-28, **Road Rutting Detection using Deep Learning on Images**, Poonam Kumari Saha et.al., Paper: [http://arxiv.org/abs/2209.14225v1](http://arxiv.org/abs/2209.14225v1)\n", "2209.14201": "- 2022-09-28, **Spatial Pruned Sparse Convolution for Efficient 3D Object Detection**, Jianhui Liu et.al., Paper: [http://arxiv.org/abs/2209.14201v1](http://arxiv.org/abs/2209.14201v1)\n", "2209.13948": "- 2022-09-28, **Obj2Seq: Formatting Objects as Sequences with Class Prompt for Visual Tasks**, Zhiyang Chen et.al., Paper: [http://arxiv.org/abs/2209.13948v1](http://arxiv.org/abs/2209.13948v1), Code: **[https://github.com/casia-iva-lab/obj2seq](https://github.com/casia-iva-lab/obj2seq)**\n", "2209.13933": "- 2022-09-28, **DPNet: Dual-Path Network for Real-time Object Detection with Lightweight Attention**, Quan Zhou et.al., Paper: [http://arxiv.org/abs/2209.13933v1](http://arxiv.org/abs/2209.13933v1), Code: **[https://github.com/huiminshii/dpnet](https://github.com/huiminshii/dpnet)**\n", "2209.13801": "- 2022-09-28, **Translation, Scale and Rotation: Cross-Modal Alignment Meets RGB-Infrared Vehicle Detection**, Maoxun Yuan et.al., Paper: [http://arxiv.org/abs/2209.13801v1](http://arxiv.org/abs/2209.13801v1)\n", "2209.15001": "- 2022-09-29, **Dilated Neighborhood Attention Transformer**, Ali Hassani et.al., Paper: [http://arxiv.org/abs/2209.15001v1](http://arxiv.org/abs/2209.15001v1), Code: **[https://github.com/SHI-Labs/Neighborhood-Attention-Transformer](https://github.com/SHI-Labs/Neighborhood-Attention-Transformer)**\n", "2209.14965": "- 2022-09-29, **DirectTracker: 3D Multi-Object Tracking Using Direct Image Alignment and Photometric Bundle Adjustment**, Mariia Gladkova et.al., Paper: [http://arxiv.org/abs/2209.14965v1](http://arxiv.org/abs/2209.14965v1)\n", "2209.14922": "- 2022-09-29, **GDIP: Gated Differentiable Image Processing for Object-Detection in Adverse Conditions**, Sanket Kalwar et.al., Paper: [http://arxiv.org/abs/2209.14922v1](http://arxiv.org/abs/2209.14922v1), Code: **[https://github.com/gatedip/gdip-yolo](https://github.com/gatedip/gdip-yolo)**\n", "2209.14831": "- 2022-09-29, **Access Control with Encrypted Feature Maps for Object Detection Models**, Teru Nagamori et.al., Paper: [http://arxiv.org/abs/2209.14831v1](http://arxiv.org/abs/2209.14831v1)\n", "2209.14525": "- 2022-09-29, **Self-Configurable Stabilized Real-Time Detection Learning for Autonomous Driving Applications**, Won Joon Yun et.al., Paper: [http://arxiv.org/abs/2209.14525v1](http://arxiv.org/abs/2209.14525v1)\n", "2209.14454": "- 2022-09-28, **CompNet: A Designated Model to Handle Combinations of Images and Designed features**, Bowen Qiu et.al., Paper: [http://arxiv.org/abs/2209.14454v1](http://arxiv.org/abs/2209.14454v1)\n", "2209.14435": "- 2022-09-28, **Out-of-Distribution Detection for LiDAR-based 3D Object Detection**, Chengjie Huang et.al., Paper: [http://arxiv.org/abs/2209.14435v1](http://arxiv.org/abs/2209.14435v1)\n", "2209.15639": "- 2022-09-30, **F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models**, Weicheng Kuo et.al., Paper: [http://arxiv.org/abs/2209.15639v1](http://arxiv.org/abs/2209.15639v1)\n", "2209.15296": "- 2022-09-30, **Wake Word Detection Based on Res2Net**, Qiuchen Yu et.al., Paper: [http://arxiv.org/abs/2209.15296v1](http://arxiv.org/abs/2209.15296v1)\n", "2209.15258": "- 2022-09-30, **Transformers for Object Detection in Large Point Clouds**, Felicia Ruppel et.al., Paper: [http://arxiv.org/abs/2209.15258v1](http://arxiv.org/abs/2209.15258v1)\n", "2209.15252": "- 2022-09-30, **PointPillars Backbone Type Selection For Fast and Accurate LiDAR Object Detection**, Konrad Lis et.al., Paper: [http://arxiv.org/abs/2209.15252v1](http://arxiv.org/abs/2209.15252v1), Code: **[https://github.com/vision-agh/pointpillars_backbone](https://github.com/vision-agh/pointpillars_backbone)**\n", "2209.15084": "- 2022-09-29, **Automatic satellite building construction monitoring**, Insaf Ashrapov et.al., Paper: [http://arxiv.org/abs/2209.15084v1](http://arxiv.org/abs/2209.15084v1)\n", "2210.01035": "- 2022-10-03, **Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning**, Weicong Liang et.al., Paper: [http://arxiv.org/abs/2210.01035v1](http://arxiv.org/abs/2210.01035v1)\n", "2210.00975": "- 2022-10-03, **DOTIE -- Detecting Objects through Temporal Isolation of Events using a Spiking Architecture**, Manish Nagaraj et.al., Paper: [http://arxiv.org/abs/2210.00975v1](http://arxiv.org/abs/2210.00975v1)\n", "2210.00808": "- 2022-10-03, **A Multi Camera Unsupervised Domain Adaptation Pipeline for Object Detection in Cultural Sites through Adversarial Learning and Self-Training**, Giovanni Pasqualino et.al., Paper: [http://arxiv.org/abs/2210.00808v1](http://arxiv.org/abs/2210.00808v1), Code: **[https://github.com/fpv-iplab/STMDA-RetinaNet](https://github.com/fpv-iplab/STMDA-RetinaNet)**\n", "2210.00588": "- 2022-10-02, **DFA: Dynamic Feature Aggregation for Efficient Video Object Detection**, Yiming Cui et.al., Paper: [http://arxiv.org/abs/2210.00588v1](http://arxiv.org/abs/2210.00588v1)\n", "2210.00129": "- 2022-09-30, **An In-depth Study of Stochastic Backpropagation**, Jun Fang et.al., Paper: [http://arxiv.org/abs/2210.00129v1](http://arxiv.org/abs/2210.00129v1)\n", "2210.00087": "- 2022-09-30, **D-Align: Dual Query Co-attention Network for 3D Object Detection Based on Multi-frame Point Cloud Sequence**, Junhyung Lee et.al., Paper: [http://arxiv.org/abs/2210.00087v1](http://arxiv.org/abs/2210.00087v1)\n", "2210.01456": "- 2022-10-04, **Long-Term Localization using Semantic Cues in Floor Plan Maps**, Nicky Zimmerman et.al., Paper: [http://arxiv.org/abs/2210.01456v1](http://arxiv.org/abs/2210.01456v1)\n", "2210.01402": "- 2022-10-04, **Streaming Video Analytics On The Edge With Asynchronous Cloud Support**, Anurag Ghosh et.al., Paper: [http://arxiv.org/abs/2210.01402v1](http://arxiv.org/abs/2210.01402v1)\n", "2210.01391": "- 2022-10-04, **Bridged Transformer for Vision and Point Cloud 3D Object Detection**, Yikai Wang et.al., Paper: [http://arxiv.org/abs/2210.01391v1](http://arxiv.org/abs/2210.01391v1)\n", "2210.01325": "- 2022-10-04, **Automated Medical Device Display Reading Using Deep Learning Object Detection**, Lucas P. Moreira et.al., Paper: [http://arxiv.org/abs/2210.01325v1](http://arxiv.org/abs/2210.01325v1)\n", "2210.02443": "- 2022-10-05, **Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection**, Jinhyung Park et.al., Paper: [http://arxiv.org/abs/2210.02443v1](http://arxiv.org/abs/2210.02443v1), Code: **[https://github.com/divadi/solofusion](https://github.com/divadi/solofusion)**\n", "2210.02368": "- 2022-10-07, **Spatio-Temporal Learnable Proposals for End-to-End Video Object Detection**, Khurram Azeem Hashmi et.al., Paper: [http://arxiv.org/abs/2210.02368v2](http://arxiv.org/abs/2210.02368v2)\n", "2210.02093": "- 2022-10-05, **Centralized Feature Pyramid for Object Detection**, Yu Quan et.al., Paper: [http://arxiv.org/abs/2210.02093v1](http://arxiv.org/abs/2210.02093v1), Code: **[https://github.com/qy1994-0919/cfpnet](https://github.com/qy1994-0919/cfpnet)**\n", "2210.02088": "- 2022-10-05, **WUDA: Unsupervised Domain Adaptation Based on Weak Source Domain Labels**, Shengjie Liu et.al., Paper: [http://arxiv.org/abs/2210.02088v1](http://arxiv.org/abs/2210.02088v1)\n", "2210.02077": "- 2022-10-05, **Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders**, Youngwan Lee et.al., Paper: [http://arxiv.org/abs/2210.02077v1](http://arxiv.org/abs/2210.02077v1)\n", "2210.02021": "- 2022-10-05, **Exploring Effective Knowledge Transfer for Few-shot Object Detection**, Zhiyuan Zhao et.al., Paper: [http://arxiv.org/abs/2210.02021v1](http://arxiv.org/abs/2210.02021v1), Code: **[https://github.com/juliozhao97/efftrans_fsdet](https://github.com/juliozhao97/efftrans_fsdet)**\n", "2210.01857": "- 2022-10-04, **Centerpoints Are All You Need in Overhead Imagery**, James Mason Inder et.al., Paper: [http://arxiv.org/abs/2210.01857v1](http://arxiv.org/abs/2210.01857v1)\n", "2210.01820": "- 2022-10-04, **MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models**, Chenglin Yang et.al., Paper: [http://arxiv.org/abs/2210.01820v1](http://arxiv.org/abs/2210.01820v1)\n", "2210.03105": "- 2022-10-06, **Mask3D for 3D Semantic Instance Segmentation**, Jonas Schult et.al., Paper: [http://arxiv.org/abs/2210.03105v1](http://arxiv.org/abs/2210.03105v1), Code: **[https://github.com/jonasschult/mask3d](https://github.com/jonasschult/mask3d)**\n", "2210.02935": "- 2022-10-06, **A Review of Uncertainty Calibration in Pretrained Object Detectors**, Denis Huseljic et.al., Paper: [http://arxiv.org/abs/2210.02935v1](http://arxiv.org/abs/2210.02935v1), Code: **[https://github.com/ies-research/uncertainty-object-detection](https://github.com/ies-research/uncertainty-object-detection)**\n", "2210.02843": "- 2022-10-06, **CIR-Net: Cross-modality Interaction and Refinement for RGB-D Salient Object Detection**, Runmin Cong et.al., Paper: [http://arxiv.org/abs/2210.02843v1](http://arxiv.org/abs/2210.02843v1)\n", "2210.02808": "- 2022-10-06, **Effective Self-supervised Pre-training on Low-compute networks without Distillation**, Fuwen Tan et.al., Paper: [http://arxiv.org/abs/2210.02808v1](http://arxiv.org/abs/2210.02808v1)\n", "2210.02607": "- 2022-10-05, **Transferring dense object detection models to event-based data**, Vincenz Mechler et.al., Paper: [http://arxiv.org/abs/2210.02607v1](http://arxiv.org/abs/2210.02607v1)\n", "2210.02539": "- 2022-10-05, **Applications of object detection networks at high-power laser systems and experiments**, Jinpu Lin et.al., Paper: [http://arxiv.org/abs/2210.02539v1](http://arxiv.org/abs/2210.02539v1)\n", "2210.03686": "- 2022-10-07, **Humans need not label more humans: Occlusion Copy & Paste for Occluded Human Instance Segmentation**, Evan Ling et.al., Paper: [http://arxiv.org/abs/2210.03686v1](http://arxiv.org/abs/2210.03686v1), Code: **[https://github.com/levan92/occlusion-copy-paste](https://github.com/levan92/occlusion-copy-paste)**\n", "2210.03586": "- 2022-10-07, **An Investigation into Whitening Loss for Self-supervised Learning**, Xi Weng et.al., Paper: [http://arxiv.org/abs/2210.03586v1](http://arxiv.org/abs/2210.03586v1), Code: **[https://github.com/winci-ai/cw-rgp](https://github.com/winci-ai/cw-rgp)**\n", "2210.03570": "- 2022-10-07, **AI-Driven Road Maintenance Inspection v2: Reducing Data Dependency & Quantifying Road Damage**, Haris Iqbal et.al., Paper: [http://arxiv.org/abs/2210.03570v1](http://arxiv.org/abs/2210.03570v1)\n", "2210.03482": "- 2022-10-07, **CLAD: A realistic Continual Learning benchmark for Autonomous Driving**, Eli Verwimp et.al., Paper: [http://arxiv.org/abs/2210.03482v1](http://arxiv.org/abs/2210.03482v1), Code: **[https://github.com/VerwimpEli/CLAD](https://github.com/VerwimpEli/CLAD)**\n", "2210.03477": "- 2022-10-07, **IDa-Det: An Information Discrepancy-aware Distillation for 1-bit Detectors**, Sheng Xu et.al., Paper: [http://arxiv.org/abs/2210.03477v1](http://arxiv.org/abs/2210.03477v1), Code: **[https://github.com/stevetsui/ida-det](https://github.com/stevetsui/ida-det)**\n", "2210.03331": "- 2022-10-07, **Resolving Class Imbalance for LiDAR-based Object Detector by Dynamic Weight Average and Contextual Ground Truth Sampling**, Daeun Lee et.al., Paper: [http://arxiv.org/abs/2210.03331v1](http://arxiv.org/abs/2210.03331v1)\n", "2210.03249": "- 2022-10-06, **Joint Protection Scheme for Deep Neural Network Hardware Accelerators and Models**, Jingbo Zhou et.al., Paper: [http://arxiv.org/abs/2210.03249v1](http://arxiv.org/abs/2210.03249v1)\n", "2210.03205": "- 2022-10-10, **Synthetic Dataset Generation for Privacy-Preserving Machine Learning**, Efstathia Soufleri et.al., Paper: [http://arxiv.org/abs/2210.03205v2](http://arxiv.org/abs/2210.03205v2)\n", "2210.04868": "- 2022-10-10, **Deep object detection for waterbird monitoring using aerial imagery**, Krish Kabra et.al., Paper: [http://arxiv.org/abs/2210.04868v1](http://arxiv.org/abs/2210.04868v1), Code: **[https://github.com/riced2klab/audubon_f21](https://github.com/riced2klab/audubon_f21)**\n", "2210.04845": "- 2022-10-10, **FS-DETR: Few-Shot DEtection TRansformer with prompting and without re-training**, Adrian Bulat et.al., Paper: [http://arxiv.org/abs/2210.04845v1](http://arxiv.org/abs/2210.04845v1)\n", "2210.04801": "- 2022-10-10, **4D Unsupervised Object Discovery**, Yuqi Wang et.al., Paper: [http://arxiv.org/abs/2210.04801v1](http://arxiv.org/abs/2210.04801v1), Code: **[https://github.com/robertwyq/lsmol](https://github.com/robertwyq/lsmol)**\n", "2210.04735": "- 2022-10-10, **Edge Device Deployment of Multi-Tasking Network for Self-Driving Operations**, Shokhrukh Miraliev et.al., Paper: [http://arxiv.org/abs/2210.04735v1](http://arxiv.org/abs/2210.04735v1)\n", "2210.04574": "- 2022-10-10, **ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object Detection**, Rebbapragada V C Sairam et.al., Paper: [http://arxiv.org/abs/2210.04574v1](http://arxiv.org/abs/2210.04574v1)\n", "2210.04562": "- 2022-10-10, **Using Detection, Tracking and Prediction in Visual SLAM to Achieve Real-time Semantic Mapping of Dynamic Scenarios**, Xingyu Chen et.al., Paper: [http://arxiv.org/abs/2210.04562v1](http://arxiv.org/abs/2210.04562v1)\n", "2210.04331": "- 2022-10-09, **Students taught by multimodal teachers are superior action recognizers**, Gorjan Radevski et.al., Paper: [http://arxiv.org/abs/2210.04331v1](http://arxiv.org/abs/2210.04331v1)\n", "2210.04266": "- 2022-10-09, **Does Thermal Really Always Matter for RGB-T Salient Object Detection?**, Runmin Cong et.al., Paper: [http://arxiv.org/abs/2210.04266v1](http://arxiv.org/abs/2210.04266v1)\n", "2210.04264": "- 2022-10-09, **CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds**, Haiyang Wang et.al., Paper: [http://arxiv.org/abs/2210.04264v1](http://arxiv.org/abs/2210.04264v1), Code: **[https://github.com/haiyang-w/cagroup3d](https://github.com/haiyang-w/cagroup3d)**\n", "2210.04252": "- 2022-10-09, **Precise Single-stage Detector**, Aisha Chandio et.al., Paper: [http://arxiv.org/abs/2210.04252v1](http://arxiv.org/abs/2210.04252v1)\n", "2210.05593": "- 2022-10-11, **Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection**, Shizhen Zhao et.al., Paper: [http://arxiv.org/abs/2210.05593v1](http://arxiv.org/abs/2210.05593v1), Code: **[https://github.com/cvmi-lab/fs3d](https://github.com/cvmi-lab/fs3d)**\n", "2210.05568": "- 2022-10-11, **Improving Long-tailed Object Detection with Image-Level Supervision by Multi-Task Collaborative Learning**, Bo Li et.al., Paper: [http://arxiv.org/abs/2210.05568v1](http://arxiv.org/abs/2210.05568v1), Code: **[https://github.com/waveboo/clis](https://github.com/waveboo/clis)**\n", "2210.05566": "- 2022-10-11, **The Equalization Losses: Gradient-Driven Training for Long-tailed Object Recognition**, Jingru Tan et.al., Paper: [http://arxiv.org/abs/2210.05566v1](http://arxiv.org/abs/2210.05566v1), Code: **[https://github.com/modeltc/united-perception](https://github.com/modeltc/united-perception)**\n", "2210.05557": "- 2022-10-11, **OPERA: Omni-Supervised Representation Learning with Hierarchical Supervisions**, Chengkun Wang et.al., Paper: [http://arxiv.org/abs/2210.05557v1](http://arxiv.org/abs/2210.05557v1), Code: **[https://github.com/wangck20/opera](https://github.com/wangck20/opera)**\n", "2210.05311": "- 2022-10-11, **CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection**, Wuti Xiong et.al., Paper: [http://arxiv.org/abs/2210.05311v1](http://arxiv.org/abs/2210.05311v1), Code: **[https://github.com/fsod/cd-fsod](https://github.com/fsod/cd-fsod)**\n", "2210.05278": "- 2022-10-11, **EnsembleMOT: A Step towards Ensemble Learning of Multiple Object Tracking**, Yunhao Du et.al., Paper: [http://arxiv.org/abs/2210.05278v1](http://arxiv.org/abs/2210.05278v1), Code: **[https://github.com/dyhbupt/ensemblemot](https://github.com/dyhbupt/ensemblemot)**\n", "2210.05182": "- 2022-10-11, **Edge-Cloud Cooperation for DNN Inference via Reinforcement Learning and Supervised Learning**, Tinghao Zhang et.al., Paper: [http://arxiv.org/abs/2210.05182v1](http://arxiv.org/abs/2210.05182v1)\n", "2210.05171": "- 2022-10-11, **Deep Fourier Up-Sampling**, Man Zhou et.al., Paper: [http://arxiv.org/abs/2210.05171v1](http://arxiv.org/abs/2210.05171v1)\n", "2210.05018": "- 2022-10-10, **LidarNAS: Unifying and Searching Neural Architectures for 3D Point Clouds**, Chenxi Liu et.al., Paper: [http://arxiv.org/abs/2210.05018v1](http://arxiv.org/abs/2210.05018v1)\n", "2210.05008": "- 2022-10-10, **Fast Hierarchical Learning for Few-Shot Object Detection**, Yihang She et.al., Paper: [http://arxiv.org/abs/2210.05008v1](http://arxiv.org/abs/2210.05008v1)\n", "2210.06455": "- 2022-10-12, **Token-Label Alignment for Vision Transformers**, Han Xiao et.al., Paper: [http://arxiv.org/abs/2210.06455v1](http://arxiv.org/abs/2210.06455v1), Code: **[https://github.com/euphoria16/tl-align](https://github.com/euphoria16/tl-align)**\n", "2210.06433": "- 2022-10-12, **Self-supervised video pretraining yields strong image representations**, Nikhil Parthasarathy et.al., Paper: [http://arxiv.org/abs/2210.06433v1](http://arxiv.org/abs/2210.06433v1)\n", "2210.06409": "- 2022-10-12, **A Unified Framework with Meta-dropout for Few-shot Learning**, Shaobo Lin et.al., Paper: [http://arxiv.org/abs/2210.06409v1](http://arxiv.org/abs/2210.06409v1)\n", "2210.06361": "- 2022-10-12, **MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection**, Dehua Zheng et.al., Paper: [http://arxiv.org/abs/2210.06361v1](http://arxiv.org/abs/2210.06361v1)\n", "2210.06223": "- 2022-10-12, **Latency-aware Spatial-wise Dynamic Networks**, Yizeng Han et.al., Paper: [http://arxiv.org/abs/2210.06223v1](http://arxiv.org/abs/2210.06223v1), Code: **[https://github.com/leaplabthu/lasnet](https://github.com/leaplabthu/lasnet)**\n", "2210.06044": "- 2022-10-12, **Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning**, Fuying Wang et.al., Paper: [http://arxiv.org/abs/2210.06044v1](http://arxiv.org/abs/2210.06044v1)\n", "2210.06008": "- 2022-10-12, **BoxMask: Revisiting Bounding Box Supervision for Video Object Detection**, Khurram Azeem Hashmi et.al., Paper: [http://arxiv.org/abs/2210.06008v1](http://arxiv.org/abs/2210.06008v1)\n", "2210.05912": "- 2022-10-12, **PSNet: Parallel Symmetric Network for Video Salient Object Detection**, Runmin Cong et.al., Paper: [http://arxiv.org/abs/2210.05912v1](http://arxiv.org/abs/2210.05912v1)\n", "2210.05896": "- 2022-10-12, **Common Corruption Robustness of Point Cloud Detectors: Benchmark and Enhancement**, Shuangzhi Li et.al., Paper: [http://arxiv.org/abs/2210.05896v1](http://arxiv.org/abs/2210.05896v1)\n", "2210.05783": "- 2022-10-11, **Towards Discriminative and Transferable One-Stage Few-Shot Object Detectors**, Karim Guirguis et.al., Paper: [http://arxiv.org/abs/2210.05783v1](http://arxiv.org/abs/2210.05783v1)\n", "2210.07224": "- 2022-10-13, **Exploring Long-Sequence Masked Autoencoders**, Ronghang Hu et.al., Paper: [http://arxiv.org/abs/2210.07224v1](http://arxiv.org/abs/2210.07224v1), Code: **[https://github.com/facebookresearch/long_seq_mae](https://github.com/facebookresearch/long_seq_mae)**\n", "2210.07049": "- 2022-10-13, **Dimensionality of datasets in object detection networks**, Ajay Chawda et.al., Paper: [http://arxiv.org/abs/2210.07049v1](http://arxiv.org/abs/2210.07049v1)\n", "2210.06886": "- 2022-10-13, **ImaginaryNet: Learning Object Detectors without Real Images and Annotations**, Minheng Ni et.al., Paper: [http://arxiv.org/abs/2210.06886v1](http://arxiv.org/abs/2210.06886v1), Code: **[https://github.com/kodenii/imaginarynet](https://github.com/kodenii/imaginarynet)**\n", "2210.06742": "- 2022-10-13, **H2RBox: Horizonal Box Annotation is All You Need for Oriented Object Detection**, Xue Yang et.al., Paper: [http://arxiv.org/abs/2210.06742v1](http://arxiv.org/abs/2210.06742v1), Code: **[https://github.com/yangxue0827/h2rbox-mmrotate](https://github.com/yangxue0827/h2rbox-mmrotate)**\n", "2210.06682": "- 2022-10-13, **Application-Driven AI Paradigm for Hand-Held Action Detection**, Kohou Wang et.al., Paper: [http://arxiv.org/abs/2210.06682v1](http://arxiv.org/abs/2210.06682v1)\n", "2210.06984": "- 2022-10-12, **QDTrack: Quasi-Dense Similarity Learning for Appearance-Only Multiple Object Tracking**, Tobias Fischer et.al., Paper: [http://arxiv.org/abs/2210.06984v1](http://arxiv.org/abs/2210.06984v1)\n", "2210.07920": "- 2022-10-14, **MOVE: Unsupervised Movable Object Segmentation and Detection**, Adam Bielski et.al., Paper: [http://arxiv.org/abs/2210.07920v1](http://arxiv.org/abs/2210.07920v1)\n", "2210.07811": "- 2022-10-17, **SAILOR: Scaling Anchors via Insights into Latent Object Representation**, Du\u0161an Mali\u0107 et.al., Paper: [http://arxiv.org/abs/2210.07811v2](http://arxiv.org/abs/2210.07811v2), Code: **[https://github.com/malicd/sailor](https://github.com/malicd/sailor)**\n", "2210.07372": "- 2022-10-13, **SWFormer: Sparse Window Transformer for 3D Object Detection in Point Clouds**, Pei Sun et.al., Paper: [http://arxiv.org/abs/2210.07372v1](http://arxiv.org/abs/2210.07372v1)\n", "2210.09267": "- 2022-10-18, **CramNet: Camera-Radar Fusion with Ray-Constrained Cross-Attention for Robust 3D Object Detection**, Jyh-Jing Hwang et.al., Paper: [http://arxiv.org/abs/2210.09267v2](http://arxiv.org/abs/2210.09267v2)\n", "2210.09263": "- 2022-10-17, **Vision-Language Pre-training: Basics, Recent Advances, and Future Trends**, Zhe Gan et.al., Paper: [http://arxiv.org/abs/2210.09263v1](http://arxiv.org/abs/2210.09263v1)\n", "2210.09224": "- 2022-10-17, **Self-Supervised Learning Through Efference Copies**, Franz Scherr et.al., Paper: [http://arxiv.org/abs/2210.09224v1](http://arxiv.org/abs/2210.09224v1)\n", "2210.09022": "- 2022-10-17, **Distilling Object Detectors With Global Knowledge**, Sanli Tang et.al., Paper: [http://arxiv.org/abs/2210.09022v1](http://arxiv.org/abs/2210.09022v1), Code: **[https://github.com/hikvision-research/davar-lab-ml](https://github.com/hikvision-research/davar-lab-ml)**\n", "2210.08870": "- 2022-10-17, **Differential Evolution based Dual Adversarial Camouflage: Fooling Human Eyes and Object Detectors**, Jialiang Sun et.al., Paper: [http://arxiv.org/abs/2210.08870v1](http://arxiv.org/abs/2210.08870v1)\n", "2210.08748": "- 2022-10-17, **Dual-Curriculum Teacher for Domain-Inconsistent Object Detection in Autonomous Driving**, Longhui Yu et.al., Paper: [http://arxiv.org/abs/2210.08748v1](http://arxiv.org/abs/2210.08748v1)\n", "2210.08738": "- 2022-10-17, **PCGen: Point Cloud Generator for LiDAR Simulation**, Chenqi Li et.al., Paper: [http://arxiv.org/abs/2210.08738v1](http://arxiv.org/abs/2210.08738v1)\n", "2210.08734": "- 2022-10-17, **How many radiographs are needed to re-train a deep learning system for object detection?**, Raniere Silva et.al., Paper: [http://arxiv.org/abs/2210.08734v1](http://arxiv.org/abs/2210.08734v1)\n", "2210.08715": "- 2022-10-17, **ReAFFPN: Rotation-equivariant Attention Feature Fusion Pyramid Networks for Aerial Object Detection**, Chongyu Sun et.al., Paper: [http://arxiv.org/abs/2210.08715v1](http://arxiv.org/abs/2210.08715v1)\n", "2210.08648": "- 2022-10-16, **AttTrack: Online Deep Attention Transfer for Multi-object Tracking**, Keivan Nalaie et.al., Paper: [http://arxiv.org/abs/2210.08648v1](http://arxiv.org/abs/2210.08648v1)\n", "2210.10046": "- 2022-10-18, **A Tri-Layer Plugin to Improve Occluded Detection**, Guanqi Zhan et.al., Paper: [http://arxiv.org/abs/2210.10046v1](http://arxiv.org/abs/2210.10046v1), Code: **[https://github.com/Championchess/Tri-Layer_Plugin_Occluded_Detection](https://github.com/Championchess/Tri-Layer_Plugin_Occluded_Detection)**\n", "2210.09739": "- 2022-10-18, **Real-Time Multi-Modal Semantic Fusion on Unmanned Aerial Vehicles with Label Propagation for Cross-Domain Adaptation**, Simon Bultmann et.al., Paper: [http://arxiv.org/abs/2210.09739v1](http://arxiv.org/abs/2210.09739v1)\n", "2210.09678": "- 2022-10-18, **Virtual Reality via Object Poses and Active Learning: Realizing Telepresence Robots with Aerial Manipulation Capabilities**, Jongseok Lee et.al., Paper: [http://arxiv.org/abs/2210.09678v1](http://arxiv.org/abs/2210.09678v1)\n", "2210.09629": "- 2022-10-18, **1st Place Solutions for the UVO Challenge 2022**, Jiajun Zhang et.al., Paper: [http://arxiv.org/abs/2210.09629v1](http://arxiv.org/abs/2210.09629v1)\n", "2210.09618": "- 2022-10-18, **Object Recognition in Different Lighting Conditions at Various Angles by Deep Learning Method**, Imran Khan Mirani et.al., Paper: [http://arxiv.org/abs/2210.09618v1](http://arxiv.org/abs/2210.09618v1)\n", "2210.09615": "- 2022-10-18, **Homogeneous Multi-modal Feature Fusion and Interaction for 3D Object Detection**, Xin Li et.al., Paper: [http://arxiv.org/abs/2210.09615v1](http://arxiv.org/abs/2210.09615v1)\n", "2210.09482": "- 2022-10-18, **You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks**, Yulong Cao et.al., Paper: [http://arxiv.org/abs/2210.09482v1](http://arxiv.org/abs/2210.09482v1)\n", "2210.09446": "- 2022-10-17, **Deformably-Scaled Transposed Convolution**, Stefano B. Blumberg et.al., Paper: [http://arxiv.org/abs/2210.09446v1](http://arxiv.org/abs/2210.09446v1)\n", "2210.10774": "- 2022-10-19, **Learning to Discover and Detect Objects**, Vladimir Fomenko et.al., Paper: [http://arxiv.org/abs/2210.10774v1](http://arxiv.org/abs/2210.10774v1), Code: **[https://github.com/vlfom/rncdl](https://github.com/vlfom/rncdl)**\n", "2210.10716": "- 2022-10-19, **CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion**, Philippe Weinzaepfel et.al., Paper: [http://arxiv.org/abs/2210.10716v1](http://arxiv.org/abs/2210.10716v1)\n", "2210.10298": "- 2022-10-19, **Evaluation Metrics for Object Detection for Autonomous Systems**, Apurva Badithela et.al., Paper: [http://arxiv.org/abs/2210.10298v1](http://arxiv.org/abs/2210.10298v1)\n", "2210.10263": "- 2022-10-19, **Time and Cost-Efficient Bathymetric Mapping System using Sparse Point Cloud Generation and Automatic Object Detection**, Andres Pulido et.al., Paper: [http://arxiv.org/abs/2210.10263v1](http://arxiv.org/abs/2210.10263v1)\n", "2210.10260": "- 2022-10-19, **End-to-End Entity Detection with Proposer and Regressor**, Xueru Wen et.al., Paper: [http://arxiv.org/abs/2210.10260v1](http://arxiv.org/abs/2210.10260v1), Code: **[https://github.com/Rosenberg37/EntityDetection](https://github.com/Rosenberg37/EntityDetection)**\n", "2210.10249": "- 2022-10-19, **Discovering Limitations of Image Quality Assessments with Noised Deep Learning Image Sets**, Wei Dai et.al., Paper: [http://arxiv.org/abs/2210.10249v1](http://arxiv.org/abs/2210.10249v1)\n", "2210.10226": "- 2022-10-19, **A Real-Time Wrong-Way Vehicle Detection Based on YOLO and Centroid Tracking**, Zillur Rahman et.al., Paper: [http://arxiv.org/abs/2210.10226v1](http://arxiv.org/abs/2210.10226v1)\n", "2210.10221": "- 2022-10-19, **Non-iterative optimization of pseudo-labeling thresholds for training object detection models from multiple datasets**, Yuki Tanaka et.al., Paper: [http://arxiv.org/abs/2210.10221v1](http://arxiv.org/abs/2210.10221v1)\n", "2210.10180": "- 2022-10-18, **Domain Adaptation in 3D Object Detection with Gradual Batch Alternation Training**, Mrigank Rochan et.al., Paper: [http://arxiv.org/abs/2210.10180v1](http://arxiv.org/abs/2210.10180v1)\n", "2210.11464": "- 2022-10-20, **Self-Supervised Learning via Maximum Entropy Coding**, Xin Liu et.al., Paper: [http://arxiv.org/abs/2210.11464v1](http://arxiv.org/abs/2210.11464v1), Code: **[https://github.com/xinliu20/mec](https://github.com/xinliu20/mec)**\n", "2210.11456": "- 2022-10-20, **MixMask: Revisiting Masked Siamese Self-supervised Learning in Asymmetric Distance**, Kirill Vishniakov et.al., Paper: [http://arxiv.org/abs/2210.11456v1](http://arxiv.org/abs/2210.11456v1)\n", "2210.11173": "- 2022-10-20, **Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem**, Albert Xu et.al., Paper: [http://arxiv.org/abs/2210.11173v1](http://arxiv.org/abs/2210.11173v1)\n", "2210.11078": "- 2022-10-20, **Large-batch Optimization for Dense Visual Predictions**, Zeyue Xue et.al., Paper: [http://arxiv.org/abs/2210.11078v1](http://arxiv.org/abs/2210.11078v1), Code: **[https://github.com/sense-x/agvm](https://github.com/sense-x/agvm)**\n", "2210.10998": "- 2022-10-20, **Semi-supervised object detection based on single-stage detector for thighbone fracture localization**, Jinman Wei et.al., Paper: [http://arxiv.org/abs/2210.10998v1](http://arxiv.org/abs/2210.10998v1)\n", "2210.10983": "- 2022-10-20, **PSA-Det3D: Pillar Set Abstraction for 3D object Detection**, Zhicong Huang et.al., Paper: [http://arxiv.org/abs/2210.10983v1](http://arxiv.org/abs/2210.10983v1)\n", "2210.10959": "- 2022-10-21, **Uni6Dv3: 5D Anchor Mechanism for 6D Pose Estimation**, Jianqiu Chen et.al., Paper: [http://arxiv.org/abs/2210.10959v2](http://arxiv.org/abs/2210.10959v2)\n", "2210.10842": "- 2022-10-19, **MMRNet: Improving Reliability for Multimodal Computer Vision for Bin Picking via Multimodal Redundancy**, Yuhao Chen et.al., Paper: [http://arxiv.org/abs/2210.10842v1](http://arxiv.org/abs/2210.10842v1)\n", "2210.11939": "- 2022-10-21, **Automatic Cattle Identification using YOLOv5 and Mosaic Augmentation: A Comparative Analysis**, Rabin Dulal et.al., Paper: [http://arxiv.org/abs/2210.11939v1](http://arxiv.org/abs/2210.11939v1)\n", "2210.11815": "- 2022-10-21, **Self-Supervised Pretraining on Satellite Imagery: a Case Study on Label-Efficient Vehicle Detection**, Jules BOURCIER et.al., Paper: [http://arxiv.org/abs/2210.11815v1](http://arxiv.org/abs/2210.11815v1)\n", "2210.11590": "- 2022-10-20, **XC: Exploring Quantitative Use Cases for Explanations in 3D Object Detection**, Sunsheng Gu et.al., Paper: [http://arxiv.org/abs/2210.11590v1](http://arxiv.org/abs/2210.11590v1), Code: **[https://github.com/sunshenggu/xc_eval_pcdet](https://github.com/sunshenggu/xc_eval_pcdet)**\n", "2210.11539": "- 2022-10-20, **ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing**, Giulio Mattolin et.al., Paper: [http://arxiv.org/abs/2210.11539v1](http://arxiv.org/abs/2210.11539v1), Code: **[https://github.com/giuliomattolin/confmix](https://github.com/giuliomattolin/confmix)**\n", "2210.13296": "- 2022-10-24, **Semantic Image Segmentation with Deep Learning for Vine Leaf Phenotyping**, Petros N. Tamvakis et.al., Paper: [http://arxiv.org/abs/2210.13296v1](http://arxiv.org/abs/2210.13296v1)\n", "2210.13053": "- 2022-10-24, **Foreground Guidance and Multi-Layer Feature Fusion for Unsupervised Object Discovery with Transformers**, Zhiwei Lin et.al., Paper: [http://arxiv.org/abs/2210.13053v1](http://arxiv.org/abs/2210.13053v1), Code: **[https://github.com/vdigpku/formula](https://github.com/vdigpku/formula)**\n", "2210.12989": "- 2022-10-24, **Robust Object Detection in Remote Sensing Imagery with Noisy and Sparse Geo-Annotations (Full Version)**, Maximilian Bernhard et.al., Paper: [http://arxiv.org/abs/2210.12989v1](http://arxiv.org/abs/2210.12989v1), Code: **[https://github.com/mxbh/robust_object_detection](https://github.com/mxbh/robust_object_detection)**\n", "2210.12918": "- 2022-10-24, **Unsupervised Object Representation Learning using Translation and Rotation Group Equivariant VAE**, Alireza Nasiri et.al., Paper: [http://arxiv.org/abs/2210.12918v1](http://arxiv.org/abs/2210.12918v1), Code: **[https://github.com/smlc-nysbc/target-vae](https://github.com/smlc-nysbc/target-vae)**\n", "2210.12878": "- 2022-10-23, **IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes**, Shubham Dokania et.al., Paper: [http://arxiv.org/abs/2210.12878v1](http://arxiv.org/abs/2210.12878v1)\n", "2210.12755": "- 2022-10-23, **LCPFormer: Towards Effective 3D Point Cloud Analysis via Local Context Propagation in Transformers**, Zhuoxu Huang et.al., Paper: [http://arxiv.org/abs/2210.12755v1](http://arxiv.org/abs/2210.12755v1)\n", "2210.12682": "- 2022-10-23, **Photo-realistic Neural Domain Randomization**, Sergey Zakharov et.al., Paper: [http://arxiv.org/abs/2210.12682v1](http://arxiv.org/abs/2210.12682v1)\n", "2210.12596": "- 2022-10-23, **DMODE: Differential Monocular Object Distance Estimation Module without Class Specific Information**, Pedram Agand et.al., Paper: [http://arxiv.org/abs/2210.12596v1](http://arxiv.org/abs/2210.12596v1), Code: **[https://github.com/anonym-paper/dmode](https://github.com/anonym-paper/dmode)**\n", "2210.13923": "- 2022-10-25, **A Comparative Attention Framework for Better Few-Shot Object Detection on Aerial Images**, Pierre Le Jeune et.al., Paper: [http://arxiv.org/abs/2210.13923v1](http://arxiv.org/abs/2210.13923v1)\n", "2210.13835": "- 2022-10-25, **Synthetic Data Supervised Salient Object Detection**, Zhenyu Wu et.al., Paper: [http://arxiv.org/abs/2210.13835v1](http://arxiv.org/abs/2210.13835v1), Code: **[https://github.com/wuzhenyubuaa/sodgan](https://github.com/wuzhenyubuaa/sodgan)**\n", "2210.13821": "- 2022-10-25, **Salient Object Detection via Dynamic Scale Routing**, Zhenyu Wu et.al., Paper: [http://arxiv.org/abs/2210.13821v1](http://arxiv.org/abs/2210.13821v1), Code: **[https://github.com/wuzhenyubuaa/dpnet](https://github.com/wuzhenyubuaa/dpnet)**\n", "2210.13567": "- 2022-10-24, **I see what you hear: a vision-inspired method to localize words**, Mohammad Samragh et.al., Paper: [http://arxiv.org/abs/2210.13567v1](http://arxiv.org/abs/2210.13567v1)\n", "2210.13488": "- 2022-10-24, **LidarAugment: Searching for Scalable 3D LiDAR Data Augmentations**, Zhaoqi Leng et.al., Paper: [http://arxiv.org/abs/2210.13488v1](http://arxiv.org/abs/2210.13488v1)\n", "2210.14391": "- 2022-10-26, **Can Transformer Attention Spread Give Insights Into Uncertainty of Detected and Tracked Objects?**, Felicia Ruppel et.al., Paper: [http://arxiv.org/abs/2210.14391v1](http://arxiv.org/abs/2210.14391v1)\n", "2210.14318": "- 2022-10-25, **Object recognition in atmospheric turbulence scenes**, Disen Hu et.al., Paper: [http://arxiv.org/abs/2210.14318v1](http://arxiv.org/abs/2210.14318v1), Code: **[https://github.com/disen-hu/fasterrcnn_fpn_dcn](https://github.com/disen-hu/fasterrcnn_fpn_dcn)**\n", "2210.15632": "- 2022-10-27, **Aerial Manipulation Using a Novel Unmanned Aerial Vehicle Cyber-Physical System**, Caiwu Ding et.al., Paper: [http://arxiv.org/abs/2210.15632v1](http://arxiv.org/abs/2210.15632v1)\n", "2210.15586": "- 2022-10-27, **Joint Multi-Person Body Detection and Orientation Estimation via One Unified Embedding**, Huayi Zhou et.al., Paper: [http://arxiv.org/abs/2210.15586v1](http://arxiv.org/abs/2210.15586v1), Code: **[https://github.com/hnuzhy/jointbdoe](https://github.com/hnuzhy/jointbdoe)**\n", "2210.15392": "- 2022-10-27, **LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise**, He Tang et.al., Paper: [http://arxiv.org/abs/2210.15392v1](http://arxiv.org/abs/2210.15392v1)\n", "2210.15365": "- 2022-10-27, **Li3DeTr: A LiDAR based 3D Detection Transformer**, Gopi Krishna Erabati et.al., Paper: [http://arxiv.org/abs/2210.15365v1](http://arxiv.org/abs/2210.15365v1)\n", "2210.15316": "- 2022-10-27, **MSF3DDETR: Multi-Sensor Fusion 3D Detection Transformer for Autonomous Driving**, Gopi Krishna Erabati et.al., Paper: [http://arxiv.org/abs/2210.15316v1](http://arxiv.org/abs/2210.15316v1)\n", "2210.15176": "- 2022-10-27, **Domain Adaptive Object Detection for Autonomous Driving under Foggy Weather**, Jinlong Li et.al., Paper: [http://arxiv.org/abs/2210.15176v1](http://arxiv.org/abs/2210.15176v1), Code: **[https://github.com/jinlong17/da-detect](https://github.com/jinlong17/da-detect)**\n", "2210.14997": "- 2022-10-26, **LiDAR-guided object search and detection in Subterranean Environments**, Manthan Patel et.al., Paper: [http://arxiv.org/abs/2210.14997v1](http://arxiv.org/abs/2210.14997v1)\n", "2210.14981": "- 2022-10-26, **Fast and Efficient Scene Categorization for Autonomous Driving using VAEs**, Saravanabalagi Ramachandran et.al., Paper: [http://arxiv.org/abs/2210.14981v1](http://arxiv.org/abs/2210.14981v1)\n", "2210.14910": "- 2022-10-26, **The eyes and hearts of UAV pilots: observations of physiological responses in real-life scenarios**, Alexandre Duval et.al., Paper: [http://arxiv.org/abs/2210.14910v1](http://arxiv.org/abs/2210.14910v1)\n", "2210.16204": "- 2022-10-28, **TripletTrack: 3D Object Tracking using Triplet Embeddings and LSTM**, Nicola Marinello et.al., Paper: [http://arxiv.org/abs/2210.16204v1](http://arxiv.org/abs/2210.16204v1)\n", "2210.16083": "- 2022-10-28, **ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy**, JunKyu Lee et.al., Paper: [http://arxiv.org/abs/2210.16083v1](http://arxiv.org/abs/2210.16083v1)\n", "2210.15999": "- 2022-10-28, **Benchmarking performance of object detection under image distortions in an uncontrolled environment**, Ayman Beghdadi et.al., Paper: [http://arxiv.org/abs/2210.15999v1](http://arxiv.org/abs/2210.15999v1), Code: **[https://github.com/aymanbegh/benchmarking-performance](https://github.com/aymanbegh/benchmarking-performance)**\n", "2210.15996": "- 2022-10-28, **Towards Few-Shot Open-Set Object Detection**, Binyi Su et.al., Paper: [http://arxiv.org/abs/2210.15996v1](http://arxiv.org/abs/2210.15996v1), Code: **[https://github.com/binyisu/fsosod](https://github.com/binyisu/fsosod)**\n", "2210.15943": "- 2022-10-28, **Grafting Vision Transformers**, Jongwoo Park et.al., Paper: [http://arxiv.org/abs/2210.15943v1](http://arxiv.org/abs/2210.15943v1)\n", "2210.15933": "- 2022-10-28, **PSFormer: Point Transformer for 3D Salient Object Detection**, Baian Chen et.al., Paper: [http://arxiv.org/abs/2210.15933v1](http://arxiv.org/abs/2210.15933v1)\n", "2210.15760": "- 2022-10-27, **Towards Improving Workers' Safety and Progress Monitoring of Construction Sites Through Construction Site Understanding**, Mahdi Bonyani et.al., Paper: [http://arxiv.org/abs/2210.15760v1](http://arxiv.org/abs/2210.15760v1)\n", "2210.16101": "- 2022-10-27, **Layer-wise Shared Attention Network on Dynamical System Perspective**, Zhongzhan Huang et.al., Paper: [http://arxiv.org/abs/2210.16101v1](http://arxiv.org/abs/2210.16101v1)\n", "2210.17252": "- 2022-10-31, **Multi-Camera Calibration Free BEV Representation for 3D Object Detection**, Hongxiang Jiang et.al., Paper: [http://arxiv.org/abs/2210.17252v1](http://arxiv.org/abs/2210.17252v1)\n", "2210.17151": "- 2022-10-31, **Tech Report: One-stage Lightweight Object Detectors**, Deokki Hong et.al., Paper: [http://arxiv.org/abs/2210.17151v1](http://arxiv.org/abs/2210.17151v1)\n", "2210.16901": "- 2022-10-30, **Foreign Object Debris Detection for Airport Pavement Images based on Self-supervised Localization and Vision Transformer**, Travis Munyer et.al., Paper: [http://arxiv.org/abs/2210.16901v1](http://arxiv.org/abs/2210.16901v1)\n", "2210.16897": "- 2022-10-30, **Time-rEversed diffusioN tEnsor Transformer: A new TENET of Few-Shot Object Detection**, Shan Zhang et.al., Paper: [http://arxiv.org/abs/2210.16897v1](http://arxiv.org/abs/2210.16897v1), Code: **[https://github.com/zs123-lang/tenet](https://github.com/zs123-lang/tenet)**\n", "2210.16810": "- 2022-10-30, **SL3D: Self-supervised-Self-labeled 3D Recognition**, Fernando Julio Cendra et.al., Paper: [http://arxiv.org/abs/2210.16810v1](http://arxiv.org/abs/2210.16810v1), Code: **[https://github.com/fcendra/sl3d](https://github.com/fcendra/sl3d)**\n", "2210.16742": "- 2022-10-30, **On-the-fly Object Detection using StyleGAN with CLIP Guidance**, Yuzhe Lu et.al., Paper: [http://arxiv.org/abs/2210.16742v1](http://arxiv.org/abs/2210.16742v1)\n", "2210.16574": "- 2022-10-29, **Boosting Monocular 3D Object Detection with Object-Centric Auxiliary Depth Supervision**, Youngseok Kim et.al., Paper: [http://arxiv.org/abs/2210.16574v1](http://arxiv.org/abs/2210.16574v1)\n", "2210.16561": "- 2022-10-29, **iSmallNet: Densely Nested Network with Label Decoupling for Infrared Small Target Detection**, Zhiheng Hu et.al., Paper: [http://arxiv.org/abs/2210.16561v1](http://arxiv.org/abs/2210.16561v1)\n", "2210.16476": "- 2022-10-29, **Pair DETR: Contrastive Learning Speeds Up DETR Training**, Mehdi Iranmanesh et.al., Paper: [http://arxiv.org/abs/2210.16476v1](http://arxiv.org/abs/2210.16476v1)\n", "2210.16472": "- 2022-10-29, **Learning Audio-Visual Dynamics Using Scene Graphs for Audio Source Separation**, Moitreya Chatterjee et.al., Paper: [http://arxiv.org/abs/2210.16472v1](http://arxiv.org/abs/2210.16472v1)\n", "2211.01254": "- 2022-11-02, **CircleSnake: Instance Segmentation with Circle Representation**, Ethan H. Nguyen et.al., Paper: [http://arxiv.org/abs/2211.01254v1](http://arxiv.org/abs/2211.01254v1), Code: **[https://github.com/hrlblab/circlesnake](https://github.com/hrlblab/circlesnake)**\n", "2211.01226": "- 2022-11-03, **DEArt: Dataset of European Art**, Artem Reshetnikov et.al., Paper: [http://arxiv.org/abs/2211.01226v2](http://arxiv.org/abs/2211.01226v2)\n", "2211.01142": "- 2022-11-02, **OPA-3D: Occlusion-Aware Pixel-Wise Aggregation for Monocular 3D Object Detection**, Yongzhi Su et.al., Paper: [http://arxiv.org/abs/2211.01142v1](http://arxiv.org/abs/2211.01142v1)\n", "2211.01098": "- 2022-11-02, **Semantic SuperPoint: A Deep Semantic Descriptor**, Gabriel S. Gama et.al., Paper: [http://arxiv.org/abs/2211.01098v1](http://arxiv.org/abs/2211.01098v1), Code: **[https://github.com/gabriel-sgama/semantic-superpoint](https://github.com/gabriel-sgama/semantic-superpoint)**\n", "2211.01080": "- 2022-11-02, **Spatial Reasoning for Few-Shot Object Detection**, Geonuk Kim et.al., Paper: [http://arxiv.org/abs/2211.01080v1](http://arxiv.org/abs/2211.01080v1)\n", "2211.00868": "- 2022-11-02, **tSF: Transformer-based Semantic Filter for Few-Shot Learning**, Jinxiang Lai et.al., Paper: [http://arxiv.org/abs/2211.00868v1](http://arxiv.org/abs/2211.00868v1)\n", "2211.00849": "- 2022-11-02, **P$^3$OVD: Fine-grained Visual-Text Prompt-Driven Self-Training for Open-Vocabulary Object Detection**, Yanxin Long et.al., Paper: [http://arxiv.org/abs/2211.00849v1](http://arxiv.org/abs/2211.00849v1)\n", "2211.00826": "- 2022-11-02, **TSAA: A Two-Stage Anchor Assignment Method towards Anchor Drift in Crowded Object Detection**, Li Xiang et.al., Paper: [http://arxiv.org/abs/2211.00826v1](http://arxiv.org/abs/2211.00826v1)\n", "2211.00746": "- 2022-11-01, **3DMODT: Attention-Guided Affinities for Joint Detection & Tracking in 3D Point Clouds**, Jyoti Kini et.al., Paper: [http://arxiv.org/abs/2211.00746v1](http://arxiv.org/abs/2211.00746v1)\n", "2211.00733": "- 2022-11-01, **State-of-the-art Models for Object Detection in Various Fields of Application**, Syed Ali John Naqvi et.al., Paper: [http://arxiv.org/abs/2211.00733v1](http://arxiv.org/abs/2211.00733v1)\n", "2211.02043": "- 2022-11-03, **Could Giant Pretrained Image Models Extract Universal Representations?**, Yutong Lin et.al., Paper: [http://arxiv.org/abs/2211.02043v1](http://arxiv.org/abs/2211.02043v1)\n", "2211.02006": "- 2022-11-03, **SAP-DETR: Bridging the Gap Between Salient Points and Queries-Based Transformer Detector for Fast Model Convergency**, Yang Liu et.al., Paper: [http://arxiv.org/abs/2211.02006v1](http://arxiv.org/abs/2211.02006v1)\n", "2211.01778": "- 2022-11-03, **Progressive Transformation Learning For Leveraging Virtual Images in Training**, Yi-Ting Shen et.al., Paper: [http://arxiv.org/abs/2211.01778v1](http://arxiv.org/abs/2211.01778v1)\n", "2211.01664": "- 2022-11-03, **PointSee: Image Enhances Point Cloud**, Lipeng Gu et.al., Paper: [http://arxiv.org/abs/2211.01664v1](http://arxiv.org/abs/2211.01664v1)\n", "2211.01556": "- 2022-11-03, **Ground Plane Matters: Picking Up Ground Plane Prior in Monocular 3D Object Detection**, Fan Yang et.al., Paper: [http://arxiv.org/abs/2211.01556v1](http://arxiv.org/abs/2211.01556v1)\n", "2211.02386": "- 2022-11-04, **PP-YOLOE-R: An Efficient Anchor-Free Rotated Object Detector**, Xinxin Wang et.al., Paper: [http://arxiv.org/abs/2211.02386v1](http://arxiv.org/abs/2211.02386v1), Code: **[https://github.com/PaddlePaddle/Paddle](https://github.com/PaddlePaddle/Paddle)**\n", "2211.02239": "- 2022-11-04, **Towards Asteroid Detection in Microlensing Surveys with Deep Learning**, Preeti Cowan et.al., Paper: [http://arxiv.org/abs/2211.02239v1](http://arxiv.org/abs/2211.02239v1)\n", "2211.02219": "- 2022-11-04, **Understanding and Mitigating Overfitting in Prompt Tuning for Vision-Language Models**, Chengcheng Ma et.al., Paper: [http://arxiv.org/abs/2211.02219v1](http://arxiv.org/abs/2211.02219v1), Code: **[https://github.com/machengcheng2016/Subspace-Prompt-Learning](https://github.com/machengcheng2016/Subspace-Prompt-Learning)**\n", "2211.02213": "- 2022-11-04, **SSDA-YOLO: Semi-supervised Domain Adaptive YOLO for Cross-Domain Object Detection**, Huayi Zhou et.al., Paper: [http://arxiv.org/abs/2211.02213v1](http://arxiv.org/abs/2211.02213v1), Code: **[https://github.com/hnuzhy/ssda-yolo](https://github.com/hnuzhy/ssda-yolo)**\n", "2211.02185": "- 2022-11-03, **Deep Learning based Defect classification and detection in SEM images: A Mask R-CNN approach**, Bappaditya Dey et.al., Paper: [http://arxiv.org/abs/2211.02185v1](http://arxiv.org/abs/2211.02185v1)\n", "2211.02128": "- 2022-11-03, **Efficient Information Sharing in ICT Supply Chain Social Network via Table Structure Recognition**, Bin Xiao et.al., Paper: [http://arxiv.org/abs/2211.02128v1](http://arxiv.org/abs/2211.02128v1)\n", "2211.03594": "- 2022-11-07, **Group DETR v2: Strong Object Detector with Encoder-Decoder Pretraining**, Qiang Chen et.al., Paper: [http://arxiv.org/abs/2211.03594v1](http://arxiv.org/abs/2211.03594v1)\n", "2211.03407": "- 2022-11-07, **3D Harmonic Loss: Towards Task-consistent and Time-friendly 3D Object Detection on Edge for Intelligent Transportation System**, Haolin Zhang et.al., Paper: [http://arxiv.org/abs/2211.03407v1](http://arxiv.org/abs/2211.03407v1), Code: **[https://github.com/XJTU-Haolin/TT3D](https://github.com/XJTU-Haolin/TT3D)**\n", "2211.03402": "- 2022-11-07, **PeSOTIF: a Challenging Visual Dataset for Perception SOTIF Problems in Long-tail Traffic Scenarios**, Liang Peng et.al., Paper: [http://arxiv.org/abs/2211.03402v1](http://arxiv.org/abs/2211.03402v1), Code: **[https://github.com/sotif-avlab/pesotif](https://github.com/sotif-avlab/pesotif)**\n", "2211.03295": "- 2022-11-07, **Efficient Multi-order Gated Aggregation Network**, Siyuan Li et.al., Paper: [http://arxiv.org/abs/2211.03295v1](http://arxiv.org/abs/2211.03295v1), Code: **[https://github.com/Westlake-AI/openmixup](https://github.com/Westlake-AI/openmixup)**\n", "2211.02972": "- 2022-11-05, **Inside Out: Transforming Images of Lab-Grown Plants for Machine Learning Applications in Agriculture**, A. E. Krosney et.al., Paper: [http://arxiv.org/abs/2211.02972v1](http://arxiv.org/abs/2211.02972v1)\n", "2211.02791": "- 2022-11-05, **Multi-Objective Evolutionary for Object Detection Mobile Architectures Search**, Haichao Zhang et.al., Paper: [http://arxiv.org/abs/2211.02791v1](http://arxiv.org/abs/2211.02791v1)\n", "2211.04656": "- 2022-11-10, **MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification**, Daniel Davila et.al., Paper: [http://arxiv.org/abs/2211.04656v2](http://arxiv.org/abs/2211.04656v2)\n", "2211.04557": "- 2022-11-08, **Estimation of Appearance and Occupancy Information in Birds Eye View from Surround Monocular Images**, Sarthak Sharma et.al., Paper: [http://arxiv.org/abs/2211.04557v1](http://arxiv.org/abs/2211.04557v1)\n", "2211.05580": "- 2022-11-10, **Hyperbolic Cosine Transformer for LiDAR 3D Object Detection**, Jigang Tong et.al., Paper: [http://arxiv.org/abs/2211.05580v1](http://arxiv.org/abs/2211.05580v1)\n", "2211.05229": "- 2022-11-07, **Automatic Number Plate Recognition (ANPR) with YOLOv3-CNN**, Rajdeep Adak et.al., Paper: [http://arxiv.org/abs/2211.05229v1](http://arxiv.org/abs/2211.05229v1)\n", "2211.06368": "- 2022-11-11, **Phase-Shifting Coder: Predicting Accurate Orientation in Oriented Object Detection**, Yi Yu et.al., Paper: [http://arxiv.org/abs/2211.06368v1](http://arxiv.org/abs/2211.06368v1), Code: **[https://github.com/open-mmlab/mmrotate](https://github.com/open-mmlab/mmrotate)**\n", "2211.06308": "- 2022-11-11, **Sensor Visibility Estimation: Metrics and Methods for Systematic Performance Evaluation and Improvement**, Joachim B\u00f6rger et.al., Paper: [http://arxiv.org/abs/2211.06308v1](http://arxiv.org/abs/2211.06308v1)\n", "2211.06241": "- 2022-11-11, **A Benchmark for Out of Distribution Detection in Point Cloud 3D Semantic Segmentation**, Lokesh Veeramacheneni et.al., Paper: [http://arxiv.org/abs/2211.06241v1](http://arxiv.org/abs/2211.06241v1)\n", "2211.06163": "- 2022-11-11, **Dual Complementary Dynamic Convolution for Image Recognition**, Longbin Yan et.al., Paper: [http://arxiv.org/abs/2211.06163v1](http://arxiv.org/abs/2211.06163v1)\n", "2211.06108": "- 2022-11-11, **RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System**, Yanlong Yang et.al., Paper: [http://arxiv.org/abs/2211.06108v1](http://arxiv.org/abs/2211.06108v1)\n", "2211.06097": "- 2022-11-11, **Interactive Context-Aware Network for RGB-T Salient Object Detection**, Yuxuan Wang et.al., Paper: [http://arxiv.org/abs/2211.06097v1](http://arxiv.org/abs/2211.06097v1)\n", "2211.06004": "- 2022-11-11, **A Comprehensive Survey of Transformers for Computer Vision**, Sonain Jamil et.al., Paper: [http://arxiv.org/abs/2211.06004v1](http://arxiv.org/abs/2211.06004v1)\n", "2211.05805": "- 2022-11-10, **Impact of Video Compression on the Performance of Object Detection Systems for Surveillance Applications**, Michael O'Byrne et.al., Paper: [http://arxiv.org/abs/2211.05805v1](http://arxiv.org/abs/2211.05805v1)\n", "2211.07636": "- 2022-11-14, **EVA: Exploring the Limits of Masked Visual Representation Learning at Scale**, Yuxin Fang et.al., Paper: [http://arxiv.org/abs/2211.07636v1](http://arxiv.org/abs/2211.07636v1), Code: **[https://github.com/baaivision/eva](https://github.com/baaivision/eva)**\n", "2211.07546": "- 2022-11-14, **Marine Microalgae Detection in Microscopy Images: A New Dataset**, Shizheng Zhou et.al., Paper: [http://arxiv.org/abs/2211.07546v1](http://arxiv.org/abs/2211.07546v1)\n", "2211.07521": "- 2022-11-14, **PKCAM: Previous Knowledge Channel Attention Module**, Eslam Mohamed Bakar et.al., Paper: [http://arxiv.org/abs/2211.07521v1](http://arxiv.org/abs/2211.07521v1), Code: **[https://github.com/eslambakr/emca](https://github.com/eslambakr/emca)**\n", "2211.07501": "- 2022-11-14, **Discovering a Variety of Objects in Spatio-Temporal Human-Object Interactions**, Yong-Lu Li et.al., Paper: [http://arxiv.org/abs/2211.07501v1](http://arxiv.org/abs/2211.07501v1), Code: **[https://github.com/dirtyharrylyl/hake-ava](https://github.com/dirtyharrylyl/hake-ava)**\n", "2211.07483": "- 2022-11-14, **Butterfly Effect Attack: Tiny and Seemingly Unrelated Perturbations for Object Detection**, Nguyen Anh Vu Doan et.al., Paper: [http://arxiv.org/abs/2211.07483v1](http://arxiv.org/abs/2211.07483v1)\n", "2211.07254": "- 2022-11-14, **The Role of Local Alignment and Uniformity in Image-Text Contrastive Learning on Medical Images**, Philip M\u00fcller et.al., Paper: [http://arxiv.org/abs/2211.07254v1](http://arxiv.org/abs/2211.07254v1)\n", "2211.07214": "- 2022-11-14, **Robust Collaborative 3D Object Detection in Presence of Pose Errors**, Yifan Lu et.al., Paper: [http://arxiv.org/abs/2211.07214v1](http://arxiv.org/abs/2211.07214v1)\n", "2211.07171": "- 2022-11-14, **Cross-Modality Knowledge Distillation Network for Monocular 3D Object Detection**, Yu Hong et.al., Paper: [http://arxiv.org/abs/2211.07171v1](http://arxiv.org/abs/2211.07171v1), Code: **[https://github.com/Cc-Hy/CMKD](https://github.com/Cc-Hy/CMKD)**\n", "2211.07108": "- 2022-11-14, **Recursive Cross-View: Use Only 2D Detectors to Achieve 3D Object Detection without 3D Annotations**, Shun Gui et.al., Paper: [http://arxiv.org/abs/2211.07108v1](http://arxiv.org/abs/2211.07108v1)\n", "2211.07084": "- 2022-11-14, **Boosting Semi-Supervised 3D Object Detection with Semi-Sampling**, Xiaopei Wu et.al., Paper: [http://arxiv.org/abs/2211.07084v1](http://arxiv.org/abs/2211.07084v1)\n", "2211.08287": "- 2022-11-15, **Towards 3D Object Detection with 2D Supervision**, Jinrong Yang et.al., Paper: [http://arxiv.org/abs/2211.08287v1](http://arxiv.org/abs/2211.08287v1)\n", "2211.08248": "- 2022-11-15, **3D Cascade RCNN: High Quality Object Detection in Point Clouds**, Qi Cai et.al., Paper: [http://arxiv.org/abs/2211.08248v1](http://arxiv.org/abs/2211.08248v1), Code: **[https://github.com/caiqi/cascasde-3d](https://github.com/caiqi/cascasde-3d)**\n", "2211.08071": "- 2022-11-15, **Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling**, Yu Wang et.al., Paper: [http://arxiv.org/abs/2211.08071v1](http://arxiv.org/abs/2211.08071v1)\n", "2211.08055": "- 2022-11-15, **PAI3D: Painting Adaptive Instance-Prior for 3D Object Detection**, Hao Liu et.al., Paper: [http://arxiv.org/abs/2211.08055v1](http://arxiv.org/abs/2211.08055v1)\n", "2211.07860": "- 2022-11-15, **Enabling AI Quality Control via Feature Hierarchical Edge Inference**, Jinhyuk Choi et.al., Paper: [http://arxiv.org/abs/2211.07860v1](http://arxiv.org/abs/2211.07860v1)\n", "2211.07859": "- 2022-11-15, **Local Magnification for Data and Feature Augmentation**, Kun He et.al., Paper: [http://arxiv.org/abs/2211.07859v1](http://arxiv.org/abs/2211.07859v1)\n", "2211.09022": "- 2022-11-16, **Region Proposal Network Pre-Training Helps Label-Efficient Object Detection**, Linus Ericsson et.al., Paper: [http://arxiv.org/abs/2211.09022v1](http://arxiv.org/abs/2211.09022v1)\n", "2211.08859": "- 2022-11-16, **Attacking Object Detector Using A Universal Targeted Label-Switch Patch**, Avishag Shapira et.al., Paper: [http://arxiv.org/abs/2211.08859v1](http://arxiv.org/abs/2211.08859v1)\n", "2211.08837": "- 2022-11-16, **RF-Annotate: Automatic RF-Supervised Image Annotation of Common Objects in Context**, Emerson Sie et.al., Paper: [http://arxiv.org/abs/2211.08837v1](http://arxiv.org/abs/2211.08837v1)\n", "2211.08824": "- 2022-11-16, **SMILEtrack: SiMIlarity LEarning for Multiple Object Tracking**, Yu-Hsiang Wang et.al., Paper: [http://arxiv.org/abs/2211.08824v1](http://arxiv.org/abs/2211.08824v1)\n", "2211.08724": "- 2022-11-16, **PAANet:Visual Perception based Four-stage Framework for Salient Object Detection using High-order Contrast Operator**, Yanbo Yuan et.al., Paper: [http://arxiv.org/abs/2211.08724v1](http://arxiv.org/abs/2211.08724v1)\n", "2211.08705": "- 2022-11-16, **Resource Allocation of Federated Learning for the Metaverse with Mobile Augmented Reality**, Xinyu Zhou et.al., Paper: [http://arxiv.org/abs/2211.08705v1](http://arxiv.org/abs/2211.08705v1)\n", "2211.08504": "- 2022-11-15, **APT: Adaptive Perceptual quality based camera Tuning using reinforcement learning**, Sibendu Paul et.al., Paper: [http://arxiv.org/abs/2211.08504v1](http://arxiv.org/abs/2211.08504v1)\n", "2211.08479": "- 2022-11-15, **Context-Matched Collage Generation for Underwater Invertebrate Detection**, R. Austin McEver et.al., Paper: [http://arxiv.org/abs/2211.08479v1](http://arxiv.org/abs/2211.08479v1)\n", "2211.08469": "- 2022-11-15, **Deep learning for table detection and structure recognition: A survey**, Mahmoud Kasem et.al., Paper: [http://arxiv.org/abs/2211.08469v1](http://arxiv.org/abs/2211.08469v1)\n", "2211.09807": "- 2022-11-17, **Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information**, Weijie Su et.al., Paper: [http://arxiv.org/abs/2211.09807v1](http://arxiv.org/abs/2211.09807v1)\n", "2211.09791": "- 2022-11-17, **MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors**, Yuang Zhang et.al., Paper: [http://arxiv.org/abs/2211.09791v1](http://arxiv.org/abs/2211.09791v1), Code: **[https://github.com/megvii-research/MOTRv2](https://github.com/megvii-research/MOTRv2)**\n", "2211.09788": "- 2022-11-17, **DiffusionDet: Diffusion Model for Object Detection**, Shoufa Chen et.al., Paper: [http://arxiv.org/abs/2211.09788v1](http://arxiv.org/abs/2211.09788v1), Code: **[https://github.com/shoufachen/diffusiondet](https://github.com/shoufachen/diffusiondet)**\n", "2211.09708": "- 2022-11-17, **Sources of performance variability in deep learning-based polyp detection**, Thuy Nuong Tran et.al., Paper: [http://arxiv.org/abs/2211.09708v1](http://arxiv.org/abs/2211.09708v1)\n", "2211.09663": "- 2022-11-17, **Multi-Camera Multi-Object Tracking on the Move via Single-Stage Global Association Approach**, Pha Nguyen et.al., Paper: [http://arxiv.org/abs/2211.09663v1](http://arxiv.org/abs/2211.09663v1)\n", "2211.09529": "- 2022-11-17, **InternVideo-Ego4D: A Pack of Champion Solutions to Ego4D Challenges**, Guo Chen et.al., Paper: [http://arxiv.org/abs/2211.09529v1](http://arxiv.org/abs/2211.09529v1), Code: **[https://github.com/opengvlab/ego4d-eccv2022-solutions](https://github.com/opengvlab/ego4d-eccv2022-solutions)**\n", "2211.09518": "- 2022-11-17, **ImLiDAR: Cross-Sensor Dynamic Message Propagation Network for 3D Object Detection**, Yiyang Shen et.al., Paper: [http://arxiv.org/abs/2211.09518v1](http://arxiv.org/abs/2211.09518v1)\n", "2211.09445": "- 2022-11-17, **aiMotive Dataset: A Multimodal Dataset for Robust Autonomous Driving with Long-Range Perception**, Tam\u00e1s Matuszka et.al., Paper: [http://arxiv.org/abs/2211.09445v1](http://arxiv.org/abs/2211.09445v1), Code: **[https://github.com/aimotive/aimotive_dataset](https://github.com/aimotive/aimotive_dataset)**\n", "2211.09386": "- 2022-11-17, **BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection**, Zehui Chen et.al., Paper: [http://arxiv.org/abs/2211.09386v1](http://arxiv.org/abs/2211.09386v1), Code: **[https://github.com/zehuichen123/bevdistill](https://github.com/zehuichen123/bevdistill)**\n", "2211.09321": "- 2022-11-17, **Interpretable Dimensionality Reduction by Feature Preserving Manifold Approximation and Projection**, Yang Yang et.al., Paper: [http://arxiv.org/abs/2211.09321v1](http://arxiv.org/abs/2211.09321v1)\n", "2211.10156": "- 2022-11-17, **DETRDistill: A Universal Knowledge Distillation Framework for DETR-families**, Jiahao Chang et.al., Paper: [http://arxiv.org/abs/2211.10156v1](http://arxiv.org/abs/2211.10156v1)\n", "2211.11682": "- 2022-11-21, **PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning**, Xiangyang Zhu et.al., Paper: [http://arxiv.org/abs/2211.11682v1](http://arxiv.org/abs/2211.11682v1), Code: **[https://github.com/yangyangyang127/pointclip_v2](https://github.com/yangyangyang127/pointclip_v2)**\n", "2211.11647": "- 2022-11-21, **Benchmarking Edge Computing Devices for Grape Bunches and Trunks Detection using Accelerated Object Detection Single Shot MultiBox Deep Learning Models**, Sandro Costa Magalh\u00e3es et.al., Paper: [http://arxiv.org/abs/2211.11647v1](http://arxiv.org/abs/2211.11647v1)\n", "2211.11646": "- 2022-11-21, **NeRF-RPN: A general framework for object detection in NeRFs**, Benran Hu et.al., Paper: [http://arxiv.org/abs/2211.11646v1](http://arxiv.org/abs/2211.11646v1)\n", "2211.11612": "- 2022-11-21, **Plug and Play Active Learning for Object Detection**, Chenhongyi Yang et.al., Paper: [http://arxiv.org/abs/2211.11612v1](http://arxiv.org/abs/2211.11612v1), Code: **[https://github.com/chenhongyiyang/ppal](https://github.com/chenhongyiyang/ppal)**\n", "2211.11530": "- 2022-11-21, **Open-Set Object Detection Using Classification-free Object Proposal and Instance-level Contrastive Learning with Appendix**, Zhongxiang Zhou et.al., Paper: [http://arxiv.org/abs/2211.11530v1](http://arxiv.org/abs/2211.11530v1)\n", "2211.11426": "- 2022-11-21, **Revealing Hidden Context Bias in Segmentation and Object Detection through Concept-specific Explanations**, Maximilian Dreyer et.al., Paper: [http://arxiv.org/abs/2211.11426v1](http://arxiv.org/abs/2211.11426v1)\n", "2211.11188": "- 2022-11-21, **Simultaneous Multiple Object Detection and Pose Estimation using 3D Model Infusion with Monocular Vision**, Congliang Li et.al., Paper: [http://arxiv.org/abs/2211.11188v1](http://arxiv.org/abs/2211.11188v1), Code: **[https://github.com/CongliangLi/LabelImg3D](https://github.com/CongliangLi/LabelImg3D)**\n", "2211.11077": "- 2022-11-20, **A Unified Model for Tracking and Image-Video Detection Has More Power**, Peirong Liu et.al., Paper: [http://arxiv.org/abs/2211.11077v1](http://arxiv.org/abs/2211.11077v1)\n", "2211.10995": "- 2022-11-20, **Distinctive Fire and Smoke Detection with Self-Similar**, Zeyu Shangguan et.al., Paper: [http://arxiv.org/abs/2211.10995v1](http://arxiv.org/abs/2211.10995v1)\n", "2211.10850": "- 2022-11-20, **Context-Aware Data Augmentation for LIDAR 3D Object Detection**, Xuzhong Hu et.al., Paper: [http://arxiv.org/abs/2211.10850v1](http://arxiv.org/abs/2211.10850v1)\n", "2211.12501": "- 2022-11-22, **AeDet: Azimuth-invariant Multi-view 3D Object Detection**, Chengjian Feng et.al., Paper: [http://arxiv.org/abs/2211.12501v1](http://arxiv.org/abs/2211.12501v1), Code: **[https://github.com/fcjian/AeDet](https://github.com/fcjian/AeDet)**\n", "2211.12324": "- 2022-11-22, **Pushing the Limits of Asynchronous Graph-based Object Detection with Event Cameras**, Daniel Gehrig et.al., Paper: [http://arxiv.org/abs/2211.12324v1](http://arxiv.org/abs/2211.12324v1)\n", "2211.12110": "- 2022-11-22, **Improving Crowded Object Detection via Copy-Paste**, Jiangfan Deng et.al., Paper: [http://arxiv.org/abs/2211.12110v1](http://arxiv.org/abs/2211.12110v1)\n", "2211.12108": "- 2022-11-22, **Explaining YOLO: Leveraging Grad-CAM to Explain Object Detections**, Armin Kirchknopf et.al., Paper: [http://arxiv.org/abs/2211.12108v1](http://arxiv.org/abs/2211.12108v1)\n", "2211.12089": "- 2022-11-22, **Ultrasound Detection of Subquadricipital Recess Distension**, Marco Colussi et.al., Paper: [http://arxiv.org/abs/2211.12089v1](http://arxiv.org/abs/2211.12089v1)\n", "2211.12048": "- 2022-11-22, **Global-Local Aggregation with Deformable Point Sampling for Camouflaged Object Detection**, Minhyeok Lee et.al., Paper: [http://arxiv.org/abs/2211.12048v1](http://arxiv.org/abs/2211.12048v1)\n", "2211.12040": "- 2022-11-22, **Rethinking Implicit Neural Representations for vision Learners**, Yiran Song et.al., Paper: [http://arxiv.org/abs/2211.12040v1](http://arxiv.org/abs/2211.12040v1)\n", "2211.12009": "- 2022-11-22, **Deep-Learning-Based Computer Vision Approach For The Segmentation Of Ball Deliveries And Tracking In Cricket**, Kumail Abbas et.al., Paper: [http://arxiv.org/abs/2211.12009v1](http://arxiv.org/abs/2211.12009v1), Code: **[https://github.com/theimad/cricket-image-segmentation](https://github.com/theimad/cricket-image-segmentation)**\n", "2211.12006": "- 2022-11-22, **Differentiable Fuzzy $\\mathcal{ALC}$: A Neural-Symbolic Representation Language for Symbol Grounding**, Xuan Wu et.al., Paper: [http://arxiv.org/abs/2211.12006v1](http://arxiv.org/abs/2211.12006v1)\n", "2211.11962": "- 2022-11-22, **Transformation-Equivariant 3D Object Detection for Autonomous Driving**, Hai Wu et.al., Paper: [http://arxiv.org/abs/2211.11962v1](http://arxiv.org/abs/2211.11962v1)\n", "2211.13228": "- 2022-11-23, **Self-Supervised Learning based on Heat Equation**, Yinpeng Chen et.al., Paper: [http://arxiv.org/abs/2211.13228v1](http://arxiv.org/abs/2211.13228v1)\n", "2211.13194": "- 2022-11-23, **Indian Commercial Truck License Plate Detection and Recognition for Weighbridge Automation**, Siddharth Agrawal et.al., Paper: [http://arxiv.org/abs/2211.13194v1](http://arxiv.org/abs/2211.13194v1)\n", "2211.13133": "- 2022-11-23, **Structural Knowledge Distillation for Object Detection**, Philip de Rijk et.al., Paper: [http://arxiv.org/abs/2211.13133v1](http://arxiv.org/abs/2211.13133v1)\n", "2211.13067": "- 2022-11-23, **Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection**, Tianyu Wang et.al., Paper: [http://arxiv.org/abs/2211.13067v1](http://arxiv.org/abs/2211.13067v1)\n", "2211.12941": "- 2022-11-23, **EurNet: Efficient Multi-Range Relational Modeling of Spatial Multi-Relational Data**, Minghao Xu et.al., Paper: [http://arxiv.org/abs/2211.12941v1](http://arxiv.org/abs/2211.12941v1), Code: **[https://github.com/hirl-team/eurnet-image](https://github.com/hirl-team/eurnet-image)**\n", "2211.12870": "- 2022-11-23, **ActMAD: Activation Matching to Align Distributions for Test-Time-Training**, Muhammad Jehanzeb Mirza et.al., Paper: [http://arxiv.org/abs/2211.12870v1](http://arxiv.org/abs/2211.12870v1)\n", "2211.12735": "- 2022-11-23, **Integrally Pre-Trained Transformer Pyramid Networks**, Yunjie Tian et.al., Paper: [http://arxiv.org/abs/2211.12735v1](http://arxiv.org/abs/2211.12735v1), Code: **[https://github.com/sunsmarterjie/itpn](https://github.com/sunsmarterjie/itpn)**\n", "2211.12698": "- 2022-11-23, **Rega-Net:Retina Gabor Attention for Deep Convolutional Neural Networks**, Chun Bao et.al., Paper: [http://arxiv.org/abs/2211.12698v1](http://arxiv.org/abs/2211.12698v1)\n", "2211.14255": "- 2022-11-25, **Degenerate Swin to Win: Plain Window-based Transformer without Sophisticated Operations**, Tan Yu et.al., Paper: [http://arxiv.org/abs/2211.14255v1](http://arxiv.org/abs/2211.14255v1)\n", "2211.14125": "- 2022-11-25, **PoET: Pose Estimation Transformer for Single-View, Multi-Object 6D Pose Estimation**, Thomas Jantos et.al., Paper: [http://arxiv.org/abs/2211.14125v1](http://arxiv.org/abs/2211.14125v1), Code: **[https://github.com/aau-cns/poet](https://github.com/aau-cns/poet)**\n", "2211.14091": "- 2022-11-25, **Language-Assisted 3D Feature Learning for Semantic Scene Understanding**, Junbo Zhang et.al., Paper: [http://arxiv.org/abs/2211.14091v1](http://arxiv.org/abs/2211.14091v1), Code: **[https://github.com/asterisci/language-assisted-3d](https://github.com/asterisci/language-assisted-3d)**\n", "2211.14054": "- 2022-11-25, **CAD2Render: A Modular Toolkit for GPU-accelerated Photorealistic Synthetic Data Generation for the Manufacturing Industry**, Steven Moonen et.al., Paper: [http://arxiv.org/abs/2211.14054v1](http://arxiv.org/abs/2211.14054v1), Code: **[https://github.com/edm-research/cad2render](https://github.com/edm-research/cad2render)**\n", "2211.13993": "- 2022-11-25, **Combating noisy labels in object detection datasets**, Krystian Chachu\u0142a et.al., Paper: [http://arxiv.org/abs/2211.13993v1](http://arxiv.org/abs/2211.13993v1)\n", "2211.13859": "- 2022-11-25, **DATE: Dual Assignment for End-to-End Fully Convolutional Object Detection**, Yiqun Chen et.al., Paper: [http://arxiv.org/abs/2211.13859v1](http://arxiv.org/abs/2211.13859v1), Code: **[https://github.com/yiqunchen1999/date](https://github.com/yiqunchen1999/date)**\n", "2211.13529": "- 2022-11-24, **3D Dual-Fusion: Dual-Domain Dual-Query Camera-LiDAR Fusion for 3D Object Detection**, Yecheol Kim et.al., Paper: [http://arxiv.org/abs/2211.13529v1](http://arxiv.org/abs/2211.13529v1)\n", "2211.13523": "- 2022-11-24, **Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark**, Floriana Ciaglia et.al., Paper: [http://arxiv.org/abs/2211.13523v1](http://arxiv.org/abs/2211.13523v1), Code: **[https://github.com/roboflow-ai/roboflow-100-benchmark](https://github.com/roboflow-ai/roboflow-100-benchmark)**\n", "2211.13508": "- 2022-11-24, **1st Workshop on Maritime Computer Vision (MaCVi) 2023: Challenge Results**, Benjamin Kiefer et.al., Paper: [http://arxiv.org/abs/2211.13508v1](http://arxiv.org/abs/2211.13508v1)\n", "2211.13495": "- 2022-11-24, **Few-shot Object Detection with Refined Contrastive Learning**, Zeyu Shangguan et.al., Paper: [http://arxiv.org/abs/2211.13495v1](http://arxiv.org/abs/2211.13495v1)\n", "2211.15516": "- 2022-11-30, **DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding**, Shilong Liu et.al., Paper: [http://arxiv.org/abs/2211.15516v2](http://arxiv.org/abs/2211.15516v2), Code: **[https://github.com/idea-research/dq-detr](https://github.com/idea-research/dq-detr)**\n", "2211.15505": "- 2022-11-28, **Object Permanence in Object Detection Leveraging Temporal Priors at Inference Time**, Michael F\u00fcrst et.al., Paper: [http://arxiv.org/abs/2211.15505v1](http://arxiv.org/abs/2211.15505v1)\n", "2211.14905": "- 2022-11-27, **Multi-Modal Few-Shot Temporal Action Detection via Vision-Language Meta-Adaptation**, Sauradip Nag et.al., Paper: [http://arxiv.org/abs/2211.14905v1](http://arxiv.org/abs/2211.14905v1)\n", "2211.14843": "- 2022-11-27, **Learning Object-Language Alignments for Open-Vocabulary Object Detection**, Chuang Lin et.al., Paper: [http://arxiv.org/abs/2211.14843v1](http://arxiv.org/abs/2211.14843v1), Code: **[https://github.com/clin1223/vldet](https://github.com/clin1223/vldet)**\n", "2211.14782": "- 2022-11-27, **Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection**, Xiaonan Lu et.al., Paper: [http://arxiv.org/abs/2211.14782v1](http://arxiv.org/abs/2211.14782v1)\n", "2211.14710": "- 2022-11-27, **3D Point Positional Encoding for Multi-Camera 3D Object Detection Transformers**, Changyong Shu et.al., Paper: [http://arxiv.org/abs/2211.14710v1](http://arxiv.org/abs/2211.14710v1)\n", "2211.14467": "- 2022-11-26, **Self-Supervised Surgical Instrument 3D Reconstruction from a Single Camera Image**, Ange Lou et.al., Paper: [http://arxiv.org/abs/2211.14467v1](http://arxiv.org/abs/2211.14467v1)\n", "2211.14461": "- 2022-11-26, **CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion**, Zixiang Zhao et.al., Paper: [http://arxiv.org/abs/2211.14461v1](http://arxiv.org/abs/2211.14461v1)\n", "2211.14419": "- 2022-11-26, **Panoramic Video Salient Object Detection with Ambisonic Audio Guidance**, Xiang Li et.al., Paper: [http://arxiv.org/abs/2211.14419v1](http://arxiv.org/abs/2211.14419v1)\n", "2211.14395": "- 2022-11-25, **Deep Learning Training Procedure Augmentations**, Cristian Simionescu et.al., Paper: [http://arxiv.org/abs/2211.14395v1](http://arxiv.org/abs/2211.14395v1)\n", "2211.16066": "- 2022-11-29, **Analysis of Training Object Detection Models with Synthetic Data**, Bram Vanherle et.al., Paper: [http://arxiv.org/abs/2211.16066v1](http://arxiv.org/abs/2211.16066v1), Code: **[https://github.com/edm-research/dimo_objectdetection](https://github.com/edm-research/dimo_objectdetection)**\n", "2211.15766": "- 2022-11-28, **Superpoint Transformer for 3D Scene Instance Segmentation**, Jiahao Sun et.al., Paper: [http://arxiv.org/abs/2211.15766v1](http://arxiv.org/abs/2211.15766v1), Code: **[https://github.com/sunjiahao1999/spformer](https://github.com/sunjiahao1999/spformer)**\n", "2211.17170": "- 2022-11-30, **How to Train an Accurate and Efficient Object Detection Model on Any Dataset**, Galina Zalesskaya et.al., Paper: [http://arxiv.org/abs/2211.17170v1](http://arxiv.org/abs/2211.17170v1), Code: **[https://github.com/openvinotoolkit/training_extensions](https://github.com/openvinotoolkit/training_extensions)**\n", "2211.17126": "- 2022-11-30, **Multi-latent Space Alignments for Unsupervised Domain Adaptation in Multi-view 3D Object Detection**, Jiaming Liu et.al., Paper: [http://arxiv.org/abs/2211.17126v1](http://arxiv.org/abs/2211.17126v1)\n", "2211.16785": "- 2022-11-30, **SafeSpace MFNet: Precise and Efficient MultiFeature Drone Detection Network**, Mahnoor Dil et.al., Paper: [http://arxiv.org/abs/2211.16785v1](http://arxiv.org/abs/2211.16785v1), Code: **[https://github.com/zeeshankaleem/multifeaturenet](https://github.com/zeeshankaleem/multifeaturenet)**\n", "2211.16779": "- 2022-11-30, **Attention-based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection**, Zizhang Wu et.al., Paper: [http://arxiv.org/abs/2211.16779v1](http://arxiv.org/abs/2211.16779v1)\n", "2211.16636": "- 2022-11-30, **Iterative Scene Graph Generation with Generative Transformers**, Sanjoy Kundu et.al., Paper: [http://arxiv.org/abs/2211.16636v1](http://arxiv.org/abs/2211.16636v1)\n", "2211.16517": "- 2022-11-29, **MUSE-ALMA Haloes VII: Survey Science Goals & Design, Data Processing and Final Catalogues**, C\u00e9line P\u00e9roux et.al., Paper: [http://arxiv.org/abs/2211.16517v1](http://arxiv.org/abs/2211.16517v1)\n", "2212.00770": "- 2022-12-01, **On Utilizing Relationships for Transferable Few-Shot Fine-Grained Object Detection**, Ambar Pal et.al., Paper: [http://arxiv.org/abs/2212.00770v1](http://arxiv.org/abs/2212.00770v1)\n", "2212.00653": "- 2022-12-01, **Hyperbolic Contrastive Learning for Visual Representations beyond Objects**, Songwei Ge et.al., Paper: [http://arxiv.org/abs/2212.00653v1](http://arxiv.org/abs/2212.00653v1), Code: **[https://github.com/shlokk/hcl](https://github.com/shlokk/hcl)**\n", "2212.00623": "- 2022-12-01, **BEV-LGKD: A Unified LiDAR-Guided Knowledge Distillation Framework for BEV 3D Object Detection**, Jianing Li et.al., Paper: [http://arxiv.org/abs/2212.00623v1](http://arxiv.org/abs/2212.00623v1)\n", "2212.00585": "- 2022-12-01, **Soft Labels for Rapid Satellite Object Detection**, Matthew Ciolino et.al., Paper: [http://arxiv.org/abs/2212.00585v1](http://arxiv.org/abs/2212.00585v1)\n", "2212.00442": "- 2022-12-01, **MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection**, Junho Koh et.al., Paper: [http://arxiv.org/abs/2212.00442v1](http://arxiv.org/abs/2212.00442v1), Code: **[https://github.com/hyjhkoh/mgtanet](https://github.com/hyjhkoh/mgtanet)**\n", "2212.00423": "- 2022-12-01, **Motion Informed Object Detection of Small Insects in Time-lapse Camera Recordings**, Kim Bjerge et.al., Paper: [http://arxiv.org/abs/2212.00423v1](http://arxiv.org/abs/2212.00423v1)\n", "2212.00352": "- 2022-12-01, **A Dataset with Multibeam Forward-Looking Sonar for Underwater Object Detection**, Kaibing Xie et.al., Paper: [http://arxiv.org/abs/2212.00352v1](http://arxiv.org/abs/2212.00352v1)\n", "2212.00313": "- 2022-12-01, **Concealed Object Detection for Passive Millimeter-Wave Security Imaging Based on Task-Aligned Detection Transformer**, Cheng Guo et.al., Paper: [http://arxiv.org/abs/2212.00313v1](http://arxiv.org/abs/2212.00313v1), Code: **[https://github.com/ch3ngguo/opening-source-pmmw-dataset](https://github.com/ch3ngguo/opening-source-pmmw-dataset)**\n", "2212.00280": "- 2022-12-01, **GRiT: A Generative Region-to-text Transformer for Object Understanding**, Jialian Wu et.al., Paper: [http://arxiv.org/abs/2212.00280v1](http://arxiv.org/abs/2212.00280v1), Code: **[https://github.com/JialianW/GRiT](https://github.com/JialianW/GRiT)**\n", "2212.00154": "- 2022-11-30, **Topological defect coarsening in quenched smectic-C films analyzed using artificial neural networks**, Ravin A. Chowdhury et.al., Paper: [http://arxiv.org/abs/2212.00154v1](http://arxiv.org/abs/2212.00154v1)\n", "2212.01376": "- 2022-12-02, **D2DF2WOD: Learning Object Proposals for Weakly-Supervised Object Detection via Progressive Domain Adaptation**, Yuting Wang et.al., Paper: [http://arxiv.org/abs/2212.01376v1](http://arxiv.org/abs/2212.01376v1)\n", "2212.01322": "- 2022-12-02, **MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation**, Lukas Hoyer et.al., Paper: [http://arxiv.org/abs/2212.01322v1](http://arxiv.org/abs/2212.01322v1), Code: **[https://github.com/lhoyer/mic](https://github.com/lhoyer/mic)**\n", "2212.01231": "- 2022-12-02, **BEV-SAN: Accurate BEV 3D Object Detection via Slice Attention Networks**, Xiaowei Chi et.al., Paper: [http://arxiv.org/abs/2212.01231v1](http://arxiv.org/abs/2212.01231v1)\n", "2212.01004": "- 2022-12-02, **Planogram Compliance Control via Object Detection, Sequence Alignment, and Focused Iterative Search**, M. Erkin Y\u00fccel et.al., Paper: [http://arxiv.org/abs/2212.01004v1](http://arxiv.org/abs/2212.01004v1)\n", "2212.00990": "- 2022-12-02, **Feature Aggregation and Propagation Network for Camouflaged Object Detection**, Tao Zhou et.al., Paper: [http://arxiv.org/abs/2212.00990v1](http://arxiv.org/abs/2212.00990v1)\n", "2212.00979": "- 2022-12-02, **PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization**, Prithvijit Chattopadhyay et.al., Paper: [http://arxiv.org/abs/2212.00979v1](http://arxiv.org/abs/2212.00979v1), Code: **[https://github.com/prithv1/pasta](https://github.com/prithv1/pasta)**\n", "2212.00972": "- 2022-12-02, **Cloud-Device Collaborative Adaptation to Continual Changing Environments in the Real-world**, Yulu Gan et.al., Paper: [http://arxiv.org/abs/2212.00972v1](http://arxiv.org/abs/2212.00972v1)\n", "2212.00968": "- 2022-12-02, **UIU-Net: U-Net in U-Net for Infrared Small Object Detection**, Xin Wu et.al., Paper: [http://arxiv.org/abs/2212.00968v1](http://arxiv.org/abs/2212.00968v1), Code: **[https://github.com/danfenghong/ieee_tip_uiu-net](https://github.com/danfenghong/ieee_tip_uiu-net)**\n", "2302.08242": "- 2023-02-16, **Tuning computer vision models with task rewards**, Andr\u00e9 Susano Pinto et.al., Paper: [http://arxiv.org/abs/2302.08242v1](http://arxiv.org/abs/2302.08242v1)\n", "2302.08231": "- 2023-02-16, **3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection**, Jongwoo Park et.al., Paper: [http://arxiv.org/abs/2302.08231v1](http://arxiv.org/abs/2302.08231v1)\n", "2302.08156": "- 2023-02-16, **Research on road object detection algorithm based on improved YOLOX**, Tao Yang et.al., Paper: [http://arxiv.org/abs/2302.08156v1](http://arxiv.org/abs/2302.08156v1)\n", "2302.08052": "- 2023-02-16, **Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection**, Hao Chen et.al., Paper: [http://arxiv.org/abs/2302.08052v1](http://arxiv.org/abs/2302.08052v1)\n", "2302.07734": "- 2023-02-15, **TFormer: A Transmission-Friendly ViT Model for IoT Devices**, Zhichao Lu et.al., Paper: [http://arxiv.org/abs/2302.07734v1](http://arxiv.org/abs/2302.07734v1)\n", "2302.07676": "- 2023-02-15, **DIVOTrack: A Novel Dataset and Baseline Method for Cross-View Multi-Object Tracking in DIVerse Open Scenes**, Shenghao Hao et.al., Paper: [http://arxiv.org/abs/2302.07676v1](http://arxiv.org/abs/2302.07676v1), Code: **[https://github.com/shengyuhao/divotrack](https://github.com/shengyuhao/divotrack)**\n", "2302.07577": "- 2023-02-16, **Efficient Teacher: Semi-Supervised Object Detection for YOLOv5**, Bowen Xu et.al., Paper: [http://arxiv.org/abs/2302.07577v2](http://arxiv.org/abs/2302.07577v2), Code: **[https://github.com/BowieHsu/EfficientTeacher](https://github.com/BowieHsu/EfficientTeacher)**\n", "2302.07483": "- 2023-02-15, **EdgeYOLO: An Edge-Real-Time Object Detector**, Shihan Liu et.al., Paper: [http://arxiv.org/abs/2302.07483v1](http://arxiv.org/abs/2302.07483v1), Code: **[https://github.com/lsh9832/edgeyolo](https://github.com/lsh9832/edgeyolo)**\n", "2302.07319": "- 2023-02-14, **Frustratingly Simple but Effective Zero-shot Detection and Segmentation: Analysis and a Strong Baseline**, Siddhesh Khandelwal et.al., Paper: [http://arxiv.org/abs/2302.07319v1](http://arxiv.org/abs/2302.07319v1)\n", "2302.07121": "- 2023-02-14, **Universal Guidance for Diffusion Models**, Arpit Bansal et.al., Paper: [http://arxiv.org/abs/2302.07121v1](http://arxiv.org/abs/2302.07121v1), Code: **[https://github.com/arpitbansal297/universal-guided-diffusion](https://github.com/arpitbansal297/universal-guided-diffusion)**\n", "2302.09043": "- 2023-02-17, **Self-Supervised Representation Learning from Temporal Ordering of Automated Driving Sequences**, Christopher Lang et.al., Paper: [http://arxiv.org/abs/2302.09043v1](http://arxiv.org/abs/2302.09043v1)\n", "2302.08943": "- 2023-02-17, **Long Range Object-Level Monocular Depth Estimation for UAVs**, David Silva et.al., Paper: [http://arxiv.org/abs/2302.08943v1](http://arxiv.org/abs/2302.08943v1)\n", "2302.08646": "- 2023-02-17, **AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving**, Tianyue Zheng et.al., Paper: [http://arxiv.org/abs/2302.08646v1](http://arxiv.org/abs/2302.08646v1)\n", "2302.10007": "- 2023-02-20, **On the Metrics for Evaluating Monocular Depth Estimation**, Akhil Gurram et.al., Paper: [http://arxiv.org/abs/2302.10007v1](http://arxiv.org/abs/2302.10007v1)\n", "2302.09854": "- 2023-02-20, **Faster Region-Based CNN Spectrum Sensing and Signal Identification in Cluttered RF Environments**, Todd Morehouse et.al., Paper: [http://arxiv.org/abs/2302.09854v1](http://arxiv.org/abs/2302.09854v1)\n", "2302.09779": "- 2023-02-20, **Incremental Few-Shot Object Detection via Simple Fine-Tuning Approach**, Tae-Min Choi et.al., Paper: [http://arxiv.org/abs/2302.09779v1](http://arxiv.org/abs/2302.09779v1), Code: **[https://github.com/tmiu/itfa](https://github.com/tmiu/itfa)**\n", "2302.09657": "- 2023-02-19, **Table Tennis Stroke Detection and Recognition Using Ball Trajectory Data**, Kaustubh Milind Kulkarni et.al., Paper: [http://arxiv.org/abs/2302.09657v1](http://arxiv.org/abs/2302.09657v1)\n", "2302.09590": "- 2023-02-19, **Accelerated Video Annotation driven by Deep Detector and Tracker**, Eric Price et.al., Paper: [http://arxiv.org/abs/2302.09590v1](http://arxiv.org/abs/2302.09590v1), Code: **[https://github.com/robot-perception-group/smarter-labelme](https://github.com/robot-perception-group/smarter-labelme)**\n", "2302.09565": "- 2023-02-19, **Optimizing YOLOv7 for Semiconductor Defect Detection**, Enrique Dehaerne et.al., Paper: [http://arxiv.org/abs/2302.09565v1](http://arxiv.org/abs/2302.09565v1)\n", "2302.09444": "- 2023-02-18, **mBEST: Realtime Deformable Linear Object Detection Through Minimal Bending Energy Skeleton Pixel Traversals**, Andrew Choi et.al., Paper: [http://arxiv.org/abs/2302.09444v1](http://arxiv.org/abs/2302.09444v1)\n", "2302.09365": "- 2023-02-18, **Hyneter: Hybrid Network Transformer for Object Detection**, Dong Chen et.al., Paper: [http://arxiv.org/abs/2302.09365v1](http://arxiv.org/abs/2302.09365v1)\n", "2302.09221": "- 2023-02-18, **2D-Empowered 3D Object Detection on the Edge**, Jingzong Li et.al., Paper: [http://arxiv.org/abs/2302.09221v1](http://arxiv.org/abs/2302.09221v1)\n", "2302.10697": "- 2023-02-21, **A General Visual Representation Guided Framework with Global Affinity for Weakly Supervised Salient Object Detection**, Binwei Xu et.al., Paper: [http://arxiv.org/abs/2302.10697v1](http://arxiv.org/abs/2302.10697v1)\n", "2302.10624": "- 2023-02-21, **Self-improving object detection via disagreement reconciliation**, Gianluca Scarpellini et.al., Paper: [http://arxiv.org/abs/2302.10624v1](http://arxiv.org/abs/2302.10624v1)\n", "2302.10549": "- 2023-02-21, **MonoPGC: Monocular 3D Object Detection with Pixel Geometry Contexts**, Zizhang Wu et.al., Paper: [http://arxiv.org/abs/2302.10549v1](http://arxiv.org/abs/2302.10549v1)\n", "2302.10511": "- 2023-02-21, **MVFusion: Multi-View 3D Object Detection with Semantic-aligned Radar and Camera Fusion**, Zizhang Wu et.al., Paper: [http://arxiv.org/abs/2302.10511v1](http://arxiv.org/abs/2302.10511v1)\n", "2302.10473": "- 2023-02-21, **Oriented Object Detection in Optical Remote Sensing Images: A Survey**, Kun Wang et.al., Paper: [http://arxiv.org/abs/2302.10473v1](http://arxiv.org/abs/2302.10473v1)\n", "2302.10469": "- 2023-02-21, **ApproxABFT: Approximate Algorithm-Based Fault Tolerance for Vision Transformers**, Xinghua Xue et.al., Paper: [http://arxiv.org/abs/2302.10469v1](http://arxiv.org/abs/2302.10469v1)\n", "2302.10465": "- 2023-02-21, **A Flexible Multi-view Multi-modal Imaging System for Outdoor Scenes**, Meng Zhang et.al., Paper: [http://arxiv.org/abs/2302.10465v1](http://arxiv.org/abs/2302.10465v1)\n", "2302.10450": "- 2023-02-21, **Automotive RADAR sub-sampling via object detection networks: Leveraging prior signal information**, Madhumitha Sakthi et.al., Paper: [http://arxiv.org/abs/2302.10450v1](http://arxiv.org/abs/2302.10450v1)\n", "2302.10396": "- 2023-02-21, **Assessing Domain Gap for Continual Domain Adaptation in Object Detection**, Anh-Dzung Doan et.al., Paper: [http://arxiv.org/abs/2302.10396v1](http://arxiv.org/abs/2302.10396v1), Code: **[https://github.com/dadung/dge-cda](https://github.com/dadung/dge-cda)**\n", "2302.11481": "- 2023-02-22, **Transformer-Based Sensor Fusion for Autonomous Driving: A Survey**, Apoorv Singh et.al., Paper: [http://arxiv.org/abs/2302.11481v1](http://arxiv.org/abs/2302.11481v1)\n", "2302.11361": "- 2023-02-23, **HDR image watermarking using saliency detection and quantization index modulation**, Ahmed Khan et.al., Paper: [http://arxiv.org/abs/2302.11361v2](http://arxiv.org/abs/2302.11361v2)\n", "2302.11349": "- 2023-02-22, **Steerable Equivariant Representation Learning**, Sangnie Bhardwaj et.al., Paper: [http://arxiv.org/abs/2302.11349v1](http://arxiv.org/abs/2302.11349v1)\n", "2302.11299": "- 2023-02-22, **Towards End-to-end Semi-supervised Learning for One-stage Object Detection**, Gen Luo et.al., Paper: [http://arxiv.org/abs/2302.11299v1](http://arxiv.org/abs/2302.11299v1), Code: **[https://github.com/luogen1996/oneteacher](https://github.com/luogen1996/oneteacher)**\n", "2302.11180": "- 2023-02-22, **DISCO: Distributed Inference with Sparse Communications**, Minghai Qin et.al., Paper: [http://arxiv.org/abs/2302.11180v1](http://arxiv.org/abs/2302.11180v1)\n", "2302.11813": "- 2023-02-23, **Deep OC-SORT: Multi-Pedestrian Tracking by Adaptive Re-Identification**, Gerard Maggiolino et.al., Paper: [http://arxiv.org/abs/2302.11813v1](http://arxiv.org/abs/2302.11813v1), Code: **[https://github.com/gerardmaggiolino/deep-oc-sort](https://github.com/gerardmaggiolino/deep-oc-sort)**\n", "2302.11810": "- 2023-02-23, **A novel efficient Multi-view traffic-related object detection framework**, Kun Yang et.al., Paper: [http://arxiv.org/abs/2302.11810v1](http://arxiv.org/abs/2302.11810v1)\n", "2302.11757": "- 2023-02-23, **Open-World Object Detection via Discriminative Class Prototype Learning**, Jinan Yu et.al., Paper: [http://arxiv.org/abs/2302.11757v1](http://arxiv.org/abs/2302.11757v1)\n", "2302.11683": "- 2023-02-22, **MVTrans: Multi-View Perception of Transparent Objects**, Yi Ru Wang et.al., Paper: [http://arxiv.org/abs/2302.11683v1](http://arxiv.org/abs/2302.11683v1)\n", "2302.11583": "- 2023-02-22, **The Digitization of Historical Astrophysical Literature with Highly-Localized Figures and Figure Captions**, Jill P. Naiman et.al., Paper: [http://arxiv.org/abs/2302.11583v1](http://arxiv.org/abs/2302.11583v1)\n", "2302.12629": "- 2023-02-24, **Quantifying Noise Limitations of Neural Network Segmentations in High-Resolution Transmission Electron Microscopy**, Matthew Helmi Leth Larsen et.al., Paper: [http://arxiv.org/abs/2302.12629v1](http://arxiv.org/abs/2302.12629v1)\n", "2302.12505": "- 2023-02-24, **Spatial Bias for Attention-free Non-local Neural Networks**, Junhyung Go et.al., Paper: [http://arxiv.org/abs/2302.12505v1](http://arxiv.org/abs/2302.12505v1)\n", "2302.13996": "- 2023-02-27, **Aligning Bag of Regions for Open-Vocabulary Object Detection**, Size Wu et.al., Paper: [http://arxiv.org/abs/2302.13996v1](http://arxiv.org/abs/2302.13996v1), Code: **[https://github.com/wusize/ovdet](https://github.com/wusize/ovdet)**\n", "2302.13891": "- 2023-02-27, **Supervised Virtual-to-Real Domain Adaptation for Object Detection Task using YOLO**, Akbar Satya Nugraha et.al., Paper: [http://arxiv.org/abs/2302.13891v1](http://arxiv.org/abs/2302.13891v1)\n", "2302.13581": "- 2023-02-27, **Saliency-Driven Hierarchical Learned Image Coding for Machines**, Kristian Fischer et.al., Paper: [http://arxiv.org/abs/2302.13581v1](http://arxiv.org/abs/2302.13581v1)\n", "2302.13577": "- 2023-02-27, **DuEqNet: Dual-Equivariance Network in Outdoor 3D Object Detection for Autonomous Driving**, Xihao Wang et.al., Paper: [http://arxiv.org/abs/2302.13577v1](http://arxiv.org/abs/2302.13577v1)\n", "2302.13487": "- 2023-02-27, **Contextual adversarial attack against aerial detection in the physical world**, Jiawei Lian et.al., Paper: [http://arxiv.org/abs/2302.13487v1](http://arxiv.org/abs/2302.13487v1)\n", "2302.13301": "- 2023-02-26, **Pillar R-CNN for Point Cloud 3D Object Detection**, Guangsheng Shi et.al., Paper: [http://arxiv.org/abs/2302.13301v1](http://arxiv.org/abs/2302.13301v1)\n", "2302.13293": "- 2023-02-26, **PDIWS: Thermal Imaging Dataset for Person Detection in Intrusion Warning Systems**, Nguyen Duc Thuan et.al., Paper: [http://arxiv.org/abs/2302.13293v1](http://arxiv.org/abs/2302.13293v1), Code: **[https://github.com/thuan-researcher/intruder-thermal-dataset](https://github.com/thuan-researcher/intruder-thermal-dataset)**\n", "2302.13075": "- 2023-02-25, **BOP Challenge 2022 on Detection, Segmentation and Pose Estimation of Specific Rigid Objects**, Martin Sundermeyer et.al., Paper: [http://arxiv.org/abs/2302.13075v1](http://arxiv.org/abs/2302.13075v1)\n", "2302.13002": "- 2023-02-25, **DA-BEV: Depth Aware BEV Transformer for 3D Object Detection**, Hao Zhang et.al., Paper: [http://arxiv.org/abs/2302.13002v1](http://arxiv.org/abs/2302.13002v1)\n", "2302.12915": "- 2023-02-24, **From Occlusion to Insight: Object Search in Semantic Shelves using Large Language Models**, Satvik Sharma et.al., Paper: [http://arxiv.org/abs/2302.12915v1](http://arxiv.org/abs/2302.12915v1)\n", "2302.14771": "- 2023-02-28, **Generic-to-Specific Distillation of Masked Autoencoders**, Wei Huang et.al., Paper: [http://arxiv.org/abs/2302.14771v1](http://arxiv.org/abs/2302.14771v1), Code: **[https://github.com/pengzhiliang/g2sd](https://github.com/pengzhiliang/g2sd)**\n", "2302.14746": "- 2023-02-28, **Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors**, Ji Hou et.al., Paper: [http://arxiv.org/abs/2302.14746v1](http://arxiv.org/abs/2302.14746v1)\n", "2302.14554": "- 2023-02-28, **FPCD: An Open Aerial VHR Dataset for Farm Pond Change Detection**, Chintan Tundia et.al., Paper: [http://arxiv.org/abs/2302.14554v1](http://arxiv.org/abs/2302.14554v1)\n", "2302.14522": "- 2023-02-28, **AdaptiveShape: Solving Shape Variability for 3D Object Detection with Geometry Aware Anchor Distributions**, Benjamin Sick et.al., Paper: [http://arxiv.org/abs/2302.14522v1](http://arxiv.org/abs/2302.14522v1)\n", "2302.14486": "- 2023-02-28, **TrainSim: A Railway Simulation Framework for LiDAR and Camera Dataset Generation**, Gianluca D'Amico et.al., Paper: [http://arxiv.org/abs/2302.14486v1](http://arxiv.org/abs/2302.14486v1)\n", "2302.14485": "- 2023-02-28, **Memory-aided Contrastive Consensus Learning for Co-salient Object Detection**, Peng Zheng et.al., Paper: [http://arxiv.org/abs/2302.14485v1](http://arxiv.org/abs/2302.14485v1), Code: **[https://github.com/zhengpeng7/mccl](https://github.com/zhengpeng7/mccl)**\n", "2302.14452": "- 2023-02-28, **An Effective Crop-Paste Pipeline for Few-shot Object Detection**, Shaobo Lin et.al., Paper: [http://arxiv.org/abs/2302.14452v1](http://arxiv.org/abs/2302.14452v1)\n", "2302.14445": "- 2023-02-28, **Embedded light-weight approach for safe landing in populated areas**, Tilemahos Mitroudas et.al., Paper: [http://arxiv.org/abs/2302.14445v1](http://arxiv.org/abs/2302.14445v1)\n", "2302.14431": "- 2023-02-28, **Efficient Masked Autoencoders with Self-Consistency**, Zhaowen Li et.al., Paper: [http://arxiv.org/abs/2302.14431v1](http://arxiv.org/abs/2302.14431v1)\n", "2302.14426": "- 2023-02-28, **At-Scale Evaluation of Weight Clustering to Enable Energy-Efficient Object Detection**, Mart\u00ed Caro et.al., Paper: [http://arxiv.org/abs/2302.14426v1](http://arxiv.org/abs/2302.14426v1)\n", "2303.00725": "- 2023-03-01, **OSRE: Object-to-Spot Rotation Estimation for Bike Parking Assessment**, Saghir Alfasly et.al., Paper: [http://arxiv.org/abs/2303.00725v1](http://arxiv.org/abs/2303.00725v1)\n", "2303.00703": "- 2023-03-01, **Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis**, Renrui Zhang et.al., Paper: [http://arxiv.org/abs/2303.00703v1](http://arxiv.org/abs/2303.00703v1)\n", "2303.00542": "- 2023-03-01, **D2Q-DETR: Decoupling and Dynamic Queries for Oriented Object Detection with Transformers**, Qiang Zhou et.al., Paper: [http://arxiv.org/abs/2303.00542v1](http://arxiv.org/abs/2303.00542v1)\n", "2303.00423": "- 2023-03-01, **Multiperspective Teaching of Unknown Objects via Shared-gaze-based Multimodal Human-Robot Interaction**, Daniel Weber et.al., Paper: [http://arxiv.org/abs/2303.00423v1](http://arxiv.org/abs/2303.00423v1)\n", "2303.00337": "- 2023-03-01, **TAU: A Framework for Video-Based Traffic Analytics Leveraging Artificial Intelligence and Unmanned Aerial Systems**, Bilel Benjdira et.al., Paper: [http://arxiv.org/abs/2303.00337v1](http://arxiv.org/abs/2303.00337v1), Code: **[https://github.com/bilel-bj/tau](https://github.com/bilel-bj/tau)**\n", "2303.00284": "- 2023-03-01, **To Make Yourself Invisible with Adversarial Semantic Contours**, Yichi Zhang et.al., Paper: [http://arxiv.org/abs/2303.00284v1](http://arxiv.org/abs/2303.00284v1)\n", "2303.00132": "- 2023-02-28, **Onboard dynamic-object detection and tracking for autonomous robot navigation with RGB-D camera**, Zhefan Xu et.al., Paper: [http://arxiv.org/abs/2303.00132v1](http://arxiv.org/abs/2303.00132v1)\n", "2303.00086": "- 2023-02-28, **Applying Plain Transformers to Real-World Point Clouds**, Lanxiao Li et.al., Paper: [http://arxiv.org/abs/2303.00086v1](http://arxiv.org/abs/2303.00086v1)\n", "2303.01503": "- 2023-03-02, **FeatAug-DETR: Enriching One-to-Many Matching for DETRs with Feature Augmentation**, Rongyao Fang et.al., Paper: [http://arxiv.org/abs/2303.01503v1](http://arxiv.org/abs/2303.01503v1), Code: **[https://github.com/rongyaofang/feataug-detr](https://github.com/rongyaofang/feataug-detr)**\n", "2303.01363": "- 2023-03-02, **Deep-NFA: a Deep $\\textit{a contrario}$ Framework for Small Object Detection**, Alina Ciocarlan et.al., Paper: [http://arxiv.org/abs/2303.01363v1](http://arxiv.org/abs/2303.01363v1)\n", "2303.01338": "- 2023-03-02, **AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision Systems**, Amira Guesmi et.al., Paper: [http://arxiv.org/abs/2303.01338v1](http://arxiv.org/abs/2303.01338v1)\n", "2303.01219": "- 2023-03-02, **A Coarse to Fine Framework for Object Detection in High Resolution Image**, Jinyan Liu et.al., Paper: [http://arxiv.org/abs/2303.01219v1](http://arxiv.org/abs/2303.01219v1)\n", "2303.01196": "- 2023-03-02, **STDepthFormer: Predicting Spatio-temporal Depth from Video with a Self-supervised Transformer Model**, Houssem Boulahbal et.al., Paper: [http://arxiv.org/abs/2303.01196v1](http://arxiv.org/abs/2303.01196v1)\n", "2303.01047": "- 2023-03-02, **Task-Specific Context Decoupling for Object Detection**, Jiayuan Zhuang et.al., Paper: [http://arxiv.org/abs/2303.01047v1](http://arxiv.org/abs/2303.01047v1)\n", "2303.00983": "- 2023-03-02, **Using simulation to quantify the performance of automotive perception systems**, Zhenyi Liu et.al., Paper: [http://arxiv.org/abs/2303.00983v1](http://arxiv.org/abs/2303.00983v1)\n", "2303.02000": "- 2023-03-03, **BSH-Det3D: Improving 3D Object Detection with BEV Shape Heatmap**, You Shen et.al., Paper: [http://arxiv.org/abs/2303.02000v1](http://arxiv.org/abs/2303.02000v1), Code: **[https://github.com/mystorm16/bsh-det3d](https://github.com/mystorm16/bsh-det3d)**\n", "2303.01920": "- 2023-03-03, **Robust Detection Outcome: A Metric for Pathology Detection in Medical Images**, Felix Meissen et.al., Paper: [http://arxiv.org/abs/2303.01920v1](http://arxiv.org/abs/2303.01920v1), Code: **[https://github.com/felime/rodeo](https://github.com/felime/rodeo)**\n", "2303.01899": "- 2023-03-03, **Quantifying the LiDAR Sim-to-Real Domain Shift: A Detailed Investigation Using Object Detectors and Analyzing Point Clouds at Target-Level**, Sebastian Huch et.al., Paper: [http://arxiv.org/abs/2303.01899v1](http://arxiv.org/abs/2303.01899v1), Code: **[https://github.com/tumftm/sim2realdistributionaligneddataset](https://github.com/tumftm/sim2realdistributionaligneddataset)**\n", "2303.01803": "- 2023-03-03, **Confidence-driven Bounding Box Localization for Small Object Detection**, Huixin Sun et.al., Paper: [http://arxiv.org/abs/2303.01803v1](http://arxiv.org/abs/2303.01803v1)\n", "2303.01788": "- 2023-03-03, **Visual Exemplar Driven Task-Prompting for Unified Perception in Autonomous Driving**, Xiwen Liang et.al., Paper: [http://arxiv.org/abs/2303.01788v1](http://arxiv.org/abs/2303.01788v1)\n", "2303.01734": "- 2023-03-03, **AdvART: Adversarial Art for Camouflaged Object Detection Attacks**, Amira Guesmi et.al., Paper: [http://arxiv.org/abs/2303.01734v1](http://arxiv.org/abs/2303.01734v1)\n", "2303.01686": "- 2023-03-03, **Towards Domain Generalization for Multi-view 3D Object Detection in Bird-Eye-View**, Shuo Wang et.al., Paper: [http://arxiv.org/abs/2303.01686v1](http://arxiv.org/abs/2303.01686v1)\n", "2303.03178": "- 2023-03-06, **A System for Generalized 3D Multi-Object Search**, Kaiyu Zheng et.al., Paper: [http://arxiv.org/abs/2303.03178v1](http://arxiv.org/abs/2303.03178v1), Code: **[https://github.com/zkytony/genmos_object_search](https://github.com/zkytony/genmos_object_search)**\n", "2303.03155": "- 2023-03-06, **Unsupervised Active Visual Search with Monte Carlo planning under Uncertain Detections**, Francesco Taioli et.al., Paper: [http://arxiv.org/abs/2303.03155v1](http://arxiv.org/abs/2303.03155v1)\n", "2303.03041": "- 2023-03-06, **Automatic detection of aerial survey ground control points based on Yolov5-OBB**, Cheng Chuanxiang et.al., Paper: [http://arxiv.org/abs/2303.03041v1](http://arxiv.org/abs/2303.03041v1)\n", "2303.03037": "- 2023-03-06, **EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning**, Monish R. Nallapareddy et.al., Paper: [http://arxiv.org/abs/2303.03037v1](http://arxiv.org/abs/2303.03037v1)\n", "2303.02998": "- 2023-03-06, **Pseudo-label Correction and Learning For Semi-Supervised Object Detection**, Yulin He et.al., Paper: [http://arxiv.org/abs/2303.02998v1](http://arxiv.org/abs/2303.02998v1)\n", "2303.02867": "- 2023-03-06, **Dual Feedback Attention Framework via Boundary-Aware Auxiliary and Progressive Semantic Optimization for Salient Object Detection in Optical Remote Sensing Imagery**, Dejun Feng et.al., Paper: [http://arxiv.org/abs/2303.02867v1](http://arxiv.org/abs/2303.02867v1), Code: **[https://github.com/yuhsss/dfa-baso](https://github.com/yuhsss/dfa-baso)**\n", "2303.02735": "- 2023-03-05, **Scalable Object Detection on Embedded Devices Using Weight Pruning and Singular Value Decomposition**, Dohyun Ham et.al., Paper: [http://arxiv.org/abs/2303.02735v1](http://arxiv.org/abs/2303.02735v1)\n", "2303.02641": "- 2023-03-05, **CueCAn: Cue Driven Contextual Attention For Identifying Missing Traffic Signs on Unconstrained Roads**, Varun Gupta et.al., Paper: [http://arxiv.org/abs/2303.02641v1](http://arxiv.org/abs/2303.02641v1)\n", "2303.02314": "- 2023-03-04, **Virtual Sparse Convolution for Multimodal 3D Object Detection**, Hai Wu et.al., Paper: [http://arxiv.org/abs/2303.02314v1](http://arxiv.org/abs/2303.02314v1), Code: **[https://github.com/hailanyi/virconv](https://github.com/hailanyi/virconv)**\n", "2303.02272": "- 2023-03-04, **Real-time SLAM Pipeline in Dynamics Environment**, Alex Fu et.al., Paper: [http://arxiv.org/abs/2303.02272v1](http://arxiv.org/abs/2303.02272v1)\n", "2303.03932": "- 2023-03-07, **FFT-based Dynamic Token Mixer for Vision**, Yuki Tatsunami et.al., Paper: [http://arxiv.org/abs/2303.03932v1](http://arxiv.org/abs/2303.03932v1)\n", "2303.03728": "- 2023-03-07, **Refined Pseudo labeling for Source-free Domain Adaptive Object Detection**, Siqi Zhang et.al., Paper: [http://arxiv.org/abs/2303.03728v1](http://arxiv.org/abs/2303.03728v1)\n", "2303.03698": "- 2023-03-07, **FIT: Frequency-based Image Translation for Domain Adaptive Object Detection**, Siqi Zhang et.al., Paper: [http://arxiv.org/abs/2303.03698v1](http://arxiv.org/abs/2303.03698v1)\n", "2303.03595": "- 2023-03-07, **LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion**, Xin Li et.al., Paper: [http://arxiv.org/abs/2303.03595v1](http://arxiv.org/abs/2303.03595v1), Code: **[https://github.com/sankin97/logonet](https://github.com/sankin97/logonet)**\n", "2303.03583": "- 2023-03-07, **Calibration-free BEV Representation for Infrastructure Perception**, Siqi Fan et.al., Paper: [http://arxiv.org/abs/2303.03583v1](http://arxiv.org/abs/2303.03583v1)\n", "2303.03508": "- 2023-03-06, **Memory Maps for Video Object Detection and Tracking on UAVs**, Benjamin Kiefer et.al., Paper: [http://arxiv.org/abs/2303.03508v1](http://arxiv.org/abs/2303.03508v1)\n", "2303.03480": "- 2023-03-06, **Can an Embodied Agent Find Your \"Cat-shaped Mug\"? LLM-Based Zero-Shot Object Navigation**, Vishnu Sashank Dorbala et.al., Paper: [http://arxiv.org/abs/2303.03480v1](http://arxiv.org/abs/2303.03480v1)\n", "2303.04506": "- 2023-03-08, **Radio astronomical images object detection and segmentation: A benchmark on deep learning methods**, Renato Sortino et.al., Paper: [http://arxiv.org/abs/2303.04506v1](http://arxiv.org/abs/2303.04506v1)\n", "2303.04458": "- 2023-03-08, **Full Point Encoding for Local Feature Aggregation in 3D Point Clouds**, Yong He et.al., Paper: [http://arxiv.org/abs/2303.04458v1](http://arxiv.org/abs/2303.04458v1)\n", "2303.04440": "- 2023-03-08, **HyT-NAS: Hybrid Transformers Neural Architecture Search for Edge Devices**, Lotfi Abdelkrim Mecharbat et.al., Paper: [http://arxiv.org/abs/2303.04440v1](http://arxiv.org/abs/2303.04440v1)\n", "2303.04240": "- 2023-03-07, **Gradient-Guided Knowledge Distillation for Object Detectors**, Qizhen Lan et.al., Paper: [http://arxiv.org/abs/2303.04240v1](http://arxiv.org/abs/2303.04240v1)\n", "2303.04238": "- 2023-03-07, **Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on Object Detectors**, Raz Lapid et.al., Paper: [http://arxiv.org/abs/2303.04238v1](http://arxiv.org/abs/2303.04238v1)\n", "2303.05499": "- 2023-03-10, **Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection**, Shilong Liu et.al., Paper: [http://arxiv.org/abs/2303.05499v2](http://arxiv.org/abs/2303.05499v2), Code: **[https://github.com/idea-research/groundingdino](https://github.com/idea-research/groundingdino)**\n", "2303.05404": "- 2023-03-09, **On Onboard LiDAR-based Flying Object Detection**, Matou\u0161 Vrba et.al., Paper: [http://arxiv.org/abs/2303.05404v1](http://arxiv.org/abs/2303.05404v1)\n", "2303.05370": "- 2023-03-09, **Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation**, Hongsuk Choi et.al., Paper: [http://arxiv.org/abs/2303.05370v1](http://arxiv.org/abs/2303.05370v1)\n", "2303.05329": "- 2023-03-09, **Tucker Bilinear Attention Network for Multi-scale Remote Sensing Object Detection**, Tao Chen et.al., Paper: [http://arxiv.org/abs/2303.05329v1](http://arxiv.org/abs/2303.05329v1)\n", "2303.05218": "- 2023-03-09, **Harnessing polarization-path entangled single photons for low reflectivity object detection in noisy background**, K. Muhammed Shafi et.al., Paper: [http://arxiv.org/abs/2303.05218v1](http://arxiv.org/abs/2303.05218v1)\n", "2303.05148": "- 2023-03-09, **Weakly Supervised Knowledge Transfer with Probabilistic Logical Reasoning for Object Detection**, Martijn Oldenhof et.al., Paper: [http://arxiv.org/abs/2303.05148v1](http://arxiv.org/abs/2303.05148v1)\n", "2303.05079": "- 2023-03-10, **DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D Object Detection**, Jingyu Li et.al., Paper: [http://arxiv.org/abs/2303.05079v2](http://arxiv.org/abs/2303.05079v2), Code: **[https://github.com/hust-jy/dds3d](https://github.com/hust-jy/dds3d)**\n", "2303.05078": "- 2023-03-09, **Efficient Transformer-based 3D Object Detection with Dynamic Token Halting**, Mao Ye et.al., Paper: [http://arxiv.org/abs/2303.05078v1](http://arxiv.org/abs/2303.05078v1)\n", "2303.05015": "- 2023-03-09, **Smooth and Stepwise Self-Distillation for Object Detection**, Jieren Deng et.al., Paper: [http://arxiv.org/abs/2303.05015v1](http://arxiv.org/abs/2303.05015v1)\n", "2303.04989": "- 2023-03-09, **ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with Transformer**, Ying Zeng et.al., Paper: [http://arxiv.org/abs/2303.04989v1](http://arxiv.org/abs/2303.04989v1), Code: **[https://github.com/httle/ars-detr](https://github.com/httle/ars-detr)**\n", "2303.05970": "- 2023-03-13, **Exploring Recurrent Long-term Temporal Fusion for Multi-view 3D Perception**, Chunrui Han et.al., Paper: [http://arxiv.org/abs/2303.05970v2](http://arxiv.org/abs/2303.05970v2)\n", "2303.05892": "- 2023-03-10, **Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection**, Luting Wang et.al., Paper: [http://arxiv.org/abs/2303.05892v1](http://arxiv.org/abs/2303.05892v1)\n", "2303.05886": "- 2023-03-10, **Bi3D: Bi-domain Active Learning for Cross-domain 3D Object Detection**, Jiakang Yuan et.al., Paper: [http://arxiv.org/abs/2303.05886v1](http://arxiv.org/abs/2303.05886v1)\n", "2303.05763": "- 2023-03-10, **Automatic Detection and Rectification of Paper Receipts on Smartphones**, Edward Whittaker et.al., Paper: [http://arxiv.org/abs/2303.05763v1](http://arxiv.org/abs/2303.05763v1)\n", "2303.05739": "- 2023-03-10, **Boosting Semi-Supervised Few-Shot Object Detection with SoftER Teacher**, Phi Vu Tran et.al., Paper: [http://arxiv.org/abs/2303.05739v1](http://arxiv.org/abs/2303.05739v1), Code: **[https://github.com/lexisnexis-risk-open-source/ledetection](https://github.com/lexisnexis-risk-open-source/ledetection)**\n", "2303.07335": "- 2023-03-13, **Lite DETR : An Interleaved Multi-Scale Encoder for Efficient DETR**, Feng Li et.al., Paper: [http://arxiv.org/abs/2303.07335v1](http://arxiv.org/abs/2303.07335v1), Code: **[https://github.com/idea-research/lite-detr](https://github.com/idea-research/lite-detr)**\n", "2303.06999": "- 2023-03-13, **Identifying Label Errors in Object Detection Datasets by Loss Inspection**, Marius Schubert et.al., Paper: [http://arxiv.org/abs/2303.06999v1](http://arxiv.org/abs/2303.06999v1)\n", "2303.06908": "- 2023-03-13, **CrossFormer++: A Versatile Vision Transformer Hinging on Cross-scale Attention**, Wenxiao Wang et.al., Paper: [http://arxiv.org/abs/2303.06908v1](http://arxiv.org/abs/2303.06908v1), Code: **[https://github.com/cheerss/CrossFormer](https://github.com/cheerss/CrossFormer)**\n", "2303.06880": "- 2023-03-13, **Uni3D: A Unified Baseline for Multi-dataset 3D Object Detection**, Bo Zhang et.al., Paper: [http://arxiv.org/abs/2303.06880v1](http://arxiv.org/abs/2303.06880v1)\n", "2303.06870": "- 2023-03-13, **Three Guidelines You Should Know for Universally Slimmable Self-Supervised Learning**, Yun-Hao Cao et.al., Paper: [http://arxiv.org/abs/2303.06870v1](http://arxiv.org/abs/2303.06870v1)\n", "2303.06817": "- 2023-03-13, **Transformation-Invariant Network for Few-Shot Object Detection in Remote Sensing Images**, Nanqing Liu et.al., Paper: [http://arxiv.org/abs/2303.06817v1](http://arxiv.org/abs/2303.06817v1)\n", "2303.06705": "- 2023-03-12, **Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement**, Yuanhao Cai et.al., Paper: [http://arxiv.org/abs/2303.06705v1](http://arxiv.org/abs/2303.06705v1)\n", "2303.06674": "- 2023-03-12, **Universal Instance Perception as Object Discovery and Retrieval**, Bin Yan et.al., Paper: [http://arxiv.org/abs/2303.06674v1](http://arxiv.org/abs/2303.06674v1), Code: **[https://github.com/MasterBin-IIAU/UNINEXT](https://github.com/MasterBin-IIAU/UNINEXT)**\n", "2303.06673": "- 2023-03-12, **SSGD: A smartphone screen glass dataset for defect detection**, Haonan Han et.al., Paper: [http://arxiv.org/abs/2303.06673v1](http://arxiv.org/abs/2303.06673v1), Code: **[https://github.com/yangr116/ssgdataset](https://github.com/yangr116/ssgdataset)**\n", "2303.06567": "- 2023-03-12, **A Monkey Swing Counting Algorithm Based on Object Detection**, Hao Chen et.al., Paper: [http://arxiv.org/abs/2303.06567v1](http://arxiv.org/abs/2303.06567v1)\n", "2303.08129": "- 2023-03-14, **PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection**, Anthony Chen et.al., Paper: [http://arxiv.org/abs/2303.08129v1](http://arxiv.org/abs/2303.08129v1), Code: **[https://github.com/blvlab/pimae](https://github.com/blvlab/pimae)**\n", "2303.07820": "- 2023-03-14, **Adaptive Rotated Convolution for Rotated Object Detection**, Yifan Pu et.al., Paper: [http://arxiv.org/abs/2303.07820v1](http://arxiv.org/abs/2303.07820v1)\n", "2303.07798": "- 2023-03-14, **OVRL-V2: A simple state-of-art baseline for ImageNav and ObjectNav**, Karmesh Yadav et.al., Paper: [http://arxiv.org/abs/2303.07798v1](http://arxiv.org/abs/2303.07798v1)\n", "2303.07790": "- 2023-03-14, **Object Detection During Newborn Resuscitation Activities**, \u00d8yvind Meinich-Bache et.al., Paper: [http://arxiv.org/abs/2303.07790v1](http://arxiv.org/abs/2303.07790v1)\n", "2303.07789": "- 2023-03-14, **Activity Recognition From Newborn Resuscitation Videos**, \u00d8yvind Meinich-Bache et.al., Paper: [http://arxiv.org/abs/2303.07789v1](http://arxiv.org/abs/2303.07789v1)\n", "2303.07670": "- 2023-03-14, **Co-Salient Object Detection with Co-Representation Purification**, Ziyue Zhu et.al., Paper: [http://arxiv.org/abs/2303.07670v1](http://arxiv.org/abs/2303.07670v1), Code: **[https://github.com/zzy816/corp](https://github.com/zzy816/corp)**\n", "2303.07601": "- 2023-03-14, **V2V4Real: A Real-world Large-scale Dataset for Vehicle-to-Vehicle Cooperative Perception**, Runsheng Xu et.al., Paper: [http://arxiv.org/abs/2303.07601v1](http://arxiv.org/abs/2303.07601v1), Code: **[https://github.com/ucla-mobility/v2v4real](https://github.com/ucla-mobility/v2v4real)**\n", "2303.07586": "- 2023-03-14, **Teacher-Student Knowledge Distillation for Radar Perception on Embedded Accelerators**, Steven Shaw et.al., Paper: [http://arxiv.org/abs/2303.07586v1](http://arxiv.org/abs/2303.07586v1)\n", "2303.07582": "- 2023-03-14, **Calibrated Teacher for Sparsely Annotated Object Detection**, Haohan Wang et.al., Paper: [http://arxiv.org/abs/2303.07582v1](http://arxiv.org/abs/2303.07582v1), Code: **[https://github.com/whileherham/calibratedteacher](https://github.com/whileherham/calibratedteacher)**\n", "2303.08817": "- 2023-03-16, **DeepMIM: Deep Supervision for Masked Image Modeling**, Sucheng Ren et.al., Paper: [http://arxiv.org/abs/2303.08817v2](http://arxiv.org/abs/2303.08817v2), Code: **[https://github.com/oliverrensu/deepmim](https://github.com/oliverrensu/deepmim)**\n", "2303.08810": "- 2023-03-15, **BiFormer: Vision Transformer with Bi-Level Routing Attention**, Lei Zhu et.al., Paper: [http://arxiv.org/abs/2303.08810v1](http://arxiv.org/abs/2303.08810v1), Code: **[https://github.com/rayleizhu/biformer](https://github.com/rayleizhu/biformer)**\n", "2303.08784": "- 2023-03-15, **Query-guided Attention in Vision Transformers for Localizing Objects Using a Single Sketch**, Aditay Tripathi et.al., Paper: [http://arxiv.org/abs/2303.08784v1](http://arxiv.org/abs/2303.08784v1)\n", "2303.08747": "- 2023-03-15, **Cascaded Zoom-in Detector for High Resolution Aerial Images**, Akhil Meethal et.al., Paper: [http://arxiv.org/abs/2303.08747v1](http://arxiv.org/abs/2303.08747v1), Code: **[https://github.com/akhilpm/dronedetectron2](https://github.com/akhilpm/dronedetectron2)**\n", "2303.08744": "- 2023-03-15, **Towards Phytoplankton Parasite Detection Using Autoencoders**, Simon Bilik et.al., Paper: [http://arxiv.org/abs/2303.08744v1](http://arxiv.org/abs/2303.08744v1)\n", "2303.08686": "- 2023-03-15, **Weakly Supervised Monocular 3D Object Detection using Multi-View Projection and Direction Consistency**, Runzhou Tao et.al., Paper: [http://arxiv.org/abs/2303.08686v1](http://arxiv.org/abs/2303.08686v1)\n", "2303.08685": "- 2023-03-15, **Making Vision Transformers Efficient from A Token Sparsification View**, Shuning Chang et.al., Paper: [http://arxiv.org/abs/2303.08685v1](http://arxiv.org/abs/2303.08685v1)\n", "2303.08498": "- 2023-03-15, **BEVHeight: A Robust Framework for Vision-based Roadside 3D Object Detection**, Lei Yang et.al., Paper: [http://arxiv.org/abs/2303.08498v1](http://arxiv.org/abs/2303.08498v1), Code: **[https://github.com/adlab-autodrive/bevheight](https://github.com/adlab-autodrive/bevheight)**\n", "2303.08481": "- 2023-03-15, **SeqCo-DETR: Sequence Consistency Training for Self-Supervised Object Detection with Transformers**, Guoqiang Jin et.al., Paper: [http://arxiv.org/abs/2303.08481v1](http://arxiv.org/abs/2303.08481v1)\n", "2303.08458": "- 2023-03-15, **Online and Predictive Warning System for Forced Lane Changes using Risk Maps**, Tim Puphal et.al., Paper: [http://arxiv.org/abs/2303.08458v1](http://arxiv.org/abs/2303.08458v1)\n", "2303.09551": "- 2023-03-16, **SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving**, Yi Wei et.al., Paper: [http://arxiv.org/abs/2303.09551v1](http://arxiv.org/abs/2303.09551v1), Code: **[https://github.com/weiyithu/surroundocc](https://github.com/weiyithu/surroundocc)**\n", "2303.09530": "- 2023-03-16, **Tackling Clutter in Radar Data -- Label Generation and Detection Using PointNet++**, Johannes Kopp et.al., Paper: [http://arxiv.org/abs/2303.09530v1](http://arxiv.org/abs/2303.09530v1), Code: **[https://github.com/kopp-j/clutter-ds](https://github.com/kopp-j/clutter-ds)**\n", "2303.09495": "- 2023-03-16, **Among Us: Adversarially Robust Collaborative Perception by Consensus**, Yiming Li et.al., Paper: [http://arxiv.org/abs/2303.09495v1](http://arxiv.org/abs/2303.09495v1), Code: **[https://github.com/coperception/robosac](https://github.com/coperception/robosac)**\n", "2303.09252": "- 2023-03-16, **GridCLIP: One-Stage Object Detection by Grid-Level CLIP Representation Learning**, Jiayi Lin et.al., Paper: [http://arxiv.org/abs/2303.09252v1](http://arxiv.org/abs/2303.09252v1)\n", "2303.09190": "- 2023-03-16, **A Framework for Real-time Object Detection and Image Restoration**, Rui-Yang Ju et.al., Paper: [http://arxiv.org/abs/2303.09190v1](http://arxiv.org/abs/2303.09190v1), Code: **[https://github.com/rubbbbbbbbby/swinoir](https://github.com/rubbbbbbbbby/swinoir)**\n", "2303.09117": "- 2023-03-16, **Visual-Linguistic Causal Intervention for Radiology Report Generation**, Weixing Chen et.al., Paper: [http://arxiv.org/abs/2303.09117v1](http://arxiv.org/abs/2303.09117v1)\n", "2303.09105": "- 2023-03-16, **Rethinking Model Ensemble in Transfer-based Adversarial Attacks**, Huanran Chen et.al., Paper: [http://arxiv.org/abs/2303.09105v1](http://arxiv.org/abs/2303.09105v1)\n", "2303.09061": "- 2023-03-16, **MixTeacher: Mining Promising Labels with Mixed Scale Teacher for Semi-Supervised Object Detection**, Liang Liu et.al., Paper: [http://arxiv.org/abs/2303.09061v1](http://arxiv.org/abs/2303.09061v1), Code: **[https://github.com/lliuz/mixteacher](https://github.com/lliuz/mixteacher)**\n", "2303.09030": "- 2023-03-16, **Large Selective Kernel Network for Remote Sensing Object Detection**, Yuxuan Li et.al., Paper: [http://arxiv.org/abs/2303.09030v1](http://arxiv.org/abs/2303.09030v1), Code: **[https://github.com/zcablii/Large-Selective-Kernel-Network](https://github.com/zcablii/Large-Selective-Kernel-Network)**\n", "2303.09026": "- 2023-03-17, **Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection**, Pu Zhang et.al., Paper: [http://arxiv.org/abs/2303.09026v2](http://arxiv.org/abs/2303.09026v2)\n", "2303.10093": "- 2023-03-17, **Enhancing the Role of Context in Region-Word Alignment for Object Detection**, Kyle Buettner et.al., Paper: [http://arxiv.org/abs/2303.10093v1](http://arxiv.org/abs/2303.10093v1)\n", "2303.10076": "- 2023-03-17, **A Simple Attempt for 3D Occupancy Estimation in Autonomous Driving**, Wanshui Gan et.al., Paper: [http://arxiv.org/abs/2303.10076v1](http://arxiv.org/abs/2303.10076v1)\n", "2303.09919": "- 2023-03-17, **Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation**, Dongsheng Wang et.al., Paper: [http://arxiv.org/abs/2303.09919v1](http://arxiv.org/abs/2303.09919v1), Code: **[https://github.com/wds320/AAAI_Event_based_detection](https://github.com/wds320/AAAI_Event_based_detection)**\n", "2303.09801": "- 2023-03-17, **Adaptive Graph Convolution Module for Salient Object Detection**, Yongwoo Lee et.al., Paper: [http://arxiv.org/abs/2303.09801v1](http://arxiv.org/abs/2303.09801v1)\n", "2303.09800": "- 2023-03-17, **GOOD: General Optimization-based Fusion for 3D Object Detection via LiDAR-Camera Object Candidates**, Bingqi Shen et.al., Paper: [http://arxiv.org/abs/2303.09800v1](http://arxiv.org/abs/2303.09800v1)\n", "2303.09733": "- 2023-03-17, **Scribble-Supervised RGB-T Salient Object Detection**, Zhengyi Liu et.al., Paper: [http://arxiv.org/abs/2303.09733v1](http://arxiv.org/abs/2303.09733v1), Code: **[https://github.com/liuzywen/rgbtscribble-icme2023](https://github.com/liuzywen/rgbtscribble-icme2023)**\n", "2303.09731": "- 2023-03-17, **Exorcising ''Wraith'': Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks**, Qifan Xiao et.al., Paper: [http://arxiv.org/abs/2303.09731v1](http://arxiv.org/abs/2303.09731v1)\n", "2303.09674": "- 2023-03-16, **DiGeo: Discriminative Geometry-Aware Learning for Generalized Few-Shot Object Detection**, Jiawei Ma et.al., Paper: [http://arxiv.org/abs/2303.09674v1](http://arxiv.org/abs/2303.09674v1), Code: **[https://github.com/phoenix-v/digeo](https://github.com/phoenix-v/digeo)**\n", "2303.09608": "- 2023-03-16, **VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection**, Arushi Rai et.al., Paper: [http://arxiv.org/abs/2303.09608v1](http://arxiv.org/abs/2303.09608v1)\n", "2303.11325": "- 2023-03-20, **Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding**, Jihao Liu et.al., Paper: [http://arxiv.org/abs/2303.11325v1](http://arxiv.org/abs/2303.11325v1)\n", "2303.11301": "- 2023-03-20, **VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking**, Yukang Chen et.al., Paper: [http://arxiv.org/abs/2303.11301v1](http://arxiv.org/abs/2303.11301v1), Code: **[https://github.com/dvlab-research/VoxelNeXt](https://github.com/dvlab-research/VoxelNeXt)**\n", "2303.11267": "- 2023-03-20, **Rethinking the backbone architecture for tiny object detection**, Jinlai Ning et.al., Paper: [http://arxiv.org/abs/2303.11267v1](http://arxiv.org/abs/2303.11267v1)\n", "2303.11243": "- 2023-03-20, **Augment and Criticize: Exploring Informative Samples for Semi-Supervised Monocular 3D Object Detection**, Zhenyu Li et.al., Paper: [http://arxiv.org/abs/2303.11243v1](http://arxiv.org/abs/2303.11243v1)\n", "2303.11214": "- 2023-03-20, **Accurate Detection of Mediastinal Lesions with nnDetection**, Michael Baumgartner et.al., Paper: [http://arxiv.org/abs/2303.11214v1](http://arxiv.org/abs/2303.11214v1)\n", "2303.11098": "- 2023-03-20, **A closer look at the training dynamics of knowledge distillation**, Roy Miles et.al., Paper: [http://arxiv.org/abs/2303.11098v1](http://arxiv.org/abs/2303.11098v1)\n", "2303.11040": "- 2023-03-20, **Benchmarking Robustness of 3D Object Detection to Common Corruptions in Autonomous Driving**, Yinpeng Dong et.al., Paper: [http://arxiv.org/abs/2303.11040v1](http://arxiv.org/abs/2303.11040v1)\n", "2303.10975": "- 2023-03-20, **VIMI: Vehicle-Infrastructure Multi-view Intermediate Fusion for Camera-based 3D Object Detection**, Zhe Wang et.al., Paper: [http://arxiv.org/abs/2303.10975v1](http://arxiv.org/abs/2303.10975v1), Code: **[https://github.com/bosszhe/vimi](https://github.com/bosszhe/vimi)**\n", "2303.10959": "- 2023-03-20, **Long-Term Indoor Localization with Metric-Semantic Mapping using a Floor Plan Prior**, Nicky Zimmerman et.al., Paper: [http://arxiv.org/abs/2303.10959v1](http://arxiv.org/abs/2303.10959v1), Code: **[https://github.com/prbonn/simp](https://github.com/prbonn/simp)**\n", "2303.10937": "- 2023-03-20, **Boosting Weakly Supervised Object Detection using Fusion and Priors from Hallucinated Depth**, Cagri Gungor et.al., Paper: [http://arxiv.org/abs/2303.10937v1](http://arxiv.org/abs/2303.10937v1)\n", "2303.11926": "- 2023-03-21, **Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection**, Shihao Wang et.al., Paper: [http://arxiv.org/abs/2303.11926v1](http://arxiv.org/abs/2303.11926v1), Code: **[https://github.com/exiawsh/streampetr](https://github.com/exiawsh/streampetr)**\n", "2303.11888": "- 2023-03-21, **Penalty-Based Imitation Learning With Cross Semantics Generation Sensor Fusion for Autonomous Driving**, Hongkuan Zhou et.al., Paper: [http://arxiv.org/abs/2303.11888v1](http://arxiv.org/abs/2303.11888v1)\n", "2303.11749": "- 2023-03-21, **Detecting Everything in the Open World: Towards Universal Object Detection**, Zhenyu Wang et.al., Paper: [http://arxiv.org/abs/2303.11749v1](http://arxiv.org/abs/2303.11749v1)\n", "2303.11694": "- 2023-03-21, **Anchor Free remote sensing detector based on solving discrete polar coordinate equation**, Linfeng Shi et.al., Paper: [http://arxiv.org/abs/2303.11694v1](http://arxiv.org/abs/2303.11694v1)\n", "2303.11654": "- 2023-03-21, **Mitigating climate and health impact of small-scale kiln industry using multi-spectral classifier and deep learning**, Usman Nazir et.al., Paper: [http://arxiv.org/abs/2303.11654v1](http://arxiv.org/abs/2303.11654v1)\n", "2303.11623": "- 2023-03-21, **Detecting the open-world objects with the help of the Brain**, Shuailei Ma et.al., Paper: [http://arxiv.org/abs/2303.11623v1](http://arxiv.org/abs/2303.11623v1), Code: **[https://github.com/xiaomabufei/dowb](https://github.com/xiaomabufei/dowb)**\n", "2303.11511": "- 2023-03-21, **STDLens: Model Hijacking-resilient Federated Learning for Object Detection**, Ka-Ho Chow et.al., Paper: [http://arxiv.org/abs/2303.11511v1](http://arxiv.org/abs/2303.11511v1), Code: **[https://github.com/git-disl/stdlens](https://github.com/git-disl/stdlens)**\n", "2303.12787": "- 2023-03-22, **EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation**, Hansheng Chen et.al., Paper: [http://arxiv.org/abs/2303.12787v1](http://arxiv.org/abs/2303.12787v1)\n", "2303.12776": "- 2023-03-22, **Dense Distinct Query for End-to-End Object Detection**, Shilong Zhang et.al., Paper: [http://arxiv.org/abs/2303.12776v1](http://arxiv.org/abs/2303.12776v1), Code: **[https://github.com/jshilong/ddq](https://github.com/jshilong/ddq)**\n", "2303.12766": "- 2023-03-22, **Spherical Transformer for LiDAR-based 3D Recognition**, Xin Lai et.al., Paper: [http://arxiv.org/abs/2303.12766v1](http://arxiv.org/abs/2303.12766v1), Code: **[https://github.com/dvlab-research/sphereformer](https://github.com/dvlab-research/sphereformer)**\n", "2303.12760": "- 2023-03-22, **Uncertainty Aware Active Learning for Reconfiguration of Pre-trained Deep Object-Detection Networks for New Target Domains**, Jiaming Na et.al., Paper: [http://arxiv.org/abs/2303.12760v1](http://arxiv.org/abs/2303.12760v1)\n", "2303.12621": "- 2023-03-22, **OcTr: Octree-based Transformer for 3D Object Detection**, Chao Zhou et.al., Paper: [http://arxiv.org/abs/2303.12621v1](http://arxiv.org/abs/2303.12621v1)\n", "2303.12396": "- 2023-03-22, **Rigidity-Aware Detection for 6D Object Pose Estimation**, Yang Hai et.al., Paper: [http://arxiv.org/abs/2303.12396v1](http://arxiv.org/abs/2303.12396v1)\n", "2303.13510": "- 2023-03-23, **MV-JAR: Masked Voxel Jigsaw and Reconstruction for LiDAR-Based Self-Supervised Pre-Training**, Runsen Xu et.al., Paper: [http://arxiv.org/abs/2303.13510v1](http://arxiv.org/abs/2303.13510v1), Code: **[https://github.com/smartbot-pjlab/mv-jar](https://github.com/smartbot-pjlab/mv-jar)**\n", "2303.13496": "- 2023-03-23, **The effectiveness of MAE pre-pretraining for billion-scale pretraining**, Mannat Singh et.al., Paper: [http://arxiv.org/abs/2303.13496v1](http://arxiv.org/abs/2303.13496v1)\n", "2303.13221": "- 2023-03-23, **Explore the Power of Synthetic Data on Few-shot Object Detection**, Shaobo Lin et.al., Paper: [http://arxiv.org/abs/2303.13221v1](http://arxiv.org/abs/2303.13221v1)\n", "2303.13212": "- 2023-03-24, **A Simple and Generic Framework for Feature Distillation via Channel-wise Transformation**, Ziwei Liu et.al., Paper: [http://arxiv.org/abs/2303.13212v2](http://arxiv.org/abs/2303.13212v2)\n", "2303.13121": "- 2023-03-23, **DetOFA: Efficient Training of Once-for-All Networks for Object Detection by Using Pre-trained Supernet and Path Filter**, Yuiko Sakuma et.al., Paper: [http://arxiv.org/abs/2303.13121v1](http://arxiv.org/abs/2303.13121v1)\n", "2303.13089": "- 2023-03-23, **Box-Level Active Detection**, Mengyao Lyu et.al., Paper: [http://arxiv.org/abs/2303.13089v1](http://arxiv.org/abs/2303.13089v1)\n", "2303.13076": "- 2023-03-23, **CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching**, Xiaoshi Wu et.al., Paper: [http://arxiv.org/abs/2303.13076v1](http://arxiv.org/abs/2303.13076v1), Code: **[https://github.com/tgxs002/cora](https://github.com/tgxs002/cora)**\n", "2303.13040": "- 2023-03-23, **Open-Vocabulary Object Detection using Pseudo Caption Labels**, Han-Cheol Cho et.al., Paper: [http://arxiv.org/abs/2303.13040v1](http://arxiv.org/abs/2303.13040v1)\n", "2303.13018": "- 2023-03-23, **MonoATT: Online Monocular 3D Object Detection with Adaptive Token Transformer**, Yunsong Zhou et.al., Paper: [http://arxiv.org/abs/2303.13018v1](http://arxiv.org/abs/2303.13018v1)\n", "2303.13916": "- 2023-03-24, **Self-Supervised Reversed Image Signal Processing via Reference-Guided Dynamic Parameter Selection**, Junji Otsuka et.al., Paper: [http://arxiv.org/abs/2303.13916v1](http://arxiv.org/abs/2303.13916v1)\n", "2303.13868": "- 2023-03-24, **Physically Adversarial Infrared Patches with Learnable Shapes and Locations**, Wei Xingxing et.al., Paper: [http://arxiv.org/abs/2303.13868v1](http://arxiv.org/abs/2303.13868v1)\n", "2303.13863": "- 2023-03-24, **MagicEye: An Intelligent Wearable Towards Independent Living of Visually Impaired**, Sibi C. Sethuraman et.al., Paper: [http://arxiv.org/abs/2303.13863v1](http://arxiv.org/abs/2303.13863v1)\n", "2303.13853": "- 2023-03-24, **2PCNet: Two-Phase Consistency Training for Day-to-Night Unsupervised Domain Adaptive Object Detection**, Mikhail Kennerley et.al., Paper: [http://arxiv.org/abs/2303.13853v1](http://arxiv.org/abs/2303.13853v1), Code: **[https://github.com/mecarill/2pcnet](https://github.com/mecarill/2pcnet)**\n", "2303.13769": "- 2023-03-24, **Unknown Sniffer for Object Detection: Don't Turn a Blind Eye to Unknown Objects**, Wenteng Liang et.al., Paper: [http://arxiv.org/abs/2303.13769v1](http://arxiv.org/abs/2303.13769v1)\n", "2303.15416": "- 2023-03-27, **3D Video Object Detection with Learnable Object-Centric Global Optimization**, Jiawei He et.al., Paper: [http://arxiv.org/abs/2303.15416v1](http://arxiv.org/abs/2303.15416v1), Code: **[https://github.com/jiaweihe1996/ba-det](https://github.com/jiaweihe1996/ba-det)**\n", "2303.15390": "- 2023-03-27, **Learning to Zoom and Unzoom**, Chittesh Thavamani et.al., Paper: [http://arxiv.org/abs/2303.15390v1](http://arxiv.org/abs/2303.15390v1)\n", "2303.15377": "- 2023-03-27, **AIR-DA: Adversarial Image Reconstruction for Unsupervised Domain Adaptive Object Detection**, Kunyang Sun et.al., Paper: [http://arxiv.org/abs/2303.15377v1](http://arxiv.org/abs/2303.15377v1)\n", "2303.15286": "- 2023-03-27, **Unsupervised Adaptation from Repeated Traversals for Autonomous Driving**, Yurong You et.al., Paper: [http://arxiv.org/abs/2303.15286v1](http://arxiv.org/abs/2303.15286v1), Code: **[https://github.com/yurongyou/rote-da](https://github.com/yurongyou/rote-da)**\n", "2303.15274": "- 2023-03-27, **Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention**, Sounak Mondal et.al., Paper: [http://arxiv.org/abs/2303.15274v1](http://arxiv.org/abs/2303.15274v1)\n", "2303.15149": "- 2023-03-27, **What Can Human Sketches Do for Object Detection?**, Pinaki Nath Chowdhury et.al., Paper: [http://arxiv.org/abs/2303.15149v1](http://arxiv.org/abs/2303.15149v1)\n", "2303.15124": "- 2023-03-27, **Blind Inpainting with Object-aware Discrimination for Artificial Marker Removal**, Xuechen Guo et.al., Paper: [http://arxiv.org/abs/2303.15124v1](http://arxiv.org/abs/2303.15124v1)\n", "2303.15105": "- 2023-03-27, **Vision Transformer with Quadrangle Attention**, Qiming Zhang et.al., Paper: [http://arxiv.org/abs/2303.15105v1](http://arxiv.org/abs/2303.15105v1)\n", "2303.15083": "- 2023-03-27, **UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View**, Shengchao Zhou et.al., Paper: [http://arxiv.org/abs/2303.15083v1](http://arxiv.org/abs/2303.15083v1), Code: **[https://github.com/megvii-research/cvpr2023-unidistill](https://github.com/megvii-research/cvpr2023-unidistill)**\n", "2303.14999": "- 2023-03-27, **Transformer-based Multi-Instance Learning for Weakly Supervised Object Detection**, Zhaofei Wang et.al., Paper: [http://arxiv.org/abs/2303.14999v1](http://arxiv.org/abs/2303.14999v1)\n", "2303.16094": "- 2023-03-28, **LinK: Linear Kernel for LiDAR-based 3D Perception**, Tao Lu et.al., Paper: [http://arxiv.org/abs/2303.16094v1](http://arxiv.org/abs/2303.16094v1)\n", "2303.15823": "- 2023-03-28, **Automated wildlife image classification: An active learning tool for ecological applications**, Ludwig Bothmann et.al., Paper: [http://arxiv.org/abs/2303.15823v1](http://arxiv.org/abs/2303.15823v1)\n", "2303.15728": "- 2023-03-28, **DiffULD: Diffusive Universal Lesion Detection**, Peiang Zhao et.al., Paper: [http://arxiv.org/abs/2303.15728v1](http://arxiv.org/abs/2303.15728v1)\n", "2303.15710": "- 2023-03-28, **Explicit Attention-Enhanced Fusion for RGB-Thermal Perception Tasks**, Mingjian Liang et.al., Paper: [http://arxiv.org/abs/2303.15710v1](http://arxiv.org/abs/2303.15710v1), Code: **[https://github.com/freeformrobotics/eaefnet](https://github.com/freeformrobotics/eaefnet)**\n", "2303.16839": "- 2023-03-30, **MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks**, Weicheng Kuo et.al., Paper: [http://arxiv.org/abs/2303.16839v2](http://arxiv.org/abs/2303.16839v2)\n", "2303.16818": "- 2023-03-30, **BEVSimDet: Simulated Multi-modal Distillation in Bird's-Eye View for Multi-view 3D Object Detection**, Haimei Zhao et.al., Paper: [http://arxiv.org/abs/2303.16818v2](http://arxiv.org/abs/2303.16818v2), Code: **[https://github.com/vitae-transformer/bevsimdet](https://github.com/vitae-transformer/bevsimdet)**\n", "2303.16710": "- 2023-03-29, **An intelligent modular real-time vision-based system for environment perception**, Amirhossein Kazerouni et.al., Paper: [http://arxiv.org/abs/2303.16710v1](http://arxiv.org/abs/2303.16710v1), Code: **[https://github.com/pandas-team/autonomous-vehicle-environment-perception](https://github.com/pandas-team/autonomous-vehicle-environment-perception)**\n", "2303.16637": "- 2023-03-29, **MuRAL: Multi-Scale Region-based Active Learning for Object Detection**, Yi-Syuan Liou et.al., Paper: [http://arxiv.org/abs/2303.16637v1](http://arxiv.org/abs/2303.16637v1)\n", "2303.16628": "- 2023-03-29, **DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking**, Qing Lian et.al., Paper: [http://arxiv.org/abs/2303.16628v1](http://arxiv.org/abs/2303.16628v1), Code: **[https://github.com/smartbot-pjlab/dort](https://github.com/smartbot-pjlab/dort)**\n", "2303.16507": "- 2023-03-29, **Improving Object Detection in Medical Image Analysis through Multiple Expert Annotators: An Empirical Investigation**, Hieu H. Pham et.al., Paper: [http://arxiv.org/abs/2303.16507v1](http://arxiv.org/abs/2303.16507v1)\n", "2303.16342": "- 2023-03-28, **Language-Guided Audio-Visual Source Separation via Trimodal Consistency**, Reuben Tan et.al., Paper: [http://arxiv.org/abs/2303.16342v1](http://arxiv.org/abs/2303.16342v1)\n", "2303.17605": "- 2023-03-30, **SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer**, Xuanyao Chen et.al., Paper: [http://arxiv.org/abs/2303.17605v1](http://arxiv.org/abs/2303.17605v1)\n", "2303.17297": "- 2023-03-30, **Understanding the Robustness of 3D Object Detection with Bird's-Eye-View Representations in Autonomous Driving**, Zijian Zhu et.al., Paper: [http://arxiv.org/abs/2303.17297v1](http://arxiv.org/abs/2303.17297v1)\n", "2303.17249": "- 2023-03-30, **Model-agnostic explainable artificial intelligence for object detection in image data**, Milad Moradi et.al., Paper: [http://arxiv.org/abs/2303.17249v1](http://arxiv.org/abs/2303.17249v1)\n", "2303.17142": "- 2023-03-30, **Soft Neighbors are Positive Supporters in Contrastive Visual Representation Learning**, Chongjian Ge et.al., Paper: [http://arxiv.org/abs/2303.17142v1](http://arxiv.org/abs/2303.17142v1)\n", "2303.17099": "- 2023-03-30, **BEVFusion4D: Learning LiDAR-Camera Fusion Under Bird's-Eye-View via Cross-Modality Guidance and Temporal Aggregation**, Hongxiang Cai et.al., Paper: [http://arxiv.org/abs/2303.17099v1](http://arxiv.org/abs/2303.17099v1)\n", "2303.16947": "- 2023-03-29, **De-coupling and De-positioning Dense Self-supervised Learning**, Congpei Qiu et.al., Paper: [http://arxiv.org/abs/2303.16947v1](http://arxiv.org/abs/2303.16947v1)\n", "2303.16940": "- 2023-03-29, **T-FFTRadNet: Object Detection with Swin Vision Transformers from Raw ADC Radar Signals**, James Giroux et.al., Paper: [http://arxiv.org/abs/2303.16940v1](http://arxiv.org/abs/2303.16940v1)\n", "2303.18101": "- 2023-03-31, **INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields**, Julia Hindel et.al., Paper: [http://arxiv.org/abs/2303.18101v1](http://arxiv.org/abs/2303.18101v1)\n", "2303.18019": "- 2023-03-31, **Live image-based neurosurgical guidance and roadmap generation using unsupervised embedding**, Gary Sarwin et.al., Paper: [http://arxiv.org/abs/2303.18019v1](http://arxiv.org/abs/2303.18019v1)\n", "2303.17937": "- 2023-03-31, **STFAR: Improving Object Detection Robustness at Test-Time by Self-Training with Feature Alignment Regularization**, Yijin Chen et.al., Paper: [http://arxiv.org/abs/2303.17937v1](http://arxiv.org/abs/2303.17937v1)\n", "2303.17921": "- 2023-03-31, **IC-FPS: Instance-Centroid Faster Point Sampling Module for 3D Point-base Object Detection**, Hu Haotian et.al., Paper: [http://arxiv.org/abs/2303.17921v1](http://arxiv.org/abs/2303.17921v1)\n", "2303.17895": "- 2023-03-31, **EA-BEV: Edge-aware Bird' s-Eye-View Projector for 3D Object Detection**, Haotian et.al., Paper: [http://arxiv.org/abs/2303.17895v1](http://arxiv.org/abs/2303.17895v1)\n", "2303.17803": "- 2023-04-03, **Rethinking Local Perception in Lightweight Vision Transformer**, Qihang Fan et.al., Paper: [http://arxiv.org/abs/2303.17803v2](http://arxiv.org/abs/2303.17803v2)\n", "2304.01168": "- 2023-04-03, **DeepAccident: A Motion and Accident Prediction Benchmark for V2X Autonomous Driving**, Tianqi Wang et.al., Paper: [http://arxiv.org/abs/2304.01168v1](http://arxiv.org/abs/2304.01168v1)\n", "2304.01054": "- 2023-04-03, **VoxelFormer: Bird's-Eye-View Feature Generation based on Dual-view Attention for Multi-view 3D Object Detection**, Zhuoling Li et.al., Paper: [http://arxiv.org/abs/2304.01054v1](http://arxiv.org/abs/2304.01054v1), Code: **[https://github.com/lizhuoling/voxelformer-public](https://github.com/lizhuoling/voxelformer-public)**\n", "2304.00967": "- 2023-04-03, **Temporal Enhanced Training of Multi-view 3D Object Detector via Historical Object Prediction**, Zhuofan Zong et.al., Paper: [http://arxiv.org/abs/2304.00967v1](http://arxiv.org/abs/2304.00967v1)\n", "2304.00788": "- 2023-04-03, **Open-Vocabulary Point-Cloud Object Detection without 3D Annotation**, Yuheng Lu et.al., Paper: [http://arxiv.org/abs/2304.00788v1](http://arxiv.org/abs/2304.00788v1)\n", "2304.00763": "- 2023-04-03, **BOLLWM: A real-world dataset for bollworm pest monitoring from cotton fields in India**, Jerome White et.al., Paper: [http://arxiv.org/abs/2304.00763v1](http://arxiv.org/abs/2304.00763v1)\n", "2304.00757": "- 2023-04-03, **Spot-the-Camel: Computer Vision for Safer Roads**, Khalid Alnujaidi et.al., Paper: [http://arxiv.org/abs/2304.00757v1](http://arxiv.org/abs/2304.00757v1)\n", "2304.00741": "- 2023-04-03, **DeGPR: Deep Guided Posterior Regularization for Multi-Class Cell Detection and Counting**, Aayush Kumar Tyagi et.al., Paper: [http://arxiv.org/abs/2304.00741v1](http://arxiv.org/abs/2304.00741v1), Code: **[https://github.com/dair-iitd/degpr](https://github.com/dair-iitd/degpr)**\n", "2304.00689": "- 2023-04-03, **Accuracy Improvement of Object Detection in VVC Coded Video Using YOLO-v7 Features**, Takahiro Shindo et.al., Paper: [http://arxiv.org/abs/2304.00689v1](http://arxiv.org/abs/2304.00689v1)\n", "2304.00670": "- 2023-04-03, **CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception**, Youngseok Kim et.al., Paper: [http://arxiv.org/abs/2304.00670v1](http://arxiv.org/abs/2304.00670v1)\n", "2304.00501": "- 2023-04-02, **A Comprehensive Review of YOLO: From YOLOv1 to YOLOv8 and Beyond**, Juan Terven et.al., Paper: [http://arxiv.org/abs/2304.00501v1](http://arxiv.org/abs/2304.00501v1)\n", "2304.01830": "- 2023-04-04, **Learning to Name Classes for Vision and Language Models**, Sarah Parisot et.al., Paper: [http://arxiv.org/abs/2304.01830v1](http://arxiv.org/abs/2304.01830v1)\n", "2304.01577": "- 2023-04-05, **Form-NLU: Dataset for the Form Language Understanding**, Yihao Ding et.al., Paper: [http://arxiv.org/abs/2304.01577v2](http://arxiv.org/abs/2304.01577v2), Code: **[https://github.com/adlnlp/form_nlu](https://github.com/adlnlp/form_nlu)**\n", "2304.01567": "- 2023-04-04, **A real-time algorithm for human action recognition in RGB and thermal video**, Hannes Fassold et.al., Paper: [http://arxiv.org/abs/2304.01567v1](http://arxiv.org/abs/2304.01567v1)\n", "2304.01519": "- 2023-04-04, **LiDAR-Based 3D Object Detection via Hybrid 2D Semantic Scene Generation**, Haitao Yang et.al., Paper: [http://arxiv.org/abs/2304.01519v1](http://arxiv.org/abs/2304.01519v1)\n", "2304.01464": "- 2023-04-04, **Hierarchical Supervision and Shuffle Data Augmentation for 3D Semi-Supervised Object Detection**, Chuandong Liu et.al., Paper: [http://arxiv.org/abs/2304.01464v1](http://arxiv.org/abs/2304.01464v1), Code: **[https://github.com/azhuantou/hssda](https://github.com/azhuantou/hssda)**\n", "2304.01289": "- 2023-04-03, **Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver**, Xianpeng Liu et.al., Paper: [http://arxiv.org/abs/2304.01289v1](http://arxiv.org/abs/2304.01289v1)\n", "2304.02431": "- 2023-04-05, **MS3D: Leveraging Multiple Detectors for Unsupervised Domain Adaptation in 3D Object Detection**, Darren Tsai et.al., Paper: [http://arxiv.org/abs/2304.02431v1](http://arxiv.org/abs/2304.02431v1), Code: **[https://github.com/darrenjkt/ms3d](https://github.com/darrenjkt/ms3d)**\n", "2304.02420": "- 2023-04-05, **Semantic Validation in Structure from Motion**, Joseph Rowell et.al., Paper: [http://arxiv.org/abs/2304.02420v1](http://arxiv.org/abs/2304.02420v1), Code: **[https://github.com/joerowelll/comp0132_rjxz25](https://github.com/joerowelll/comp0132_rjxz25)**\n", "2304.02291": "- 2023-04-05, **Trap-Based Pest Counting: Multiscale and Deformable Attention CenterNet Integrating Internal LR and HR Joint Feature Learning**, Jae-Hyeon Lee et.al., Paper: [http://arxiv.org/abs/2304.02291v1](http://arxiv.org/abs/2304.02291v1)\n", "2304.02250": "- 2023-04-05, **DPPD: Deformable Polar Polygon Object Detection**, Yang Zheng et.al., Paper: [http://arxiv.org/abs/2304.02250v1](http://arxiv.org/abs/2304.02250v1)\n", "2304.02186": "- 2023-04-05, **Training Strategies for Vision Transformers for Object Detection**, Apoorv Singh et.al., Paper: [http://arxiv.org/abs/2304.02186v1](http://arxiv.org/abs/2304.02186v1)\n", "2304.03198": "- 2023-04-06, **RFAConv: Innovating Spatital Attention and Standard Convolutional Operation**, Xin Zhang et.al., Paper: [http://arxiv.org/abs/2304.03198v1](http://arxiv.org/abs/2304.03198v1), Code: **[https://github.com/liuchen1997/rfaconv](https://github.com/liuchen1997/rfaconv)**\n", "2304.03188": "- 2023-04-06, **Advances in Data-Driven Analysis and Synthesis of 3D Indoor Scenes**, Akshay Gadi Patil et.al., Paper: [http://arxiv.org/abs/2304.03188v1](http://arxiv.org/abs/2304.03188v1)\n", "2304.03177": "- 2023-04-06, **Mutual Interference Mitigation for MIMO-FMCW Automotive Radar**, Sian Jin et.al., Paper: [http://arxiv.org/abs/2304.03177v1](http://arxiv.org/abs/2304.03177v1)\n", "2304.03110": "- 2023-04-06, **Continual Detection Transformer for Incremental Object Detection**, Yaoyao Liu et.al., Paper: [http://arxiv.org/abs/2304.03110v1](http://arxiv.org/abs/2304.03110v1)\n", "2304.03105": "- 2023-04-07, **Geometric-aware Pretraining for Vision-centric 3D Object Detection**, Linyan Huang et.al., Paper: [http://arxiv.org/abs/2304.03105v2](http://arxiv.org/abs/2304.03105v2), Code: **[https://github.com/opendrivelab/bevperception-survey-recipe](https://github.com/opendrivelab/bevperception-survey-recipe)**\n", "2304.02950": "- 2023-04-06, **Multi-view Adversarial Discriminator: Mine the Non-causal Factors for Object Detection in Unseen Domains**, Mingjun Xu et.al., Paper: [http://arxiv.org/abs/2304.02950v1](http://arxiv.org/abs/2304.02950v1), Code: **[https://github.com/k2okoh/mad](https://github.com/k2okoh/mad)**\n", "2304.02867": "- 2023-04-06, **VPFusion: Towards Robust Vertical Representation Learning for 3D Object Detection**, Yuhao Huang et.al., Paper: [http://arxiv.org/abs/2304.02867v1](http://arxiv.org/abs/2304.02867v1)\n", "2304.02859": "- 2023-04-06, **MULLER: Multilayer Laplacian Resizer for Vision**, Zhengzhong Tu et.al., Paper: [http://arxiv.org/abs/2304.02859v1](http://arxiv.org/abs/2304.02859v1)\n", "2304.02848": "- 2023-04-06, **Patch-aware Batch Normalization for Improving Cross-domain Robustness**, Lei Qi et.al., Paper: [http://arxiv.org/abs/2304.02848v1](http://arxiv.org/abs/2304.02848v1)\n", "2304.02833": "- 2023-04-06, **DoUnseen: Zero-Shot Object Detection for Robotic Grasping**, Anas Gouda et.al., Paper: [http://arxiv.org/abs/2304.02833v1](http://arxiv.org/abs/2304.02833v1), Code: **[https://github.com/AnasIbrahim/image_agnostic_segmentation](https://github.com/AnasIbrahim/image_agnostic_segmentation)**\n", "2304.03752": "- 2023-04-07, **V3Det: Vast Vocabulary Visual Detection Dataset**, Jiaqi Wang et.al., Paper: [http://arxiv.org/abs/2304.03752v1](http://arxiv.org/abs/2304.03752v1)\n", "2304.03696": "- 2023-04-07, **Reduce, Reuse, Recycle: Modular Multi-Object Navigation**, Sonia Raychaudhuri et.al., Paper: [http://arxiv.org/abs/2304.03696v1](http://arxiv.org/abs/2304.03696v1)\n", "2304.03580": "- 2023-04-07, **Language-aware Multiple Datasets Detection Pretraining for DETRs**, Jing Hao et.al., Paper: [http://arxiv.org/abs/2304.03580v1](http://arxiv.org/abs/2304.03580v1)\n", "2304.03526": "- 2023-04-07, **Lift3D: Synthesize 3D Training Data by Lifting 2D GAN to 3D Generative Radiance Field**, Leheng Li et.al., Paper: [http://arxiv.org/abs/2304.03526v1](http://arxiv.org/abs/2304.03526v1)\n", "2304.03481": "- 2023-04-07, **PSLT: A Light-weight Vision Transformer with Ladder Self-Attention and Progressive Shift**, Gaojie Wu et.al., Paper: [http://arxiv.org/abs/2304.03481v1](http://arxiv.org/abs/2304.03481v1)\n", "2304.03428": "- 2023-04-07, **TinyDet: Accurate Small Object Detection in Lightweight Generic Detectors**, Shaoyu Chen et.al., Paper: [http://arxiv.org/abs/2304.03428v1](http://arxiv.org/abs/2304.03428v1)\n", "2304.04709": "- 2023-04-11, **Can SAM Segment Anything? When SAM Meets Camouflaged Object Detection**, Lv Tang et.al., Paper: [http://arxiv.org/abs/2304.04709v2](http://arxiv.org/abs/2304.04709v2), Code: **[https://github.com/luckybird1994/samcod](https://github.com/luckybird1994/samcod)**\n", "2304.04704": "- 2023-04-10, **Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition**, Shuhuai Ren et.al., Paper: [http://arxiv.org/abs/2304.04704v1](http://arxiv.org/abs/2304.04704v1), Code: **[https://github.com/amazon-science/prompt-pretraining](https://github.com/amazon-science/prompt-pretraining)**\n", "2304.04554": "- 2023-04-10, **Use the Detection Transformer as a Data Augmenter**, Luping Wang et.al., Paper: [http://arxiv.org/abs/2304.04554v1](http://arxiv.org/abs/2304.04554v1), Code: **[https://github.com/zjlab-ammi/demix](https://github.com/zjlab-ammi/demix)**\n", "2304.04518": "- 2023-04-10, **Are Visual Recognition Models Robust to Image Compression?**, Jo\u00e3o Maria Janeiro et.al., Paper: [http://arxiv.org/abs/2304.04518v1](http://arxiv.org/abs/2304.04518v1)\n", "2304.04515": "- 2023-04-10, **SOOD: Towards Semi-Supervised Oriented Object Detection**, Wei Hua et.al., Paper: [http://arxiv.org/abs/2304.04515v1](http://arxiv.org/abs/2304.04515v1), Code: **[https://github.com/hamperdredes/sood](https://github.com/hamperdredes/sood)**\n", "2304.04514": "- 2023-04-10, **DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-training via Word-Region Alignment**, Lewei Yao et.al., Paper: [http://arxiv.org/abs/2304.04514v1](http://arxiv.org/abs/2304.04514v1)\n", "2304.04512": "- 2023-04-10, **Defense-Prefix for Preventing Typographic Attacks on CLIP**, Hiroki Azuma et.al., Paper: [http://arxiv.org/abs/2304.04512v1](http://arxiv.org/abs/2304.04512v1)\n", "2304.04503": "- 2023-04-10, **Head-tail Loss: A simple function for Oriented Object Detection and Anchor-free models**, Pau Gall\u00e9s et.al., Paper: [http://arxiv.org/abs/2304.04503v1](http://arxiv.org/abs/2304.04503v1)\n", "2304.04403": "- 2023-04-11, **H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via Symmetric Learning**, Yi Yu et.al., Paper: [http://arxiv.org/abs/2304.04403v2](http://arxiv.org/abs/2304.04403v2), Code: **[https://github.com/li-qingyun/sam-mmrotate](https://github.com/li-qingyun/sam-mmrotate)**\n", "2304.04356": "- 2023-04-10, **Eagle: End-to-end Deep Reinforcement Learning based Autonomous Control of PTZ Cameras**, Sandeep Singh Sandha et.al., Paper: [http://arxiv.org/abs/2304.04356v1](http://arxiv.org/abs/2304.04356v1), Code: **[https://github.com/nesl/eagle_ptz_cameras](https://github.com/nesl/eagle_ptz_cameras)**\n", "2304.05387": "- 2023-04-11, **MOST: Multiple Object localization with Self-supervised Transformers for object discovery**, Sai Saketh Rambhatla et.al., Paper: [http://arxiv.org/abs/2304.05387v1](http://arxiv.org/abs/2304.05387v1)\n", "2304.05370": "- 2023-04-12, **Overload: Latency Attacks on Object Detection for Edge Devices**, Erh-Chung Chen et.al., Paper: [http://arxiv.org/abs/2304.05370v2](http://arxiv.org/abs/2304.05370v2)\n", "2304.05339": "- 2023-04-11, **Deep-learning assisted detection and quantification of (oo)cysts of Giardia and Cryptosporidium on smartphone microscopy images**, Suprim Nakarmi et.al., Paper: [http://arxiv.org/abs/2304.05339v1](http://arxiv.org/abs/2304.05339v1)\n", "2304.05295": "- 2023-04-11, **A Comprehensive Study on Object Detection Techniques in Unconstrained Environments**, Hrishitva Patel et.al., Paper: [http://arxiv.org/abs/2304.05295v1](http://arxiv.org/abs/2304.05295v1)\n", "2304.05215": "- 2023-04-11, **A Billion-scale Foundation Model for Remote Sensing Images**, Keumgang Cha et.al., Paper: [http://arxiv.org/abs/2304.05215v1](http://arxiv.org/abs/2304.05215v1)\n", "2304.05107": "- 2023-04-11, **Simulation Analysis of Exploration Strategies and UAV Planning for Search and Rescue**, Phuoc Nguyen Thuan et.al., Paper: [http://arxiv.org/abs/2304.05107v1](http://arxiv.org/abs/2304.05107v1)\n", "2304.05096": "- 2023-04-11, **Generating Features with Increased Crop-related Diversity for Few-Shot Object Detection**, Jingyi Xu et.al., Paper: [http://arxiv.org/abs/2304.05096v1](http://arxiv.org/abs/2304.05096v1)\n", "2304.05090": "- 2023-04-11, **CrowdSim2: an Open Synthetic Benchmark for Object Detectors**, Pawe\u0142 Foszner et.al., Paper: [http://arxiv.org/abs/2304.05090v1](http://arxiv.org/abs/2304.05090v1)\n", "2304.04978": "- 2023-04-11, **StageInteractor: Query-based Object Detector with Cross-stage Interaction**, Yao Teng et.al., Paper: [http://arxiv.org/abs/2304.04978v1](http://arxiv.org/abs/2304.04978v1)\n", "2304.04963": "- 2023-04-11, **PlantDet: A benchmark for Plant Detection in the Three-Rivers-Source Region**, Huanhuan Li et.al., Paper: [http://arxiv.org/abs/2304.04963v1](http://arxiv.org/abs/2304.04963v1)\n", "2304.05552": "- 2023-04-12, **DynamicDet: A Unified Dynamic Architecture for Object Detection**, Zhihao Lin et.al., Paper: [http://arxiv.org/abs/2304.05552v1](http://arxiv.org/abs/2304.05552v1), Code: **[https://github.com/VDIGPKU/DynamicDet](https://github.com/VDIGPKU/DynamicDet)**\n", "2304.05469": "- 2023-04-11, **CamDiff: Camouflage Image Augmentation via Diffusion Model**, Xue-Jing Luo et.al., Paper: [http://arxiv.org/abs/2304.05469v1](http://arxiv.org/abs/2304.05469v1), Code: **[https://github.com/drlxj/camdiff](https://github.com/drlxj/camdiff)**\n", "2304.05417": "- 2023-04-11, **The MONET dataset: Multimodal drone thermal dataset recorded in rural scenarios**, Luigi Riz et.al., Paper: [http://arxiv.org/abs/2304.05417v1](http://arxiv.org/abs/2304.05417v1), Code: **[https://github.com/fabiopoiesi/monet_dataset](https://github.com/fabiopoiesi/monet_dataset)**\n", "2304.06619": "- 2023-04-13, **Class-Incremental Learning of Plant and Disease Detection: Growing Branches with Knowledge Distillation**, Mathieu Pag\u00e9 Fortin et.al., Paper: [http://arxiv.org/abs/2304.06619v1](http://arxiv.org/abs/2304.06619v1)\n", "2304.06547": "- 2023-04-13, **RadarGNN: Transformation Invariant Graph Neural Network for Radar-based Perception**, Felix Fent et.al., Paper: [http://arxiv.org/abs/2304.06547v1](http://arxiv.org/abs/2304.06547v1), Code: **[https://github.com/tumftm/radargnn](https://github.com/tumftm/radargnn)**\n", "2304.06446": "- 2023-04-14, **SpectFormer: Frequency and Attention is what you need in a Vision Transformer**, Badri N. Patro et.al., Paper: [http://arxiv.org/abs/2304.06446v2](http://arxiv.org/abs/2304.06446v2)\n", "2304.06393": "- 2023-04-13, **Learning Accurate Performance Predictors for Ultrafast Automated Model Compression**, Ziwei Wang et.al., Paper: [http://arxiv.org/abs/2304.06393v1](http://arxiv.org/abs/2304.06393v1), Code: **[https://github.com/ziweiwangthu/seernet](https://github.com/ziweiwangthu/seernet)**\n", "2304.06373": "- 2023-04-17, **You are here! Finding position and orientation on a 2D map from a single image: The Flatlandia localization problem and dataset**, Matteo Toso et.al., Paper: [http://arxiv.org/abs/2304.06373v3](http://arxiv.org/abs/2304.06373v3), Code: **[https://github.com/IIT-PAVIS/Flatlandia](https://github.com/IIT-PAVIS/Flatlandia)**\n", "2304.06354": "- 2023-04-13, **ODAM: Gradient-based instance-specific visual explanations for object detection**, Chenyang Zhao et.al., Paper: [http://arxiv.org/abs/2304.06354v1](http://arxiv.org/abs/2304.06354v1)\n", "2304.06327": "- 2023-04-13, **An Automotive Case Study on the Limits of Approximation for Object Detection**, Mart\u00ed Caro et.al., Paper: [http://arxiv.org/abs/2304.06327v1](http://arxiv.org/abs/2304.06327v1)\n", "2304.06305": "- 2023-04-13, **Boosting Convolutional Neural Networks with Middle Spectrum Grouped Convolution**, Zhuo Su et.al., Paper: [http://arxiv.org/abs/2304.06305v1](http://arxiv.org/abs/2304.06305v1), Code: **[https://github.com/hellozhuo/msgc](https://github.com/hellozhuo/msgc)**\n", "2304.06270": "- 2023-04-13, **Gamifying Math Education using Object Detection**, Yueqiu Sun et.al., Paper: [http://arxiv.org/abs/2304.06270v1](http://arxiv.org/abs/2304.06270v1)\n", "2304.06227": "- 2023-04-13, **Quasi Real-Time Autonomous Satellite Detection and Orbit Estimation**, Jarred Jordan et.al., Paper: [http://arxiv.org/abs/2304.06227v1](http://arxiv.org/abs/2304.06227v1)\n", "2304.07256": "- 2023-04-14, **Directly Optimizing IoU for Bounding Box Localization**, Mofassir ul Islam Arif et.al., Paper: [http://arxiv.org/abs/2304.07256v1](http://arxiv.org/abs/2304.07256v1)\n", "2304.07082": "- 2023-04-14, **DETR with Additional Global Aggregation for Cross-domain Weakly Supervised Object Detection**, Zongheng Tang et.al., Paper: [http://arxiv.org/abs/2304.07082v1](http://arxiv.org/abs/2304.07082v1)\n", "2304.06925": "- 2023-04-14, **YOLO-Drone:Airborne real-time detection of dense small objects from high-altitude perspective**, Li Zhu et.al., Paper: [http://arxiv.org/abs/2304.06925v1](http://arxiv.org/abs/2304.06925v1)\n", "2304.08447": "- 2023-04-17, **RadarFormer: Lightweight and Accurate Real-Time Radar Object Detection Model**, Yahia Dalbah et.al., Paper: [http://arxiv.org/abs/2304.08447v1](http://arxiv.org/abs/2304.08447v1), Code: **[https://github.com/yahidar/radarformer](https://github.com/yahidar/radarformer)**\n", "2304.08304": "- 2023-04-17, **SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object Detection**, Binglu Ren et.al., Paper: [http://arxiv.org/abs/2304.08304v1](http://arxiv.org/abs/2304.08304v1)\n", "2304.08193": "- 2023-04-17, **Applications of Deep Learning for Top-View Omnidirectional Imaging: A Survey**, Jingrui Yu et.al., Paper: [http://arxiv.org/abs/2304.08193v1](http://arxiv.org/abs/2304.08193v1)\n", "2304.08152": "- 2023-04-17, **The Impact of Frame-Dropping on Performance and Energy Consumption for Multi-Object Tracking**, Matti Henning et.al., Paper: [http://arxiv.org/abs/2304.08152v1](http://arxiv.org/abs/2304.08152v1)\n", "2304.08130": "- 2023-04-17, **A Survey on Few-Shot Class-Incremental Learning**, Songsong Tian et.al., Paper: [http://arxiv.org/abs/2304.08130v1](http://arxiv.org/abs/2304.08130v1)\n", "2304.08111": "- 2023-04-17, **Leveraging Multi-view Data for Improved Detection Performance: An Industrial Use Case**, Faranak Shamsafar et.al., Paper: [http://arxiv.org/abs/2304.08111v1](http://arxiv.org/abs/2304.08111v1)\n", "2304.08069": "- 2023-04-17, **DETRs Beat YOLOs on Real-time Object Detection**, Wenyu Lv et.al., Paper: [http://arxiv.org/abs/2304.08069v1](http://arxiv.org/abs/2304.08069v1), Code: **[https://github.com/PaddlePaddle/PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)**\n", "2304.07705": "- 2023-04-16, **Handling Heavy Occlusion in Dense Crowd Tracking by Focusing on the Heads**, Yu Zhang et.al., Paper: [http://arxiv.org/abs/2304.07705v1](http://arxiv.org/abs/2304.07705v1)\n", "2304.07609": "- 2023-04-15, **ODSmoothGrad: Generating Saliency Maps for Object Detectors**, Chul Gwon et.al., Paper: [http://arxiv.org/abs/2304.07609v1](http://arxiv.org/abs/2304.07609v1)\n", "2304.07527": "- 2023-04-15, **Align-DETR: Improving DETR with Simple IoU-aware BCE loss**, Zhi Cai et.al., Paper: [http://arxiv.org/abs/2304.07527v1](http://arxiv.org/abs/2304.07527v1), Code: **[https://github.com/felixcaae/aligndetr](https://github.com/felixcaae/aligndetr)**\n", "2304.09148": "- 2023-04-19, **SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More**, Tianrun Chen et.al., Paper: [http://arxiv.org/abs/2304.09148v2](http://arxiv.org/abs/2304.09148v2)\n", "2304.08876": "- 2023-04-18, **Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection**, Chang Xu et.al., Paper: [http://arxiv.org/abs/2304.08876v1](http://arxiv.org/abs/2304.08876v1), Code: **[https://github.com/chasel-tsui/mmrotate-dcfl](https://github.com/chasel-tsui/mmrotate-dcfl)**\n", "2304.08842": "- 2023-04-18, **UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite**, Sicen Guo et.al., Paper: [http://arxiv.org/abs/2304.08842v1](http://arxiv.org/abs/2304.08842v1)\n", "2304.08709": "- 2023-04-18, **You Only Need Two Detectors to Achieve Multi-Modal 3D Multi-Object Tracking**, Xiyang Wang et.al., Paper: [http://arxiv.org/abs/2304.08709v1](http://arxiv.org/abs/2304.08709v1), Code: **[https://github.com/wangxiyang2022/YONTD-MOT](https://github.com/wangxiyang2022/YONTD-MOT)**\n", "2304.09801": "- 2023-04-19, **MetaBEV: Solving Sensor Failures for BEV Detection and Map Segmentation**, Chongjian Ge et.al., Paper: [http://arxiv.org/abs/2304.09801v1](http://arxiv.org/abs/2304.09801v1)\n", "2304.09785": "- 2023-04-19, **Post-Training Quantization for Object Detection**, Lin Niu et.al., Paper: [http://arxiv.org/abs/2304.09785v1](http://arxiv.org/abs/2304.09785v1)\n", "2304.09694": "- 2023-04-19, **CrossFusion: Interleaving Cross-modal Complementation for Noise-resistant 3D Object Detection**, Yang Yang et.al., Paper: [http://arxiv.org/abs/2304.09694v1](http://arxiv.org/abs/2304.09694v1)\n", "2304.09670": "- 2023-04-19, **CMID: A Unified Self-Supervised Learning Framework for Remote Sensing Image Understanding**, Dilxat Muhtar et.al., Paper: [http://arxiv.org/abs/2304.09670v1](http://arxiv.org/abs/2304.09670v1), Code: **[https://github.com/NJU-LHRS/official-CMID](https://github.com/NJU-LHRS/official-CMID)**\n", "2304.09609": "- 2023-04-19, **MMDR: A Result Feature Fusion Object Detection Approach for Autonomous System**, Wendong Zhang et.al., Paper: [http://arxiv.org/abs/2304.09609v1](http://arxiv.org/abs/2304.09609v1)\n", "2304.09588": "- 2023-04-19, **DADFNet: Dual Attention and Dual Frequency-Guided Dehazing Network for Video-Empowered Intelligent Transportation**, Yu Guo et.al., Paper: [http://arxiv.org/abs/2304.09588v1](http://arxiv.org/abs/2304.09588v1)\n", "2304.09446": "- 2023-04-19, **Density-Insensitive Unsupervised Domain Adaption on 3D Object Detection**, Qianjiang Hu et.al., Paper: [http://arxiv.org/abs/2304.09446v1](http://arxiv.org/abs/2304.09446v1), Code: **[https://github.com/woodwindhu/dts](https://github.com/woodwindhu/dts)**\n", "2304.09351": "- 2023-04-19, **Machine Vision System for Early-stage Apple Flowers and Flower Clusters Detection for Precision Thinning and Pollination**, Salik Ram Khanal et.al., Paper: [http://arxiv.org/abs/2304.09351v1](http://arxiv.org/abs/2304.09351v1)\n", "2304.10410": "- 2023-04-20, **Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review**, Shanliang Yao et.al., Paper: [http://arxiv.org/abs/2304.10410v1](http://arxiv.org/abs/2304.10410v1)\n", "2304.10049": "- 2023-04-21, **Dynablox: Real-time Detection of Diverse Dynamic Objects in Complex Environments**, Lukas Schmid et.al., Paper: [http://arxiv.org/abs/2304.10049v2](http://arxiv.org/abs/2304.10049v2)\n", "2304.10987": "- 2023-04-21, **RGB-D Inertial Odometry for a Resource-Restricted Robot in Dynamic Environments**, Jianheng Liu et.al., Paper: [http://arxiv.org/abs/2304.10987v1](http://arxiv.org/abs/2304.10987v1)\n", "2304.10854": "- 2023-04-21, **HabitatDyn Dataset: Dynamic Object Detection to Kinematics Estimation**, Zhengcheng Shen et.al., Paper: [http://arxiv.org/abs/2304.10854v1](http://arxiv.org/abs/2304.10854v1), Code: **[https://github.com/ignc-research/habitatdyn](https://github.com/ignc-research/habitatdyn)**\n", "2304.10671": "- 2023-04-20, **Point-supervised Single-cell Segmentation via Collaborative Knowledge Sharing**, Ji Yu et.al., Paper: [http://arxiv.org/abs/2304.10671v1](http://arxiv.org/abs/2304.10671v1), Code: **[https://github.com/jiyuuchc/lacss_jax](https://github.com/jiyuuchc/lacss_jax)**\n", "2304.10622": "- 2023-04-20, **Enhancing object detection robustness: A synthetic and natural perturbation approach**, Nilantha Premakumara et.al., Paper: [http://arxiv.org/abs/2304.10622v1](http://arxiv.org/abs/2304.10622v1)\n", "2304.12315": "- 2023-04-24, **Once Detected, Never Lost: Surpassing Human Performance in Offline LiDAR based 3D Object Detection**, Lue Fan et.al., Paper: [http://arxiv.org/abs/2304.12315v1](http://arxiv.org/abs/2304.12315v1), Code: **[https://github.com/tusen-ai/sst](https://github.com/tusen-ai/sst)**\n", "2304.12310": "- 2023-04-25, **Fully Sparse Fusion for 3D Object Detection**, Yingyan Li et.al., Paper: [http://arxiv.org/abs/2304.12310v2](http://arxiv.org/abs/2304.12310v2), Code: **[https://github.com/bravegroup/fullysparsefusion](https://github.com/bravegroup/fullysparsefusion)**\n", "2304.12161": "- 2023-04-24, **Meta-tuning Loss Functions and Data Augmentation for Few-shot Object Detection**, Berkan Demirel et.al., Paper: [http://arxiv.org/abs/2304.12161v1](http://arxiv.org/abs/2304.12161v1)\n", "2304.12043": "- 2023-04-24, **MixPro: Data Augmentation with MaskMix and Progressive Attention Labeling for Vision Transformer**, Qihao Zhao et.al., Paper: [http://arxiv.org/abs/2304.12043v1](http://arxiv.org/abs/2304.12043v1), Code: **[https://github.com/fistyee/mixpro](https://github.com/fistyee/mixpro)**\n", "2304.11906": "- 2023-04-24, **Transformer-based stereo-aware 3D object detection from binocular images**, Hanqing Sun et.al., Paper: [http://arxiv.org/abs/2304.11906v1](http://arxiv.org/abs/2304.11906v1)\n", "2304.11832": "- 2023-04-24, **Function-Consistent Feature Distillation**, Dongyang Liu et.al., Paper: [http://arxiv.org/abs/2304.11832v1](http://arxiv.org/abs/2304.11832v1), Code: **[https://github.com/liudongyang6/fcfd](https://github.com/liudongyang6/fcfd)**\n", "2304.11805": "- 2023-04-24, **OGMN: Occlusion-guided Multi-task Network for Object Detection in UAV Images**, Xuexue Li et.al., Paper: [http://arxiv.org/abs/2304.11805v1](http://arxiv.org/abs/2304.11805v1)\n", "2304.11717": "- 2023-04-23, **Automatized marine vessel monitoring from sentinel-1 data using convolution neural network**, Surya Prakash Tiwari et.al., Paper: [http://arxiv.org/abs/2304.11717v1](http://arxiv.org/abs/2304.11717v1)\n", "2304.11697": "- 2023-04-23, **Informative Data Selection with Uncertainty for Multi-modal Object Detection**, Xinyu Zhang et.al., Paper: [http://arxiv.org/abs/2304.11697v1](http://arxiv.org/abs/2304.11697v1)\n", "2304.11595": "- 2023-04-23, **Segment Anything in Non-Euclidean Domains: Challenges and Opportunities**, Yongcheng Jing et.al., Paper: [http://arxiv.org/abs/2304.11595v1](http://arxiv.org/abs/2304.11595v1)\n", "2304.13031": "- 2023-04-25, **DQS3D: Densely-matched Quantization-aware Semi-supervised 3D Detection**, Huan-ang Gao et.al., Paper: [http://arxiv.org/abs/2304.13031v1](http://arxiv.org/abs/2304.13031v1), Code: **[https://github.com/air-discover/dqs3d](https://github.com/air-discover/dqs3d)**\n", "2304.13027": "- 2023-04-25, **A Strong and Reproducible Object Detector with Only Public Datasets**, Tianhe Ren et.al., Paper: [http://arxiv.org/abs/2304.13027v1](http://arxiv.org/abs/2304.13027v1), Code: **[https://github.com/microsoft/FocalNet](https://github.com/microsoft/FocalNet)**\n", "2304.12542": "- 2023-04-25, **Object Semantics Give Us the Depth We Need: Multi-task Approach to Aerial Depth Completion**, Sara Hatami Gazani et.al., Paper: [http://arxiv.org/abs/2304.12542v1](http://arxiv.org/abs/2304.12542v1)\n", "2304.13455": "- 2023-04-27, **From Chaos Comes Order: Ordering Event Representations for Object Detection**, Nikola Zubi\u0107 et.al., Paper: [http://arxiv.org/abs/2304.13455v2](http://arxiv.org/abs/2304.13455v2)\n", "2304.13427": "- 2023-04-26, **Training-Free Location-Aware Text-to-Image Synthesis**, Jiafeng Mao et.al., Paper: [http://arxiv.org/abs/2304.13427v1](http://arxiv.org/abs/2304.13427v1)\n", "2304.13390": "- 2023-04-26, **Group Equivariant BEV for 3D Object Detection**, Hongwei Liu et.al., Paper: [http://arxiv.org/abs/2304.13390v1](http://arxiv.org/abs/2304.13390v1)\n", "2304.14356": "- 2023-04-27, **SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments**, Tingxiang Fan et.al., Paper: [http://arxiv.org/abs/2304.14356v1](http://arxiv.org/abs/2304.14356v1)\n", "2304.14340": "- 2023-04-27, **SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection**, Yichen Xie et.al., Paper: [http://arxiv.org/abs/2304.14340v1](http://arxiv.org/abs/2304.14340v1), Code: **[https://github.com/yichen928/sparsefusion](https://github.com/yichen928/sparsefusion)**\n", "2304.14114": "- 2023-04-27, **Towards Precise Weakly Supervised Object Detection via Interactive Contrastive Learning of Context Information**, Lai Qi et.al., Paper: [http://arxiv.org/abs/2304.14114v1](http://arxiv.org/abs/2304.14114v1)\n", "2304.13919": "- 2023-04-27, **Detection of Adversarial Physical Attacks in Time-Series Image Data**, Ramneet Kaur et.al., Paper: [http://arxiv.org/abs/2304.13919v1](http://arxiv.org/abs/2304.13919v1)\n", "2304.14864": "- 2023-04-28, **Evaluating the Stability of Semantic Concept Representations in CNNs for Robust Explainability**, Georgii Mikriukov et.al., Paper: [http://arxiv.org/abs/2304.14864v1](http://arxiv.org/abs/2304.14864v1)\n", "2304.14619": "- 2023-04-28, **A positive feedback method based on F-measure value for Salient Object Detection**, Ailing Pan et.al., Paper: [http://arxiv.org/abs/2304.14619v1](http://arxiv.org/abs/2304.14619v1)\n", "2304.14614": "- 2023-04-28, **Fusion is Not Enough: Single-Modal Attacks to Compromise Fusion Models in Autonomous Driving**, Zhiyuan Cheng et.al., Paper: [http://arxiv.org/abs/2304.14614v1](http://arxiv.org/abs/2304.14614v1)\n", "2304.14484": "- 2023-04-27, **OriCon3D: Effective 3D Object Detection using Orientation and Confidence**, Dhyey Manish Rajani et.al., Paper: [http://arxiv.org/abs/2304.14484v1](http://arxiv.org/abs/2304.14484v1)\n", "2304.14466": "- 2023-04-27, **Nordic Vehicle Dataset (NVD): Performance of vehicle detectors using newly captured NVD from UAV in different snowy weather conditions**, Hamam Mokayed et.al., Paper: [http://arxiv.org/abs/2304.14466v1](http://arxiv.org/abs/2304.14466v1)\n", "2304.14460": "- 2023-04-27, **Gradient-based Maximally Interfered Retrieval for Domain Incremental 3D Object Detection**, Barza Nisar et.al., Paper: [http://arxiv.org/abs/2304.14460v1](http://arxiv.org/abs/2304.14460v1), Code: **[https://github.com/trailab/gmir](https://github.com/trailab/gmir)**\n", "2304.14446": "- 2023-04-27, **HyperMODEST: Self-Supervised 3D Object Detection with Confidence Score Filtering**, Jenny Xu et.al., Paper: [http://arxiv.org/abs/2304.14446v1](http://arxiv.org/abs/2304.14446v1), Code: **[https://github.com/trailab/hypermodest](https://github.com/trailab/hypermodest)**\n", "2305.00884": "- 2023-05-01, **Hypernuclear event detection in the nuclear emulsion with Monte Carlo simulation and machine learning**, A. Kasagi et.al., Paper: [http://arxiv.org/abs/2305.00884v1](http://arxiv.org/abs/2305.00884v1)\n", "2305.00795": "- 2023-05-02, **SelfDocSeg: A Self-Supervised vision-based Approach towards Document Segmentation**, Subhajit Maity et.al., Paper: [http://arxiv.org/abs/2305.00795v2](http://arxiv.org/abs/2305.00795v2), Code: **[https://github.com/maitysubhajit/selfdocseg](https://github.com/maitysubhajit/selfdocseg)**\n", "2305.00718": "- 2023-05-01, **Event Camera as Region Proposal Network**, Shrutarv Awasthi et.al., Paper: [http://arxiv.org/abs/2305.00718v1](http://arxiv.org/abs/2305.00718v1)\n", "2305.00620": "- 2023-05-01, **Refined Response Distillation for Class-Incremental Player Detection**, Liang Bai et.al., Paper: [http://arxiv.org/abs/2305.00620v1](http://arxiv.org/abs/2305.00620v1)\n", "2305.00594": "- 2023-04-30, **The MCC approaches the geometric mean of precision and recall as true negatives approach infinity**, Jon Crall et.al., Paper: [http://arxiv.org/abs/2305.00594v1](http://arxiv.org/abs/2305.00594v1)\n", "2305.00514": "- 2023-04-30, **Discriminative Co-Saliency and Background Mining Transformer for Co-Salient Object Detection**, Long Li et.al., Paper: [http://arxiv.org/abs/2305.00514v1](http://arxiv.org/abs/2305.00514v1), Code: **[https://github.com/dragonlee258079/DMT](https://github.com/dragonlee258079/DMT)**\n", "2305.00412": "- 2023-04-30, **A Simulation-Augmented Benchmarking Framework for Automatic RSO Streak Detection in Single-Frame Space Images**, Zhe Chen et.al., Paper: [http://arxiv.org/abs/2305.00412v1](http://arxiv.org/abs/2305.00412v1)\n", "2305.00406": "- 2023-04-30, **LIMOT: A Tightly-Coupled System for LiDAR-Inertial Odometry and Multi-Object Tracking**, Zhongyang Zhu et.al., Paper: [http://arxiv.org/abs/2305.00406v1](http://arxiv.org/abs/2305.00406v1)\n", "2305.00397": "- 2023-04-30, **TransCAR: Transformer-based Camera-And-Radar Fusion for 3D Object Detection**, Su Pang et.al., Paper: [http://arxiv.org/abs/2305.00397v1](http://arxiv.org/abs/2305.00397v1)\n", "2305.00314": "- 2023-04-29, **InfraDet3D: Multi-Modal 3D Object Detection based on Roadside Infrastructure Camera and LiDAR Sensors**, Walter Zimmer et.al., Paper: [http://arxiv.org/abs/2305.00314v1](http://arxiv.org/abs/2305.00314v1)\n", "2305.01183": "- 2023-05-02, **Faster OreFSDet : A Lightweight and Effective Few-shot Object Detector for Ore Images**, Yang Zhang et.al., Paper: [http://arxiv.org/abs/2305.01183v1](http://arxiv.org/abs/2305.01183v1), Code: **[https://github.com/mvme-hbut/faster-orefsdet](https://github.com/mvme-hbut/faster-orefsdet)**\n", "2305.01135": "- 2023-05-02, **A New Wave in Robotics: Survey on Recent mmWave Radar Applications in Robotics**, Kyle Harlow et.al., Paper: [http://arxiv.org/abs/2305.01135v1](http://arxiv.org/abs/2305.01135v1)\n", "2305.02086": "- 2023-05-03, **Rethinking the Encoding of Satellite Image Time Series**, Xin Cai et.al., Paper: [http://arxiv.org/abs/2305.02086v1](http://arxiv.org/abs/2305.02086v1), Code: **[https://github.com/TotalVariation/Exchanger4SITS](https://github.com/TotalVariation/Exchanger4SITS)**\n", "2305.02061": "- 2023-05-03, **Attention Based Feature Fusion For Multi-Agent Collaborative Perception**, Ahmed N. Ahmed et.al., Paper: [http://arxiv.org/abs/2305.02061v1](http://arxiv.org/abs/2305.02061v1)\n", "2305.02034": "- 2023-05-03, **Scaling-up Remote Sensing Segmentation Dataset with Segment Anything Model**, Di Wang et.al., Paper: [http://arxiv.org/abs/2305.02034v1](http://arxiv.org/abs/2305.02034v1), Code: **[https://github.com/vitae-transformer/samrs](https://github.com/vitae-transformer/samrs)**\n", "2305.01936": "- 2023-05-03, **Illicit item detection in X-ray images for security applications**, Georgios Batsis et.al., Paper: [http://arxiv.org/abs/2305.01936v1](http://arxiv.org/abs/2305.01936v1)\n", "2305.03045": "- 2023-05-08, **OctFormer: Octree-based Transformers for 3D Point Clouds**, Peng-Shuai Wang et.al., Paper: [http://arxiv.org/abs/2305.03045v2](http://arxiv.org/abs/2305.03045v2)\n", "2305.03034": "- 2023-05-04, **Contrastive Mean Teacher for Domain Adaptive Object Detectors**, Shengcao Cao et.al., Paper: [http://arxiv.org/abs/2305.03034v1](http://arxiv.org/abs/2305.03034v1)\n", "2305.03001": "- 2023-05-04, **OSDaR23: Open Sensor Data for Rail 2023**, Rustam Tagiew et.al., Paper: [http://arxiv.org/abs/2305.03001v1](http://arxiv.org/abs/2305.03001v1)\n", "2305.02909": "- 2023-05-04, **Aligning Bird-Eye View Representation of Point Cloud Sequences using Scene Flow**, Minh-Quan Dao et.al., Paper: [http://arxiv.org/abs/2305.02909v1](http://arxiv.org/abs/2305.02909v1), Code: **[https://github.com/quan-dao/pc-corrector](https://github.com/quan-dao/pc-corrector)**\n", "2305.02722": "- 2023-05-04, **Avatar Knowledge Distillation: Self-ensemble Teacher Paradigm with Uncertainty**, Yuan Zhang et.al., Paper: [http://arxiv.org/abs/2305.02722v1](http://arxiv.org/abs/2305.02722v1)\n", "2305.02562": "- 2023-05-04, **Conditional and Residual Methods in Scalable Coding for Humans and Machines**, Anderson de Andrade et.al., Paper: [http://arxiv.org/abs/2305.02562v1](http://arxiv.org/abs/2305.02562v1), Code: **[https://github.com/adeandrade/research](https://github.com/adeandrade/research)**\n", "2305.02398": "- 2023-05-03, **Learning-based Relational Object Matching Across Views**, Cathrin Elich et.al., Paper: [http://arxiv.org/abs/2305.02398v1](http://arxiv.org/abs/2305.02398v1)\n", "2305.03716": "- 2023-05-05, **DSPDet3D: Dynamic Spatial Pruning for 3D Small Object Detection**, Xiuwei Xu et.al., Paper: [http://arxiv.org/abs/2305.03716v1](http://arxiv.org/abs/2305.03716v1), Code: **[https://github.com/xuxw98/dspdet3d](https://github.com/xuxw98/dspdet3d)**\n", "2305.03601": "- 2023-05-05, **Human Attention-Guided Explainable Artificial Intelligence for Computer Vision Models**, Guoyang Liu et.al., Paper: [http://arxiv.org/abs/2305.03601v1](http://arxiv.org/abs/2305.03601v1)\n", "2305.03425": "- 2023-05-05, **GAANet: Ghost Auto Anchor Network for Detecting Varying Size Drones in Dark**, Misha Urooj Khan et.al., Paper: [http://arxiv.org/abs/2305.03425v1](http://arxiv.org/abs/2305.03425v1), Code: **[https://github.com/zeeshankaleem/ghostautoanchornet](https://github.com/zeeshankaleem/ghostautoanchornet)**\n", "2305.03273": "- 2023-05-05, **Semantic Segmentation using Vision Transformers: A survey**, Hans Thisanke et.al., Paper: [http://arxiv.org/abs/2305.03273v1](http://arxiv.org/abs/2305.03273v1)\n", "2305.04925": "- 2023-05-08, **PillarNeXt: Rethinking Network Designs for 3D Object Detection in LiDAR Point Clouds**, Jinyu Li et.al., Paper: [http://arxiv.org/abs/2305.04925v1](http://arxiv.org/abs/2305.04925v1), Code: **[https://github.com/qcraftai/pillarnext](https://github.com/qcraftai/pillarnext)**\n", "2305.04722": "- 2023-05-08, **Understanding Gaussian Attention Bias of Vision Transformers Using Effective Receptive Fields**, Bum Jun Kim et.al., Paper: [http://arxiv.org/abs/2305.04722v1](http://arxiv.org/abs/2305.04722v1)\n", "2305.04516": "- 2023-05-08, **Robust Traffic Light Detection Using Salience-Sensitive Loss: Computational Framework and Evaluations**, Ross Greer et.al., Paper: [http://arxiv.org/abs/2305.04516v1](http://arxiv.org/abs/2305.04516v1)\n", "2305.04396": "- 2023-05-08, **SegGPT Meets Co-Saliency Scene**, Yi Liu et.al., Paper: [http://arxiv.org/abs/2305.04396v1](http://arxiv.org/abs/2305.04396v1)\n", "2305.04170": "- 2023-05-07, **YOLOCS: Object Detection based on Dense Channel Compression for Feature Spatial Solidification**, Lin Huang et.al., Paper: [http://arxiv.org/abs/2305.04170v1](http://arxiv.org/abs/2305.04170v1)\n", "2305.04151": "- 2023-05-07, **Context-Aware Chart Element Detection**, Pengyu Yan et.al., Paper: [http://arxiv.org/abs/2305.04151v1](http://arxiv.org/abs/2305.04151v1), Code: **[https://github.com/pengyu965/chartdete](https://github.com/pengyu965/chartdete)**\n", "2305.05511": "- 2023-05-09, **Self-supervised dense representation learning for live-cell microscopy with time arrow prediction**, Benjamin Gallusser et.al., Paper: [http://arxiv.org/abs/2305.05511v1](http://arxiv.org/abs/2305.05511v1), Code: **[https://github.com/weigertlab/tarrow](https://github.com/weigertlab/tarrow)**\n", "2305.05499": "- 2023-05-09, **Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object Recognition Model**, Farhin Farhad Riya et.al., Paper: [http://arxiv.org/abs/2305.05499v1](http://arxiv.org/abs/2305.05499v1)\n", "2305.05423": "- 2023-05-09, **High-throughput Cotton Phenotyping Big Data Pipeline Lambda Architecture Computer Vision Deep Neural Networks**, Amanda Issac et.al., Paper: [http://arxiv.org/abs/2305.05423v1](http://arxiv.org/abs/2305.05423v1)\n", "2305.05260": "- 2023-05-09, **Guided Focal Stack Refinement Network for Light Field Salient Object Detection**, Bo Yuan et.al., Paper: [http://arxiv.org/abs/2305.05260v1](http://arxiv.org/abs/2305.05260v1)\n", "2305.05836": "- 2023-05-10, **Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection**, Hsiu-Wei Yang et.al., Paper: [http://arxiv.org/abs/2305.05836v1](http://arxiv.org/abs/2305.05836v1)\n", "2305.05726": "- 2023-05-09, **Vision-Language Models in Remote Sensing: Current Progress and Future Trends**, Congcong Wen et.al., Paper: [http://arxiv.org/abs/2305.05726v1](http://arxiv.org/abs/2305.05726v1)\n", "2305.07011": "- 2023-05-11, **Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers**, Dahun Kim et.al., Paper: [http://arxiv.org/abs/2305.07011v1](http://arxiv.org/abs/2305.07011v1)\n", "2305.06940": "- 2023-05-11, **SalienDet: A Saliency-based Feature Enhancement Algorithm for Object Detection for Autonomous Driving**, Ning Ding et.al., Paper: [http://arxiv.org/abs/2305.06940v1](http://arxiv.org/abs/2305.06940v1), Code: **[https://github.com/dingmike001/saliendet-open-detection](https://github.com/dingmike001/saliendet-open-detection)**\n", "2305.06820": "- 2023-05-11, **DeepSTEP -- Deep Learning-Based Spatio-Temporal End-To-End Perception for Autonomous Vehicles**, Sebastian Huch et.al., Paper: [http://arxiv.org/abs/2305.06820v1](http://arxiv.org/abs/2305.06820v1)\n", "2305.06773": "- 2023-05-11, **Towards a Better Understanding of the Computer Vision Research Community in Africa**, Abdul-Hakeem Omotayo et.al., Paper: [http://arxiv.org/abs/2305.06773v1](http://arxiv.org/abs/2305.06773v1)\n", "2305.06621": "- 2023-05-11, **PVT-SSD: Single-Stage 3D Object Detector with Point-Voxel Transformer**, Honghui Yang et.al., Paper: [http://arxiv.org/abs/2305.06621v1](http://arxiv.org/abs/2305.06621v1), Code: **[https://github.com/nightmare-n/pvt-ssd](https://github.com/nightmare-n/pvt-ssd)**\n", "2305.07598": "- 2023-05-15, **RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for Oriented Object Detection**, Hakjin Lee et.al., Paper: [http://arxiv.org/abs/2305.07598v2](http://arxiv.org/abs/2305.07598v2)\n", "2305.07552": "- 2023-05-12, **Dish detection in food platters: A framework for automated diet logging and nutrition management**, Mansi Goel et.al., Paper: [http://arxiv.org/abs/2305.07552v1](http://arxiv.org/abs/2305.07552v1)\n", "2305.07528": "- 2023-05-12, **WEDGE: A multi-weather autonomous driving dataset built from generative vision-language models**, Aboli Marathe et.al., Paper: [http://arxiv.org/abs/2305.07528v1](http://arxiv.org/abs/2305.07528v1), Code: **[https://github.com/Infernolia/WEDGE](https://github.com/Infernolia/WEDGE)**\n", "2305.07522": "- 2023-05-15, **PillarAcc: Sparse PointPillars Accelerator for Real-Time Point Cloud 3D Object Detection on Edge Devices**, Minjae Lee et.al., Paper: [http://arxiv.org/abs/2305.07522v2](http://arxiv.org/abs/2305.07522v2)\n", "2305.07304": "- 2023-05-12, **CLIP-Count: Towards Text-Guided Zero-Shot Object Counting**, Ruixiang Jiang et.al., Paper: [http://arxiv.org/abs/2305.07304v1](http://arxiv.org/abs/2305.07304v1), Code: **[https://github.com/songrise/clip-count](https://github.com/songrise/clip-count)**\n", "2305.07270": "- 2023-05-12, **SSD-MonoDTR: Supervised Scale-constrained Deformable Transformer for Monocular 3D Object Detection**, Xuan He et.al., Paper: [http://arxiv.org/abs/2305.07270v1](http://arxiv.org/abs/2305.07270v1), Code: **[https://github.com/mikasa3lili/ssd-monodetr](https://github.com/mikasa3lili/ssd-monodetr)**\n", "2305.08808": "- 2023-05-15, **GeoMAE: Masked Geometric Target Prediction for Self-supervised Point Cloud Pre-Training**, Xiaoyu Tian et.al., Paper: [http://arxiv.org/abs/2305.08808v1](http://arxiv.org/abs/2305.08808v1)\n", "2305.08776": "- 2023-05-16, **Bridging the Domain Gap: Self-Supervised 3D Scene Understanding with Foundation Models**, Zhimin Chen et.al., Paper: [http://arxiv.org/abs/2305.08776v2](http://arxiv.org/abs/2305.08776v2)\n", "2305.08673": "- 2023-05-15, **aUToLights: A Robust Multi-Camera Traffic Light Detection and Tracking System**, Sean Wu et.al., Paper: [http://arxiv.org/abs/2305.08673v1](http://arxiv.org/abs/2305.08673v1)\n", "2305.08611": "- 2023-05-15, **GeNAS: Neural Architecture Search with Better Generalization**, Joonhyun Jeong et.al., Paper: [http://arxiv.org/abs/2305.08611v1](http://arxiv.org/abs/2305.08611v1)\n", "2305.08551": "- 2023-05-15, **Enhancing Performance of Vision Transformers on Small Datasets through Local Inductive Bias Incorporation**, Ibrahim Batuhan Akkaya et.al., Paper: [http://arxiv.org/abs/2305.08551v1](http://arxiv.org/abs/2305.08551v1)\n", "2305.08462": "- 2023-05-15, **Not All Pixels Are Equal: Learning Pixel Hardness for Semantic Segmentation**, Xin Xiao et.al., Paper: [http://arxiv.org/abs/2305.08462v1](http://arxiv.org/abs/2305.08462v1), Code: **[https://github.com/menoly-xin/hardness-level-learning](https://github.com/menoly-xin/hardness-level-learning)**\n", "2305.08232": "- 2023-05-14, **Combining geolocation and height estimation of objects from street level imagery**, Matej Ulicny et.al., Paper: [http://arxiv.org/abs/2305.08232v1](http://arxiv.org/abs/2305.08232v1)\n", "2305.08069": "- 2023-05-14, **Instance-Aware Repeat Factor Sampling for Long-Tailed Object Detection**, Burhaneddin Yaman et.al., Paper: [http://arxiv.org/abs/2305.08069v1](http://arxiv.org/abs/2305.08069v1)\n", "2305.08053": "- 2023-05-14, **SCRNet: a Retinex Structure-based Low-light Enhancement Model Guided by Spatial Consistency**, Miao Zhang et.al., Paper: [http://arxiv.org/abs/2305.08053v1](http://arxiv.org/abs/2305.08053v1)\n", "2305.07783": "- 2023-05-12, **ROI-based Deep Image Compression with Swin Transformers**, Binglin Li et.al., Paper: [http://arxiv.org/abs/2305.07783v1](http://arxiv.org/abs/2305.07783v1)\n", "2305.09407": "- 2023-05-16, **A Novel Strategy for Improving Robustness in Computer Vision Manufacturing Defect Detection**, Ahmad Mohamad Mezher et.al., Paper: [http://arxiv.org/abs/2305.09407v1](http://arxiv.org/abs/2305.09407v1)\n", "2305.09327": "- 2023-05-16, **Improved Type III solar radio burst detection using congruent deep learning models**, Jeremiah Scully et.al., Paper: [http://arxiv.org/abs/2305.09327v1](http://arxiv.org/abs/2305.09327v1)\n", "2305.09293": "- 2023-05-16, **Out-of-Distribution Detection for Adaptive Computer Vision**, Simon Kristoffersson Lind et.al., Paper: [http://arxiv.org/abs/2305.09293v1](http://arxiv.org/abs/2305.09293v1)\n", "2305.10424": "- 2023-05-17, **ZeroFlow: Fast Zero Label Scene Flow via Distillation**, Kyle Vedder et.al., Paper: [http://arxiv.org/abs/2305.10424v1](http://arxiv.org/abs/2305.10424v1)\n", "2305.10270": "- 2023-05-17, **Boosting Local Spectro-Temporal Features for Speech Analysis**, Michael Guerzhoy et.al., Paper: [http://arxiv.org/abs/2305.10270v1](http://arxiv.org/abs/2305.10270v1)\n", "2305.10061": "- 2023-05-17, **Rethinking Boundary Discontinuity Problem for Oriented Object Detection**, Hang Xu et.al., Paper: [http://arxiv.org/abs/2305.10061v1](http://arxiv.org/abs/2305.10061v1)\n", "2305.09999": "- 2023-05-17, **An Interactively Reinforced Paradigm for Joint Infrared-Visible Image Fusion and Saliency Object Detection**, Di Wang et.al., Paper: [http://arxiv.org/abs/2305.09999v1](http://arxiv.org/abs/2305.09999v1), Code: **[https://github.com/wdhudiekou/irfs](https://github.com/wdhudiekou/irfs)**\n", "2305.09972": "- 2023-05-17, **Real-Time Flying Object Detection with YOLOv8**, Dillon Reis et.al., Paper: [http://arxiv.org/abs/2305.09972v1](http://arxiv.org/abs/2305.09972v1)\n", "2305.09810": "- 2023-05-16, **Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery**, Enyu Cai et.al., Paper: [http://arxiv.org/abs/2305.09810v1](http://arxiv.org/abs/2305.09810v1)\n", "2305.09699": "- 2023-05-16, **Mobile User Interface Element Detection Via Adaptively Prompt Tuning**, Zhangxuan Gu et.al., Paper: [http://arxiv.org/abs/2305.09699v1](http://arxiv.org/abs/2305.09699v1), Code: **[https://github.com/antmachineintelligence/mui-zh](https://github.com/antmachineintelligence/mui-zh)**\n", "2305.11173": "- 2023-05-18, **Going Denser with Open-Vocabulary Part Segmentation**, Peize Sun et.al., Paper: [http://arxiv.org/abs/2305.11173v1](http://arxiv.org/abs/2305.11173v1), Code: **[https://github.com/facebookresearch/vlpart](https://github.com/facebookresearch/vlpart)**\n", "2305.10974": "- 2023-05-18, **MonoTDP: Twin Depth Perception for Monocular 3D Object Detection in Adverse Scenes**, Xingyuan Li et.al., Paper: [http://arxiv.org/abs/2305.10974v1](http://arxiv.org/abs/2305.10974v1)\n", "2305.10801": "- 2023-05-18, **Selecting Learnable Training Samples is All DETRs Need in Crowded Pedestrian Detection**, Feng Gao et.al., Paper: [http://arxiv.org/abs/2305.10801v1](http://arxiv.org/abs/2305.10801v1)\n", "2305.10766": "- 2023-05-18, **Adversarial Amendment is the Only Force Capable of Transforming an Enemy into a Friend**, Chong Yu et.al., Paper: [http://arxiv.org/abs/2305.10766v1](http://arxiv.org/abs/2305.10766v1)\n", "2305.10643": "- 2023-05-18, **STREAMLINE: Streaming Active Learning for Realistic Multi-Distributional Settings**, Nathan Beck et.al., Paper: [http://arxiv.org/abs/2305.10643v1](http://arxiv.org/abs/2305.10643v1), Code: **[https://github.com/nab170130/new_streamline](https://github.com/nab170130/new_streamline)**\n", "2305.10616": "- 2023-05-18, **Evaluation Metrics for CNNs Compression**, Abanoub Ghobrial et.al., Paper: [http://arxiv.org/abs/2305.10616v1](http://arxiv.org/abs/2305.10616v1)\n", "2305.11729": "- 2023-05-19, **ViDaS Video Depth-aware Saliency Network**, Ioanna Diamanti et.al., Paper: [http://arxiv.org/abs/2305.11729v1](http://arxiv.org/abs/2305.11729v1)\n", "2305.11692": "- 2023-05-19, **Surgical-VQLA: Transformer with Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery**, Long Bai et.al., Paper: [http://arxiv.org/abs/2305.11692v1](http://arxiv.org/abs/2305.11692v1), Code: **[https://github.com/longbai1006/surgical-vqla](https://github.com/longbai1006/surgical-vqla)**\n", "2305.11624": "- 2023-05-19, **Tune-Mode ConvBN Blocks For Efficient Transfer Learning**, Kaichao You et.al., Paper: [http://arxiv.org/abs/2305.11624v1](http://arxiv.org/abs/2305.11624v1)\n", "2305.11513": "- 2023-05-19, **When SAM Meets Shadow Detection**, Leiping Jie et.al., Paper: [http://arxiv.org/abs/2305.11513v1](http://arxiv.org/abs/2305.11513v1)\n", "2305.11427": "- 2023-05-19, **RGB-D And Thermal Sensor Fusion: A Systematic Literature Review**, Martin Brenner et.al., Paper: [http://arxiv.org/abs/2305.11427v1](http://arxiv.org/abs/2305.11427v1)\n", "2305.12853": "- 2023-05-22, **Real-Aug: Realistic Scene Synthesis for LiDAR Augmentation in 3D Object Detection**, Jinglin Zhan et.al., Paper: [http://arxiv.org/abs/2305.12853v1](http://arxiv.org/abs/2305.12853v1)\n", "2305.12845": "- 2023-05-22, **Bright Channel Prior Attention for Multispectral Pedestrian Detection**, Chenhang Cui et.al., Paper: [http://arxiv.org/abs/2305.12845v1](http://arxiv.org/abs/2305.12845v1)\n", "2305.12833": "- 2023-05-22, **Boosting Long-tailed Object Detection via Step-wise Learning on Smooth-tail Data**, Na Dong et.al., Paper: [http://arxiv.org/abs/2305.12833v1](http://arxiv.org/abs/2305.12833v1)\n", "2305.12635": "- 2023-05-22, **A bioinspired three-stage model for camouflaged object detection**, Tianyou Chen et.al., Paper: [http://arxiv.org/abs/2305.12635v1](http://arxiv.org/abs/2305.12635v1)\n", "2305.12497": "- 2023-05-21, **PanoContext-Former: Panoramic Total Scene Understanding with a Transformer**, Yuan Dong et.al., Paper: [http://arxiv.org/abs/2305.12497v1](http://arxiv.org/abs/2305.12497v1)\n", "2305.12452": "- 2023-05-21, **Advancing Referring Expression Segmentation Beyond Single Image**, Yixuan Wu et.al., Paper: [http://arxiv.org/abs/2305.12452v1](http://arxiv.org/abs/2305.12452v1)\n", "2305.12344": "- 2023-05-21, **YOLOv3 with Spatial Pyramid Pooling for Object Detection with Unmanned Aerial Vehicles**, Wahyu Pebrianto et.al., Paper: [http://arxiv.org/abs/2305.12344v1](http://arxiv.org/abs/2305.12344v1)\n", "2305.14281": "- 2023-05-23, **Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining**, Emanuele Bugliarello et.al., Paper: [http://arxiv.org/abs/2305.14281v1](http://arxiv.org/abs/2305.14281v1)\n", "2305.14167": "- 2023-05-24, **DetGPT: Detect What You Need via Reasoning**, Renjie Pi et.al., Paper: [http://arxiv.org/abs/2305.14167v2](http://arxiv.org/abs/2305.14167v2)\n", "2305.14165": "- 2023-05-23, **Impact of Light and Shadow on Robustness of Deep Neural Networks**, Chengyin Hu et.al., Paper: [http://arxiv.org/abs/2305.14165v1](http://arxiv.org/abs/2305.14165v1)\n", "2305.14141": "- 2023-05-23, **Learning Remote Sensing Object Detection with Single Point Supervision**, Shitian He et.al., Paper: [http://arxiv.org/abs/2305.14141v1](http://arxiv.org/abs/2305.14141v1), Code: **[https://github.com/heshitian/plug](https://github.com/heshitian/plug)**\n", "2305.14008": "- 2023-05-23, **Multi-Echo Denoising in Adverse Weather**, Alvari Sepp\u00e4nen et.al., Paper: [http://arxiv.org/abs/2305.14008v1](http://arxiv.org/abs/2305.14008v1), Code: **[https://github.com/alvariseppanen/smednet](https://github.com/alvariseppanen/smednet)**\n", "2305.13802": "- 2023-05-23, **Online Open-set Semi-supervised Object Detection via Semi-supervised Outlier Filtering**, Zerun Wang et.al., Paper: [http://arxiv.org/abs/2305.13802v1](http://arxiv.org/abs/2305.13802v1)\n", "2305.13563": "- 2023-05-23, **Efficient Multi-Scale Attention Module with Cross-Spatial Learning**, Daliang Ouyang et.al., Paper: [http://arxiv.org/abs/2305.13563v1](http://arxiv.org/abs/2305.13563v1)\n", "2305.13509": "- 2023-05-22, **ColMix -- A Simple Data Augmentation Framework to Improve Object Detector Performance and Robustness in Aerial Images**, Cuong Ly et.al., Paper: [http://arxiv.org/abs/2305.13509v1](http://arxiv.org/abs/2305.13509v1)\n", "2305.13398": "- 2023-05-22, **nnDetection for Intracranial Aneurysms Detection and Localization**, Maysam Orouskhani et.al., Paper: [http://arxiv.org/abs/2305.13398v1](http://arxiv.org/abs/2305.13398v1)\n", "2305.15219": "- 2023-05-24, **DynStatF: An Efficient Feature Fusion Strategy for LiDAR 3D Object Detection**, Yao Rong et.al., Paper: [http://arxiv.org/abs/2305.15219v1](http://arxiv.org/abs/2305.15219v1)\n", "2305.15097": "- 2023-05-24, **Computer Vision for Construction Progress Monitoring: A Real-Time Object Detection Approach**, Jiesheng Yang et.al., Paper: [http://arxiv.org/abs/2305.15097v1](http://arxiv.org/abs/2305.15097v1)\n", "2305.14955": "- 2023-05-24, **DC-Net: Divide-and-Conquer for Salient Object Detection**, Jiayi Zhu et.al., Paper: [http://arxiv.org/abs/2305.14955v1](http://arxiv.org/abs/2305.14955v1)\n", "2305.14813": "- 2023-05-24, **Semi-Supervised and Long-Tailed Object Detection with CascadeMatch**, Yuhang Zang et.al., Paper: [http://arxiv.org/abs/2305.14813v1](http://arxiv.org/abs/2305.14813v1)\n", "2305.14768": "- 2023-05-24, **Dual Path Transformer with Partition Attention**, Zhengkai Jiang et.al., Paper: [http://arxiv.org/abs/2305.14768v1](http://arxiv.org/abs/2305.14768v1)\n", "2305.14713": "- 2023-05-24, **Streaming Object Detection on Fisheye Cameras for Automatic Parking**, Yixiong Yan et.al., Paper: [http://arxiv.org/abs/2305.14713v1](http://arxiv.org/abs/2305.14713v1)\n", "2305.14621": "- 2023-05-24, **Realistically distributing object placements in synthetic training data improves the performance of vision-based object detection models**, Setareh Dabiri et.al., Paper: [http://arxiv.org/abs/2305.14621v1](http://arxiv.org/abs/2305.14621v1)\n", "2305.16319": "- 2023-05-25, **Image is First-order Norm+Linear Autoregressive**, Yinpeng Chen et.al., Paper: [http://arxiv.org/abs/2305.16319v1](http://arxiv.org/abs/2305.16319v1)\n", "2305.16301": "- 2023-05-25, **Look Ma, No Hands! Agent-Environment Factorization of Egocentric Videos**, Matthew Chang et.al., Paper: [http://arxiv.org/abs/2305.16301v1](http://arxiv.org/abs/2305.16301v1)\n", "2305.16066": "- 2023-05-25, **Guided Attention for Next Active Object @ EGO4D STA Challenge**, Sanket Thakur et.al., Paper: [http://arxiv.org/abs/2305.16066v1](http://arxiv.org/abs/2305.16066v1)\n", "2305.16008": "- 2023-05-25, **Vision-based Safe Autonomous UAV Docking with Panoramic Sensors**, Phuoc Nguyen Thuan et.al., Paper: [http://arxiv.org/abs/2305.16008v1](http://arxiv.org/abs/2305.16008v1)\n", "2305.15957": "- 2023-05-25, **DiffCLIP: Leveraging Stable Diffusion for Language Grounded 3D Classification**, Sitian Shen et.al., Paper: [http://arxiv.org/abs/2305.15957v1](http://arxiv.org/abs/2305.15957v1)\n", "2305.15883": "- 2023-05-25, **RC-BEVFusion: A Plug-In Module for Radar-Camera Bird's Eye View Feature Fusion**, Lukas St\u00e4cker et.al., Paper: [http://arxiv.org/abs/2305.15883v1](http://arxiv.org/abs/2305.15883v1)\n", "2305.15836": "- 2023-05-25, **Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object Detection Networks**, Daniel K\u00f6hler et.al., Paper: [http://arxiv.org/abs/2305.15836v1](http://arxiv.org/abs/2305.15836v1)\n", "2305.15813": "- 2023-05-25, **Leveraging object detection for the identification of lung cancer**, Karthick Prasad Gunasekaran et.al., Paper: [http://arxiv.org/abs/2305.15813v1](http://arxiv.org/abs/2305.15813v1)\n", "2305.15765": "- 2023-05-25, **Language-Guided 3D Object Detection in Point Cloud for Autonomous Driving**, Wenhao Cheng et.al., Paper: [http://arxiv.org/abs/2305.15765v1](http://arxiv.org/abs/2305.15765v1)\n", "2305.15750": "- 2023-05-25, **Towards Large-scale Single-shot Millimeter-wave Imaging for Low-cost Security Inspection**, Liheng Bian et.al., Paper: [http://arxiv.org/abs/2305.15750v1](http://arxiv.org/abs/2305.15750v1)\n", "2305.16968": "- 2023-05-26, **Linear Object Detection in Document Images using Multiple Object Tracking**, Philippe Bernet et.al., Paper: [http://arxiv.org/abs/2305.16968v1](http://arxiv.org/abs/2305.16968v1)\n", "2305.16450": "- 2023-05-25, **Vision-based UAV Detection in Complex Backgrounds and Rainy Conditions**, Adnan Munir et.al., Paper: [http://arxiv.org/abs/2305.16450v1](http://arxiv.org/abs/2305.16450v1)\n", "2305.18279": "- 2023-05-29, **Contextual Object Detection with Multimodal Large Language Models**, Yuhang Zang et.al., Paper: [http://arxiv.org/abs/2305.18279v1](http://arxiv.org/abs/2305.18279v1), Code: **[https://github.com/yuhangzang/contextdet](https://github.com/yuhangzang/contextdet)**\n", "2305.18276": "- 2023-05-29, **Development of a ROS-based Architecture for Intelligent Autonomous on Demand Last Mile Delivery**, Georg Novtony et.al., Paper: [http://arxiv.org/abs/2305.18276v1](http://arxiv.org/abs/2305.18276v1)\n", "2305.18092": "- 2023-05-29, **Contrastive Learning Based Recursive Dynamic Multi-Scale Network for Image Deraining**, Zhiying Jiang et.al., Paper: [http://arxiv.org/abs/2305.18092v1](http://arxiv.org/abs/2305.18092v1)\n", "2305.18060": "- 2023-05-29, **Mining Negative Temporal Contexts For False Positive Suppression In Real-Time Ultrasound Lesion Detection**, Haojun Yu et.al., Paper: [http://arxiv.org/abs/2305.18060v1](http://arxiv.org/abs/2305.18060v1)\n", "2305.17972": "- 2023-05-29, **View-to-Label: Multi-View Consistency for Self-Supervised 3D Object Detection**, Issa Mouawad et.al., Paper: [http://arxiv.org/abs/2305.17972v1](http://arxiv.org/abs/2305.17972v1)\n", "2305.17932": "- 2023-05-29, **CamoDiffusion: Camouflaged Object Detection via Conditional Diffusion Models**, Zhongxi Chen et.al., Paper: [http://arxiv.org/abs/2305.17932v1](http://arxiv.org/abs/2305.17932v1), Code: **[https://github.com/rapisurazurite/camodiffusion](https://github.com/rapisurazurite/camodiffusion)**\n", "2305.17931": "- 2023-05-29, **Monocular 2D Camera-based Proximity Monitoring for Human-Machine Collision Warning on Construction Sites**, Yuexiong Ding et.al., Paper: [http://arxiv.org/abs/2305.17931v1](http://arxiv.org/abs/2305.17931v1)\n", "2305.17927": "- 2023-05-29, **VCVW-3D: A Virtual Construction Vehicles and Workers Dataset with 3D Annotations**, Yuexiong Ding et.al., Paper: [http://arxiv.org/abs/2305.17927v1](http://arxiv.org/abs/2305.17927v1)\n", "2305.17892": "- 2023-05-29, **SEIP: Simulation-based Design and Evaluation of Infrastructure-based Collective Perception**, Ao Qu et.al., Paper: [http://arxiv.org/abs/2305.17892v1](http://arxiv.org/abs/2305.17892v1)\n", "2305.17786": "- 2023-05-28, **Real-time Object Detection: YOLOv1 Re-Implementation in PyTorch**, Michael Shenoda et.al., Paper: [http://arxiv.org/abs/2305.17786v1](http://arxiv.org/abs/2305.17786v1)\n", "2305.19181": "- 2023-05-30, **Table Detection for Visually Rich Document Images**, Bin Xiao et.al., Paper: [http://arxiv.org/abs/2305.19181v1](http://arxiv.org/abs/2305.19181v1)\n", "2305.18993": "- 2023-05-30, **ConES: Concept Embedding Search for Parameter Efficient Tuning Large Vision Language Models**, Huahui Yi et.al., Paper: [http://arxiv.org/abs/2305.18993v1](http://arxiv.org/abs/2305.18993v1)\n", "2305.18980": "- 2023-05-30, **Multi-modal Queried Object Detection in the Wild**, Yifan Xu et.al., Paper: [http://arxiv.org/abs/2305.18980v1](http://arxiv.org/abs/2305.18980v1), Code: **[https://github.com/yifanxu74/mq-det](https://github.com/yifanxu74/mq-det)**\n", "2305.18953": "- 2023-05-30, **Sit Back and Relax: Learning to Drive Incrementally in All Weather Conditions**, Stefan Leitner et.al., Paper: [http://arxiv.org/abs/2305.18953v1](http://arxiv.org/abs/2305.18953v1), Code: **[https://github.com/jmiemirza/dilam](https://github.com/jmiemirza/dilam)**\n", "2305.18829": "- 2023-05-30, **Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction**, Chen Min et.al., Paper: [http://arxiv.org/abs/2305.18829v1](http://arxiv.org/abs/2305.18829v1), Code: **[https://github.com/chaytonmin/occ-bev](https://github.com/chaytonmin/occ-bev)**\n", "2305.18782": "- 2023-05-30, **VVC Extension Scheme for Object Detection Using Contrast Reduction**, Takahiro Shindo et.al., Paper: [http://arxiv.org/abs/2305.18782v1](http://arxiv.org/abs/2305.18782v1)\n", "2305.18565": "- 2023-05-29, **PaLI-X: On Scaling up a Multilingual Vision and Language Model**, Xi Chen et.al., Paper: [http://arxiv.org/abs/2305.18565v1](http://arxiv.org/abs/2305.18565v1)\n", "2305.20055": "- 2023-05-31, **Cross-Domain Car Detection Model with Integrated Convolutional Block Attention Mechanism**, Haoxuan Xu et.al., Paper: [http://arxiv.org/abs/2305.20055v1](http://arxiv.org/abs/2305.20055v1)\n", "2305.20047": "- 2023-05-31, **LOWA: Localize Objects in the Wild with Attributes**, Xiaoyuan Guo et.al., Paper: [http://arxiv.org/abs/2305.20047v1](http://arxiv.org/abs/2305.20047v1)\n", "2305.19889": "- 2023-05-31, **Evaluating Machine Learning Models with NERO: Non-Equivariance Revealed on Orbits**, Zhuokai Zhao et.al., Paper: [http://arxiv.org/abs/2305.19889v1](http://arxiv.org/abs/2305.19889v1)\n", "2305.19868": "- 2023-05-31, **Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN**, Yangfan Hu et.al., Paper: [http://arxiv.org/abs/2305.19868v1](http://arxiv.org/abs/2305.19868v1), Code: **[https://github.com/yangfan-hu/fast-snn](https://github.com/yangfan-hu/fast-snn)**\n", "2305.19623": "- 2023-06-01, **Point-GCC: Universal Self-supervised 3D Scene Pre-training via Geometry-Color Contrast**, Guofan Fan et.al., Paper: [http://arxiv.org/abs/2305.19623v2](http://arxiv.org/abs/2305.19623v2), Code: **[https://github.com/asterisci/point-gcc](https://github.com/asterisci/point-gcc)**\n", "2305.19511": "- 2023-05-31, **An MCMC Approach to Bayesian Image Analysis in Fourier Space**, Konstantinos Bakas et.al., Paper: [http://arxiv.org/abs/2305.19511v1](http://arxiv.org/abs/2305.19511v1)\n", "2305.19481": "- 2023-05-31, **Bayesian Image Analysis in Fourier Space**, John Kornak et.al., Paper: [http://arxiv.org/abs/2305.19481v1](http://arxiv.org/abs/2305.19481v1)\n", "2306.00440": "- 2023-06-01, **Edge-guided Representation Learning for Underwater Object Detection**, Linhui Dai et.al., Paper: [http://arxiv.org/abs/2306.00440v1](http://arxiv.org/abs/2306.00440v1)\n", "2306.00424": "- 2023-06-01, **End-to-end Knowledge Retrieval with Multi-modal Queries**, Man Luo et.al., Paper: [http://arxiv.org/abs/2306.00424v1](http://arxiv.org/abs/2306.00424v1), Code: **[https://github.com/luomancs/remuq](https://github.com/luomancs/remuq)**\n", "2306.00349": "- 2023-06-01, **CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception**, Jiachen Sun et.al., Paper: [http://arxiv.org/abs/2306.00349v1](http://arxiv.org/abs/2306.00349v1)\n", "2306.00265": "- 2023-06-01, **Doubly Robust Self-Training**, Banghua Zhu et.al., Paper: [http://arxiv.org/abs/2306.00265v1](http://arxiv.org/abs/2306.00265v1), Code: **[https://github.com/dingmyu/doubly-robust-self-training](https://github.com/dingmyu/doubly-robust-self-training)**\n"}}